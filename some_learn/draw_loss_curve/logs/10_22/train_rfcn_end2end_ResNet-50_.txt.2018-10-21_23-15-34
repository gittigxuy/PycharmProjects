+ echo Logging output to experiments/10_22/logs/train_rfcn_end2end_ResNet-50_.txt.2018-10-21_23-15-34
Logging output to experiments/10_22/logs/train_rfcn_end2end_ResNet-50_.txt.2018-10-21_23-15-34
+ ./tools/train_net.py --gpu 3 --solver experiments/10_22/server_script/solver_ohem.prototxt --weights data/imagenet_models/ResNet-50-model.caffemodel --imdb voc_0712_trainval --iters 14000 --cfg experiments/10_22/rfcn_end2end_ohem.yml
Called with args:
Namespace(cfg_file='experiments/10_22/rfcn_end2end_ohem.yml', gpu_id=3, imdb_name='voc_0712_trainval', max_iters=14000, pretrained_model='data/imagenet_models/ResNet-50-model.caffemodel', randomize=False, set_cfgs=None, solver='experiments/10_22/server_script/solver_ohem.prototxt')
Using config:
{'DATA_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '10_22/model',
 'GPU_ID': 3,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/models/pascal_voc',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/neuiva1/sol/10_12/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.55,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 20,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 20,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 2000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_0712_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_0712_trainval gt roidb loaded from /home/neuiva1/sol/10_12/py-R-FCN/data/cache/voc_0712_trainval_gt_roidb.pkl
done
Preparing training data...
done
8500 roidb entries
Output will be saved to `/home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval`
Filtered 5522 roidb entries: 8500 -> 2978
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1021 23:15:38.033938 25759 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/neuiva1/sol/10_12/py-R-FCN/experiments/10_22/model_ohem/multi_ohem.prototxt"
base_lr: 0.002
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 0
snapshot_prefix: "fpn_rfcn_ohem"
stepvalue: 10000
stepvalue: 12000
iter_size: 8
I1021 23:15:38.033993 25759 solver.cpp:81] Creating training net from train_net file: /home/neuiva1/sol/10_12/py-R-FCN/experiments/10_22/model_ohem/multi_ohem.prototxt
I1021 23:15:38.037510 25759 net.cpp:58] Initializing net from parameters: 
name: "ResNet-50"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  t
I1021 23:15:38.038772 25759 layer_factory.hpp:77] Creating layer input-data
I1021 23:15:38.081650 25759 net.cpp:100] Creating Layer input-data
I1021 23:15:38.081687 25759 net.cpp:418] input-data -> data
I1021 23:15:38.081699 25759 net.cpp:418] input-data -> im_info
I1021 23:15:38.081704 25759 net.cpp:418] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I1021 23:15:38.482383 25759 net.cpp:150] Setting up input-data
I1021 23:15:38.482424 25759 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I1021 23:15:38.482429 25759 net.cpp:157] Top shape: 1 3 (3)
I1021 23:15:38.482432 25759 net.cpp:157] Top shape: 1 4 (4)
I1021 23:15:38.482434 25759 net.cpp:165] Memory required for data: 14745628
I1021 23:15:38.482441 25759 layer_factory.hpp:77] Creating layer data_input-data_0_split
I1021 23:15:38.482455 25759 net.cpp:100] Creating Layer data_input-data_0_split
I1021 23:15:38.482460 25759 net.cpp:444] data_input-data_0_split <- data
I1021 23:15:38.482468 25759 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_0
I1021 23:15:38.482481 25759 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_1
I1021 23:15:38.482535 25759 net.cpp:150] Setting up data_input-data_0_split
I1021 23:15:38.482542 25759 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I1021 23:15:38.482547 25759 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I1021 23:15:38.482549 25759 net.cpp:165] Memory required for data: 44236828
I1021 23:15:38.482551 25759 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I1021 23:15:38.482556 25759 net.cpp:100] Creating Layer im_info_input-data_1_split
I1021 23:15:38.482559 25759 net.cpp:444] im_info_input-data_1_split <- im_info
I1021 23:15:38.482565 25759 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_0
I1021 23:15:38.482586 25759 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_1
I1021 23:15:38.482632 25759 net.cpp:150] Setting up im_info_input-data_1_split
I1021 23:15:38.482637 25759 net.cpp:157] Top shape: 1 3 (3)
I1021 23:15:38.482642 25759 net.cpp:157] Top shape: 1 3 (3)
I1021 23:15:38.482645 25759 net.cpp:165] Memory required for data: 44236852
I1021 23:15:38.482647 25759 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I1021 23:15:38.482653 25759 net.cpp:100] Creating Layer gt_boxes_input-data_2_split
I1021 23:15:38.482656 25759 net.cpp:444] gt_boxes_input-data_2_split <- gt_boxes
I1021 23:15:38.482661 25759 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I1021 23:15:38.482667 25759 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I1021 23:15:38.482709 25759 net.cpp:150] Setting up gt_boxes_input-data_2_split
I1021 23:15:38.482715 25759 net.cpp:157] Top shape: 1 4 (4)
I1021 23:15:38.482720 25759 net.cpp:157] Top shape: 1 4 (4)
I1021 23:15:38.482722 25759 net.cpp:165] Memory required for data: 44236884
I1021 23:15:38.482725 25759 layer_factory.hpp:77] Creating layer conv1
I1021 23:15:38.482739 25759 net.cpp:100] Creating Layer conv1
I1021 23:15:38.482743 25759 net.cpp:444] conv1 <- data_input-data_0_split_0
I1021 23:15:38.482748 25759 net.cpp:418] conv1 -> conv1
I1021 23:15:39.027148 25759 net.cpp:150] Setting up conv1
I1021 23:15:39.027191 25759 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I1021 23:15:39.027194 25759 net.cpp:165] Memory required for data: 122880084
I1021 23:15:39.027209 25759 layer_factory.hpp:77] Creating layer bn_conv1
I1021 23:15:39.027223 25759 net.cpp:100] Creating Layer bn_conv1
I1021 23:15:39.027227 25759 net.cpp:444] bn_conv1 <- conv1
I1021 23:15:39.027233 25759 net.cpp:405] bn_conv1 -> conv1 (in-place)
I1021 23:15:39.029417 25759 net.cpp:150] Setting up bn_conv1
I1021 23:15:39.029428 25759 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I1021 23:15:39.029448 25759 net.cpp:165] Memory required for data: 201523284
I1021 23:15:39.029458 25759 layer_factory.hpp:77] Creating layer scale_conv1
I1021 23:15:39.029465 25759 net.cpp:100] Creating Layer scale_conv1
I1021 23:15:39.029469 25759 net.cpp:444] scale_conv1 <- conv1
I1021 23:15:39.029474 25759 net.cpp:405] scale_conv1 -> conv1 (in-place)
I1021 23:15:39.029561 25759 layer_factory.hpp:77] Creating layer scale_conv1
I1021 23:15:39.033252 25759 net.cpp:150] Setting up scale_conv1
I1021 23:15:39.033264 25759 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I1021 23:15:39.033282 25759 net.cpp:165] Memory required for data: 280166484
I1021 23:15:39.033288 25759 layer_factory.hpp:77] Creating layer conv1_relu
I1021 23:15:39.033294 25759 net.cpp:100] Creating Layer conv1_relu
I1021 23:15:39.033298 25759 net.cpp:444] conv1_relu <- conv1
I1021 23:15:39.033301 25759 net.cpp:405] conv1_relu -> conv1 (in-place)
I1021 23:15:39.033531 25759 net.cpp:150] Setting up conv1_relu
I1021 23:15:39.033540 25759 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I1021 23:15:39.033543 25759 net.cpp:165] Memory required for data: 358809684
I1021 23:15:39.033546 25759 layer_factory.hpp:77] Creating layer pool1
I1021 23:15:39.033555 25759 net.cpp:100] Creating Layer pool1
I1021 23:15:39.033558 25759 net.cpp:444] pool1 <- conv1
I1021 23:15:39.033562 25759 net.cpp:418] pool1 -> pool1
I1021 23:15:39.033622 25759 net.cpp:150] Setting up pool1
I1021 23:15:39.033628 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.033632 25759 net.cpp:165] Memory required for data: 378470484
I1021 23:15:39.033634 25759 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I1021 23:15:39.033640 25759 net.cpp:100] Creating Layer pool1_pool1_0_split
I1021 23:15:39.033643 25759 net.cpp:444] pool1_pool1_0_split <- pool1
I1021 23:15:39.033648 25759 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1021 23:15:39.033653 25759 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1021 23:15:39.033715 25759 net.cpp:150] Setting up pool1_pool1_0_split
I1021 23:15:39.033720 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.033725 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.033727 25759 net.cpp:165] Memory required for data: 417792084
I1021 23:15:39.033730 25759 layer_factory.hpp:77] Creating layer res2a_branch1
I1021 23:15:39.033740 25759 net.cpp:100] Creating Layer res2a_branch1
I1021 23:15:39.033742 25759 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I1021 23:15:39.033747 25759 net.cpp:418] res2a_branch1 -> res2a_branch1
I1021 23:15:39.043284 25759 net.cpp:150] Setting up res2a_branch1
I1021 23:15:39.043298 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.043318 25759 net.cpp:165] Memory required for data: 496435284
I1021 23:15:39.043323 25759 layer_factory.hpp:77] Creating layer bn2a_branch1
I1021 23:15:39.043330 25759 net.cpp:100] Creating Layer bn2a_branch1
I1021 23:15:39.043334 25759 net.cpp:444] bn2a_branch1 <- res2a_branch1
I1021 23:15:39.043339 25759 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I1021 23:15:39.043756 25759 net.cpp:150] Setting up bn2a_branch1
I1021 23:15:39.043762 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.043766 25759 net.cpp:165] Memory required for data: 575078484
I1021 23:15:39.043789 25759 layer_factory.hpp:77] Creating layer scale2a_branch1
I1021 23:15:39.043797 25759 net.cpp:100] Creating Layer scale2a_branch1
I1021 23:15:39.043800 25759 net.cpp:444] scale2a_branch1 <- res2a_branch1
I1021 23:15:39.043805 25759 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I1021 23:15:39.043889 25759 layer_factory.hpp:77] Creating layer scale2a_branch1
I1021 23:15:39.044124 25759 net.cpp:150] Setting up scale2a_branch1
I1021 23:15:39.044132 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.044136 25759 net.cpp:165] Memory required for data: 653721684
I1021 23:15:39.044140 25759 layer_factory.hpp:77] Creating layer res2a_branch2a
I1021 23:15:39.044148 25759 net.cpp:100] Creating Layer res2a_branch2a
I1021 23:15:39.044152 25759 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I1021 23:15:39.044157 25759 net.cpp:418] res2a_branch2a -> res2a_branch2a
I1021 23:15:39.047683 25759 net.cpp:150] Setting up res2a_branch2a
I1021 23:15:39.047695 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.047714 25759 net.cpp:165] Memory required for data: 673382484
I1021 23:15:39.047719 25759 layer_factory.hpp:77] Creating layer bn2a_branch2a
I1021 23:15:39.047726 25759 net.cpp:100] Creating Layer bn2a_branch2a
I1021 23:15:39.047729 25759 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I1021 23:15:39.047735 25759 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I1021 23:15:39.048130 25759 net.cpp:150] Setting up bn2a_branch2a
I1021 23:15:39.048152 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.048154 25759 net.cpp:165] Memory required for data: 693043284
I1021 23:15:39.048179 25759 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1021 23:15:39.048187 25759 net.cpp:100] Creating Layer scale2a_branch2a
I1021 23:15:39.048189 25759 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I1021 23:15:39.048194 25759 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I1021 23:15:39.048279 25759 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1021 23:15:39.048527 25759 net.cpp:150] Setting up scale2a_branch2a
I1021 23:15:39.048534 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.048537 25759 net.cpp:165] Memory required for data: 712704084
I1021 23:15:39.048543 25759 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I1021 23:15:39.048550 25759 net.cpp:100] Creating Layer res2a_branch2a_relu
I1021 23:15:39.048553 25759 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I1021 23:15:39.048558 25759 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I1021 23:15:39.048763 25759 net.cpp:150] Setting up res2a_branch2a_relu
I1021 23:15:39.048772 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.048775 25759 net.cpp:165] Memory required for data: 732364884
I1021 23:15:39.048779 25759 layer_factory.hpp:77] Creating layer res2a_branch2b
I1021 23:15:39.048787 25759 net.cpp:100] Creating Layer res2a_branch2b
I1021 23:15:39.048790 25759 net.cpp:444] res2a_branch2b <- res2a_branch2a
I1021 23:15:39.048795 25759 net.cpp:418] res2a_branch2b -> res2a_branch2b
I1021 23:15:39.052294 25759 net.cpp:150] Setting up res2a_branch2b
I1021 23:15:39.052305 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.052309 25759 net.cpp:165] Memory required for data: 752025684
I1021 23:15:39.052328 25759 layer_factory.hpp:77] Creating layer bn2a_branch2b
I1021 23:15:39.052336 25759 net.cpp:100] Creating Layer bn2a_branch2b
I1021 23:15:39.052340 25759 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I1021 23:15:39.052345 25759 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I1021 23:15:39.052770 25759 net.cpp:150] Setting up bn2a_branch2b
I1021 23:15:39.052778 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.052780 25759 net.cpp:165] Memory required for data: 771686484
I1021 23:15:39.052803 25759 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1021 23:15:39.052809 25759 net.cpp:100] Creating Layer scale2a_branch2b
I1021 23:15:39.052812 25759 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I1021 23:15:39.052819 25759 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I1021 23:15:39.052903 25759 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1021 23:15:39.057842 25759 net.cpp:150] Setting up scale2a_branch2b
I1021 23:15:39.057854 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.057874 25759 net.cpp:165] Memory required for data: 791347284
I1021 23:15:39.057880 25759 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I1021 23:15:39.057886 25759 net.cpp:100] Creating Layer res2a_branch2b_relu
I1021 23:15:39.057890 25759 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I1021 23:15:39.057895 25759 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I1021 23:15:39.058708 25759 net.cpp:150] Setting up res2a_branch2b_relu
I1021 23:15:39.058719 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.058722 25759 net.cpp:165] Memory required for data: 811008084
I1021 23:15:39.058740 25759 layer_factory.hpp:77] Creating layer res2a_branch2c
I1021 23:15:39.058748 25759 net.cpp:100] Creating Layer res2a_branch2c
I1021 23:15:39.058751 25759 net.cpp:444] res2a_branch2c <- res2a_branch2b
I1021 23:15:39.058759 25759 net.cpp:418] res2a_branch2c -> res2a_branch2c
I1021 23:15:39.060706 25759 net.cpp:150] Setting up res2a_branch2c
I1021 23:15:39.060719 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.060737 25759 net.cpp:165] Memory required for data: 889651284
I1021 23:15:39.060742 25759 layer_factory.hpp:77] Creating layer bn2a_branch2c
I1021 23:15:39.060766 25759 net.cpp:100] Creating Layer bn2a_branch2c
I1021 23:15:39.060770 25759 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I1021 23:15:39.060775 25759 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I1021 23:15:39.061177 25759 net.cpp:150] Setting up bn2a_branch2c
I1021 23:15:39.061185 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.061187 25759 net.cpp:165] Memory required for data: 968294484
I1021 23:15:39.061209 25759 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1021 23:15:39.061231 25759 net.cpp:100] Creating Layer scale2a_branch2c
I1021 23:15:39.061234 25759 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I1021 23:15:39.061239 25759 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I1021 23:15:39.061321 25759 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1021 23:15:39.061549 25759 net.cpp:150] Setting up scale2a_branch2c
I1021 23:15:39.061558 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.061561 25759 net.cpp:165] Memory required for data: 1046937684
I1021 23:15:39.061565 25759 layer_factory.hpp:77] Creating layer res2a
I1021 23:15:39.061571 25759 net.cpp:100] Creating Layer res2a
I1021 23:15:39.061575 25759 net.cpp:444] res2a <- res2a_branch1
I1021 23:15:39.061578 25759 net.cpp:444] res2a <- res2a_branch2c
I1021 23:15:39.061583 25759 net.cpp:418] res2a -> res2a
I1021 23:15:39.061631 25759 net.cpp:150] Setting up res2a
I1021 23:15:39.061637 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.061641 25759 net.cpp:165] Memory required for data: 1125580884
I1021 23:15:39.061643 25759 layer_factory.hpp:77] Creating layer res2a_relu
I1021 23:15:39.061650 25759 net.cpp:100] Creating Layer res2a_relu
I1021 23:15:39.061652 25759 net.cpp:444] res2a_relu <- res2a
I1021 23:15:39.061655 25759 net.cpp:405] res2a_relu -> res2a (in-place)
I1021 23:15:39.061836 25759 net.cpp:150] Setting up res2a_relu
I1021 23:15:39.061846 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.061848 25759 net.cpp:165] Memory required for data: 1204224084
I1021 23:15:39.061851 25759 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I1021 23:15:39.061857 25759 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I1021 23:15:39.061861 25759 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I1021 23:15:39.061866 25759 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I1021 23:15:39.061872 25759 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I1021 23:15:39.061924 25759 net.cpp:150] Setting up res2a_res2a_relu_0_split
I1021 23:15:39.061930 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.061935 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.061938 25759 net.cpp:165] Memory required for data: 1361510484
I1021 23:15:39.061940 25759 layer_factory.hpp:77] Creating layer res2b_branch2a
I1021 23:15:39.061949 25759 net.cpp:100] Creating Layer res2b_branch2a
I1021 23:15:39.061951 25759 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I1021 23:15:39.061957 25759 net.cpp:418] res2b_branch2a -> res2b_branch2a
I1021 23:15:39.064302 25759 net.cpp:150] Setting up res2b_branch2a
I1021 23:15:39.064316 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.064333 25759 net.cpp:165] Memory required for data: 1381171284
I1021 23:15:39.064338 25759 layer_factory.hpp:77] Creating layer bn2b_branch2a
I1021 23:15:39.064347 25759 net.cpp:100] Creating Layer bn2b_branch2a
I1021 23:15:39.064350 25759 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I1021 23:15:39.064357 25759 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I1021 23:15:39.064790 25759 net.cpp:150] Setting up bn2b_branch2a
I1021 23:15:39.064797 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.064800 25759 net.cpp:165] Memory required for data: 1400832084
I1021 23:15:39.064826 25759 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1021 23:15:39.064833 25759 net.cpp:100] Creating Layer scale2b_branch2a
I1021 23:15:39.064836 25759 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I1021 23:15:39.064841 25759 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I1021 23:15:39.064929 25759 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1021 23:15:39.066818 25759 net.cpp:150] Setting up scale2b_branch2a
I1021 23:15:39.066830 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.066833 25759 net.cpp:165] Memory required for data: 1420492884
I1021 23:15:39.066839 25759 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I1021 23:15:39.066862 25759 net.cpp:100] Creating Layer res2b_branch2a_relu
I1021 23:15:39.066865 25759 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I1021 23:15:39.066870 25759 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I1021 23:15:39.067108 25759 net.cpp:150] Setting up res2b_branch2a_relu
I1021 23:15:39.067117 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.067121 25759 net.cpp:165] Memory required for data: 1440153684
I1021 23:15:39.067123 25759 layer_factory.hpp:77] Creating layer res2b_branch2b
I1021 23:15:39.067131 25759 net.cpp:100] Creating Layer res2b_branch2b
I1021 23:15:39.067134 25759 net.cpp:444] res2b_branch2b <- res2b_branch2a
I1021 23:15:39.067140 25759 net.cpp:418] res2b_branch2b -> res2b_branch2b
I1021 23:15:39.068584 25759 net.cpp:150] Setting up res2b_branch2b
I1021 23:15:39.068595 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.068598 25759 net.cpp:165] Memory required for data: 1459814484
I1021 23:15:39.068639 25759 layer_factory.hpp:77] Creating layer bn2b_branch2b
I1021 23:15:39.068648 25759 net.cpp:100] Creating Layer bn2b_branch2b
I1021 23:15:39.068651 25759 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I1021 23:15:39.068656 25759 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I1021 23:15:39.069049 25759 net.cpp:150] Setting up bn2b_branch2b
I1021 23:15:39.069057 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.069061 25759 net.cpp:165] Memory required for data: 1479475284
I1021 23:15:39.069082 25759 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1021 23:15:39.069088 25759 net.cpp:100] Creating Layer scale2b_branch2b
I1021 23:15:39.069092 25759 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I1021 23:15:39.069095 25759 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I1021 23:15:39.069180 25759 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1021 23:15:39.069429 25759 net.cpp:150] Setting up scale2b_branch2b
I1021 23:15:39.069437 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.069440 25759 net.cpp:165] Memory required for data: 1499136084
I1021 23:15:39.069445 25759 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I1021 23:15:39.069452 25759 net.cpp:100] Creating Layer res2b_branch2b_relu
I1021 23:15:39.069454 25759 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I1021 23:15:39.069459 25759 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I1021 23:15:39.070284 25759 net.cpp:150] Setting up res2b_branch2b_relu
I1021 23:15:39.070294 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.070297 25759 net.cpp:165] Memory required for data: 1518796884
I1021 23:15:39.070315 25759 layer_factory.hpp:77] Creating layer res2b_branch2c
I1021 23:15:39.070323 25759 net.cpp:100] Creating Layer res2b_branch2c
I1021 23:15:39.070327 25759 net.cpp:444] res2b_branch2c <- res2b_branch2b
I1021 23:15:39.070331 25759 net.cpp:418] res2b_branch2c -> res2b_branch2c
I1021 23:15:39.072310 25759 net.cpp:150] Setting up res2b_branch2c
I1021 23:15:39.072321 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.072340 25759 net.cpp:165] Memory required for data: 1597440084
I1021 23:15:39.072345 25759 layer_factory.hpp:77] Creating layer bn2b_branch2c
I1021 23:15:39.072353 25759 net.cpp:100] Creating Layer bn2b_branch2c
I1021 23:15:39.072357 25759 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I1021 23:15:39.072361 25759 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I1021 23:15:39.072808 25759 net.cpp:150] Setting up bn2b_branch2c
I1021 23:15:39.072818 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.072819 25759 net.cpp:165] Memory required for data: 1676083284
I1021 23:15:39.072841 25759 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1021 23:15:39.072849 25759 net.cpp:100] Creating Layer scale2b_branch2c
I1021 23:15:39.072851 25759 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I1021 23:15:39.072857 25759 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I1021 23:15:39.072948 25759 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1021 23:15:39.077949 25759 net.cpp:150] Setting up scale2b_branch2c
I1021 23:15:39.077960 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.077977 25759 net.cpp:165] Memory required for data: 1754726484
I1021 23:15:39.077983 25759 layer_factory.hpp:77] Creating layer res2b
I1021 23:15:39.077989 25759 net.cpp:100] Creating Layer res2b
I1021 23:15:39.077992 25759 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I1021 23:15:39.077996 25759 net.cpp:444] res2b <- res2b_branch2c
I1021 23:15:39.078002 25759 net.cpp:418] res2b -> res2b
I1021 23:15:39.078076 25759 net.cpp:150] Setting up res2b
I1021 23:15:39.078083 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.078088 25759 net.cpp:165] Memory required for data: 1833369684
I1021 23:15:39.078089 25759 layer_factory.hpp:77] Creating layer res2b_relu
I1021 23:15:39.078096 25759 net.cpp:100] Creating Layer res2b_relu
I1021 23:15:39.078099 25759 net.cpp:444] res2b_relu <- res2b
I1021 23:15:39.078104 25759 net.cpp:405] res2b_relu -> res2b (in-place)
I1021 23:15:39.078308 25759 net.cpp:150] Setting up res2b_relu
I1021 23:15:39.078317 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.078320 25759 net.cpp:165] Memory required for data: 1912012884
I1021 23:15:39.078323 25759 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I1021 23:15:39.078330 25759 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I1021 23:15:39.078332 25759 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I1021 23:15:39.078339 25759 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I1021 23:15:39.078346 25759 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I1021 23:15:39.078404 25759 net.cpp:150] Setting up res2b_res2b_relu_0_split
I1021 23:15:39.078411 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.078415 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.078418 25759 net.cpp:165] Memory required for data: 2069299284
I1021 23:15:39.078420 25759 layer_factory.hpp:77] Creating layer res2c_branch2a
I1021 23:15:39.078429 25759 net.cpp:100] Creating Layer res2c_branch2a
I1021 23:15:39.078433 25759 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I1021 23:15:39.078436 25759 net.cpp:418] res2c_branch2a -> res2c_branch2a
I1021 23:15:39.080499 25759 net.cpp:150] Setting up res2c_branch2a
I1021 23:15:39.080510 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.080528 25759 net.cpp:165] Memory required for data: 2088960084
I1021 23:15:39.080533 25759 layer_factory.hpp:77] Creating layer bn2c_branch2a
I1021 23:15:39.080539 25759 net.cpp:100] Creating Layer bn2c_branch2a
I1021 23:15:39.080543 25759 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I1021 23:15:39.080551 25759 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I1021 23:15:39.081028 25759 net.cpp:150] Setting up bn2c_branch2a
I1021 23:15:39.081037 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.081039 25759 net.cpp:165] Memory required for data: 2108620884
I1021 23:15:39.081063 25759 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1021 23:15:39.081069 25759 net.cpp:100] Creating Layer scale2c_branch2a
I1021 23:15:39.081073 25759 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I1021 23:15:39.081076 25759 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I1021 23:15:39.081167 25759 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1021 23:15:39.081446 25759 net.cpp:150] Setting up scale2c_branch2a
I1021 23:15:39.081455 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.081472 25759 net.cpp:165] Memory required for data: 2128281684
I1021 23:15:39.081478 25759 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I1021 23:15:39.081497 25759 net.cpp:100] Creating Layer res2c_branch2a_relu
I1021 23:15:39.081501 25759 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I1021 23:15:39.081503 25759 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I1021 23:15:39.081775 25759 net.cpp:150] Setting up res2c_branch2a_relu
I1021 23:15:39.081784 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.081787 25759 net.cpp:165] Memory required for data: 2147942484
I1021 23:15:39.081790 25759 layer_factory.hpp:77] Creating layer res2c_branch2b
I1021 23:15:39.081799 25759 net.cpp:100] Creating Layer res2c_branch2b
I1021 23:15:39.081802 25759 net.cpp:444] res2c_branch2b <- res2c_branch2a
I1021 23:15:39.081807 25759 net.cpp:418] res2c_branch2b -> res2c_branch2b
I1021 23:15:39.084050 25759 net.cpp:150] Setting up res2c_branch2b
I1021 23:15:39.084061 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.084079 25759 net.cpp:165] Memory required for data: 2167603284
I1021 23:15:39.084084 25759 layer_factory.hpp:77] Creating layer bn2c_branch2b
I1021 23:15:39.084094 25759 net.cpp:100] Creating Layer bn2c_branch2b
I1021 23:15:39.084097 25759 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I1021 23:15:39.084103 25759 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I1021 23:15:39.084535 25759 net.cpp:150] Setting up bn2c_branch2b
I1021 23:15:39.084542 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.084544 25759 net.cpp:165] Memory required for data: 2187264084
I1021 23:15:39.084566 25759 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1021 23:15:39.084573 25759 net.cpp:100] Creating Layer scale2c_branch2b
I1021 23:15:39.084576 25759 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I1021 23:15:39.084581 25759 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I1021 23:15:39.084683 25759 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1021 23:15:39.086580 25759 net.cpp:150] Setting up scale2c_branch2b
I1021 23:15:39.086591 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.086593 25759 net.cpp:165] Memory required for data: 2206924884
I1021 23:15:39.086616 25759 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I1021 23:15:39.086622 25759 net.cpp:100] Creating Layer res2c_branch2b_relu
I1021 23:15:39.086625 25759 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I1021 23:15:39.086629 25759 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I1021 23:15:39.086879 25759 net.cpp:150] Setting up res2c_branch2b_relu
I1021 23:15:39.086887 25759 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I1021 23:15:39.086890 25759 net.cpp:165] Memory required for data: 2226585684
I1021 23:15:39.086894 25759 layer_factory.hpp:77] Creating layer res2c_branch2c
I1021 23:15:39.086904 25759 net.cpp:100] Creating Layer res2c_branch2c
I1021 23:15:39.086906 25759 net.cpp:444] res2c_branch2c <- res2c_branch2b
I1021 23:15:39.086911 25759 net.cpp:418] res2c_branch2c -> res2c_branch2c
I1021 23:15:39.088927 25759 net.cpp:150] Setting up res2c_branch2c
I1021 23:15:39.088955 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.088958 25759 net.cpp:165] Memory required for data: 2305228884
I1021 23:15:39.088963 25759 layer_factory.hpp:77] Creating layer bn2c_branch2c
I1021 23:15:39.088969 25759 net.cpp:100] Creating Layer bn2c_branch2c
I1021 23:15:39.088974 25759 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I1021 23:15:39.088979 25759 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I1021 23:15:39.089393 25759 net.cpp:150] Setting up bn2c_branch2c
I1021 23:15:39.089401 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.089403 25759 net.cpp:165] Memory required for data: 2383872084
I1021 23:15:39.089443 25759 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1021 23:15:39.089452 25759 net.cpp:100] Creating Layer scale2c_branch2c
I1021 23:15:39.089454 25759 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I1021 23:15:39.089458 25759 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I1021 23:15:39.089541 25759 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1021 23:15:39.089784 25759 net.cpp:150] Setting up scale2c_branch2c
I1021 23:15:39.089792 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.089795 25759 net.cpp:165] Memory required for data: 2462515284
I1021 23:15:39.089800 25759 layer_factory.hpp:77] Creating layer res2c
I1021 23:15:39.089805 25759 net.cpp:100] Creating Layer res2c
I1021 23:15:39.089808 25759 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I1021 23:15:39.089812 25759 net.cpp:444] res2c <- res2c_branch2c
I1021 23:15:39.089818 25759 net.cpp:418] res2c -> res2c
I1021 23:15:39.089851 25759 net.cpp:150] Setting up res2c
I1021 23:15:39.089859 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.089861 25759 net.cpp:165] Memory required for data: 2541158484
I1021 23:15:39.089864 25759 layer_factory.hpp:77] Creating layer res2c_relu
I1021 23:15:39.089869 25759 net.cpp:100] Creating Layer res2c_relu
I1021 23:15:39.089871 25759 net.cpp:444] res2c_relu <- res2c
I1021 23:15:39.089877 25759 net.cpp:405] res2c_relu -> res2c (in-place)
I1021 23:15:39.090708 25759 net.cpp:150] Setting up res2c_relu
I1021 23:15:39.090718 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.090721 25759 net.cpp:165] Memory required for data: 2619801684
I1021 23:15:39.090740 25759 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I1021 23:15:39.090747 25759 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I1021 23:15:39.090750 25759 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I1021 23:15:39.090755 25759 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I1021 23:15:39.090761 25759 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I1021 23:15:39.090855 25759 net.cpp:150] Setting up res2c_res2c_relu_0_split
I1021 23:15:39.090864 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.090869 25759 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I1021 23:15:39.090872 25759 net.cpp:165] Memory required for data: 2777088084
I1021 23:15:39.090874 25759 layer_factory.hpp:77] Creating layer res3a_branch1
I1021 23:15:39.090883 25759 net.cpp:100] Creating Layer res3a_branch1
I1021 23:15:39.090885 25759 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I1021 23:15:39.090890 25759 net.cpp:418] res3a_branch1 -> res3a_branch1
I1021 23:15:39.092447 25759 net.cpp:150] Setting up res3a_branch1
I1021 23:15:39.092458 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.092478 25759 net.cpp:165] Memory required for data: 2816409684
I1021 23:15:39.092483 25759 layer_factory.hpp:77] Creating layer bn3a_branch1
I1021 23:15:39.092490 25759 net.cpp:100] Creating Layer bn3a_branch1
I1021 23:15:39.092494 25759 net.cpp:444] bn3a_branch1 <- res3a_branch1
I1021 23:15:39.092501 25759 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I1021 23:15:39.095567 25759 net.cpp:150] Setting up bn3a_branch1
I1021 23:15:39.095580 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.095582 25759 net.cpp:165] Memory required for data: 2855731284
I1021 23:15:39.095607 25759 layer_factory.hpp:77] Creating layer scale3a_branch1
I1021 23:15:39.095614 25759 net.cpp:100] Creating Layer scale3a_branch1
I1021 23:15:39.095618 25759 net.cpp:444] scale3a_branch1 <- res3a_branch1
I1021 23:15:39.095623 25759 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I1021 23:15:39.095706 25759 layer_factory.hpp:77] Creating layer scale3a_branch1
I1021 23:15:39.095906 25759 net.cpp:150] Setting up scale3a_branch1
I1021 23:15:39.095914 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.095916 25759 net.cpp:165] Memory required for data: 2895052884
I1021 23:15:39.095922 25759 layer_factory.hpp:77] Creating layer res3a_branch2a
I1021 23:15:39.095930 25759 net.cpp:100] Creating Layer res3a_branch2a
I1021 23:15:39.095933 25759 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I1021 23:15:39.095940 25759 net.cpp:418] res3a_branch2a -> res3a_branch2a
I1021 23:15:39.097527 25759 net.cpp:150] Setting up res3a_branch2a
I1021 23:15:39.097538 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.097556 25759 net.cpp:165] Memory required for data: 2904883284
I1021 23:15:39.097561 25759 layer_factory.hpp:77] Creating layer bn3a_branch2a
I1021 23:15:39.097570 25759 net.cpp:100] Creating Layer bn3a_branch2a
I1021 23:15:39.097574 25759 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I1021 23:15:39.097581 25759 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I1021 23:15:39.097952 25759 net.cpp:150] Setting up bn3a_branch2a
I1021 23:15:39.097960 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.097962 25759 net.cpp:165] Memory required for data: 2914713684
I1021 23:15:39.097985 25759 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1021 23:15:39.098007 25759 net.cpp:100] Creating Layer scale3a_branch2a
I1021 23:15:39.098011 25759 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I1021 23:15:39.098016 25759 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I1021 23:15:39.098104 25759 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1021 23:15:39.098291 25759 net.cpp:150] Setting up scale3a_branch2a
I1021 23:15:39.098299 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.098301 25759 net.cpp:165] Memory required for data: 2924544084
I1021 23:15:39.098306 25759 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I1021 23:15:39.098311 25759 net.cpp:100] Creating Layer res3a_branch2a_relu
I1021 23:15:39.098315 25759 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I1021 23:15:39.098320 25759 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I1021 23:15:39.098520 25759 net.cpp:150] Setting up res3a_branch2a_relu
I1021 23:15:39.098527 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.098531 25759 net.cpp:165] Memory required for data: 2934374484
I1021 23:15:39.098533 25759 layer_factory.hpp:77] Creating layer res3a_branch2b
I1021 23:15:39.098541 25759 net.cpp:100] Creating Layer res3a_branch2b
I1021 23:15:39.098544 25759 net.cpp:444] res3a_branch2b <- res3a_branch2a
I1021 23:15:39.098551 25759 net.cpp:418] res3a_branch2b -> res3a_branch2b
I1021 23:15:39.104113 25759 net.cpp:150] Setting up res3a_branch2b
I1021 23:15:39.104125 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.104144 25759 net.cpp:165] Memory required for data: 2944204884
I1021 23:15:39.104151 25759 layer_factory.hpp:77] Creating layer bn3a_branch2b
I1021 23:15:39.104158 25759 net.cpp:100] Creating Layer bn3a_branch2b
I1021 23:15:39.104161 25759 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I1021 23:15:39.104167 25759 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I1021 23:15:39.104549 25759 net.cpp:150] Setting up bn3a_branch2b
I1021 23:15:39.104557 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.104558 25759 net.cpp:165] Memory required for data: 2954035284
I1021 23:15:39.104580 25759 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1021 23:15:39.104590 25759 net.cpp:100] Creating Layer scale3a_branch2b
I1021 23:15:39.104595 25759 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I1021 23:15:39.104599 25759 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I1021 23:15:39.104696 25759 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1021 23:15:39.104887 25759 net.cpp:150] Setting up scale3a_branch2b
I1021 23:15:39.104895 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.104897 25759 net.cpp:165] Memory required for data: 2963865684
I1021 23:15:39.104902 25759 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I1021 23:15:39.104909 25759 net.cpp:100] Creating Layer res3a_branch2b_relu
I1021 23:15:39.104912 25759 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I1021 23:15:39.104917 25759 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I1021 23:15:39.105116 25759 net.cpp:150] Setting up res3a_branch2b_relu
I1021 23:15:39.105125 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.105127 25759 net.cpp:165] Memory required for data: 2973696084
I1021 23:15:39.105130 25759 layer_factory.hpp:77] Creating layer res3a_branch2c
I1021 23:15:39.105140 25759 net.cpp:100] Creating Layer res3a_branch2c
I1021 23:15:39.105144 25759 net.cpp:444] res3a_branch2c <- res3a_branch2b
I1021 23:15:39.105149 25759 net.cpp:418] res3a_branch2c -> res3a_branch2c
I1021 23:15:39.106739 25759 net.cpp:150] Setting up res3a_branch2c
I1021 23:15:39.106750 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.106752 25759 net.cpp:165] Memory required for data: 3013017684
I1021 23:15:39.106757 25759 layer_factory.hpp:77] Creating layer bn3a_branch2c
I1021 23:15:39.106781 25759 net.cpp:100] Creating Layer bn3a_branch2c
I1021 23:15:39.106784 25759 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I1021 23:15:39.106791 25759 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I1021 23:15:39.107136 25759 net.cpp:150] Setting up bn3a_branch2c
I1021 23:15:39.107142 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.107144 25759 net.cpp:165] Memory required for data: 3052339284
I1021 23:15:39.107167 25759 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1021 23:15:39.107173 25759 net.cpp:100] Creating Layer scale3a_branch2c
I1021 23:15:39.107177 25759 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I1021 23:15:39.107179 25759 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I1021 23:15:39.107249 25759 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1021 23:15:39.107451 25759 net.cpp:150] Setting up scale3a_branch2c
I1021 23:15:39.107458 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.107461 25759 net.cpp:165] Memory required for data: 3091660884
I1021 23:15:39.107466 25759 layer_factory.hpp:77] Creating layer res3a
I1021 23:15:39.107470 25759 net.cpp:100] Creating Layer res3a
I1021 23:15:39.107475 25759 net.cpp:444] res3a <- res3a_branch1
I1021 23:15:39.107477 25759 net.cpp:444] res3a <- res3a_branch2c
I1021 23:15:39.107484 25759 net.cpp:418] res3a -> res3a
I1021 23:15:39.107517 25759 net.cpp:150] Setting up res3a
I1021 23:15:39.107524 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.107527 25759 net.cpp:165] Memory required for data: 3130982484
I1021 23:15:39.107529 25759 layer_factory.hpp:77] Creating layer res3a_relu
I1021 23:15:39.107535 25759 net.cpp:100] Creating Layer res3a_relu
I1021 23:15:39.107538 25759 net.cpp:444] res3a_relu <- res3a
I1021 23:15:39.107542 25759 net.cpp:405] res3a_relu -> res3a (in-place)
I1021 23:15:39.108378 25759 net.cpp:150] Setting up res3a_relu
I1021 23:15:39.108392 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.108394 25759 net.cpp:165] Memory required for data: 3170304084
I1021 23:15:39.108397 25759 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I1021 23:15:39.108414 25759 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I1021 23:15:39.108418 25759 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I1021 23:15:39.108424 25759 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I1021 23:15:39.108448 25759 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I1021 23:15:39.108515 25759 net.cpp:150] Setting up res3a_res3a_relu_0_split
I1021 23:15:39.108522 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.108525 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.108528 25759 net.cpp:165] Memory required for data: 3248947284
I1021 23:15:39.108531 25759 layer_factory.hpp:77] Creating layer res3b_branch2a
I1021 23:15:39.108539 25759 net.cpp:100] Creating Layer res3b_branch2a
I1021 23:15:39.108543 25759 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I1021 23:15:39.108551 25759 net.cpp:418] res3b_branch2a -> res3b_branch2a
I1021 23:15:39.111506 25759 net.cpp:150] Setting up res3b_branch2a
I1021 23:15:39.111519 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.111532 25759 net.cpp:165] Memory required for data: 3258777684
I1021 23:15:39.111538 25759 layer_factory.hpp:77] Creating layer bn3b_branch2a
I1021 23:15:39.111546 25759 net.cpp:100] Creating Layer bn3b_branch2a
I1021 23:15:39.111549 25759 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I1021 23:15:39.111567 25759 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I1021 23:15:39.111897 25759 net.cpp:150] Setting up bn3b_branch2a
I1021 23:15:39.111905 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.111907 25759 net.cpp:165] Memory required for data: 3268608084
I1021 23:15:39.111929 25759 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1021 23:15:39.111937 25759 net.cpp:100] Creating Layer scale3b_branch2a
I1021 23:15:39.111939 25759 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I1021 23:15:39.111945 25759 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I1021 23:15:39.112018 25759 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1021 23:15:39.113890 25759 net.cpp:150] Setting up scale3b_branch2a
I1021 23:15:39.113901 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.113903 25759 net.cpp:165] Memory required for data: 3278438484
I1021 23:15:39.113925 25759 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I1021 23:15:39.113930 25759 net.cpp:100] Creating Layer res3b_branch2a_relu
I1021 23:15:39.113934 25759 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I1021 23:15:39.113940 25759 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I1021 23:15:39.114167 25759 net.cpp:150] Setting up res3b_branch2a_relu
I1021 23:15:39.114176 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.114178 25759 net.cpp:165] Memory required for data: 3288268884
I1021 23:15:39.114181 25759 layer_factory.hpp:77] Creating layer res3b_branch2b
I1021 23:15:39.114189 25759 net.cpp:100] Creating Layer res3b_branch2b
I1021 23:15:39.114192 25759 net.cpp:444] res3b_branch2b <- res3b_branch2a
I1021 23:15:39.114199 25759 net.cpp:418] res3b_branch2b -> res3b_branch2b
I1021 23:15:39.116909 25759 net.cpp:150] Setting up res3b_branch2b
I1021 23:15:39.116935 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.116938 25759 net.cpp:165] Memory required for data: 3298099284
I1021 23:15:39.116943 25759 layer_factory.hpp:77] Creating layer bn3b_branch2b
I1021 23:15:39.116966 25759 net.cpp:100] Creating Layer bn3b_branch2b
I1021 23:15:39.116968 25759 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I1021 23:15:39.116974 25759 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I1021 23:15:39.117296 25759 net.cpp:150] Setting up bn3b_branch2b
I1021 23:15:39.117319 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.117321 25759 net.cpp:165] Memory required for data: 3307929684
I1021 23:15:39.117342 25759 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1021 23:15:39.117365 25759 net.cpp:100] Creating Layer scale3b_branch2b
I1021 23:15:39.117368 25759 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I1021 23:15:39.117374 25759 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I1021 23:15:39.117447 25759 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1021 23:15:39.117625 25759 net.cpp:150] Setting up scale3b_branch2b
I1021 23:15:39.117633 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.117635 25759 net.cpp:165] Memory required for data: 3317760084
I1021 23:15:39.117640 25759 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I1021 23:15:39.117645 25759 net.cpp:100] Creating Layer res3b_branch2b_relu
I1021 23:15:39.117648 25759 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I1021 23:15:39.117652 25759 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I1021 23:15:39.117861 25759 net.cpp:150] Setting up res3b_branch2b_relu
I1021 23:15:39.117878 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.117882 25759 net.cpp:165] Memory required for data: 3327590484
I1021 23:15:39.117883 25759 layer_factory.hpp:77] Creating layer res3b_branch2c
I1021 23:15:39.117892 25759 net.cpp:100] Creating Layer res3b_branch2c
I1021 23:15:39.117895 25759 net.cpp:444] res3b_branch2c <- res3b_branch2b
I1021 23:15:39.117900 25759 net.cpp:418] res3b_branch2c -> res3b_branch2c
I1021 23:15:39.119426 25759 net.cpp:150] Setting up res3b_branch2c
I1021 23:15:39.119436 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.119454 25759 net.cpp:165] Memory required for data: 3366912084
I1021 23:15:39.119459 25759 layer_factory.hpp:77] Creating layer bn3b_branch2c
I1021 23:15:39.119467 25759 net.cpp:100] Creating Layer bn3b_branch2c
I1021 23:15:39.119472 25759 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I1021 23:15:39.119477 25759 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I1021 23:15:39.119838 25759 net.cpp:150] Setting up bn3b_branch2c
I1021 23:15:39.119845 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.119848 25759 net.cpp:165] Memory required for data: 3406233684
I1021 23:15:39.119869 25759 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1021 23:15:39.119874 25759 net.cpp:100] Creating Layer scale3b_branch2c
I1021 23:15:39.119877 25759 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I1021 23:15:39.119884 25759 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I1021 23:15:39.119956 25759 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1021 23:15:39.120146 25759 net.cpp:150] Setting up scale3b_branch2c
I1021 23:15:39.120153 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.120157 25759 net.cpp:165] Memory required for data: 3445555284
I1021 23:15:39.120162 25759 layer_factory.hpp:77] Creating layer res3b
I1021 23:15:39.120167 25759 net.cpp:100] Creating Layer res3b
I1021 23:15:39.120169 25759 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I1021 23:15:39.120172 25759 net.cpp:444] res3b <- res3b_branch2c
I1021 23:15:39.120177 25759 net.cpp:418] res3b -> res3b
I1021 23:15:39.120213 25759 net.cpp:150] Setting up res3b
I1021 23:15:39.120219 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.120223 25759 net.cpp:165] Memory required for data: 3484876884
I1021 23:15:39.120225 25759 layer_factory.hpp:77] Creating layer res3b_relu
I1021 23:15:39.120229 25759 net.cpp:100] Creating Layer res3b_relu
I1021 23:15:39.120232 25759 net.cpp:444] res3b_relu <- res3b
I1021 23:15:39.120236 25759 net.cpp:405] res3b_relu -> res3b (in-place)
I1021 23:15:39.121064 25759 net.cpp:150] Setting up res3b_relu
I1021 23:15:39.121078 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.121080 25759 net.cpp:165] Memory required for data: 3524198484
I1021 23:15:39.121083 25759 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I1021 23:15:39.121089 25759 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I1021 23:15:39.121093 25759 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I1021 23:15:39.121099 25759 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I1021 23:15:39.121105 25759 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I1021 23:15:39.121170 25759 net.cpp:150] Setting up res3b_res3b_relu_0_split
I1021 23:15:39.121176 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.121181 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.121182 25759 net.cpp:165] Memory required for data: 3602841684
I1021 23:15:39.121186 25759 layer_factory.hpp:77] Creating layer res3c_branch2a
I1021 23:15:39.121193 25759 net.cpp:100] Creating Layer res3c_branch2a
I1021 23:15:39.121196 25759 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I1021 23:15:39.121218 25759 net.cpp:418] res3c_branch2a -> res3c_branch2a
I1021 23:15:39.123684 25759 net.cpp:150] Setting up res3c_branch2a
I1021 23:15:39.123697 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.123698 25759 net.cpp:165] Memory required for data: 3612672084
I1021 23:15:39.123714 25759 layer_factory.hpp:77] Creating layer bn3c_branch2a
I1021 23:15:39.123724 25759 net.cpp:100] Creating Layer bn3c_branch2a
I1021 23:15:39.123728 25759 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I1021 23:15:39.123747 25759 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I1021 23:15:39.124101 25759 net.cpp:150] Setting up bn3c_branch2a
I1021 23:15:39.124109 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.124110 25759 net.cpp:165] Memory required for data: 3622502484
I1021 23:15:39.124132 25759 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1021 23:15:39.124140 25759 net.cpp:100] Creating Layer scale3c_branch2a
I1021 23:15:39.124142 25759 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I1021 23:15:39.124147 25759 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I1021 23:15:39.124223 25759 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1021 23:15:39.124404 25759 net.cpp:150] Setting up scale3c_branch2a
I1021 23:15:39.124411 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.124415 25759 net.cpp:165] Memory required for data: 3632332884
I1021 23:15:39.124419 25759 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I1021 23:15:39.124426 25759 net.cpp:100] Creating Layer res3c_branch2a_relu
I1021 23:15:39.124430 25759 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I1021 23:15:39.124433 25759 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I1021 23:15:39.124650 25759 net.cpp:150] Setting up res3c_branch2a_relu
I1021 23:15:39.124658 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.124661 25759 net.cpp:165] Memory required for data: 3642163284
I1021 23:15:39.124665 25759 layer_factory.hpp:77] Creating layer res3c_branch2b
I1021 23:15:39.124672 25759 net.cpp:100] Creating Layer res3c_branch2b
I1021 23:15:39.124675 25759 net.cpp:444] res3c_branch2b <- res3c_branch2a
I1021 23:15:39.124681 25759 net.cpp:418] res3c_branch2b -> res3c_branch2b
I1021 23:15:39.126754 25759 net.cpp:150] Setting up res3c_branch2b
I1021 23:15:39.126765 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.126778 25759 net.cpp:165] Memory required for data: 3651993684
I1021 23:15:39.126783 25759 layer_factory.hpp:77] Creating layer bn3c_branch2b
I1021 23:15:39.126790 25759 net.cpp:100] Creating Layer bn3c_branch2b
I1021 23:15:39.126792 25759 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I1021 23:15:39.126809 25759 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I1021 23:15:39.127140 25759 net.cpp:150] Setting up bn3c_branch2b
I1021 23:15:39.127147 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.127149 25759 net.cpp:165] Memory required for data: 3661824084
I1021 23:15:39.127171 25759 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1021 23:15:39.127178 25759 net.cpp:100] Creating Layer scale3c_branch2b
I1021 23:15:39.127182 25759 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I1021 23:15:39.127187 25759 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I1021 23:15:39.127259 25759 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1021 23:15:39.127434 25759 net.cpp:150] Setting up scale3c_branch2b
I1021 23:15:39.127441 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.127444 25759 net.cpp:165] Memory required for data: 3671654484
I1021 23:15:39.127449 25759 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I1021 23:15:39.127454 25759 net.cpp:100] Creating Layer res3c_branch2b_relu
I1021 23:15:39.127456 25759 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I1021 23:15:39.127460 25759 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I1021 23:15:39.127660 25759 net.cpp:150] Setting up res3c_branch2b_relu
I1021 23:15:39.127669 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.127672 25759 net.cpp:165] Memory required for data: 3681484884
I1021 23:15:39.127674 25759 layer_factory.hpp:77] Creating layer res3c_branch2c
I1021 23:15:39.127681 25759 net.cpp:100] Creating Layer res3c_branch2c
I1021 23:15:39.127684 25759 net.cpp:444] res3c_branch2c <- res3c_branch2b
I1021 23:15:39.127691 25759 net.cpp:418] res3c_branch2c -> res3c_branch2c
I1021 23:15:39.131075 25759 net.cpp:150] Setting up res3c_branch2c
I1021 23:15:39.131088 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.131103 25759 net.cpp:165] Memory required for data: 3720806484
I1021 23:15:39.131108 25759 layer_factory.hpp:77] Creating layer bn3c_branch2c
I1021 23:15:39.131116 25759 net.cpp:100] Creating Layer bn3c_branch2c
I1021 23:15:39.131119 25759 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I1021 23:15:39.131125 25759 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I1021 23:15:39.131450 25759 net.cpp:150] Setting up bn3c_branch2c
I1021 23:15:39.131458 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.131459 25759 net.cpp:165] Memory required for data: 3760128084
I1021 23:15:39.131482 25759 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1021 23:15:39.131487 25759 net.cpp:100] Creating Layer scale3c_branch2c
I1021 23:15:39.131490 25759 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I1021 23:15:39.131503 25759 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I1021 23:15:39.131573 25759 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1021 23:15:39.131762 25759 net.cpp:150] Setting up scale3c_branch2c
I1021 23:15:39.131770 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.131772 25759 net.cpp:165] Memory required for data: 3799449684
I1021 23:15:39.131778 25759 layer_factory.hpp:77] Creating layer res3c
I1021 23:15:39.131783 25759 net.cpp:100] Creating Layer res3c
I1021 23:15:39.131785 25759 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I1021 23:15:39.131789 25759 net.cpp:444] res3c <- res3c_branch2c
I1021 23:15:39.131794 25759 net.cpp:418] res3c -> res3c
I1021 23:15:39.131830 25759 net.cpp:150] Setting up res3c
I1021 23:15:39.131836 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.131839 25759 net.cpp:165] Memory required for data: 3838771284
I1021 23:15:39.131842 25759 layer_factory.hpp:77] Creating layer res3c_relu
I1021 23:15:39.131846 25759 net.cpp:100] Creating Layer res3c_relu
I1021 23:15:39.131850 25759 net.cpp:444] res3c_relu <- res3c
I1021 23:15:39.131852 25759 net.cpp:405] res3c_relu -> res3c (in-place)
I1021 23:15:39.132046 25759 net.cpp:150] Setting up res3c_relu
I1021 23:15:39.132056 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.132058 25759 net.cpp:165] Memory required for data: 3878092884
I1021 23:15:39.132061 25759 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I1021 23:15:39.132067 25759 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I1021 23:15:39.132069 25759 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I1021 23:15:39.132076 25759 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I1021 23:15:39.132081 25759 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I1021 23:15:39.132145 25759 net.cpp:150] Setting up res3c_res3c_relu_0_split
I1021 23:15:39.132151 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.132155 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.132158 25759 net.cpp:165] Memory required for data: 3956736084
I1021 23:15:39.132160 25759 layer_factory.hpp:77] Creating layer res3d_branch2a
I1021 23:15:39.132169 25759 net.cpp:100] Creating Layer res3d_branch2a
I1021 23:15:39.132171 25759 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I1021 23:15:39.132177 25759 net.cpp:418] res3d_branch2a -> res3d_branch2a
I1021 23:15:39.135223 25759 net.cpp:150] Setting up res3d_branch2a
I1021 23:15:39.135234 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.135237 25759 net.cpp:165] Memory required for data: 3966566484
I1021 23:15:39.135253 25759 layer_factory.hpp:77] Creating layer bn3d_branch2a
I1021 23:15:39.135262 25759 net.cpp:100] Creating Layer bn3d_branch2a
I1021 23:15:39.135265 25759 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I1021 23:15:39.135269 25759 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I1021 23:15:39.135624 25759 net.cpp:150] Setting up bn3d_branch2a
I1021 23:15:39.135632 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.135634 25759 net.cpp:165] Memory required for data: 3976396884
I1021 23:15:39.135668 25759 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1021 23:15:39.135673 25759 net.cpp:100] Creating Layer scale3d_branch2a
I1021 23:15:39.135675 25759 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I1021 23:15:39.135681 25759 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I1021 23:15:39.135756 25759 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1021 23:15:39.135933 25759 net.cpp:150] Setting up scale3d_branch2a
I1021 23:15:39.135941 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.135943 25759 net.cpp:165] Memory required for data: 3986227284
I1021 23:15:39.135948 25759 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I1021 23:15:39.135953 25759 net.cpp:100] Creating Layer res3d_branch2a_relu
I1021 23:15:39.135957 25759 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I1021 23:15:39.135959 25759 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I1021 23:15:39.136859 25759 net.cpp:150] Setting up res3d_branch2a_relu
I1021 23:15:39.136873 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.136886 25759 net.cpp:165] Memory required for data: 3996057684
I1021 23:15:39.136889 25759 layer_factory.hpp:77] Creating layer res3d_branch2b
I1021 23:15:39.136900 25759 net.cpp:100] Creating Layer res3d_branch2b
I1021 23:15:39.136904 25759 net.cpp:444] res3d_branch2b <- res3d_branch2a
I1021 23:15:39.136911 25759 net.cpp:418] res3d_branch2b -> res3d_branch2b
I1021 23:15:39.141563 25759 net.cpp:150] Setting up res3d_branch2b
I1021 23:15:39.141577 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.141595 25759 net.cpp:165] Memory required for data: 4005888084
I1021 23:15:39.141602 25759 layer_factory.hpp:77] Creating layer bn3d_branch2b
I1021 23:15:39.141610 25759 net.cpp:100] Creating Layer bn3d_branch2b
I1021 23:15:39.141614 25759 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I1021 23:15:39.141619 25759 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I1021 23:15:39.141997 25759 net.cpp:150] Setting up bn3d_branch2b
I1021 23:15:39.142004 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.142006 25759 net.cpp:165] Memory required for data: 4015718484
I1021 23:15:39.142029 25759 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1021 23:15:39.142035 25759 net.cpp:100] Creating Layer scale3d_branch2b
I1021 23:15:39.142037 25759 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I1021 23:15:39.142045 25759 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I1021 23:15:39.142136 25759 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1021 23:15:39.142331 25759 net.cpp:150] Setting up scale3d_branch2b
I1021 23:15:39.142338 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.142341 25759 net.cpp:165] Memory required for data: 4025548884
I1021 23:15:39.142346 25759 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I1021 23:15:39.142351 25759 net.cpp:100] Creating Layer res3d_branch2b_relu
I1021 23:15:39.142354 25759 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I1021 23:15:39.142359 25759 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I1021 23:15:39.142575 25759 net.cpp:150] Setting up res3d_branch2b_relu
I1021 23:15:39.142583 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.142585 25759 net.cpp:165] Memory required for data: 4035379284
I1021 23:15:39.142588 25759 layer_factory.hpp:77] Creating layer res3d_branch2c
I1021 23:15:39.142597 25759 net.cpp:100] Creating Layer res3d_branch2c
I1021 23:15:39.142601 25759 net.cpp:444] res3d_branch2c <- res3d_branch2b
I1021 23:15:39.142606 25759 net.cpp:418] res3d_branch2c -> res3d_branch2c
I1021 23:15:39.144136 25759 net.cpp:150] Setting up res3d_branch2c
I1021 23:15:39.144146 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.144150 25759 net.cpp:165] Memory required for data: 4074700884
I1021 23:15:39.144170 25759 layer_factory.hpp:77] Creating layer bn3d_branch2c
I1021 23:15:39.144178 25759 net.cpp:100] Creating Layer bn3d_branch2c
I1021 23:15:39.144181 25759 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I1021 23:15:39.144186 25759 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I1021 23:15:39.144563 25759 net.cpp:150] Setting up bn3d_branch2c
I1021 23:15:39.144570 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.144573 25759 net.cpp:165] Memory required for data: 4114022484
I1021 23:15:39.144594 25759 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1021 23:15:39.144601 25759 net.cpp:100] Creating Layer scale3d_branch2c
I1021 23:15:39.144604 25759 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I1021 23:15:39.144644 25759 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I1021 23:15:39.144716 25759 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1021 23:15:39.144922 25759 net.cpp:150] Setting up scale3d_branch2c
I1021 23:15:39.144930 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.144932 25759 net.cpp:165] Memory required for data: 4153344084
I1021 23:15:39.144937 25759 layer_factory.hpp:77] Creating layer res3d
I1021 23:15:39.144944 25759 net.cpp:100] Creating Layer res3d
I1021 23:15:39.144948 25759 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I1021 23:15:39.144953 25759 net.cpp:444] res3d <- res3d_branch2c
I1021 23:15:39.144956 25759 net.cpp:418] res3d -> res3d
I1021 23:15:39.145009 25759 net.cpp:150] Setting up res3d
I1021 23:15:39.145015 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.145017 25759 net.cpp:165] Memory required for data: 4192665684
I1021 23:15:39.145020 25759 layer_factory.hpp:77] Creating layer res3d_relu
I1021 23:15:39.145025 25759 net.cpp:100] Creating Layer res3d_relu
I1021 23:15:39.145026 25759 net.cpp:444] res3d_relu <- res3d
I1021 23:15:39.145030 25759 net.cpp:405] res3d_relu -> res3d (in-place)
I1021 23:15:39.145241 25759 net.cpp:150] Setting up res3d_relu
I1021 23:15:39.145249 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.145252 25759 net.cpp:165] Memory required for data: 4231987284
I1021 23:15:39.145256 25759 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I1021 23:15:39.145262 25759 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I1021 23:15:39.145265 25759 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I1021 23:15:39.145270 25759 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I1021 23:15:39.145277 25759 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I1021 23:15:39.145283 25759 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_2
I1021 23:15:39.145366 25759 net.cpp:150] Setting up res3d_res3d_relu_0_split
I1021 23:15:39.145373 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.145376 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.145380 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.145382 25759 net.cpp:165] Memory required for data: 4349952084
I1021 23:15:39.145385 25759 layer_factory.hpp:77] Creating layer res4a_branch1
I1021 23:15:39.145395 25759 net.cpp:100] Creating Layer res4a_branch1
I1021 23:15:39.145398 25759 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I1021 23:15:39.145404 25759 net.cpp:418] res4a_branch1 -> res4a_branch1
I1021 23:15:39.149469 25759 net.cpp:150] Setting up res4a_branch1
I1021 23:15:39.149482 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.149500 25759 net.cpp:165] Memory required for data: 4369612884
I1021 23:15:39.149505 25759 layer_factory.hpp:77] Creating layer bn4a_branch1
I1021 23:15:39.149513 25759 net.cpp:100] Creating Layer bn4a_branch1
I1021 23:15:39.149516 25759 net.cpp:444] bn4a_branch1 <- res4a_branch1
I1021 23:15:39.149521 25759 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I1021 23:15:39.149874 25759 net.cpp:150] Setting up bn4a_branch1
I1021 23:15:39.149881 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.149883 25759 net.cpp:165] Memory required for data: 4389273684
I1021 23:15:39.149906 25759 layer_factory.hpp:77] Creating layer scale4a_branch1
I1021 23:15:39.149914 25759 net.cpp:100] Creating Layer scale4a_branch1
I1021 23:15:39.149917 25759 net.cpp:444] scale4a_branch1 <- res4a_branch1
I1021 23:15:39.149922 25759 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I1021 23:15:39.149977 25759 layer_factory.hpp:77] Creating layer scale4a_branch1
I1021 23:15:39.150185 25759 net.cpp:150] Setting up scale4a_branch1
I1021 23:15:39.150192 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.150194 25759 net.cpp:165] Memory required for data: 4408934484
I1021 23:15:39.150199 25759 layer_factory.hpp:77] Creating layer res4a_branch2a
I1021 23:15:39.150223 25759 net.cpp:100] Creating Layer res4a_branch2a
I1021 23:15:39.150228 25759 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I1021 23:15:39.150233 25759 net.cpp:418] res4a_branch2a -> res4a_branch2a
I1021 23:15:39.151862 25759 net.cpp:150] Setting up res4a_branch2a
I1021 23:15:39.151873 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.151875 25759 net.cpp:165] Memory required for data: 4413849684
I1021 23:15:39.151880 25759 layer_factory.hpp:77] Creating layer bn4a_branch2a
I1021 23:15:39.151898 25759 net.cpp:100] Creating Layer bn4a_branch2a
I1021 23:15:39.151902 25759 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I1021 23:15:39.151924 25759 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I1021 23:15:39.152266 25759 net.cpp:150] Setting up bn4a_branch2a
I1021 23:15:39.152274 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.152277 25759 net.cpp:165] Memory required for data: 4418764884
I1021 23:15:39.152298 25759 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1021 23:15:39.152304 25759 net.cpp:100] Creating Layer scale4a_branch2a
I1021 23:15:39.152307 25759 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I1021 23:15:39.152313 25759 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I1021 23:15:39.152390 25759 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1021 23:15:39.152580 25759 net.cpp:150] Setting up scale4a_branch2a
I1021 23:15:39.152588 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.152591 25759 net.cpp:165] Memory required for data: 4423680084
I1021 23:15:39.152596 25759 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I1021 23:15:39.152601 25759 net.cpp:100] Creating Layer res4a_branch2a_relu
I1021 23:15:39.152604 25759 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I1021 23:15:39.152613 25759 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I1021 23:15:39.155114 25759 net.cpp:150] Setting up res4a_branch2a_relu
I1021 23:15:39.155128 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.155148 25759 net.cpp:165] Memory required for data: 4428595284
I1021 23:15:39.155150 25759 layer_factory.hpp:77] Creating layer res4a_branch2b
I1021 23:15:39.155162 25759 net.cpp:100] Creating Layer res4a_branch2b
I1021 23:15:39.155166 25759 net.cpp:444] res4a_branch2b <- res4a_branch2a
I1021 23:15:39.155171 25759 net.cpp:418] res4a_branch2b -> res4a_branch2b
I1021 23:15:39.160876 25759 net.cpp:150] Setting up res4a_branch2b
I1021 23:15:39.160892 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.160912 25759 net.cpp:165] Memory required for data: 4433510484
I1021 23:15:39.160919 25759 layer_factory.hpp:77] Creating layer bn4a_branch2b
I1021 23:15:39.160929 25759 net.cpp:100] Creating Layer bn4a_branch2b
I1021 23:15:39.160933 25759 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I1021 23:15:39.160938 25759 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I1021 23:15:39.161342 25759 net.cpp:150] Setting up bn4a_branch2b
I1021 23:15:39.161350 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.161351 25759 net.cpp:165] Memory required for data: 4438425684
I1021 23:15:39.161373 25759 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1021 23:15:39.161398 25759 net.cpp:100] Creating Layer scale4a_branch2b
I1021 23:15:39.161402 25759 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I1021 23:15:39.161406 25759 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I1021 23:15:39.161468 25759 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1021 23:15:39.161659 25759 net.cpp:150] Setting up scale4a_branch2b
I1021 23:15:39.161666 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.161669 25759 net.cpp:165] Memory required for data: 4443340884
I1021 23:15:39.161674 25759 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I1021 23:15:39.161679 25759 net.cpp:100] Creating Layer res4a_branch2b_relu
I1021 23:15:39.161682 25759 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I1021 23:15:39.161687 25759 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I1021 23:15:39.161891 25759 net.cpp:150] Setting up res4a_branch2b_relu
I1021 23:15:39.161900 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.161902 25759 net.cpp:165] Memory required for data: 4448256084
I1021 23:15:39.161906 25759 layer_factory.hpp:77] Creating layer res4a_branch2c
I1021 23:15:39.161913 25759 net.cpp:100] Creating Layer res4a_branch2c
I1021 23:15:39.161917 25759 net.cpp:444] res4a_branch2c <- res4a_branch2b
I1021 23:15:39.161923 25759 net.cpp:418] res4a_branch2c -> res4a_branch2c
I1021 23:15:39.165274 25759 net.cpp:150] Setting up res4a_branch2c
I1021 23:15:39.165287 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.165289 25759 net.cpp:165] Memory required for data: 4467916884
I1021 23:15:39.165310 25759 layer_factory.hpp:77] Creating layer bn4a_branch2c
I1021 23:15:39.165318 25759 net.cpp:100] Creating Layer bn4a_branch2c
I1021 23:15:39.165321 25759 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I1021 23:15:39.165328 25759 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I1021 23:15:39.165706 25759 net.cpp:150] Setting up bn4a_branch2c
I1021 23:15:39.165714 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.165715 25759 net.cpp:165] Memory required for data: 4487577684
I1021 23:15:39.165737 25759 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1021 23:15:39.165745 25759 net.cpp:100] Creating Layer scale4a_branch2c
I1021 23:15:39.165748 25759 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I1021 23:15:39.165755 25759 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I1021 23:15:39.165825 25759 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1021 23:15:39.166024 25759 net.cpp:150] Setting up scale4a_branch2c
I1021 23:15:39.166033 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.166034 25759 net.cpp:165] Memory required for data: 4507238484
I1021 23:15:39.166040 25759 layer_factory.hpp:77] Creating layer res4a
I1021 23:15:39.166054 25759 net.cpp:100] Creating Layer res4a
I1021 23:15:39.166059 25759 net.cpp:444] res4a <- res4a_branch1
I1021 23:15:39.166062 25759 net.cpp:444] res4a <- res4a_branch2c
I1021 23:15:39.166066 25759 net.cpp:418] res4a -> res4a
I1021 23:15:39.166102 25759 net.cpp:150] Setting up res4a
I1021 23:15:39.166108 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.166112 25759 net.cpp:165] Memory required for data: 4526899284
I1021 23:15:39.166115 25759 layer_factory.hpp:77] Creating layer res4a_relu
I1021 23:15:39.166121 25759 net.cpp:100] Creating Layer res4a_relu
I1021 23:15:39.166123 25759 net.cpp:444] res4a_relu <- res4a
I1021 23:15:39.166126 25759 net.cpp:405] res4a_relu -> res4a (in-place)
I1021 23:15:39.166324 25759 net.cpp:150] Setting up res4a_relu
I1021 23:15:39.166332 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.166334 25759 net.cpp:165] Memory required for data: 4546560084
I1021 23:15:39.166337 25759 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I1021 23:15:39.166343 25759 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I1021 23:15:39.166347 25759 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I1021 23:15:39.166352 25759 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I1021 23:15:39.166357 25759 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I1021 23:15:39.166427 25759 net.cpp:150] Setting up res4a_res4a_relu_0_split
I1021 23:15:39.166435 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.166438 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.166441 25759 net.cpp:165] Memory required for data: 4585881684
I1021 23:15:39.166443 25759 layer_factory.hpp:77] Creating layer res4b_branch2a
I1021 23:15:39.166452 25759 net.cpp:100] Creating Layer res4b_branch2a
I1021 23:15:39.166455 25759 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I1021 23:15:39.166477 25759 net.cpp:418] res4b_branch2a -> res4b_branch2a
I1021 23:15:39.168164 25759 net.cpp:150] Setting up res4b_branch2a
I1021 23:15:39.168175 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.168177 25759 net.cpp:165] Memory required for data: 4590796884
I1021 23:15:39.168197 25759 layer_factory.hpp:77] Creating layer bn4b_branch2a
I1021 23:15:39.168206 25759 net.cpp:100] Creating Layer bn4b_branch2a
I1021 23:15:39.168210 25759 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I1021 23:15:39.168216 25759 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I1021 23:15:39.168596 25759 net.cpp:150] Setting up bn4b_branch2a
I1021 23:15:39.168603 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.168606 25759 net.cpp:165] Memory required for data: 4595712084
I1021 23:15:39.168653 25759 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1021 23:15:39.168659 25759 net.cpp:100] Creating Layer scale4b_branch2a
I1021 23:15:39.168663 25759 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I1021 23:15:39.168668 25759 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I1021 23:15:39.168732 25759 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1021 23:15:39.168929 25759 net.cpp:150] Setting up scale4b_branch2a
I1021 23:15:39.168936 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.168939 25759 net.cpp:165] Memory required for data: 4600627284
I1021 23:15:39.168944 25759 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I1021 23:15:39.168962 25759 net.cpp:100] Creating Layer res4b_branch2a_relu
I1021 23:15:39.168967 25759 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I1021 23:15:39.168970 25759 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I1021 23:15:39.169801 25759 net.cpp:150] Setting up res4b_branch2a_relu
I1021 23:15:39.169811 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.169831 25759 net.cpp:165] Memory required for data: 4605542484
I1021 23:15:39.169833 25759 layer_factory.hpp:77] Creating layer res4b_branch2b
I1021 23:15:39.169842 25759 net.cpp:100] Creating Layer res4b_branch2b
I1021 23:15:39.169845 25759 net.cpp:444] res4b_branch2b <- res4b_branch2a
I1021 23:15:39.169854 25759 net.cpp:418] res4b_branch2b -> res4b_branch2b
I1021 23:15:39.175765 25759 net.cpp:150] Setting up res4b_branch2b
I1021 23:15:39.175778 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.175797 25759 net.cpp:165] Memory required for data: 4610457684
I1021 23:15:39.175803 25759 layer_factory.hpp:77] Creating layer bn4b_branch2b
I1021 23:15:39.175813 25759 net.cpp:100] Creating Layer bn4b_branch2b
I1021 23:15:39.175817 25759 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I1021 23:15:39.175822 25759 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I1021 23:15:39.176213 25759 net.cpp:150] Setting up bn4b_branch2b
I1021 23:15:39.176221 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.176223 25759 net.cpp:165] Memory required for data: 4615372884
I1021 23:15:39.176245 25759 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1021 23:15:39.176251 25759 net.cpp:100] Creating Layer scale4b_branch2b
I1021 23:15:39.176254 25759 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I1021 23:15:39.176260 25759 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I1021 23:15:39.176338 25759 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1021 23:15:39.176537 25759 net.cpp:150] Setting up scale4b_branch2b
I1021 23:15:39.176544 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.176546 25759 net.cpp:165] Memory required for data: 4620288084
I1021 23:15:39.176551 25759 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I1021 23:15:39.176556 25759 net.cpp:100] Creating Layer res4b_branch2b_relu
I1021 23:15:39.176559 25759 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I1021 23:15:39.176565 25759 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I1021 23:15:39.176784 25759 net.cpp:150] Setting up res4b_branch2b_relu
I1021 23:15:39.176795 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.176797 25759 net.cpp:165] Memory required for data: 4625203284
I1021 23:15:39.176800 25759 layer_factory.hpp:77] Creating layer res4b_branch2c
I1021 23:15:39.176810 25759 net.cpp:100] Creating Layer res4b_branch2c
I1021 23:15:39.176813 25759 net.cpp:444] res4b_branch2c <- res4b_branch2b
I1021 23:15:39.176820 25759 net.cpp:418] res4b_branch2c -> res4b_branch2c
I1021 23:15:39.180220 25759 net.cpp:150] Setting up res4b_branch2c
I1021 23:15:39.180233 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.180251 25759 net.cpp:165] Memory required for data: 4644864084
I1021 23:15:39.180256 25759 layer_factory.hpp:77] Creating layer bn4b_branch2c
I1021 23:15:39.180264 25759 net.cpp:100] Creating Layer bn4b_branch2c
I1021 23:15:39.180269 25759 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I1021 23:15:39.180276 25759 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I1021 23:15:39.180678 25759 net.cpp:150] Setting up bn4b_branch2c
I1021 23:15:39.180686 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.180688 25759 net.cpp:165] Memory required for data: 4664524884
I1021 23:15:39.180711 25759 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1021 23:15:39.180718 25759 net.cpp:100] Creating Layer scale4b_branch2c
I1021 23:15:39.180721 25759 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I1021 23:15:39.180727 25759 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I1021 23:15:39.180801 25759 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1021 23:15:39.181026 25759 net.cpp:150] Setting up scale4b_branch2c
I1021 23:15:39.181035 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.181037 25759 net.cpp:165] Memory required for data: 4684185684
I1021 23:15:39.181042 25759 layer_factory.hpp:77] Creating layer res4b
I1021 23:15:39.181047 25759 net.cpp:100] Creating Layer res4b
I1021 23:15:39.181051 25759 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I1021 23:15:39.181054 25759 net.cpp:444] res4b <- res4b_branch2c
I1021 23:15:39.181059 25759 net.cpp:418] res4b -> res4b
I1021 23:15:39.181097 25759 net.cpp:150] Setting up res4b
I1021 23:15:39.181102 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.181107 25759 net.cpp:165] Memory required for data: 4703846484
I1021 23:15:39.181108 25759 layer_factory.hpp:77] Creating layer res4b_relu
I1021 23:15:39.181113 25759 net.cpp:100] Creating Layer res4b_relu
I1021 23:15:39.181116 25759 net.cpp:444] res4b_relu <- res4b
I1021 23:15:39.181121 25759 net.cpp:405] res4b_relu -> res4b (in-place)
I1021 23:15:39.181340 25759 net.cpp:150] Setting up res4b_relu
I1021 23:15:39.181349 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.181351 25759 net.cpp:165] Memory required for data: 4723507284
I1021 23:15:39.181354 25759 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I1021 23:15:39.181360 25759 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I1021 23:15:39.181362 25759 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I1021 23:15:39.181370 25759 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I1021 23:15:39.181375 25759 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I1021 23:15:39.181444 25759 net.cpp:150] Setting up res4b_res4b_relu_0_split
I1021 23:15:39.181450 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.181454 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.181457 25759 net.cpp:165] Memory required for data: 4762828884
I1021 23:15:39.181459 25759 layer_factory.hpp:77] Creating layer res4c_branch2a
I1021 23:15:39.181468 25759 net.cpp:100] Creating Layer res4c_branch2a
I1021 23:15:39.181471 25759 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I1021 23:15:39.181478 25759 net.cpp:418] res4c_branch2a -> res4c_branch2a
I1021 23:15:39.184265 25759 net.cpp:150] Setting up res4c_branch2a
I1021 23:15:39.184278 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.184295 25759 net.cpp:165] Memory required for data: 4767744084
I1021 23:15:39.184300 25759 layer_factory.hpp:77] Creating layer bn4c_branch2a
I1021 23:15:39.184306 25759 net.cpp:100] Creating Layer bn4c_branch2a
I1021 23:15:39.184309 25759 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I1021 23:15:39.184316 25759 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I1021 23:15:39.184705 25759 net.cpp:150] Setting up bn4c_branch2a
I1021 23:15:39.184712 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.184715 25759 net.cpp:165] Memory required for data: 4772659284
I1021 23:15:39.184737 25759 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1021 23:15:39.184742 25759 net.cpp:100] Creating Layer scale4c_branch2a
I1021 23:15:39.184746 25759 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I1021 23:15:39.184753 25759 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I1021 23:15:39.184831 25759 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1021 23:15:39.185036 25759 net.cpp:150] Setting up scale4c_branch2a
I1021 23:15:39.185045 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.185046 25759 net.cpp:165] Memory required for data: 4777574484
I1021 23:15:39.185051 25759 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I1021 23:15:39.185056 25759 net.cpp:100] Creating Layer res4c_branch2a_relu
I1021 23:15:39.185060 25759 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I1021 23:15:39.185065 25759 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I1021 23:15:39.185262 25759 net.cpp:150] Setting up res4c_branch2a_relu
I1021 23:15:39.185271 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.185274 25759 net.cpp:165] Memory required for data: 4782489684
I1021 23:15:39.185276 25759 layer_factory.hpp:77] Creating layer res4c_branch2b
I1021 23:15:39.185286 25759 net.cpp:100] Creating Layer res4c_branch2b
I1021 23:15:39.185288 25759 net.cpp:444] res4c_branch2b <- res4c_branch2a
I1021 23:15:39.185294 25759 net.cpp:418] res4c_branch2b -> res4c_branch2b
I1021 23:15:39.189980 25759 net.cpp:150] Setting up res4c_branch2b
I1021 23:15:39.189991 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.190009 25759 net.cpp:165] Memory required for data: 4787404884
I1021 23:15:39.190014 25759 layer_factory.hpp:77] Creating layer bn4c_branch2b
I1021 23:15:39.190022 25759 net.cpp:100] Creating Layer bn4c_branch2b
I1021 23:15:39.190028 25759 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I1021 23:15:39.190032 25759 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I1021 23:15:39.190420 25759 net.cpp:150] Setting up bn4c_branch2b
I1021 23:15:39.190428 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.190430 25759 net.cpp:165] Memory required for data: 4792320084
I1021 23:15:39.190451 25759 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1021 23:15:39.190459 25759 net.cpp:100] Creating Layer scale4c_branch2b
I1021 23:15:39.190461 25759 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I1021 23:15:39.190466 25759 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I1021 23:15:39.190544 25759 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1021 23:15:39.190743 25759 net.cpp:150] Setting up scale4c_branch2b
I1021 23:15:39.190750 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.190753 25759 net.cpp:165] Memory required for data: 4797235284
I1021 23:15:39.190758 25759 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I1021 23:15:39.190764 25759 net.cpp:100] Creating Layer res4c_branch2b_relu
I1021 23:15:39.190768 25759 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I1021 23:15:39.190771 25759 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I1021 23:15:39.191597 25759 net.cpp:150] Setting up res4c_branch2b_relu
I1021 23:15:39.191607 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.191609 25759 net.cpp:165] Memory required for data: 4802150484
I1021 23:15:39.191628 25759 layer_factory.hpp:77] Creating layer res4c_branch2c
I1021 23:15:39.191637 25759 net.cpp:100] Creating Layer res4c_branch2c
I1021 23:15:39.191642 25759 net.cpp:444] res4c_branch2c <- res4c_branch2b
I1021 23:15:39.191648 25759 net.cpp:418] res4c_branch2c -> res4c_branch2c
I1021 23:15:39.198561 25759 net.cpp:150] Setting up res4c_branch2c
I1021 23:15:39.198593 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.198596 25759 net.cpp:165] Memory required for data: 4821811284
I1021 23:15:39.198603 25759 layer_factory.hpp:77] Creating layer bn4c_branch2c
I1021 23:15:39.198613 25759 net.cpp:100] Creating Layer bn4c_branch2c
I1021 23:15:39.198617 25759 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I1021 23:15:39.198623 25759 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I1021 23:15:39.199023 25759 net.cpp:150] Setting up bn4c_branch2c
I1021 23:15:39.199030 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.199033 25759 net.cpp:165] Memory required for data: 4841472084
I1021 23:15:39.199054 25759 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1021 23:15:39.199062 25759 net.cpp:100] Creating Layer scale4c_branch2c
I1021 23:15:39.199065 25759 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I1021 23:15:39.199070 25759 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I1021 23:15:39.199143 25759 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1021 23:15:39.199367 25759 net.cpp:150] Setting up scale4c_branch2c
I1021 23:15:39.199373 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.199376 25759 net.cpp:165] Memory required for data: 4861132884
I1021 23:15:39.199383 25759 layer_factory.hpp:77] Creating layer res4c
I1021 23:15:39.199390 25759 net.cpp:100] Creating Layer res4c
I1021 23:15:39.199393 25759 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I1021 23:15:39.199398 25759 net.cpp:444] res4c <- res4c_branch2c
I1021 23:15:39.199403 25759 net.cpp:418] res4c -> res4c
I1021 23:15:39.199440 25759 net.cpp:150] Setting up res4c
I1021 23:15:39.199447 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.199450 25759 net.cpp:165] Memory required for data: 4880793684
I1021 23:15:39.199453 25759 layer_factory.hpp:77] Creating layer res4c_relu
I1021 23:15:39.199457 25759 net.cpp:100] Creating Layer res4c_relu
I1021 23:15:39.199460 25759 net.cpp:444] res4c_relu <- res4c
I1021 23:15:39.199466 25759 net.cpp:405] res4c_relu -> res4c (in-place)
I1021 23:15:39.199685 25759 net.cpp:150] Setting up res4c_relu
I1021 23:15:39.199708 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.199712 25759 net.cpp:165] Memory required for data: 4900454484
I1021 23:15:39.199714 25759 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I1021 23:15:39.199721 25759 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I1021 23:15:39.199724 25759 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I1021 23:15:39.199729 25759 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I1021 23:15:39.199735 25759 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I1021 23:15:39.199802 25759 net.cpp:150] Setting up res4c_res4c_relu_0_split
I1021 23:15:39.199810 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.199815 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.199816 25759 net.cpp:165] Memory required for data: 4939776084
I1021 23:15:39.199820 25759 layer_factory.hpp:77] Creating layer res4d_branch2a
I1021 23:15:39.199827 25759 net.cpp:100] Creating Layer res4d_branch2a
I1021 23:15:39.199831 25759 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I1021 23:15:39.199836 25759 net.cpp:418] res4d_branch2a -> res4d_branch2a
I1021 23:15:39.201581 25759 net.cpp:150] Setting up res4d_branch2a
I1021 23:15:39.201593 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.201611 25759 net.cpp:165] Memory required for data: 4944691284
I1021 23:15:39.201616 25759 layer_factory.hpp:77] Creating layer bn4d_branch2a
I1021 23:15:39.201623 25759 net.cpp:100] Creating Layer bn4d_branch2a
I1021 23:15:39.201627 25759 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I1021 23:15:39.201632 25759 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I1021 23:15:39.202050 25759 net.cpp:150] Setting up bn4d_branch2a
I1021 23:15:39.202057 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.202060 25759 net.cpp:165] Memory required for data: 4949606484
I1021 23:15:39.202081 25759 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1021 23:15:39.202088 25759 net.cpp:100] Creating Layer scale4d_branch2a
I1021 23:15:39.202092 25759 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I1021 23:15:39.202097 25759 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I1021 23:15:39.202177 25759 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1021 23:15:39.202380 25759 net.cpp:150] Setting up scale4d_branch2a
I1021 23:15:39.202389 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.202390 25759 net.cpp:165] Memory required for data: 4954521684
I1021 23:15:39.202395 25759 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I1021 23:15:39.202400 25759 net.cpp:100] Creating Layer res4d_branch2a_relu
I1021 23:15:39.202404 25759 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I1021 23:15:39.202409 25759 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I1021 23:15:39.202636 25759 net.cpp:150] Setting up res4d_branch2a_relu
I1021 23:15:39.202646 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.202648 25759 net.cpp:165] Memory required for data: 4959436884
I1021 23:15:39.202651 25759 layer_factory.hpp:77] Creating layer res4d_branch2b
I1021 23:15:39.202661 25759 net.cpp:100] Creating Layer res4d_branch2b
I1021 23:15:39.202666 25759 net.cpp:444] res4d_branch2b <- res4d_branch2a
I1021 23:15:39.202672 25759 net.cpp:418] res4d_branch2b -> res4d_branch2b
I1021 23:15:39.213994 25759 net.cpp:150] Setting up res4d_branch2b
I1021 23:15:39.214032 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.214035 25759 net.cpp:165] Memory required for data: 4964352084
I1021 23:15:39.214046 25759 layer_factory.hpp:77] Creating layer bn4d_branch2b
I1021 23:15:39.214057 25759 net.cpp:100] Creating Layer bn4d_branch2b
I1021 23:15:39.214061 25759 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I1021 23:15:39.214069 25759 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I1021 23:15:39.214504 25759 net.cpp:150] Setting up bn4d_branch2b
I1021 23:15:39.214511 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.214514 25759 net.cpp:165] Memory required for data: 4969267284
I1021 23:15:39.214536 25759 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1021 23:15:39.214545 25759 net.cpp:100] Creating Layer scale4d_branch2b
I1021 23:15:39.214550 25759 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I1021 23:15:39.214555 25759 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I1021 23:15:39.214639 25759 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1021 23:15:39.214849 25759 net.cpp:150] Setting up scale4d_branch2b
I1021 23:15:39.214856 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.214859 25759 net.cpp:165] Memory required for data: 4974182484
I1021 23:15:39.214864 25759 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I1021 23:15:39.214871 25759 net.cpp:100] Creating Layer res4d_branch2b_relu
I1021 23:15:39.214874 25759 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I1021 23:15:39.214879 25759 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I1021 23:15:39.215754 25759 net.cpp:150] Setting up res4d_branch2b_relu
I1021 23:15:39.215766 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.215785 25759 net.cpp:165] Memory required for data: 4979097684
I1021 23:15:39.215787 25759 layer_factory.hpp:77] Creating layer res4d_branch2c
I1021 23:15:39.215796 25759 net.cpp:100] Creating Layer res4d_branch2c
I1021 23:15:39.215801 25759 net.cpp:444] res4d_branch2c <- res4d_branch2b
I1021 23:15:39.215808 25759 net.cpp:418] res4d_branch2c -> res4d_branch2c
I1021 23:15:39.219977 25759 net.cpp:150] Setting up res4d_branch2c
I1021 23:15:39.219991 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.220010 25759 net.cpp:165] Memory required for data: 4998758484
I1021 23:15:39.220016 25759 layer_factory.hpp:77] Creating layer bn4d_branch2c
I1021 23:15:39.220022 25759 net.cpp:100] Creating Layer bn4d_branch2c
I1021 23:15:39.220027 25759 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I1021 23:15:39.220034 25759 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I1021 23:15:39.220448 25759 net.cpp:150] Setting up bn4d_branch2c
I1021 23:15:39.220454 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.220458 25759 net.cpp:165] Memory required for data: 5018419284
I1021 23:15:39.220479 25759 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1021 23:15:39.220485 25759 net.cpp:100] Creating Layer scale4d_branch2c
I1021 23:15:39.220489 25759 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I1021 23:15:39.220495 25759 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I1021 23:15:39.220571 25759 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1021 23:15:39.220801 25759 net.cpp:150] Setting up scale4d_branch2c
I1021 23:15:39.220809 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.220813 25759 net.cpp:165] Memory required for data: 5038080084
I1021 23:15:39.220818 25759 layer_factory.hpp:77] Creating layer res4d
I1021 23:15:39.220824 25759 net.cpp:100] Creating Layer res4d
I1021 23:15:39.220826 25759 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I1021 23:15:39.220830 25759 net.cpp:444] res4d <- res4d_branch2c
I1021 23:15:39.220835 25759 net.cpp:418] res4d -> res4d
I1021 23:15:39.220875 25759 net.cpp:150] Setting up res4d
I1021 23:15:39.220881 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.220885 25759 net.cpp:165] Memory required for data: 5057740884
I1021 23:15:39.220887 25759 layer_factory.hpp:77] Creating layer res4d_relu
I1021 23:15:39.220892 25759 net.cpp:100] Creating Layer res4d_relu
I1021 23:15:39.220896 25759 net.cpp:444] res4d_relu <- res4d
I1021 23:15:39.220899 25759 net.cpp:405] res4d_relu -> res4d (in-place)
I1021 23:15:39.221103 25759 net.cpp:150] Setting up res4d_relu
I1021 23:15:39.221113 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.221115 25759 net.cpp:165] Memory required for data: 5077401684
I1021 23:15:39.221118 25759 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I1021 23:15:39.221124 25759 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I1021 23:15:39.221127 25759 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I1021 23:15:39.221133 25759 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I1021 23:15:39.221139 25759 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I1021 23:15:39.221209 25759 net.cpp:150] Setting up res4d_res4d_relu_0_split
I1021 23:15:39.221215 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.221220 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.221221 25759 net.cpp:165] Memory required for data: 5116723284
I1021 23:15:39.221225 25759 layer_factory.hpp:77] Creating layer res4e_branch2a
I1021 23:15:39.221233 25759 net.cpp:100] Creating Layer res4e_branch2a
I1021 23:15:39.221236 25759 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I1021 23:15:39.221242 25759 net.cpp:418] res4e_branch2a -> res4e_branch2a
I1021 23:15:39.224156 25759 net.cpp:150] Setting up res4e_branch2a
I1021 23:15:39.224169 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.224171 25759 net.cpp:165] Memory required for data: 5121638484
I1021 23:15:39.224191 25759 layer_factory.hpp:77] Creating layer bn4e_branch2a
I1021 23:15:39.224200 25759 net.cpp:100] Creating Layer bn4e_branch2a
I1021 23:15:39.224203 25759 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I1021 23:15:39.224210 25759 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I1021 23:15:39.224591 25759 net.cpp:150] Setting up bn4e_branch2a
I1021 23:15:39.224599 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.224602 25759 net.cpp:165] Memory required for data: 5126553684
I1021 23:15:39.224637 25759 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1021 23:15:39.224644 25759 net.cpp:100] Creating Layer scale4e_branch2a
I1021 23:15:39.224648 25759 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I1021 23:15:39.224653 25759 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I1021 23:15:39.224720 25759 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1021 23:15:39.224927 25759 net.cpp:150] Setting up scale4e_branch2a
I1021 23:15:39.224936 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.224937 25759 net.cpp:165] Memory required for data: 5131468884
I1021 23:15:39.224942 25759 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I1021 23:15:39.224949 25759 net.cpp:100] Creating Layer res4e_branch2a_relu
I1021 23:15:39.224952 25759 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I1021 23:15:39.224956 25759 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I1021 23:15:39.225160 25759 net.cpp:150] Setting up res4e_branch2a_relu
I1021 23:15:39.225169 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.225172 25759 net.cpp:165] Memory required for data: 5136384084
I1021 23:15:39.225175 25759 layer_factory.hpp:77] Creating layer res4e_branch2b
I1021 23:15:39.225183 25759 net.cpp:100] Creating Layer res4e_branch2b
I1021 23:15:39.225186 25759 net.cpp:444] res4e_branch2b <- res4e_branch2a
I1021 23:15:39.225191 25759 net.cpp:418] res4e_branch2b -> res4e_branch2b
I1021 23:15:39.229562 25759 net.cpp:150] Setting up res4e_branch2b
I1021 23:15:39.229575 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.229593 25759 net.cpp:165] Memory required for data: 5141299284
I1021 23:15:39.229599 25759 layer_factory.hpp:77] Creating layer bn4e_branch2b
I1021 23:15:39.229605 25759 net.cpp:100] Creating Layer bn4e_branch2b
I1021 23:15:39.229609 25759 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I1021 23:15:39.229615 25759 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I1021 23:15:39.230032 25759 net.cpp:150] Setting up bn4e_branch2b
I1021 23:15:39.230039 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.230041 25759 net.cpp:165] Memory required for data: 5146214484
I1021 23:15:39.230062 25759 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1021 23:15:39.230070 25759 net.cpp:100] Creating Layer scale4e_branch2b
I1021 23:15:39.230072 25759 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I1021 23:15:39.230078 25759 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I1021 23:15:39.230156 25759 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1021 23:15:39.230362 25759 net.cpp:150] Setting up scale4e_branch2b
I1021 23:15:39.230370 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.230372 25759 net.cpp:165] Memory required for data: 5151129684
I1021 23:15:39.230376 25759 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I1021 23:15:39.230381 25759 net.cpp:100] Creating Layer res4e_branch2b_relu
I1021 23:15:39.230384 25759 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I1021 23:15:39.230389 25759 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I1021 23:15:39.231220 25759 net.cpp:150] Setting up res4e_branch2b_relu
I1021 23:15:39.231230 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.231232 25759 net.cpp:165] Memory required for data: 5156044884
I1021 23:15:39.231251 25759 layer_factory.hpp:77] Creating layer res4e_branch2c
I1021 23:15:39.231259 25759 net.cpp:100] Creating Layer res4e_branch2c
I1021 23:15:39.231262 25759 net.cpp:444] res4e_branch2c <- res4e_branch2b
I1021 23:15:39.231268 25759 net.cpp:418] res4e_branch2c -> res4e_branch2c
I1021 23:15:39.234679 25759 net.cpp:150] Setting up res4e_branch2c
I1021 23:15:39.234691 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.234709 25759 net.cpp:165] Memory required for data: 5175705684
I1021 23:15:39.234714 25759 layer_factory.hpp:77] Creating layer bn4e_branch2c
I1021 23:15:39.234721 25759 net.cpp:100] Creating Layer bn4e_branch2c
I1021 23:15:39.234725 25759 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I1021 23:15:39.234731 25759 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I1021 23:15:39.235121 25759 net.cpp:150] Setting up bn4e_branch2c
I1021 23:15:39.235127 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.235129 25759 net.cpp:165] Memory required for data: 5195366484
I1021 23:15:39.235152 25759 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1021 23:15:39.235158 25759 net.cpp:100] Creating Layer scale4e_branch2c
I1021 23:15:39.235162 25759 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I1021 23:15:39.235167 25759 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I1021 23:15:39.235241 25759 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1021 23:15:39.235453 25759 net.cpp:150] Setting up scale4e_branch2c
I1021 23:15:39.235460 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.235462 25759 net.cpp:165] Memory required for data: 5215027284
I1021 23:15:39.235468 25759 layer_factory.hpp:77] Creating layer res4e
I1021 23:15:39.235473 25759 net.cpp:100] Creating Layer res4e
I1021 23:15:39.235476 25759 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I1021 23:15:39.235479 25759 net.cpp:444] res4e <- res4e_branch2c
I1021 23:15:39.235483 25759 net.cpp:418] res4e -> res4e
I1021 23:15:39.235522 25759 net.cpp:150] Setting up res4e
I1021 23:15:39.235528 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.235532 25759 net.cpp:165] Memory required for data: 5234688084
I1021 23:15:39.235533 25759 layer_factory.hpp:77] Creating layer res4e_relu
I1021 23:15:39.235538 25759 net.cpp:100] Creating Layer res4e_relu
I1021 23:15:39.235540 25759 net.cpp:444] res4e_relu <- res4e
I1021 23:15:39.235544 25759 net.cpp:405] res4e_relu -> res4e (in-place)
I1021 23:15:39.235761 25759 net.cpp:150] Setting up res4e_relu
I1021 23:15:39.235770 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.235772 25759 net.cpp:165] Memory required for data: 5254348884
I1021 23:15:39.235775 25759 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I1021 23:15:39.235780 25759 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I1021 23:15:39.235783 25759 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I1021 23:15:39.235790 25759 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I1021 23:15:39.235796 25759 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I1021 23:15:39.235882 25759 net.cpp:150] Setting up res4e_res4e_relu_0_split
I1021 23:15:39.235888 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.235893 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.235895 25759 net.cpp:165] Memory required for data: 5293670484
I1021 23:15:39.235898 25759 layer_factory.hpp:77] Creating layer res4f_branch2a
I1021 23:15:39.235906 25759 net.cpp:100] Creating Layer res4f_branch2a
I1021 23:15:39.235909 25759 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I1021 23:15:39.235915 25759 net.cpp:418] res4f_branch2a -> res4f_branch2a
I1021 23:15:39.238402 25759 net.cpp:150] Setting up res4f_branch2a
I1021 23:15:39.238416 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.238435 25759 net.cpp:165] Memory required for data: 5298585684
I1021 23:15:39.238440 25759 layer_factory.hpp:77] Creating layer bn4f_branch2a
I1021 23:15:39.238445 25759 net.cpp:100] Creating Layer bn4f_branch2a
I1021 23:15:39.238449 25759 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I1021 23:15:39.238456 25759 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I1021 23:15:39.238847 25759 net.cpp:150] Setting up bn4f_branch2a
I1021 23:15:39.238854 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.238857 25759 net.cpp:165] Memory required for data: 5303500884
I1021 23:15:39.238878 25759 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1021 23:15:39.238888 25759 net.cpp:100] Creating Layer scale4f_branch2a
I1021 23:15:39.238890 25759 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I1021 23:15:39.238895 25759 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I1021 23:15:39.238972 25759 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1021 23:15:39.239178 25759 net.cpp:150] Setting up scale4f_branch2a
I1021 23:15:39.239186 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.239188 25759 net.cpp:165] Memory required for data: 5308416084
I1021 23:15:39.239192 25759 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I1021 23:15:39.239197 25759 net.cpp:100] Creating Layer res4f_branch2a_relu
I1021 23:15:39.239200 25759 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I1021 23:15:39.239205 25759 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I1021 23:15:39.239400 25759 net.cpp:150] Setting up res4f_branch2a_relu
I1021 23:15:39.239408 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.239410 25759 net.cpp:165] Memory required for data: 5313331284
I1021 23:15:39.239413 25759 layer_factory.hpp:77] Creating layer res4f_branch2b
I1021 23:15:39.239421 25759 net.cpp:100] Creating Layer res4f_branch2b
I1021 23:15:39.239424 25759 net.cpp:444] res4f_branch2b <- res4f_branch2a
I1021 23:15:39.239431 25759 net.cpp:418] res4f_branch2b -> res4f_branch2b
I1021 23:15:39.244705 25759 net.cpp:150] Setting up res4f_branch2b
I1021 23:15:39.244719 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.244736 25759 net.cpp:165] Memory required for data: 5318246484
I1021 23:15:39.244742 25759 layer_factory.hpp:77] Creating layer bn4f_branch2b
I1021 23:15:39.244751 25759 net.cpp:100] Creating Layer bn4f_branch2b
I1021 23:15:39.244755 25759 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I1021 23:15:39.244760 25759 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I1021 23:15:39.245158 25759 net.cpp:150] Setting up bn4f_branch2b
I1021 23:15:39.245165 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.245168 25759 net.cpp:165] Memory required for data: 5323161684
I1021 23:15:39.245189 25759 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1021 23:15:39.245199 25759 net.cpp:100] Creating Layer scale4f_branch2b
I1021 23:15:39.245203 25759 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I1021 23:15:39.245206 25759 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I1021 23:15:39.245287 25759 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1021 23:15:39.245503 25759 net.cpp:150] Setting up scale4f_branch2b
I1021 23:15:39.245512 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.245513 25759 net.cpp:165] Memory required for data: 5328076884
I1021 23:15:39.245518 25759 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I1021 23:15:39.245525 25759 net.cpp:100] Creating Layer res4f_branch2b_relu
I1021 23:15:39.245528 25759 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I1021 23:15:39.245532 25759 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I1021 23:15:39.245748 25759 net.cpp:150] Setting up res4f_branch2b_relu
I1021 23:15:39.245759 25759 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I1021 23:15:39.245761 25759 net.cpp:165] Memory required for data: 5332992084
I1021 23:15:39.245764 25759 layer_factory.hpp:77] Creating layer res4f_branch2c
I1021 23:15:39.245771 25759 net.cpp:100] Creating Layer res4f_branch2c
I1021 23:15:39.245774 25759 net.cpp:444] res4f_branch2c <- res4f_branch2b
I1021 23:15:39.245781 25759 net.cpp:418] res4f_branch2c -> res4f_branch2c
I1021 23:15:39.249199 25759 net.cpp:150] Setting up res4f_branch2c
I1021 23:15:39.249228 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.249231 25759 net.cpp:165] Memory required for data: 5352652884
I1021 23:15:39.249236 25759 layer_factory.hpp:77] Creating layer bn4f_branch2c
I1021 23:15:39.249243 25759 net.cpp:100] Creating Layer bn4f_branch2c
I1021 23:15:39.249248 25759 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I1021 23:15:39.249253 25759 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I1021 23:15:39.249661 25759 net.cpp:150] Setting up bn4f_branch2c
I1021 23:15:39.249668 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.249671 25759 net.cpp:165] Memory required for data: 5372313684
I1021 23:15:39.249714 25759 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1021 23:15:39.249720 25759 net.cpp:100] Creating Layer scale4f_branch2c
I1021 23:15:39.249723 25759 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I1021 23:15:39.249743 25759 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I1021 23:15:39.249801 25759 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1021 23:15:39.250022 25759 net.cpp:150] Setting up scale4f_branch2c
I1021 23:15:39.250044 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.250047 25759 net.cpp:165] Memory required for data: 5391974484
I1021 23:15:39.250052 25759 layer_factory.hpp:77] Creating layer res4f
I1021 23:15:39.250059 25759 net.cpp:100] Creating Layer res4f
I1021 23:15:39.250062 25759 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I1021 23:15:39.250066 25759 net.cpp:444] res4f <- res4f_branch2c
I1021 23:15:39.250071 25759 net.cpp:418] res4f -> res4f
I1021 23:15:39.250111 25759 net.cpp:150] Setting up res4f
I1021 23:15:39.250118 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.250120 25759 net.cpp:165] Memory required for data: 5411635284
I1021 23:15:39.250123 25759 layer_factory.hpp:77] Creating layer res4f_relu
I1021 23:15:39.250128 25759 net.cpp:100] Creating Layer res4f_relu
I1021 23:15:39.250130 25759 net.cpp:444] res4f_relu <- res4f
I1021 23:15:39.250136 25759 net.cpp:405] res4f_relu -> res4f (in-place)
I1021 23:15:39.251024 25759 net.cpp:150] Setting up res4f_relu
I1021 23:15:39.251035 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.251037 25759 net.cpp:165] Memory required for data: 5431296084
I1021 23:15:39.251040 25759 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I1021 23:15:39.251065 25759 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I1021 23:15:39.251070 25759 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I1021 23:15:39.251075 25759 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I1021 23:15:39.251082 25759 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I1021 23:15:39.251087 25759 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I1021 23:15:39.251185 25759 net.cpp:150] Setting up res4f_res4f_relu_0_split
I1021 23:15:39.251193 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.251196 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.251199 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.251201 25759 net.cpp:165] Memory required for data: 5490278484
I1021 23:15:39.251204 25759 layer_factory.hpp:77] Creating layer res5a_branch1
I1021 23:15:39.251214 25759 net.cpp:100] Creating Layer res5a_branch1
I1021 23:15:39.251216 25759 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I1021 23:15:39.251224 25759 net.cpp:418] res5a_branch1 -> res5a_branch1
I1021 23:15:39.258292 25759 net.cpp:150] Setting up res5a_branch1
I1021 23:15:39.258304 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.258322 25759 net.cpp:165] Memory required for data: 5500108884
I1021 23:15:39.258327 25759 layer_factory.hpp:77] Creating layer bn5a_branch1
I1021 23:15:39.258337 25759 net.cpp:100] Creating Layer bn5a_branch1
I1021 23:15:39.258339 25759 net.cpp:444] bn5a_branch1 <- res5a_branch1
I1021 23:15:39.258344 25759 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I1021 23:15:39.258734 25759 net.cpp:150] Setting up bn5a_branch1
I1021 23:15:39.258741 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.258744 25759 net.cpp:165] Memory required for data: 5509939284
I1021 23:15:39.258765 25759 layer_factory.hpp:77] Creating layer scale5a_branch1
I1021 23:15:39.258772 25759 net.cpp:100] Creating Layer scale5a_branch1
I1021 23:15:39.258775 25759 net.cpp:444] scale5a_branch1 <- res5a_branch1
I1021 23:15:39.258782 25759 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I1021 23:15:39.258869 25759 layer_factory.hpp:77] Creating layer scale5a_branch1
I1021 23:15:39.259063 25759 net.cpp:150] Setting up scale5a_branch1
I1021 23:15:39.259070 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.259073 25759 net.cpp:165] Memory required for data: 5519769684
I1021 23:15:39.259078 25759 layer_factory.hpp:77] Creating layer res5a_branch2a
I1021 23:15:39.259086 25759 net.cpp:100] Creating Layer res5a_branch2a
I1021 23:15:39.259089 25759 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I1021 23:15:39.259094 25759 net.cpp:418] res5a_branch2a -> res5a_branch2a
I1021 23:15:39.264076 25759 net.cpp:150] Setting up res5a_branch2a
I1021 23:15:39.264088 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.264106 25759 net.cpp:165] Memory required for data: 5522227284
I1021 23:15:39.264111 25759 layer_factory.hpp:77] Creating layer bn5a_branch2a
I1021 23:15:39.264119 25759 net.cpp:100] Creating Layer bn5a_branch2a
I1021 23:15:39.264124 25759 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I1021 23:15:39.264130 25759 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I1021 23:15:39.264524 25759 net.cpp:150] Setting up bn5a_branch2a
I1021 23:15:39.264533 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.264551 25759 net.cpp:165] Memory required for data: 5524684884
I1021 23:15:39.264557 25759 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1021 23:15:39.264562 25759 net.cpp:100] Creating Layer scale5a_branch2a
I1021 23:15:39.264565 25759 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I1021 23:15:39.264572 25759 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I1021 23:15:39.264667 25759 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1021 23:15:39.264873 25759 net.cpp:150] Setting up scale5a_branch2a
I1021 23:15:39.264881 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.264884 25759 net.cpp:165] Memory required for data: 5527142484
I1021 23:15:39.264889 25759 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I1021 23:15:39.264894 25759 net.cpp:100] Creating Layer res5a_branch2a_relu
I1021 23:15:39.264897 25759 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I1021 23:15:39.264900 25759 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I1021 23:15:39.265107 25759 net.cpp:150] Setting up res5a_branch2a_relu
I1021 23:15:39.265116 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.265118 25759 net.cpp:165] Memory required for data: 5529600084
I1021 23:15:39.265121 25759 layer_factory.hpp:77] Creating layer res5a_branch2b
I1021 23:15:39.265130 25759 net.cpp:100] Creating Layer res5a_branch2b
I1021 23:15:39.265132 25759 net.cpp:444] res5a_branch2b <- res5a_branch2a
I1021 23:15:39.265139 25759 net.cpp:418] res5a_branch2b -> res5a_branch2b
I1021 23:15:39.270977 25759 net.cpp:150] Setting up res5a_branch2b
I1021 23:15:39.270988 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.270992 25759 net.cpp:165] Memory required for data: 5532057684
I1021 23:15:39.271011 25759 layer_factory.hpp:77] Creating layer bn5a_branch2b
I1021 23:15:39.271019 25759 net.cpp:100] Creating Layer bn5a_branch2b
I1021 23:15:39.271023 25759 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I1021 23:15:39.271029 25759 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I1021 23:15:39.271422 25759 net.cpp:150] Setting up bn5a_branch2b
I1021 23:15:39.271430 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.271432 25759 net.cpp:165] Memory required for data: 5534515284
I1021 23:15:39.271453 25759 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1021 23:15:39.271461 25759 net.cpp:100] Creating Layer scale5a_branch2b
I1021 23:15:39.271463 25759 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I1021 23:15:39.271468 25759 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I1021 23:15:39.271548 25759 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1021 23:15:39.271755 25759 net.cpp:150] Setting up scale5a_branch2b
I1021 23:15:39.271762 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.271765 25759 net.cpp:165] Memory required for data: 5536972884
I1021 23:15:39.271770 25759 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I1021 23:15:39.271775 25759 net.cpp:100] Creating Layer res5a_branch2b_relu
I1021 23:15:39.271778 25759 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I1021 23:15:39.271781 25759 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I1021 23:15:39.271996 25759 net.cpp:150] Setting up res5a_branch2b_relu
I1021 23:15:39.272006 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.272009 25759 net.cpp:165] Memory required for data: 5539430484
I1021 23:15:39.272011 25759 layer_factory.hpp:77] Creating layer res5a_branch2c
I1021 23:15:39.272018 25759 net.cpp:100] Creating Layer res5a_branch2c
I1021 23:15:39.272022 25759 net.cpp:444] res5a_branch2c <- res5a_branch2b
I1021 23:15:39.272027 25759 net.cpp:418] res5a_branch2c -> res5a_branch2c
I1021 23:15:39.276571 25759 net.cpp:150] Setting up res5a_branch2c
I1021 23:15:39.276583 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.276587 25759 net.cpp:165] Memory required for data: 5549260884
I1021 23:15:39.276592 25759 layer_factory.hpp:77] Creating layer bn5a_branch2c
I1021 23:15:39.276618 25759 net.cpp:100] Creating Layer bn5a_branch2c
I1021 23:15:39.276623 25759 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I1021 23:15:39.276631 25759 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I1021 23:15:39.277014 25759 net.cpp:150] Setting up bn5a_branch2c
I1021 23:15:39.277020 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.277022 25759 net.cpp:165] Memory required for data: 5559091284
I1021 23:15:39.277045 25759 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1021 23:15:39.277052 25759 net.cpp:100] Creating Layer scale5a_branch2c
I1021 23:15:39.277055 25759 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I1021 23:15:39.277061 25759 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I1021 23:15:39.277146 25759 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1021 23:15:39.277344 25759 net.cpp:150] Setting up scale5a_branch2c
I1021 23:15:39.277351 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.277354 25759 net.cpp:165] Memory required for data: 5568921684
I1021 23:15:39.277359 25759 layer_factory.hpp:77] Creating layer res5a
I1021 23:15:39.277366 25759 net.cpp:100] Creating Layer res5a
I1021 23:15:39.277369 25759 net.cpp:444] res5a <- res5a_branch1
I1021 23:15:39.277372 25759 net.cpp:444] res5a <- res5a_branch2c
I1021 23:15:39.277377 25759 net.cpp:418] res5a -> res5a
I1021 23:15:39.277415 25759 net.cpp:150] Setting up res5a
I1021 23:15:39.277420 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.277423 25759 net.cpp:165] Memory required for data: 5578752084
I1021 23:15:39.277426 25759 layer_factory.hpp:77] Creating layer res5a_relu
I1021 23:15:39.277432 25759 net.cpp:100] Creating Layer res5a_relu
I1021 23:15:39.277436 25759 net.cpp:444] res5a_relu <- res5a
I1021 23:15:39.277441 25759 net.cpp:405] res5a_relu -> res5a (in-place)
I1021 23:15:39.278300 25759 net.cpp:150] Setting up res5a_relu
I1021 23:15:39.278311 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.278312 25759 net.cpp:165] Memory required for data: 5588582484
I1021 23:15:39.278331 25759 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I1021 23:15:39.278337 25759 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I1021 23:15:39.278340 25759 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I1021 23:15:39.278348 25759 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I1021 23:15:39.278355 25759 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I1021 23:15:39.278447 25759 net.cpp:150] Setting up res5a_res5a_relu_0_split
I1021 23:15:39.278455 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.278460 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.278461 25759 net.cpp:165] Memory required for data: 5608243284
I1021 23:15:39.278465 25759 layer_factory.hpp:77] Creating layer res5b_branch2a
I1021 23:15:39.278472 25759 net.cpp:100] Creating Layer res5b_branch2a
I1021 23:15:39.278475 25759 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I1021 23:15:39.278481 25759 net.cpp:418] res5b_branch2a -> res5b_branch2a
I1021 23:15:39.283977 25759 net.cpp:150] Setting up res5b_branch2a
I1021 23:15:39.283988 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.284008 25759 net.cpp:165] Memory required for data: 5610700884
I1021 23:15:39.284013 25759 layer_factory.hpp:77] Creating layer bn5b_branch2a
I1021 23:15:39.284020 25759 net.cpp:100] Creating Layer bn5b_branch2a
I1021 23:15:39.284025 25759 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I1021 23:15:39.284031 25759 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I1021 23:15:39.284431 25759 net.cpp:150] Setting up bn5b_branch2a
I1021 23:15:39.284440 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.284441 25759 net.cpp:165] Memory required for data: 5613158484
I1021 23:15:39.284463 25759 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1021 23:15:39.284469 25759 net.cpp:100] Creating Layer scale5b_branch2a
I1021 23:15:39.284473 25759 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I1021 23:15:39.284477 25759 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I1021 23:15:39.284556 25759 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1021 23:15:39.284781 25759 net.cpp:150] Setting up scale5b_branch2a
I1021 23:15:39.284790 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.284791 25759 net.cpp:165] Memory required for data: 5615616084
I1021 23:15:39.284796 25759 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I1021 23:15:39.284801 25759 net.cpp:100] Creating Layer res5b_branch2a_relu
I1021 23:15:39.284806 25759 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I1021 23:15:39.284809 25759 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I1021 23:15:39.285015 25759 net.cpp:150] Setting up res5b_branch2a_relu
I1021 23:15:39.285024 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.285027 25759 net.cpp:165] Memory required for data: 5618073684
I1021 23:15:39.285029 25759 layer_factory.hpp:77] Creating layer res5b_branch2b
I1021 23:15:39.285037 25759 net.cpp:100] Creating Layer res5b_branch2b
I1021 23:15:39.285039 25759 net.cpp:444] res5b_branch2b <- res5b_branch2a
I1021 23:15:39.285046 25759 net.cpp:418] res5b_branch2b -> res5b_branch2b
I1021 23:15:39.290912 25759 net.cpp:150] Setting up res5b_branch2b
I1021 23:15:39.290925 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.290943 25759 net.cpp:165] Memory required for data: 5620531284
I1021 23:15:39.290947 25759 layer_factory.hpp:77] Creating layer bn5b_branch2b
I1021 23:15:39.290954 25759 net.cpp:100] Creating Layer bn5b_branch2b
I1021 23:15:39.290957 25759 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I1021 23:15:39.290964 25759 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I1021 23:15:39.291365 25759 net.cpp:150] Setting up bn5b_branch2b
I1021 23:15:39.291373 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.291374 25759 net.cpp:165] Memory required for data: 5622988884
I1021 23:15:39.291395 25759 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1021 23:15:39.291404 25759 net.cpp:100] Creating Layer scale5b_branch2b
I1021 23:15:39.291406 25759 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I1021 23:15:39.291414 25759 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I1021 23:15:39.291488 25759 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1021 23:15:39.291698 25759 net.cpp:150] Setting up scale5b_branch2b
I1021 23:15:39.291705 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.291708 25759 net.cpp:165] Memory required for data: 5625446484
I1021 23:15:39.291713 25759 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I1021 23:15:39.291718 25759 net.cpp:100] Creating Layer res5b_branch2b_relu
I1021 23:15:39.291721 25759 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I1021 23:15:39.291725 25759 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I1021 23:15:39.291939 25759 net.cpp:150] Setting up res5b_branch2b_relu
I1021 23:15:39.291949 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.291950 25759 net.cpp:165] Memory required for data: 5627904084
I1021 23:15:39.291954 25759 layer_factory.hpp:77] Creating layer res5b_branch2c
I1021 23:15:39.291962 25759 net.cpp:100] Creating Layer res5b_branch2c
I1021 23:15:39.291965 25759 net.cpp:444] res5b_branch2c <- res5b_branch2b
I1021 23:15:39.291971 25759 net.cpp:418] res5b_branch2c -> res5b_branch2c
I1021 23:15:39.297245 25759 net.cpp:150] Setting up res5b_branch2c
I1021 23:15:39.297256 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.297260 25759 net.cpp:165] Memory required for data: 5637734484
I1021 23:15:39.297264 25759 layer_factory.hpp:77] Creating layer bn5b_branch2c
I1021 23:15:39.297287 25759 net.cpp:100] Creating Layer bn5b_branch2c
I1021 23:15:39.297292 25759 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I1021 23:15:39.297297 25759 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I1021 23:15:39.297721 25759 net.cpp:150] Setting up bn5b_branch2c
I1021 23:15:39.297727 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.297729 25759 net.cpp:165] Memory required for data: 5647564884
I1021 23:15:39.297751 25759 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1021 23:15:39.297758 25759 net.cpp:100] Creating Layer scale5b_branch2c
I1021 23:15:39.297761 25759 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I1021 23:15:39.297767 25759 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I1021 23:15:39.297854 25759 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1021 23:15:39.298059 25759 net.cpp:150] Setting up scale5b_branch2c
I1021 23:15:39.298066 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.298069 25759 net.cpp:165] Memory required for data: 5657395284
I1021 23:15:39.298074 25759 layer_factory.hpp:77] Creating layer res5b
I1021 23:15:39.298081 25759 net.cpp:100] Creating Layer res5b
I1021 23:15:39.298084 25759 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I1021 23:15:39.298089 25759 net.cpp:444] res5b <- res5b_branch2c
I1021 23:15:39.298092 25759 net.cpp:418] res5b -> res5b
I1021 23:15:39.298149 25759 net.cpp:150] Setting up res5b
I1021 23:15:39.298156 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.298159 25759 net.cpp:165] Memory required for data: 5667225684
I1021 23:15:39.298161 25759 layer_factory.hpp:77] Creating layer res5b_relu
I1021 23:15:39.298166 25759 net.cpp:100] Creating Layer res5b_relu
I1021 23:15:39.298168 25759 net.cpp:444] res5b_relu <- res5b
I1021 23:15:39.298172 25759 net.cpp:405] res5b_relu -> res5b (in-place)
I1021 23:15:39.299082 25759 net.cpp:150] Setting up res5b_relu
I1021 23:15:39.299093 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.299094 25759 net.cpp:165] Memory required for data: 5677056084
I1021 23:15:39.299113 25759 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I1021 23:15:39.299119 25759 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I1021 23:15:39.299123 25759 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I1021 23:15:39.299129 25759 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I1021 23:15:39.299134 25759 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I1021 23:15:39.299224 25759 net.cpp:150] Setting up res5b_res5b_relu_0_split
I1021 23:15:39.299232 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.299235 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.299237 25759 net.cpp:165] Memory required for data: 5696716884
I1021 23:15:39.299240 25759 layer_factory.hpp:77] Creating layer res5c_branch2a
I1021 23:15:39.299248 25759 net.cpp:100] Creating Layer res5c_branch2a
I1021 23:15:39.299252 25759 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I1021 23:15:39.299257 25759 net.cpp:418] res5c_branch2a -> res5c_branch2a
I1021 23:15:39.305922 25759 net.cpp:150] Setting up res5c_branch2a
I1021 23:15:39.305934 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.305953 25759 net.cpp:165] Memory required for data: 5699174484
I1021 23:15:39.305958 25759 layer_factory.hpp:77] Creating layer bn5c_branch2a
I1021 23:15:39.305965 25759 net.cpp:100] Creating Layer bn5c_branch2a
I1021 23:15:39.305970 25759 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I1021 23:15:39.305974 25759 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I1021 23:15:39.306377 25759 net.cpp:150] Setting up bn5c_branch2a
I1021 23:15:39.306385 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.306387 25759 net.cpp:165] Memory required for data: 5701632084
I1021 23:15:39.306409 25759 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1021 23:15:39.306414 25759 net.cpp:100] Creating Layer scale5c_branch2a
I1021 23:15:39.306417 25759 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I1021 23:15:39.306423 25759 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I1021 23:15:39.306504 25759 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1021 23:15:39.306723 25759 net.cpp:150] Setting up scale5c_branch2a
I1021 23:15:39.306730 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.306733 25759 net.cpp:165] Memory required for data: 5704089684
I1021 23:15:39.306738 25759 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I1021 23:15:39.306743 25759 net.cpp:100] Creating Layer res5c_branch2a_relu
I1021 23:15:39.306746 25759 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I1021 23:15:39.306752 25759 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I1021 23:15:39.306963 25759 net.cpp:150] Setting up res5c_branch2a_relu
I1021 23:15:39.306972 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.306974 25759 net.cpp:165] Memory required for data: 5706547284
I1021 23:15:39.306977 25759 layer_factory.hpp:77] Creating layer res5c_branch2b
I1021 23:15:39.306987 25759 net.cpp:100] Creating Layer res5c_branch2b
I1021 23:15:39.306989 25759 net.cpp:444] res5c_branch2b <- res5c_branch2a
I1021 23:15:39.306996 25759 net.cpp:418] res5c_branch2b -> res5c_branch2b
I1021 23:15:39.313045 25759 net.cpp:150] Setting up res5c_branch2b
I1021 23:15:39.313056 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.313074 25759 net.cpp:165] Memory required for data: 5709004884
I1021 23:15:39.313079 25759 layer_factory.hpp:77] Creating layer bn5c_branch2b
I1021 23:15:39.313087 25759 net.cpp:100] Creating Layer bn5c_branch2b
I1021 23:15:39.313092 25759 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I1021 23:15:39.313100 25759 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I1021 23:15:39.313525 25759 net.cpp:150] Setting up bn5c_branch2b
I1021 23:15:39.313534 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.313536 25759 net.cpp:165] Memory required for data: 5711462484
I1021 23:15:39.313558 25759 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1021 23:15:39.313565 25759 net.cpp:100] Creating Layer scale5c_branch2b
I1021 23:15:39.313567 25759 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I1021 23:15:39.313575 25759 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I1021 23:15:39.313653 25759 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1021 23:15:39.313881 25759 net.cpp:150] Setting up scale5c_branch2b
I1021 23:15:39.313889 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.313891 25759 net.cpp:165] Memory required for data: 5713920084
I1021 23:15:39.313896 25759 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I1021 23:15:39.313901 25759 net.cpp:100] Creating Layer res5c_branch2b_relu
I1021 23:15:39.313905 25759 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I1021 23:15:39.313910 25759 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I1021 23:15:39.314151 25759 net.cpp:150] Setting up res5c_branch2b_relu
I1021 23:15:39.314159 25759 net.cpp:157] Top shape: 1 512 30 40 (614400)
I1021 23:15:39.314162 25759 net.cpp:165] Memory required for data: 5716377684
I1021 23:15:39.314164 25759 layer_factory.hpp:77] Creating layer res5c_branch2c
I1021 23:15:39.314173 25759 net.cpp:100] Creating Layer res5c_branch2c
I1021 23:15:39.314177 25759 net.cpp:444] res5c_branch2c <- res5c_branch2b
I1021 23:15:39.314183 25759 net.cpp:418] res5c_branch2c -> res5c_branch2c
I1021 23:15:39.320029 25759 net.cpp:150] Setting up res5c_branch2c
I1021 23:15:39.320044 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.320049 25759 net.cpp:165] Memory required for data: 5726208084
I1021 23:15:39.320070 25759 layer_factory.hpp:77] Creating layer bn5c_branch2c
I1021 23:15:39.320077 25759 net.cpp:100] Creating Layer bn5c_branch2c
I1021 23:15:39.320080 25759 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I1021 23:15:39.320087 25759 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I1021 23:15:39.320488 25759 net.cpp:150] Setting up bn5c_branch2c
I1021 23:15:39.320494 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.320497 25759 net.cpp:165] Memory required for data: 5736038484
I1021 23:15:39.320520 25759 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1021 23:15:39.320528 25759 net.cpp:100] Creating Layer scale5c_branch2c
I1021 23:15:39.320530 25759 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I1021 23:15:39.320535 25759 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I1021 23:15:39.320636 25759 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1021 23:15:39.320866 25759 net.cpp:150] Setting up scale5c_branch2c
I1021 23:15:39.320873 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.320876 25759 net.cpp:165] Memory required for data: 5745868884
I1021 23:15:39.320881 25759 layer_factory.hpp:77] Creating layer res5c
I1021 23:15:39.320886 25759 net.cpp:100] Creating Layer res5c
I1021 23:15:39.320890 25759 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I1021 23:15:39.320894 25759 net.cpp:444] res5c <- res5c_branch2c
I1021 23:15:39.320900 25759 net.cpp:418] res5c -> res5c
I1021 23:15:39.320942 25759 net.cpp:150] Setting up res5c
I1021 23:15:39.320948 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.320951 25759 net.cpp:165] Memory required for data: 5755699284
I1021 23:15:39.320955 25759 layer_factory.hpp:77] Creating layer res5c_relu
I1021 23:15:39.320960 25759 net.cpp:100] Creating Layer res5c_relu
I1021 23:15:39.320962 25759 net.cpp:444] res5c_relu <- res5c
I1021 23:15:39.320966 25759 net.cpp:405] res5c_relu -> res5c (in-place)
I1021 23:15:39.321175 25759 net.cpp:150] Setting up res5c_relu
I1021 23:15:39.321185 25759 net.cpp:157] Top shape: 1 2048 30 40 (2457600)
I1021 23:15:39.321188 25759 net.cpp:165] Memory required for data: 5765529684
I1021 23:15:39.321190 25759 layer_factory.hpp:77] Creating layer upP4
I1021 23:15:39.321197 25759 net.cpp:100] Creating Layer upP4
I1021 23:15:39.321200 25759 net.cpp:444] upP4 <- res5c
I1021 23:15:39.321207 25759 net.cpp:418] upP4 -> upP4
I1021 23:15:39.322899 25759 net.cpp:150] Setting up upP4
I1021 23:15:39.322909 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.322927 25759 net.cpp:165] Memory required for data: 5775360084
I1021 23:15:39.322932 25759 layer_factory.hpp:77] Creating layer newC4
I1021 23:15:39.322940 25759 net.cpp:100] Creating Layer newC4
I1021 23:15:39.322945 25759 net.cpp:444] newC4 <- res4f_res4f_relu_0_split_2
I1021 23:15:39.322950 25759 net.cpp:418] newC4 -> c4
I1021 23:15:39.330999 25759 net.cpp:150] Setting up newC4
I1021 23:15:39.331010 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.331029 25759 net.cpp:165] Memory required for data: 5785190484
I1021 23:15:39.331035 25759 layer_factory.hpp:77] Creating layer eltwise_bnc4_bnp4
I1021 23:15:39.331044 25759 net.cpp:100] Creating Layer eltwise_bnc4_bnp4
I1021 23:15:39.331048 25759 net.cpp:444] eltwise_bnc4_bnp4 <- c4
I1021 23:15:39.331051 25759 net.cpp:444] eltwise_bnc4_bnp4 <- upP4
I1021 23:15:39.331056 25759 net.cpp:418] eltwise_bnc4_bnp4 -> skip_eltwise1
I1021 23:15:39.331120 25759 net.cpp:150] Setting up eltwise_bnc4_bnp4
I1021 23:15:39.331130 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.331132 25759 net.cpp:165] Memory required for data: 5795020884
I1021 23:15:39.331135 25759 layer_factory.hpp:77] Creating layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1021 23:15:39.331140 25759 net.cpp:100] Creating Layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1021 23:15:39.331143 25759 net.cpp:444] skip_eltwise1_eltwise_bnc4_bnp4_0_split <- skip_eltwise1
I1021 23:15:39.331151 25759 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1021 23:15:39.331156 25759 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1021 23:15:39.331225 25759 net.cpp:150] Setting up skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1021 23:15:39.331233 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.331235 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.331238 25759 net.cpp:165] Memory required for data: 5814681684
I1021 23:15:39.331240 25759 layer_factory.hpp:77] Creating layer bnp4_conv
I1021 23:15:39.331251 25759 net.cpp:100] Creating Layer bnp4_conv
I1021 23:15:39.331255 25759 net.cpp:444] bnp4_conv <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1021 23:15:39.331262 25759 net.cpp:418] bnp4_conv -> bnp4_conv
I1021 23:15:39.333595 25759 net.cpp:150] Setting up bnp4_conv
I1021 23:15:39.333606 25759 net.cpp:157] Top shape: 1 128 60 80 (614400)
I1021 23:15:39.333624 25759 net.cpp:165] Memory required for data: 5817139284
I1021 23:15:39.333628 25759 layer_factory.hpp:77] Creating layer bnp4_bn
I1021 23:15:39.333636 25759 net.cpp:100] Creating Layer bnp4_bn
I1021 23:15:39.333639 25759 net.cpp:444] bnp4_bn <- bnp4_conv
I1021 23:15:39.333644 25759 net.cpp:405] bnp4_bn -> bnp4_conv (in-place)
I1021 23:15:39.334066 25759 net.cpp:150] Setting up bnp4_bn
I1021 23:15:39.334074 25759 net.cpp:157] Top shape: 1 128 60 80 (614400)
I1021 23:15:39.334075 25759 net.cpp:165] Memory required for data: 5819596884
I1021 23:15:39.334097 25759 layer_factory.hpp:77] Creating layer bnp4_scale
I1021 23:15:39.334105 25759 net.cpp:100] Creating Layer bnp4_scale
I1021 23:15:39.334108 25759 net.cpp:444] bnp4_scale <- bnp4_conv
I1021 23:15:39.334112 25759 net.cpp:405] bnp4_scale -> bnp4_conv (in-place)
I1021 23:15:39.334195 25759 layer_factory.hpp:77] Creating layer bnp4_scale
I1021 23:15:39.334419 25759 net.cpp:150] Setting up bnp4_scale
I1021 23:15:39.334425 25759 net.cpp:157] Top shape: 1 128 60 80 (614400)
I1021 23:15:39.334429 25759 net.cpp:165] Memory required for data: 5822054484
I1021 23:15:39.334448 25759 layer_factory.hpp:77] Creating layer bnp4_ReLU
I1021 23:15:39.334453 25759 net.cpp:100] Creating Layer bnp4_ReLU
I1021 23:15:39.334456 25759 net.cpp:444] bnp4_ReLU <- bnp4_conv
I1021 23:15:39.334461 25759 net.cpp:405] bnp4_ReLU -> bnp4_conv (in-place)
I1021 23:15:39.335350 25759 net.cpp:150] Setting up bnp4_ReLU
I1021 23:15:39.335359 25759 net.cpp:157] Top shape: 1 128 60 80 (614400)
I1021 23:15:39.335361 25759 net.cpp:165] Memory required for data: 5824512084
I1021 23:15:39.335379 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_conv
I1021 23:15:39.335391 25759 net.cpp:100] Creating Layer bn_eltwise_1_1_conv
I1021 23:15:39.335393 25759 net.cpp:444] bn_eltwise_1_1_conv <- bnp4_conv
I1021 23:15:39.335400 25759 net.cpp:418] bn_eltwise_1_1_conv -> bn_eltwise_1_1_conv
I1021 23:15:39.339054 25759 net.cpp:150] Setting up bn_eltwise_1_1_conv
I1021 23:15:39.339066 25759 net.cpp:157] Top shape: 1 128 60 80 (614400)
I1021 23:15:39.339083 25759 net.cpp:165] Memory required for data: 5826969684
I1021 23:15:39.339088 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_bn
I1021 23:15:39.339094 25759 net.cpp:100] Creating Layer bn_eltwise_1_1_bn
I1021 23:15:39.339098 25759 net.cpp:444] bn_eltwise_1_1_bn <- bn_eltwise_1_1_conv
I1021 23:15:39.339102 25759 net.cpp:405] bn_eltwise_1_1_bn -> bn_eltwise_1_1_conv (in-place)
I1021 23:15:39.339519 25759 net.cpp:150] Setting up bn_eltwise_1_1_bn
I1021 23:15:39.339526 25759 net.cpp:157] Top shape: 1 128 60 80 (614400)
I1021 23:15:39.339529 25759 net.cpp:165] Memory required for data: 5829427284
I1021 23:15:39.339550 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1021 23:15:39.339557 25759 net.cpp:100] Creating Layer bn_eltwise_1_1_scale
I1021 23:15:39.339560 25759 net.cpp:444] bn_eltwise_1_1_scale <- bn_eltwise_1_1_conv
I1021 23:15:39.339565 25759 net.cpp:405] bn_eltwise_1_1_scale -> bn_eltwise_1_1_conv (in-place)
I1021 23:15:39.339643 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1021 23:15:39.339881 25759 net.cpp:150] Setting up bn_eltwise_1_1_scale
I1021 23:15:39.339888 25759 net.cpp:157] Top shape: 1 128 60 80 (614400)
I1021 23:15:39.339891 25759 net.cpp:165] Memory required for data: 5831884884
I1021 23:15:39.339896 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_ReLU
I1021 23:15:39.339917 25759 net.cpp:100] Creating Layer bn_eltwise_1_1_ReLU
I1021 23:15:39.339921 25759 net.cpp:444] bn_eltwise_1_1_ReLU <- bn_eltwise_1_1_conv
I1021 23:15:39.339926 25759 net.cpp:405] bn_eltwise_1_1_ReLU -> bn_eltwise_1_1_conv (in-place)
I1021 23:15:39.340140 25759 net.cpp:150] Setting up bn_eltwise_1_1_ReLU
I1021 23:15:39.340148 25759 net.cpp:157] Top shape: 1 128 60 80 (614400)
I1021 23:15:39.340152 25759 net.cpp:165] Memory required for data: 5834342484
I1021 23:15:39.340154 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_conv
I1021 23:15:39.340162 25759 net.cpp:100] Creating Layer bn_eltwise_1_2_conv
I1021 23:15:39.340165 25759 net.cpp:444] bn_eltwise_1_2_conv <- bn_eltwise_1_1_conv
I1021 23:15:39.340173 25759 net.cpp:418] bn_eltwise_1_2_conv -> bn_eltwise_1_2_conv
I1021 23:15:39.346016 25759 net.cpp:150] Setting up bn_eltwise_1_2_conv
I1021 23:15:39.346029 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.346047 25759 net.cpp:165] Memory required for data: 5844172884
I1021 23:15:39.346052 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_bn
I1021 23:15:39.346061 25759 net.cpp:100] Creating Layer bn_eltwise_1_2_bn
I1021 23:15:39.346066 25759 net.cpp:444] bn_eltwise_1_2_bn <- bn_eltwise_1_2_conv
I1021 23:15:39.346071 25759 net.cpp:405] bn_eltwise_1_2_bn -> bn_eltwise_1_2_conv (in-place)
I1021 23:15:39.346504 25759 net.cpp:150] Setting up bn_eltwise_1_2_bn
I1021 23:15:39.346511 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.346513 25759 net.cpp:165] Memory required for data: 5854003284
I1021 23:15:39.346535 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1021 23:15:39.346544 25759 net.cpp:100] Creating Layer bn_eltwise_1_2_scale
I1021 23:15:39.346546 25759 net.cpp:444] bn_eltwise_1_2_scale <- bn_eltwise_1_2_conv
I1021 23:15:39.346551 25759 net.cpp:405] bn_eltwise_1_2_scale -> bn_eltwise_1_2_conv (in-place)
I1021 23:15:39.346632 25759 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1021 23:15:39.346866 25759 net.cpp:150] Setting up bn_eltwise_1_2_scale
I1021 23:15:39.346874 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.346876 25759 net.cpp:165] Memory required for data: 5863833684
I1021 23:15:39.346881 25759 layer_factory.hpp:77] Creating layer p3
I1021 23:15:39.346889 25759 net.cpp:100] Creating Layer p3
I1021 23:15:39.346892 25759 net.cpp:444] p3 <- bn_eltwise_1_2_conv
I1021 23:15:39.346896 25759 net.cpp:444] p3 <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1021 23:15:39.346900 25759 net.cpp:418] p3 -> p3
I1021 23:15:39.346956 25759 net.cpp:150] Setting up p3
I1021 23:15:39.346962 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.346966 25759 net.cpp:165] Memory required for data: 5873664084
I1021 23:15:39.346967 25759 layer_factory.hpp:77] Creating layer p3_relu
I1021 23:15:39.346973 25759 net.cpp:100] Creating Layer p3_relu
I1021 23:15:39.346976 25759 net.cpp:444] p3_relu <- p3
I1021 23:15:39.346981 25759 net.cpp:405] p3_relu -> p3 (in-place)
I1021 23:15:39.347182 25759 net.cpp:150] Setting up p3_relu
I1021 23:15:39.347189 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.347193 25759 net.cpp:165] Memory required for data: 5883494484
I1021 23:15:39.347194 25759 layer_factory.hpp:77] Creating layer p3_p3_relu_0_split
I1021 23:15:39.347199 25759 net.cpp:100] Creating Layer p3_p3_relu_0_split
I1021 23:15:39.347203 25759 net.cpp:444] p3_p3_relu_0_split <- p3
I1021 23:15:39.347209 25759 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_0
I1021 23:15:39.347215 25759 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_1
I1021 23:15:39.347219 25759 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_2
I1021 23:15:39.347319 25759 net.cpp:150] Setting up p3_p3_relu_0_split
I1021 23:15:39.347326 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.347331 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.347333 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.347335 25759 net.cpp:165] Memory required for data: 5912985684
I1021 23:15:39.347338 25759 layer_factory.hpp:77] Creating layer newC3
I1021 23:15:39.347348 25759 net.cpp:100] Creating Layer newC3
I1021 23:15:39.347352 25759 net.cpp:444] newC3 <- res3d_res3d_relu_0_split_2
I1021 23:15:39.347358 25759 net.cpp:418] newC3 -> c3
I1021 23:15:39.353313 25759 net.cpp:150] Setting up newC3
I1021 23:15:39.353325 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.353328 25759 net.cpp:165] Memory required for data: 5952307284
I1021 23:15:39.353333 25759 layer_factory.hpp:77] Creating layer upP3
I1021 23:15:39.353343 25759 net.cpp:100] Creating Layer upP3
I1021 23:15:39.353346 25759 net.cpp:444] upP3 <- p3_p3_relu_0_split_0
I1021 23:15:39.353353 25759 net.cpp:418] upP3 -> upP3
I1021 23:15:39.354065 25759 net.cpp:150] Setting up upP3
I1021 23:15:39.354074 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.354075 25759 net.cpp:165] Memory required for data: 5991628884
I1021 23:15:39.354095 25759 layer_factory.hpp:77] Creating layer eltwise_bnc3_bnp3
I1021 23:15:39.354102 25759 net.cpp:100] Creating Layer eltwise_bnc3_bnp3
I1021 23:15:39.354105 25759 net.cpp:444] eltwise_bnc3_bnp3 <- c3
I1021 23:15:39.354110 25759 net.cpp:444] eltwise_bnc3_bnp3 <- upP3
I1021 23:15:39.354115 25759 net.cpp:418] eltwise_bnc3_bnp3 -> skip_eltwise2
I1021 23:15:39.354171 25759 net.cpp:150] Setting up eltwise_bnc3_bnp3
I1021 23:15:39.354180 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.354183 25759 net.cpp:165] Memory required for data: 6030950484
I1021 23:15:39.354185 25759 layer_factory.hpp:77] Creating layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1021 23:15:39.354190 25759 net.cpp:100] Creating Layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1021 23:15:39.354193 25759 net.cpp:444] skip_eltwise2_eltwise_bnc3_bnp3_0_split <- skip_eltwise2
I1021 23:15:39.354199 25759 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1021 23:15:39.354215 25759 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1021 23:15:39.354279 25759 net.cpp:150] Setting up skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1021 23:15:39.354287 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.354291 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.354293 25759 net.cpp:165] Memory required for data: 6109593684
I1021 23:15:39.354296 25759 layer_factory.hpp:77] Creating layer bnp3_conv
I1021 23:15:39.354306 25759 net.cpp:100] Creating Layer bnp3_conv
I1021 23:15:39.354310 25759 net.cpp:444] bnp3_conv <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1021 23:15:39.354315 25759 net.cpp:418] bnp3_conv -> bnp3_conv
I1021 23:15:39.358358 25759 net.cpp:150] Setting up bnp3_conv
I1021 23:15:39.358371 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.358373 25759 net.cpp:165] Memory required for data: 6119424084
I1021 23:15:39.358378 25759 layer_factory.hpp:77] Creating layer bnp3_bn
I1021 23:15:39.358386 25759 net.cpp:100] Creating Layer bnp3_bn
I1021 23:15:39.358389 25759 net.cpp:444] bnp3_bn <- bnp3_conv
I1021 23:15:39.358393 25759 net.cpp:405] bnp3_bn -> bnp3_conv (in-place)
I1021 23:15:39.358783 25759 net.cpp:150] Setting up bnp3_bn
I1021 23:15:39.358790 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.358793 25759 net.cpp:165] Memory required for data: 6129254484
I1021 23:15:39.358815 25759 layer_factory.hpp:77] Creating layer bnp3_scale
I1021 23:15:39.358822 25759 net.cpp:100] Creating Layer bnp3_scale
I1021 23:15:39.358825 25759 net.cpp:444] bnp3_scale <- bnp3_conv
I1021 23:15:39.358830 25759 net.cpp:405] bnp3_scale -> bnp3_conv (in-place)
I1021 23:15:39.358898 25759 layer_factory.hpp:77] Creating layer bnp3_scale
I1021 23:15:39.359109 25759 net.cpp:150] Setting up bnp3_scale
I1021 23:15:39.359133 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.359135 25759 net.cpp:165] Memory required for data: 6139084884
I1021 23:15:39.359139 25759 layer_factory.hpp:77] Creating layer bnp3_ReLU
I1021 23:15:39.359145 25759 net.cpp:100] Creating Layer bnp3_ReLU
I1021 23:15:39.359148 25759 net.cpp:444] bnp3_ReLU <- bnp3_conv
I1021 23:15:39.359153 25759 net.cpp:405] bnp3_ReLU -> bnp3_conv (in-place)
I1021 23:15:39.360052 25759 net.cpp:150] Setting up bnp3_ReLU
I1021 23:15:39.360064 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.360083 25759 net.cpp:165] Memory required for data: 6148915284
I1021 23:15:39.360086 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_conv
I1021 23:15:39.360095 25759 net.cpp:100] Creating Layer bn_eltwise_2_1_conv
I1021 23:15:39.360100 25759 net.cpp:444] bn_eltwise_2_1_conv <- bnp3_conv
I1021 23:15:39.360105 25759 net.cpp:418] bn_eltwise_2_1_conv -> bn_eltwise_2_1_conv
I1021 23:15:39.371188 25759 net.cpp:150] Setting up bn_eltwise_2_1_conv
I1021 23:15:39.371203 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.371222 25759 net.cpp:165] Memory required for data: 6158745684
I1021 23:15:39.371227 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_bn
I1021 23:15:39.371248 25759 net.cpp:100] Creating Layer bn_eltwise_2_1_bn
I1021 23:15:39.371251 25759 net.cpp:444] bn_eltwise_2_1_bn <- bn_eltwise_2_1_conv
I1021 23:15:39.371258 25759 net.cpp:405] bn_eltwise_2_1_bn -> bn_eltwise_2_1_conv (in-place)
I1021 23:15:39.371701 25759 net.cpp:150] Setting up bn_eltwise_2_1_bn
I1021 23:15:39.371709 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.371711 25759 net.cpp:165] Memory required for data: 6168576084
I1021 23:15:39.371733 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1021 23:15:39.371740 25759 net.cpp:100] Creating Layer bn_eltwise_2_1_scale
I1021 23:15:39.371744 25759 net.cpp:444] bn_eltwise_2_1_scale <- bn_eltwise_2_1_conv
I1021 23:15:39.371748 25759 net.cpp:405] bn_eltwise_2_1_scale -> bn_eltwise_2_1_conv (in-place)
I1021 23:15:39.371834 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1021 23:15:39.372051 25759 net.cpp:150] Setting up bn_eltwise_2_1_scale
I1021 23:15:39.372058 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.372061 25759 net.cpp:165] Memory required for data: 6178406484
I1021 23:15:39.372066 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_ReLU
I1021 23:15:39.372073 25759 net.cpp:100] Creating Layer bn_eltwise_2_1_ReLU
I1021 23:15:39.372076 25759 net.cpp:444] bn_eltwise_2_1_ReLU <- bn_eltwise_2_1_conv
I1021 23:15:39.372081 25759 net.cpp:405] bn_eltwise_2_1_ReLU -> bn_eltwise_2_1_conv (in-place)
I1021 23:15:39.372303 25759 net.cpp:150] Setting up bn_eltwise_2_1_ReLU
I1021 23:15:39.372313 25759 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I1021 23:15:39.372315 25759 net.cpp:165] Memory required for data: 6188236884
I1021 23:15:39.372318 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_conv
I1021 23:15:39.372328 25759 net.cpp:100] Creating Layer bn_eltwise_2_2_conv
I1021 23:15:39.372330 25759 net.cpp:444] bn_eltwise_2_2_conv <- bn_eltwise_2_1_conv
I1021 23:15:39.372337 25759 net.cpp:418] bn_eltwise_2_2_conv -> bn_eltwise_2_2_conv
I1021 23:15:39.379662 25759 net.cpp:150] Setting up bn_eltwise_2_2_conv
I1021 23:15:39.379674 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.379693 25759 net.cpp:165] Memory required for data: 6227558484
I1021 23:15:39.379698 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_bn
I1021 23:15:39.379706 25759 net.cpp:100] Creating Layer bn_eltwise_2_2_bn
I1021 23:15:39.379711 25759 net.cpp:444] bn_eltwise_2_2_bn <- bn_eltwise_2_2_conv
I1021 23:15:39.379717 25759 net.cpp:405] bn_eltwise_2_2_bn -> bn_eltwise_2_2_conv (in-place)
I1021 23:15:39.380167 25759 net.cpp:150] Setting up bn_eltwise_2_2_bn
I1021 23:15:39.380174 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.380177 25759 net.cpp:165] Memory required for data: 6266880084
I1021 23:15:39.380198 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1021 23:15:39.380206 25759 net.cpp:100] Creating Layer bn_eltwise_2_2_scale
I1021 23:15:39.380209 25759 net.cpp:444] bn_eltwise_2_2_scale <- bn_eltwise_2_2_conv
I1021 23:15:39.380214 25759 net.cpp:405] bn_eltwise_2_2_scale -> bn_eltwise_2_2_conv (in-place)
I1021 23:15:39.380296 25759 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1021 23:15:39.380556 25759 net.cpp:150] Setting up bn_eltwise_2_2_scale
I1021 23:15:39.380564 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.380568 25759 net.cpp:165] Memory required for data: 6306201684
I1021 23:15:39.380573 25759 layer_factory.hpp:77] Creating layer p2
I1021 23:15:39.380578 25759 net.cpp:100] Creating Layer p2
I1021 23:15:39.380583 25759 net.cpp:444] p2 <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1021 23:15:39.380586 25759 net.cpp:444] p2 <- bn_eltwise_2_2_conv
I1021 23:15:39.380592 25759 net.cpp:418] p2 -> p2
I1021 23:15:39.380652 25759 net.cpp:150] Setting up p2
I1021 23:15:39.380661 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.380662 25759 net.cpp:165] Memory required for data: 6345523284
I1021 23:15:39.380666 25759 layer_factory.hpp:77] Creating layer p2_relu
I1021 23:15:39.380671 25759 net.cpp:100] Creating Layer p2_relu
I1021 23:15:39.380673 25759 net.cpp:444] p2_relu <- p2
I1021 23:15:39.380677 25759 net.cpp:405] p2_relu -> p2 (in-place)
I1021 23:15:39.380890 25759 net.cpp:150] Setting up p2_relu
I1021 23:15:39.380899 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.380903 25759 net.cpp:165] Memory required for data: 6384844884
I1021 23:15:39.380904 25759 layer_factory.hpp:77] Creating layer p2_p2_relu_0_split
I1021 23:15:39.380909 25759 net.cpp:100] Creating Layer p2_p2_relu_0_split
I1021 23:15:39.380915 25759 net.cpp:444] p2_p2_relu_0_split <- p2
I1021 23:15:39.380920 25759 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_0
I1021 23:15:39.380928 25759 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_1
I1021 23:15:39.381018 25759 net.cpp:150] Setting up p2_p2_relu_0_split
I1021 23:15:39.381026 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.381029 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.381031 25759 net.cpp:165] Memory required for data: 6463488084
I1021 23:15:39.381033 25759 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p2
I1021 23:15:39.381042 25759 net.cpp:100] Creating Layer rpn_conv/3x3_p2
I1021 23:15:39.381044 25759 net.cpp:444] rpn_conv/3x3_p2 <- p2_p2_relu_0_split_0
I1021 23:15:39.381052 25759 net.cpp:418] rpn_conv/3x3_p2 -> rpn/output_p2
I1021 23:15:39.413094 25759 net.cpp:150] Setting up rpn_conv/3x3_p2
I1021 23:15:39.413107 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.413125 25759 net.cpp:165] Memory required for data: 6502809684
I1021 23:15:39.413130 25759 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p2
I1021 23:15:39.413138 25759 net.cpp:100] Creating Layer rpn_relu/3x3_p2
I1021 23:15:39.413142 25759 net.cpp:444] rpn_relu/3x3_p2 <- rpn/output_p2
I1021 23:15:39.413148 25759 net.cpp:405] rpn_relu/3x3_p2 -> rpn/output_p2 (in-place)
I1021 23:15:39.414080 25759 net.cpp:150] Setting up rpn_relu/3x3_p2
I1021 23:15:39.414090 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.414108 25759 net.cpp:165] Memory required for data: 6542131284
I1021 23:15:39.414111 25759 layer_factory.hpp:77] Creating layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1021 23:15:39.414117 25759 net.cpp:100] Creating Layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1021 23:15:39.414120 25759 net.cpp:444] rpn/output_p2_rpn_relu/3x3_p2_0_split <- rpn/output_p2
I1021 23:15:39.414126 25759 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1021 23:15:39.414134 25759 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1021 23:15:39.414228 25759 net.cpp:150] Setting up rpn/output_p2_rpn_relu/3x3_p2_0_split
I1021 23:15:39.414237 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.414240 25759 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I1021 23:15:39.414243 25759 net.cpp:165] Memory required for data: 6620774484
I1021 23:15:39.414245 25759 layer_factory.hpp:77] Creating layer rpn_cls_score_p2
I1021 23:15:39.414255 25759 net.cpp:100] Creating Layer rpn_cls_score_p2
I1021 23:15:39.414258 25759 net.cpp:444] rpn_cls_score_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1021 23:15:39.414265 25759 net.cpp:418] rpn_cls_score_p2 -> rpn_cls_score_p2
I1021 23:15:39.416174 25759 net.cpp:150] Setting up rpn_cls_score_p2
I1021 23:15:39.416184 25759 net.cpp:157] Top shape: 1 22 120 160 (422400)
I1021 23:15:39.416188 25759 net.cpp:165] Memory required for data: 6622464084
I1021 23:15:39.416208 25759 layer_factory.hpp:77] Creating layer rpn_cls_score_p2_rpn_cls_score_p2_0_split
I1021 23:15:39.416214 25759 net.cpp:100] Creating Layer rpn_cls_score_p2_rpn_cls_score_p2_0_split
I1021 23:15:39.416218 25759 net.cpp:444] rpn_cls_score_p2_rpn_cls_score_p2_0_split <- rpn_cls_score_p2
I1021 23:15:39.416225 25759 net.cpp:418] rpn_cls_score_p2_rpn_cls_score_p2_0_split -> rpn_cls_score_p2_rpn_cls_score_p2_0_split_0
I1021 23:15:39.416231 25759 net.cpp:418] rpn_cls_score_p2_rpn_cls_score_p2_0_split -> rpn_cls_score_p2_rpn_cls_score_p2_0_split_1
I1021 23:15:39.416321 25759 net.cpp:150] Setting up rpn_cls_score_p2_rpn_cls_score_p2_0_split
I1021 23:15:39.416327 25759 net.cpp:157] Top shape: 1 22 120 160 (422400)
I1021 23:15:39.416332 25759 net.cpp:157] Top shape: 1 22 120 160 (422400)
I1021 23:15:39.416334 25759 net.cpp:165] Memory required for data: 6625843284
I1021 23:15:39.416337 25759 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p2
I1021 23:15:39.416350 25759 net.cpp:100] Creating Layer rpn_bbox_pred_p2
I1021 23:15:39.416354 25759 net.cpp:444] rpn_bbox_pred_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1021 23:15:39.416375 25759 net.cpp:418] rpn_bbox_pred_p2 -> rpn_bbox_pred_p2
I1021 23:15:39.418386 25759 net.cpp:150] Setting up rpn_bbox_pred_p2
I1021 23:15:39.418397 25759 net.cpp:157] Top shape: 1 44 120 160 (844800)
I1021 23:15:39.418416 25759 net.cpp:165] Memory required for data: 6629222484
I1021 23:15:39.418421 25759 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split
I1021 23:15:39.418426 25759 net.cpp:100] Creating Layer rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split
I1021 23:15:39.418429 25759 net.cpp:444] rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split <- rpn_bbox_pred_p2
I1021 23:15:39.418437 25759 net.cpp:418] rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split -> rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split_0
I1021 23:15:39.418443 25759 net.cpp:418] rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split -> rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split_1
I1021 23:15:39.418534 25759 net.cpp:150] Setting up rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split
I1021 23:15:39.418541 25759 net.cpp:157] Top shape: 1 44 120 160 (844800)
I1021 23:15:39.418546 25759 net.cpp:157] Top shape: 1 44 120 160 (844800)
I1021 23:15:39.418548 25759 net.cpp:165] Memory required for data: 6635980884
I1021 23:15:39.418551 25759 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p2
I1021 23:15:39.418560 25759 net.cpp:100] Creating Layer rpn_cls_score_reshape_p2
I1021 23:15:39.418563 25759 net.cpp:444] rpn_cls_score_reshape_p2 <- rpn_cls_score_p2_rpn_cls_score_p2_0_split_0
I1021 23:15:39.418567 25759 net.cpp:418] rpn_cls_score_reshape_p2 -> rpn_cls_score_reshape_p2
I1021 23:15:39.418613 25759 net.cpp:150] Setting up rpn_cls_score_reshape_p2
I1021 23:15:39.418620 25759 net.cpp:157] Top shape: 1 2 1320 160 (422400)
I1021 23:15:39.418623 25759 net.cpp:165] Memory required for data: 6637670484
I1021 23:15:39.418625 25759 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split
I1021 23:15:39.418630 25759 net.cpp:100] Creating Layer rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split
I1021 23:15:39.418633 25759 net.cpp:444] rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split <- rpn_cls_score_reshape_p2
I1021 23:15:39.418639 25759 net.cpp:418] rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split -> rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split_0
I1021 23:15:39.418645 25759 net.cpp:418] rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split -> rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split_1
I1021 23:15:39.418726 25759 net.cpp:150] Setting up rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split
I1021 23:15:39.418733 25759 net.cpp:157] Top shape: 1 2 1320 160 (422400)
I1021 23:15:39.418737 25759 net.cpp:157] Top shape: 1 2 1320 160 (422400)
I1021 23:15:39.418740 25759 net.cpp:165] Memory required for data: 6641049684
I1021 23:15:39.418741 25759 layer_factory.hpp:77] Creating layer rpn_cls_prob_p2
I1021 23:15:39.418750 25759 net.cpp:100] Creating Layer rpn_cls_prob_p2
I1021 23:15:39.418752 25759 net.cpp:444] rpn_cls_prob_p2 <- rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split_0
I1021 23:15:39.418756 25759 net.cpp:418] rpn_cls_prob_p2 -> rpn_cls_prob_p2
I1021 23:15:39.419109 25759 net.cpp:150] Setting up rpn_cls_prob_p2
I1021 23:15:39.419119 25759 net.cpp:157] Top shape: 1 2 1320 160 (422400)
I1021 23:15:39.419138 25759 net.cpp:165] Memory required for data: 6642739284
I1021 23:15:39.419142 25759 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p2
I1021 23:15:39.419147 25759 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p2
I1021 23:15:39.419149 25759 net.cpp:444] rpn_cls_prob_reshape_p2 <- rpn_cls_prob_p2
I1021 23:15:39.419157 25759 net.cpp:418] rpn_cls_prob_reshape_p2 -> rpn_cls_prob_reshape_p2
I1021 23:15:39.419217 25759 net.cpp:150] Setting up rpn_cls_prob_reshape_p2
I1021 23:15:39.419224 25759 net.cpp:157] Top shape: 1 22 120 160 (422400)
I1021 23:15:39.419226 25759 net.cpp:165] Memory required for data: 6644428884
I1021 23:15:39.419229 25759 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p3
I1021 23:15:39.419239 25759 net.cpp:100] Creating Layer rpn_conv/3x3_p3
I1021 23:15:39.419242 25759 net.cpp:444] rpn_conv/3x3_p3 <- p3_p3_relu_0_split_1
I1021 23:15:39.419250 25759 net.cpp:418] rpn_conv/3x3_p3 -> rpn/output_p3
I1021 23:15:39.447485 25759 net.cpp:150] Setting up rpn_conv/3x3_p3
I1021 23:15:39.447499 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.447516 25759 net.cpp:165] Memory required for data: 6654259284
I1021 23:15:39.447522 25759 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p3
I1021 23:15:39.447532 25759 net.cpp:100] Creating Layer rpn_relu/3x3_p3
I1021 23:15:39.447536 25759 net.cpp:444] rpn_relu/3x3_p3 <- rpn/output_p3
I1021 23:15:39.447540 25759 net.cpp:405] rpn_relu/3x3_p3 -> rpn/output_p3 (in-place)
I1021 23:15:39.447769 25759 net.cpp:150] Setting up rpn_relu/3x3_p3
I1021 23:15:39.447780 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.447783 25759 net.cpp:165] Memory required for data: 6664089684
I1021 23:15:39.447787 25759 layer_factory.hpp:77] Creating layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1021 23:15:39.447791 25759 net.cpp:100] Creating Layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1021 23:15:39.447794 25759 net.cpp:444] rpn/output_p3_rpn_relu/3x3_p3_0_split <- rpn/output_p3
I1021 23:15:39.447800 25759 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1021 23:15:39.447808 25759 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1021 23:15:39.447904 25759 net.cpp:150] Setting up rpn/output_p3_rpn_relu/3x3_p3_0_split
I1021 23:15:39.447911 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.447916 25759 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I1021 23:15:39.447918 25759 net.cpp:165] Memory required for data: 6683750484
I1021 23:15:39.447921 25759 layer_factory.hpp:77] Creating layer rpn_cls_score_p3
I1021 23:15:39.447932 25759 net.cpp:100] Creating Layer rpn_cls_score_p3
I1021 23:15:39.447935 25759 net.cpp:444] rpn_cls_score_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1021 23:15:39.447942 25759 net.cpp:418] rpn_cls_score_p3 -> rpn_cls_score_p3
I1021 23:15:39.450495 25759 net.cpp:150] Setting up rpn_cls_score_p3
I1021 23:15:39.450507 25759 net.cpp:157] Top shape: 1 22 60 80 (105600)
I1021 23:15:39.450510 25759 net.cpp:165] Memory required for data: 6684172884
I1021 23:15:39.450531 25759 layer_factory.hpp:77] Creating layer rpn_cls_score_p3_rpn_cls_score_p3_0_split
I1021 23:15:39.450537 25759 net.cpp:100] Creating Layer rpn_cls_score_p3_rpn_cls_score_p3_0_split
I1021 23:15:39.450541 25759 net.cpp:444] rpn_cls_score_p3_rpn_cls_score_p3_0_split <- rpn_cls_score_p3
I1021 23:15:39.450546 25759 net.cpp:418] rpn_cls_score_p3_rpn_cls_score_p3_0_split -> rpn_cls_score_p3_rpn_cls_score_p3_0_split_0
I1021 23:15:39.450556 25759 net.cpp:418] rpn_cls_score_p3_rpn_cls_score_p3_0_split -> rpn_cls_score_p3_rpn_cls_score_p3_0_split_1
I1021 23:15:39.450644 25759 net.cpp:150] Setting up rpn_cls_score_p3_rpn_cls_score_p3_0_split
I1021 23:15:39.450651 25759 net.cpp:157] Top shape: 1 22 60 80 (105600)
I1021 23:15:39.450654 25759 net.cpp:157] Top shape: 1 22 60 80 (105600)
I1021 23:15:39.450657 25759 net.cpp:165] Memory required for data: 6685017684
I1021 23:15:39.450659 25759 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p3
I1021 23:15:39.450672 25759 net.cpp:100] Creating Layer rpn_bbox_pred_p3
I1021 23:15:39.450676 25759 net.cpp:444] rpn_bbox_pred_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1021 23:15:39.450683 25759 net.cpp:418] rpn_bbox_pred_p3 -> rpn_bbox_pred_p3
I1021 23:15:39.453392 25759 net.cpp:150] Setting up rpn_bbox_pred_p3
I1021 23:15:39.453403 25759 net.cpp:157] Top shape: 1 44 60 80 (211200)
I1021 23:15:39.453405 25759 net.cpp:165] Memory required for data: 6685862484
I1021 23:15:39.453426 25759 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split
I1021 23:15:39.453433 25759 net.cpp:100] Creating Layer rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split
I1021 23:15:39.453436 25759 net.cpp:444] rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split <- rpn_bbox_pred_p3
I1021 23:15:39.453444 25759 net.cpp:418] rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split -> rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split_0
I1021 23:15:39.453451 25759 net.cpp:418] rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split -> rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split_1
I1021 23:15:39.453557 25759 net.cpp:150] Setting up rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split
I1021 23:15:39.453564 25759 net.cpp:157] Top shape: 1 44 60 80 (211200)
I1021 23:15:39.453568 25759 net.cpp:157] Top shape: 1 44 60 80 (211200)
I1021 23:15:39.453570 25759 net.cpp:165] Memory required for data: 6687552084
I1021 23:15:39.453573 25759 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p3
I1021 23:15:39.453582 25759 net.cpp:100] Creating Layer rpn_cls_score_reshape_p3
I1021 23:15:39.453584 25759 net.cpp:444] rpn_cls_score_reshape_p3 <- rpn_cls_score_p3_rpn_cls_score_p3_0_split_0
I1021 23:15:39.453591 25759 net.cpp:418] rpn_cls_score_reshape_p3 -> rpn_cls_score_reshape_p3
I1021 23:15:39.453635 25759 net.cpp:150] Setting up rpn_cls_score_reshape_p3
I1021 23:15:39.453641 25759 net.cpp:157] Top shape: 1 2 660 80 (105600)
I1021 23:15:39.453644 25759 net.cpp:165] Memory required for data: 6687974484
I1021 23:15:39.453647 25759 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split
I1021 23:15:39.453652 25759 net.cpp:100] Creating Layer rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split
I1021 23:15:39.453656 25759 net.cpp:444] rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split <- rpn_cls_score_reshape_p3
I1021 23:15:39.453662 25759 net.cpp:418] rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split -> rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split_0
I1021 23:15:39.453668 25759 net.cpp:418] rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split -> rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split_1
I1021 23:15:39.453734 25759 net.cpp:150] Setting up rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split
I1021 23:15:39.453743 25759 net.cpp:157] Top shape: 1 2 660 80 (105600)
I1021 23:15:39.453747 25759 net.cpp:157] Top shape: 1 2 660 80 (105600)
I1021 23:15:39.453749 25759 net.cpp:165] Memory required for data: 6688819284
I1021 23:15:39.453752 25759 layer_factory.hpp:77] Creating layer rpn_cls_prob_p3
I1021 23:15:39.453757 25759 net.cpp:100] Creating Layer rpn_cls_prob_p3
I1021 23:15:39.453760 25759 net.cpp:444] rpn_cls_prob_p3 <- rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split_0
I1021 23:15:39.453764 25759 net.cpp:418] rpn_cls_prob_p3 -> rpn_cls_prob_p3
I1021 23:15:39.454099 25759 net.cpp:150] Setting up rpn_cls_prob_p3
I1021 23:15:39.454109 25759 net.cpp:157] Top shape: 1 2 660 80 (105600)
I1021 23:15:39.454111 25759 net.cpp:165] Memory required for data: 6689241684
I1021 23:15:39.454114 25759 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p3
I1021 23:15:39.454120 25759 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p3
I1021 23:15:39.454123 25759 net.cpp:444] rpn_cls_prob_reshape_p3 <- rpn_cls_prob_p3
I1021 23:15:39.454130 25759 net.cpp:418] rpn_cls_prob_reshape_p3 -> rpn_cls_prob_reshape_p3
I1021 23:15:39.454175 25759 net.cpp:150] Setting up rpn_cls_prob_reshape_p3
I1021 23:15:39.454182 25759 net.cpp:157] Top shape: 1 22 60 80 (105600)
I1021 23:15:39.454185 25759 net.cpp:165] Memory required for data: 6689664084
I1021 23:15:39.454187 25759 layer_factory.hpp:77] Creating layer rpn-data
I1021 23:15:39.457326 25759 net.cpp:100] Creating Layer rpn-data
I1021 23:15:39.457337 25759 net.cpp:444] rpn-data <- rpn_cls_score_p2_rpn_cls_score_p2_0_split_1
I1021 23:15:39.457358 25759 net.cpp:444] rpn-data <- rpn_cls_score_p3_rpn_cls_score_p3_0_split_1
I1021 23:15:39.457363 25759 net.cpp:444] rpn-data <- gt_boxes_input-data_2_split_0
I1021 23:15:39.457367 25759 net.cpp:444] rpn-data <- im_info_input-data_1_split_0
I1021 23:15:39.457373 25759 net.cpp:418] rpn-data -> rpn_labels_p2
I1021 23:15:39.457381 25759 net.cpp:418] rpn-data -> rpn_bbox_targets_p2
I1021 23:15:39.457388 25759 net.cpp:418] rpn-data -> rpn_bbox_inside_weights_p2
I1021 23:15:39.457394 25759 net.cpp:418] rpn-data -> rpn_bbox_outside_weights_p2
I1021 23:15:39.457401 25759 net.cpp:418] rpn-data -> rpn_labels_p3
I1021 23:15:39.457406 25759 net.cpp:418] rpn-data -> rpn_bbox_targets_p3
I1021 23:15:39.457412 25759 net.cpp:418] rpn-data -> rpn_bbox_inside_weights_p3
I1021 23:15:39.457417 25759 net.cpp:418] rpn-data -> rpn_bbox_outside_weights_p3
I1021 23:15:39.459962 25759 net.cpp:150] Setting up rpn-data
I1021 23:15:39.459975 25759 net.cpp:157] Top shape: 1 1 1320 160 (211200)
I1021 23:15:39.459995 25759 net.cpp:157] Top shape: 1 44 120 160 (844800)
I1021 23:15:39.459998 25759 net.cpp:157] Top shape: 1 44 120 160 (844800)
I1021 23:15:39.460001 25759 net.cpp:157] Top shape: 1 44 120 160 (844800)
I1021 23:15:39.460005 25759 net.cpp:157] Top shape: 1 1 660 80 (52800)
I1021 23:15:39.460007 25759 net.cpp:157] Top shape: 1 44 60 80 (211200)
I1021 23:15:39.460011 25759 net.cpp:157] Top shape: 1 44 60 80 (211200)
I1021 23:15:39.460014 25759 net.cpp:157] Top shape: 1 44 60 80 (211200)
I1021 23:15:39.460016 25759 net.cpp:165] Memory required for data: 6703392084
I1021 23:15:39.460019 25759 layer_factory.hpp:77] Creating layer rpn_loss_cls_p2
I1021 23:15:39.460027 25759 net.cpp:100] Creating Layer rpn_loss_cls_p2
I1021 23:15:39.460031 25759 net.cpp:444] rpn_loss_cls_p2 <- rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split_1
I1021 23:15:39.460036 25759 net.cpp:444] rpn_loss_cls_p2 <- rpn_labels_p2
I1021 23:15:39.460041 25759 net.cpp:418] rpn_loss_cls_p2 -> rpn_cls_loss_p2
I1021 23:15:39.460050 25759 layer_factory.hpp:77] Creating layer rpn_loss_cls_p2
I1021 23:15:39.466329 25759 net.cpp:150] Setting up rpn_loss_cls_p2
I1021 23:15:39.466343 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.466361 25759 net.cpp:160]     with loss weight 1
I1021 23:15:39.466372 25759 net.cpp:165] Memory required for data: 6703392088
I1021 23:15:39.466374 25759 layer_factory.hpp:77] Creating layer rpn_loss_bbox_p2
I1021 23:15:39.466384 25759 net.cpp:100] Creating Layer rpn_loss_bbox_p2
I1021 23:15:39.466388 25759 net.cpp:444] rpn_loss_bbox_p2 <- rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split_0
I1021 23:15:39.466393 25759 net.cpp:444] rpn_loss_bbox_p2 <- rpn_bbox_targets_p2
I1021 23:15:39.466398 25759 net.cpp:444] rpn_loss_bbox_p2 <- rpn_bbox_inside_weights_p2
I1021 23:15:39.466418 25759 net.cpp:444] rpn_loss_bbox_p2 <- rpn_bbox_outside_weights_p2
I1021 23:15:39.466423 25759 net.cpp:418] rpn_loss_bbox_p2 -> rpn_loss_bbox_p2
I1021 23:15:39.479580 25759 net.cpp:150] Setting up rpn_loss_bbox_p2
I1021 23:15:39.479629 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.479632 25759 net.cpp:160]     with loss weight 1
I1021 23:15:39.479646 25759 net.cpp:165] Memory required for data: 6703392092
I1021 23:15:39.479653 25759 layer_factory.hpp:77] Creating layer rpn_loss_cls_p3
I1021 23:15:39.479667 25759 net.cpp:100] Creating Layer rpn_loss_cls_p3
I1021 23:15:39.479689 25759 net.cpp:444] rpn_loss_cls_p3 <- rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split_1
I1021 23:15:39.479697 25759 net.cpp:444] rpn_loss_cls_p3 <- rpn_labels_p3
I1021 23:15:39.479704 25759 net.cpp:418] rpn_loss_cls_p3 -> rpn_cls_loss_p3
I1021 23:15:39.479734 25759 layer_factory.hpp:77] Creating layer rpn_loss_cls_p3
I1021 23:15:39.480434 25759 net.cpp:150] Setting up rpn_loss_cls_p3
I1021 23:15:39.480443 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.480445 25759 net.cpp:160]     with loss weight 1
I1021 23:15:39.480466 25759 net.cpp:165] Memory required for data: 6703392096
I1021 23:15:39.480469 25759 layer_factory.hpp:77] Creating layer rpn_loss_bbox_p3
I1021 23:15:39.480478 25759 net.cpp:100] Creating Layer rpn_loss_bbox_p3
I1021 23:15:39.480482 25759 net.cpp:444] rpn_loss_bbox_p3 <- rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split_0
I1021 23:15:39.480486 25759 net.cpp:444] rpn_loss_bbox_p3 <- rpn_bbox_targets_p3
I1021 23:15:39.480491 25759 net.cpp:444] rpn_loss_bbox_p3 <- rpn_bbox_inside_weights_p3
I1021 23:15:39.480494 25759 net.cpp:444] rpn_loss_bbox_p3 <- rpn_bbox_outside_weights_p3
I1021 23:15:39.480516 25759 net.cpp:418] rpn_loss_bbox_p3 -> rpn_loss_bbox_p3
I1021 23:15:39.481995 25759 net.cpp:150] Setting up rpn_loss_bbox_p3
I1021 23:15:39.482004 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.482007 25759 net.cpp:160]     with loss weight 1
I1021 23:15:39.482025 25759 net.cpp:165] Memory required for data: 6703392100
I1021 23:15:39.482028 25759 layer_factory.hpp:77] Creating layer proposal
I1021 23:15:39.484297 25759 net.cpp:100] Creating Layer proposal
I1021 23:15:39.484308 25759 net.cpp:444] proposal <- im_info_input-data_1_split_1
I1021 23:15:39.484329 25759 net.cpp:444] proposal <- rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split_1
I1021 23:15:39.484333 25759 net.cpp:444] proposal <- rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split_1
I1021 23:15:39.484338 25759 net.cpp:444] proposal <- rpn_cls_prob_reshape_p2
I1021 23:15:39.484341 25759 net.cpp:444] proposal <- rpn_cls_prob_reshape_p3
I1021 23:15:39.484346 25759 net.cpp:418] proposal -> rpn_rois_p2
I1021 23:15:39.484369 25759 net.cpp:418] proposal -> rpn_rois_p3
I1021 23:15:39.485256 25759 net.cpp:150] Setting up proposal
I1021 23:15:39.485270 25759 net.cpp:157] Top shape: 1 5 (5)
I1021 23:15:39.485287 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.485291 25759 net.cpp:165] Memory required for data: 6703392124
I1021 23:15:39.485293 25759 layer_factory.hpp:77] Creating layer roi-data
I1021 23:15:39.486974 25759 net.cpp:100] Creating Layer roi-data
I1021 23:15:39.486984 25759 net.cpp:444] roi-data <- rpn_rois_p2
I1021 23:15:39.487004 25759 net.cpp:444] roi-data <- rpn_rois_p3
I1021 23:15:39.487009 25759 net.cpp:444] roi-data <- gt_boxes_input-data_2_split_1
I1021 23:15:39.487011 25759 net.cpp:444] roi-data <- data_input-data_0_split_1
I1021 23:15:39.487017 25759 net.cpp:418] roi-data -> rois_p2
I1021 23:15:39.487025 25759 net.cpp:418] roi-data -> rois_p3
I1021 23:15:39.487031 25759 net.cpp:418] roi-data -> labels_p2
I1021 23:15:39.487036 25759 net.cpp:418] roi-data -> labels_p3
I1021 23:15:39.487058 25759 net.cpp:418] roi-data -> bbox_targets_p2
I1021 23:15:39.487063 25759 net.cpp:418] roi-data -> bbox_targets_p3
I1021 23:15:39.487069 25759 net.cpp:418] roi-data -> bbox_inside_weights_p2
I1021 23:15:39.487076 25759 net.cpp:418] roi-data -> bbox_inside_weights_p3
I1021 23:15:39.487097 25759 net.cpp:418] roi-data -> bbox_outside_weights_p2
I1021 23:15:39.487103 25759 net.cpp:418] roi-data -> bbox_outside_weights_p3
I1021 23:15:39.487740 25759 net.cpp:150] Setting up roi-data
I1021 23:15:39.487751 25759 net.cpp:157] Top shape: 1 5 1 1 (5)
I1021 23:15:39.487769 25759 net.cpp:157] Top shape: 1 5 1 1 (5)
I1021 23:15:39.487772 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.487776 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.487778 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.487782 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.487783 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.487787 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.487790 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.487792 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.487794 25759 net.cpp:165] Memory required for data: 6703392364
I1021 23:15:39.487798 25759 layer_factory.hpp:77] Creating layer rois_p2_roi-data_0_split
I1021 23:15:39.487819 25759 net.cpp:100] Creating Layer rois_p2_roi-data_0_split
I1021 23:15:39.487823 25759 net.cpp:444] rois_p2_roi-data_0_split <- rois_p2
I1021 23:15:39.487828 25759 net.cpp:418] rois_p2_roi-data_0_split -> rois_p2_roi-data_0_split_0
I1021 23:15:39.487835 25759 net.cpp:418] rois_p2_roi-data_0_split -> rois_p2_roi-data_0_split_1
I1021 23:15:39.487841 25759 net.cpp:418] rois_p2_roi-data_0_split -> rois_p2_roi-data_0_split_2
I1021 23:15:39.487963 25759 net.cpp:150] Setting up rois_p2_roi-data_0_split
I1021 23:15:39.487970 25759 net.cpp:157] Top shape: 1 5 1 1 (5)
I1021 23:15:39.487975 25759 net.cpp:157] Top shape: 1 5 1 1 (5)
I1021 23:15:39.487978 25759 net.cpp:157] Top shape: 1 5 1 1 (5)
I1021 23:15:39.487982 25759 net.cpp:165] Memory required for data: 6703392424
I1021 23:15:39.487983 25759 layer_factory.hpp:77] Creating layer rois_p3_roi-data_1_split
I1021 23:15:39.487989 25759 net.cpp:100] Creating Layer rois_p3_roi-data_1_split
I1021 23:15:39.487993 25759 net.cpp:444] rois_p3_roi-data_1_split <- rois_p3
I1021 23:15:39.487998 25759 net.cpp:418] rois_p3_roi-data_1_split -> rois_p3_roi-data_1_split_0
I1021 23:15:39.488003 25759 net.cpp:418] rois_p3_roi-data_1_split -> rois_p3_roi-data_1_split_1
I1021 23:15:39.488008 25759 net.cpp:418] rois_p3_roi-data_1_split -> rois_p3_roi-data_1_split_2
I1021 23:15:39.488095 25759 net.cpp:150] Setting up rois_p3_roi-data_1_split
I1021 23:15:39.488101 25759 net.cpp:157] Top shape: 1 5 1 1 (5)
I1021 23:15:39.488106 25759 net.cpp:157] Top shape: 1 5 1 1 (5)
I1021 23:15:39.488109 25759 net.cpp:157] Top shape: 1 5 1 1 (5)
I1021 23:15:39.488111 25759 net.cpp:165] Memory required for data: 6703392484
I1021 23:15:39.488114 25759 layer_factory.hpp:77] Creating layer labels_p2_roi-data_2_split
I1021 23:15:39.488119 25759 net.cpp:100] Creating Layer labels_p2_roi-data_2_split
I1021 23:15:39.488122 25759 net.cpp:444] labels_p2_roi-data_2_split <- labels_p2
I1021 23:15:39.488127 25759 net.cpp:418] labels_p2_roi-data_2_split -> labels_p2_roi-data_2_split_0
I1021 23:15:39.488133 25759 net.cpp:418] labels_p2_roi-data_2_split -> labels_p2_roi-data_2_split_1
I1021 23:15:39.488194 25759 net.cpp:150] Setting up labels_p2_roi-data_2_split
I1021 23:15:39.488201 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.488205 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.488207 25759 net.cpp:165] Memory required for data: 6703392492
I1021 23:15:39.488210 25759 layer_factory.hpp:77] Creating layer labels_p3_roi-data_3_split
I1021 23:15:39.488215 25759 net.cpp:100] Creating Layer labels_p3_roi-data_3_split
I1021 23:15:39.488219 25759 net.cpp:444] labels_p3_roi-data_3_split <- labels_p3
I1021 23:15:39.488224 25759 net.cpp:418] labels_p3_roi-data_3_split -> labels_p3_roi-data_3_split_0
I1021 23:15:39.488229 25759 net.cpp:418] labels_p3_roi-data_3_split -> labels_p3_roi-data_3_split_1
I1021 23:15:39.488292 25759 net.cpp:150] Setting up labels_p3_roi-data_3_split
I1021 23:15:39.488298 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.488302 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.488304 25759 net.cpp:165] Memory required for data: 6703392500
I1021 23:15:39.488307 25759 layer_factory.hpp:77] Creating layer bbox_targets_p2_roi-data_4_split
I1021 23:15:39.488312 25759 net.cpp:100] Creating Layer bbox_targets_p2_roi-data_4_split
I1021 23:15:39.488315 25759 net.cpp:444] bbox_targets_p2_roi-data_4_split <- bbox_targets_p2
I1021 23:15:39.488319 25759 net.cpp:418] bbox_targets_p2_roi-data_4_split -> bbox_targets_p2_roi-data_4_split_0
I1021 23:15:39.488327 25759 net.cpp:418] bbox_targets_p2_roi-data_4_split -> bbox_targets_p2_roi-data_4_split_1
I1021 23:15:39.488389 25759 net.cpp:150] Setting up bbox_targets_p2_roi-data_4_split
I1021 23:15:39.488394 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.488399 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.488401 25759 net.cpp:165] Memory required for data: 6703392564
I1021 23:15:39.488404 25759 layer_factory.hpp:77] Creating layer bbox_targets_p3_roi-data_5_split
I1021 23:15:39.488409 25759 net.cpp:100] Creating Layer bbox_targets_p3_roi-data_5_split
I1021 23:15:39.488411 25759 net.cpp:444] bbox_targets_p3_roi-data_5_split <- bbox_targets_p3
I1021 23:15:39.488416 25759 net.cpp:418] bbox_targets_p3_roi-data_5_split -> bbox_targets_p3_roi-data_5_split_0
I1021 23:15:39.488422 25759 net.cpp:418] bbox_targets_p3_roi-data_5_split -> bbox_targets_p3_roi-data_5_split_1
I1021 23:15:39.488484 25759 net.cpp:150] Setting up bbox_targets_p3_roi-data_5_split
I1021 23:15:39.488505 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.488509 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.488512 25759 net.cpp:165] Memory required for data: 6703392628
I1021 23:15:39.488513 25759 layer_factory.hpp:77] Creating layer bbox_inside_weights_p2_roi-data_6_split
I1021 23:15:39.488518 25759 net.cpp:100] Creating Layer bbox_inside_weights_p2_roi-data_6_split
I1021 23:15:39.488521 25759 net.cpp:444] bbox_inside_weights_p2_roi-data_6_split <- bbox_inside_weights_p2
I1021 23:15:39.488526 25759 net.cpp:418] bbox_inside_weights_p2_roi-data_6_split -> bbox_inside_weights_p2_roi-data_6_split_0
I1021 23:15:39.488531 25759 net.cpp:418] bbox_inside_weights_p2_roi-data_6_split -> bbox_inside_weights_p2_roi-data_6_split_1
I1021 23:15:39.488592 25759 net.cpp:150] Setting up bbox_inside_weights_p2_roi-data_6_split
I1021 23:15:39.488600 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.488602 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.488605 25759 net.cpp:165] Memory required for data: 6703392692
I1021 23:15:39.488607 25759 layer_factory.hpp:77] Creating layer bbox_inside_weights_p3_roi-data_7_split
I1021 23:15:39.488617 25759 net.cpp:100] Creating Layer bbox_inside_weights_p3_roi-data_7_split
I1021 23:15:39.488620 25759 net.cpp:444] bbox_inside_weights_p3_roi-data_7_split <- bbox_inside_weights_p3
I1021 23:15:39.488631 25759 net.cpp:418] bbox_inside_weights_p3_roi-data_7_split -> bbox_inside_weights_p3_roi-data_7_split_0
I1021 23:15:39.488636 25759 net.cpp:418] bbox_inside_weights_p3_roi-data_7_split -> bbox_inside_weights_p3_roi-data_7_split_1
I1021 23:15:39.488718 25759 net.cpp:150] Setting up bbox_inside_weights_p3_roi-data_7_split
I1021 23:15:39.488724 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.488729 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.488730 25759 net.cpp:165] Memory required for data: 6703392756
I1021 23:15:39.488734 25759 layer_factory.hpp:77] Creating layer conv_new_p2
I1021 23:15:39.488746 25759 net.cpp:100] Creating Layer conv_new_p2
I1021 23:15:39.488750 25759 net.cpp:444] conv_new_p2 <- p2_p2_relu_0_split_1
I1021 23:15:39.488755 25759 net.cpp:418] conv_new_p2 -> conv_new_p2
I1021 23:15:39.497623 25759 net.cpp:150] Setting up conv_new_p2
I1021 23:15:39.497635 25759 net.cpp:157] Top shape: 1 1024 120 160 (19660800)
I1021 23:15:39.497638 25759 net.cpp:165] Memory required for data: 6782035956
I1021 23:15:39.497647 25759 layer_factory.hpp:77] Creating layer conv_new_p2_relu
I1021 23:15:39.497653 25759 net.cpp:100] Creating Layer conv_new_p2_relu
I1021 23:15:39.497656 25759 net.cpp:444] conv_new_p2_relu <- conv_new_p2
I1021 23:15:39.497663 25759 net.cpp:405] conv_new_p2_relu -> conv_new_p2 (in-place)
I1021 23:15:39.497875 25759 net.cpp:150] Setting up conv_new_p2_relu
I1021 23:15:39.497884 25759 net.cpp:157] Top shape: 1 1024 120 160 (19660800)
I1021 23:15:39.497886 25759 net.cpp:165] Memory required for data: 6860679156
I1021 23:15:39.497889 25759 layer_factory.hpp:77] Creating layer conv_new_p2_conv_new_p2_relu_0_split
I1021 23:15:39.497896 25759 net.cpp:100] Creating Layer conv_new_p2_conv_new_p2_relu_0_split
I1021 23:15:39.497900 25759 net.cpp:444] conv_new_p2_conv_new_p2_relu_0_split <- conv_new_p2
I1021 23:15:39.497905 25759 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_0
I1021 23:15:39.497910 25759 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_1
I1021 23:15:39.497989 25759 net.cpp:150] Setting up conv_new_p2_conv_new_p2_relu_0_split
I1021 23:15:39.497999 25759 net.cpp:157] Top shape: 1 1024 120 160 (19660800)
I1021 23:15:39.498003 25759 net.cpp:157] Top shape: 1 1024 120 160 (19660800)
I1021 23:15:39.498005 25759 net.cpp:165] Memory required for data: 7017965556
I1021 23:15:39.498008 25759 layer_factory.hpp:77] Creating layer rfcn_cls_p2
I1021 23:15:39.498019 25759 net.cpp:100] Creating Layer rfcn_cls_p2
I1021 23:15:39.498023 25759 net.cpp:444] rfcn_cls_p2 <- conv_new_p2_conv_new_p2_relu_0_split_0
I1021 23:15:39.498030 25759 net.cpp:418] rfcn_cls_p2 -> rfcn_cls_p2
I1021 23:15:39.502118 25759 net.cpp:150] Setting up rfcn_cls_p2
I1021 23:15:39.502132 25759 net.cpp:157] Top shape: 1 98 120 160 (1881600)
I1021 23:15:39.502135 25759 net.cpp:165] Memory required for data: 7025491956
I1021 23:15:39.502141 25759 layer_factory.hpp:77] Creating layer rfcn_bbox_p2
I1021 23:15:39.502151 25759 net.cpp:100] Creating Layer rfcn_bbox_p2
I1021 23:15:39.502156 25759 net.cpp:444] rfcn_bbox_p2 <- conv_new_p2_conv_new_p2_relu_0_split_1
I1021 23:15:39.502163 25759 net.cpp:418] rfcn_bbox_p2 -> rfcn_bbox_p2
I1021 23:15:39.510841 25759 net.cpp:150] Setting up rfcn_bbox_p2
I1021 23:15:39.510854 25759 net.cpp:157] Top shape: 1 392 120 160 (7526400)
I1021 23:15:39.510872 25759 net.cpp:165] Memory required for data: 7055597556
I1021 23:15:39.510879 25759 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p2
I1021 23:15:39.510887 25759 net.cpp:100] Creating Layer psroipooled_cls_rois_p2
I1021 23:15:39.510891 25759 net.cpp:444] psroipooled_cls_rois_p2 <- rfcn_cls_p2
I1021 23:15:39.510896 25759 net.cpp:444] psroipooled_cls_rois_p2 <- rois_p2_roi-data_0_split_0
I1021 23:15:39.510902 25759 net.cpp:418] psroipooled_cls_rois_p2 -> psroipooled_cls_rois_p2
I1021 23:15:39.510910 25759 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1021 23:15:39.511010 25759 net.cpp:150] Setting up psroipooled_cls_rois_p2
I1021 23:15:39.511018 25759 net.cpp:157] Top shape: 1 2 7 7 (98)
I1021 23:15:39.511021 25759 net.cpp:165] Memory required for data: 7055597948
I1021 23:15:39.511023 25759 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p2
I1021 23:15:39.511031 25759 net.cpp:100] Creating Layer ave_cls_score_rois_p2
I1021 23:15:39.511035 25759 net.cpp:444] ave_cls_score_rois_p2 <- psroipooled_cls_rois_p2
I1021 23:15:39.511041 25759 net.cpp:418] ave_cls_score_rois_p2 -> cls_score_p2
I1021 23:15:39.512058 25759 net.cpp:150] Setting up ave_cls_score_rois_p2
I1021 23:15:39.512068 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.512086 25759 net.cpp:165] Memory required for data: 7055597956
I1021 23:15:39.512089 25759 layer_factory.hpp:77] Creating layer cls_score_p2_ave_cls_score_rois_p2_0_split
I1021 23:15:39.512095 25759 net.cpp:100] Creating Layer cls_score_p2_ave_cls_score_rois_p2_0_split
I1021 23:15:39.512099 25759 net.cpp:444] cls_score_p2_ave_cls_score_rois_p2_0_split <- cls_score_p2
I1021 23:15:39.512106 25759 net.cpp:418] cls_score_p2_ave_cls_score_rois_p2_0_split -> cls_score_p2_ave_cls_score_rois_p2_0_split_0
I1021 23:15:39.512114 25759 net.cpp:418] cls_score_p2_ave_cls_score_rois_p2_0_split -> cls_score_p2_ave_cls_score_rois_p2_0_split_1
I1021 23:15:39.512120 25759 net.cpp:418] cls_score_p2_ave_cls_score_rois_p2_0_split -> cls_score_p2_ave_cls_score_rois_p2_0_split_2
I1021 23:15:39.512241 25759 net.cpp:150] Setting up cls_score_p2_ave_cls_score_rois_p2_0_split
I1021 23:15:39.512248 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.512253 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.512256 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.512259 25759 net.cpp:165] Memory required for data: 7055597980
I1021 23:15:39.512261 25759 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p2
I1021 23:15:39.512269 25759 net.cpp:100] Creating Layer psroipooled_loc_rois_p2
I1021 23:15:39.512271 25759 net.cpp:444] psroipooled_loc_rois_p2 <- rfcn_bbox_p2
I1021 23:15:39.512275 25759 net.cpp:444] psroipooled_loc_rois_p2 <- rois_p2_roi-data_0_split_1
I1021 23:15:39.512280 25759 net.cpp:418] psroipooled_loc_rois_p2 -> psroipooled_loc_rois_p2
I1021 23:15:39.512286 25759 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1021 23:15:39.512363 25759 net.cpp:150] Setting up psroipooled_loc_rois_p2
I1021 23:15:39.512370 25759 net.cpp:157] Top shape: 1 8 7 7 (392)
I1021 23:15:39.512372 25759 net.cpp:165] Memory required for data: 7055599548
I1021 23:15:39.512375 25759 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p2
I1021 23:15:39.512383 25759 net.cpp:100] Creating Layer ave_bbox_pred_rois_p2
I1021 23:15:39.512387 25759 net.cpp:444] ave_bbox_pred_rois_p2 <- psroipooled_loc_rois_p2
I1021 23:15:39.512392 25759 net.cpp:418] ave_bbox_pred_rois_p2 -> bbox_pred_p2
I1021 23:15:39.512679 25759 net.cpp:150] Setting up ave_bbox_pred_rois_p2
I1021 23:15:39.512704 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.512706 25759 net.cpp:165] Memory required for data: 7055599580
I1021 23:15:39.512725 25759 layer_factory.hpp:77] Creating layer bbox_pred_p2_ave_bbox_pred_rois_p2_0_split
I1021 23:15:39.512732 25759 net.cpp:100] Creating Layer bbox_pred_p2_ave_bbox_pred_rois_p2_0_split
I1021 23:15:39.512735 25759 net.cpp:444] bbox_pred_p2_ave_bbox_pred_rois_p2_0_split <- bbox_pred_p2
I1021 23:15:39.512740 25759 net.cpp:418] bbox_pred_p2_ave_bbox_pred_rois_p2_0_split -> bbox_pred_p2_ave_bbox_pred_rois_p2_0_split_0
I1021 23:15:39.512749 25759 net.cpp:418] bbox_pred_p2_ave_bbox_pred_rois_p2_0_split -> bbox_pred_p2_ave_bbox_pred_rois_p2_0_split_1
I1021 23:15:39.512823 25759 net.cpp:150] Setting up bbox_pred_p2_ave_bbox_pred_rois_p2_0_split
I1021 23:15:39.512830 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.512833 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.512836 25759 net.cpp:165] Memory required for data: 7055599644
I1021 23:15:39.512840 25759 layer_factory.hpp:77] Creating layer per_roi_loss_cls_p2
I1021 23:15:39.512846 25759 net.cpp:100] Creating Layer per_roi_loss_cls_p2
I1021 23:15:39.512850 25759 net.cpp:444] per_roi_loss_cls_p2 <- cls_score_p2_ave_cls_score_rois_p2_0_split_0
I1021 23:15:39.512854 25759 net.cpp:444] per_roi_loss_cls_p2 <- labels_p2_roi-data_2_split_0
I1021 23:15:39.512862 25759 net.cpp:418] per_roi_loss_cls_p2 -> temp_loss_cls_p2
I1021 23:15:39.512869 25759 net.cpp:418] per_roi_loss_cls_p2 -> temp_prob_cls_p2
I1021 23:15:39.512874 25759 net.cpp:418] per_roi_loss_cls_p2 -> per_roi_loss_cls_p2
I1021 23:15:39.512884 25759 layer_factory.hpp:77] Creating layer per_roi_loss_cls_p2
I1021 23:15:39.513300 25759 net.cpp:150] Setting up per_roi_loss_cls_p2
I1021 23:15:39.513309 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.513311 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.513314 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.513332 25759 net.cpp:165] Memory required for data: 7055599660
I1021 23:15:39.513334 25759 layer_factory.hpp:77] Creating layer per_roi_loss_bbox_p2
I1021 23:15:39.513340 25759 net.cpp:100] Creating Layer per_roi_loss_bbox_p2
I1021 23:15:39.513345 25759 net.cpp:444] per_roi_loss_bbox_p2 <- bbox_pred_p2_ave_bbox_pred_rois_p2_0_split_0
I1021 23:15:39.513348 25759 net.cpp:444] per_roi_loss_bbox_p2 <- bbox_targets_p2_roi-data_4_split_0
I1021 23:15:39.513352 25759 net.cpp:444] per_roi_loss_bbox_p2 <- bbox_inside_weights_p2_roi-data_6_split_0
I1021 23:15:39.513358 25759 net.cpp:418] per_roi_loss_bbox_p2 -> temp_loss_bbox_p2
I1021 23:15:39.513365 25759 net.cpp:418] per_roi_loss_bbox_p2 -> per_roi_loss_bbox_p2
I1021 23:15:39.513485 25759 net.cpp:150] Setting up per_roi_loss_bbox_p2
I1021 23:15:39.513492 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.513495 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.513499 25759 net.cpp:165] Memory required for data: 7055599668
I1021 23:15:39.513500 25759 layer_factory.hpp:77] Creating layer per_roi_loss_p2
I1021 23:15:39.513506 25759 net.cpp:100] Creating Layer per_roi_loss_p2
I1021 23:15:39.513509 25759 net.cpp:444] per_roi_loss_p2 <- per_roi_loss_cls_p2
I1021 23:15:39.513514 25759 net.cpp:444] per_roi_loss_p2 <- per_roi_loss_bbox_p2
I1021 23:15:39.513520 25759 net.cpp:418] per_roi_loss_p2 -> per_roi_loss_p2
I1021 23:15:39.513563 25759 net.cpp:150] Setting up per_roi_loss_p2
I1021 23:15:39.513569 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.513573 25759 net.cpp:165] Memory required for data: 7055599672
I1021 23:15:39.513576 25759 layer_factory.hpp:77] Creating layer annotator_detector_p2
I1021 23:15:39.513584 25759 net.cpp:100] Creating Layer annotator_detector_p2
I1021 23:15:39.513587 25759 net.cpp:444] annotator_detector_p2 <- rois_p2_roi-data_0_split_2
I1021 23:15:39.513592 25759 net.cpp:444] annotator_detector_p2 <- per_roi_loss_p2
I1021 23:15:39.513595 25759 net.cpp:444] annotator_detector_p2 <- labels_p2_roi-data_2_split_1
I1021 23:15:39.513599 25759 net.cpp:444] annotator_detector_p2 <- bbox_inside_weights_p2_roi-data_6_split_1
I1021 23:15:39.513607 25759 net.cpp:418] annotator_detector_p2 -> labels_ohem_p2
I1021 23:15:39.513612 25759 net.cpp:418] annotator_detector_p2 -> bbox_loss_weights_ohem_p2
I1021 23:15:39.513700 25759 net.cpp:150] Setting up annotator_detector_p2
I1021 23:15:39.513705 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.513710 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.513711 25759 net.cpp:165] Memory required for data: 7055599708
I1021 23:15:39.513715 25759 layer_factory.hpp:77] Creating layer labels_ohem_p2_annotator_detector_p2_0_split
I1021 23:15:39.513720 25759 net.cpp:100] Creating Layer labels_ohem_p2_annotator_detector_p2_0_split
I1021 23:15:39.513723 25759 net.cpp:444] labels_ohem_p2_annotator_detector_p2_0_split <- labels_ohem_p2
I1021 23:15:39.513728 25759 net.cpp:418] labels_ohem_p2_annotator_detector_p2_0_split -> labels_ohem_p2_annotator_detector_p2_0_split_0
I1021 23:15:39.513734 25759 net.cpp:418] labels_ohem_p2_annotator_detector_p2_0_split -> labels_ohem_p2_annotator_detector_p2_0_split_1
I1021 23:15:39.513799 25759 net.cpp:150] Setting up labels_ohem_p2_annotator_detector_p2_0_split
I1021 23:15:39.513805 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.513809 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.513811 25759 net.cpp:165] Memory required for data: 7055599716
I1021 23:15:39.513813 25759 layer_factory.hpp:77] Creating layer conv_new_p3
I1021 23:15:39.513823 25759 net.cpp:100] Creating Layer conv_new_p3
I1021 23:15:39.513826 25759 net.cpp:444] conv_new_p3 <- p3_p3_relu_0_split_2
I1021 23:15:39.513833 25759 net.cpp:418] conv_new_p3 -> conv_new_p3
I1021 23:15:39.522720 25759 net.cpp:150] Setting up conv_new_p3
I1021 23:15:39.522733 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.522737 25759 net.cpp:165] Memory required for data: 7075260516
I1021 23:15:39.522742 25759 layer_factory.hpp:77] Creating layer conv_new_p3_relu
I1021 23:15:39.522765 25759 net.cpp:100] Creating Layer conv_new_p3_relu
I1021 23:15:39.522769 25759 net.cpp:444] conv_new_p3_relu <- conv_new_p3
I1021 23:15:39.522775 25759 net.cpp:405] conv_new_p3_relu -> conv_new_p3 (in-place)
I1021 23:15:39.524344 25759 net.cpp:150] Setting up conv_new_p3_relu
I1021 23:15:39.524369 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.524396 25759 net.cpp:165] Memory required for data: 7094921316
I1021 23:15:39.524399 25759 layer_factory.hpp:77] Creating layer conv_new_p3_conv_new_p3_relu_0_split
I1021 23:15:39.524406 25759 net.cpp:100] Creating Layer conv_new_p3_conv_new_p3_relu_0_split
I1021 23:15:39.524410 25759 net.cpp:444] conv_new_p3_conv_new_p3_relu_0_split <- conv_new_p3
I1021 23:15:39.524415 25759 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_0
I1021 23:15:39.524439 25759 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_1
I1021 23:15:39.524523 25759 net.cpp:150] Setting up conv_new_p3_conv_new_p3_relu_0_split
I1021 23:15:39.524529 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.524534 25759 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I1021 23:15:39.524536 25759 net.cpp:165] Memory required for data: 7134242916
I1021 23:15:39.524539 25759 layer_factory.hpp:77] Creating layer rfcn_cls_p3
I1021 23:15:39.524549 25759 net.cpp:100] Creating Layer rfcn_cls_p3
I1021 23:15:39.524554 25759 net.cpp:444] rfcn_cls_p3 <- conv_new_p3_conv_new_p3_relu_0_split_0
I1021 23:15:39.524559 25759 net.cpp:418] rfcn_cls_p3 -> rfcn_cls_p3
I1021 23:15:39.527329 25759 net.cpp:150] Setting up rfcn_cls_p3
I1021 23:15:39.527340 25759 net.cpp:157] Top shape: 1 98 60 80 (470400)
I1021 23:15:39.527343 25759 net.cpp:165] Memory required for data: 7136124516
I1021 23:15:39.527364 25759 layer_factory.hpp:77] Creating layer rfcn_bbox_p3
I1021 23:15:39.527374 25759 net.cpp:100] Creating Layer rfcn_bbox_p3
I1021 23:15:39.527379 25759 net.cpp:444] rfcn_bbox_p3 <- conv_new_p3_conv_new_p3_relu_0_split_1
I1021 23:15:39.527385 25759 net.cpp:418] rfcn_bbox_p3 -> rfcn_bbox_p3
I1021 23:15:39.535600 25759 net.cpp:150] Setting up rfcn_bbox_p3
I1021 23:15:39.535612 25759 net.cpp:157] Top shape: 1 392 60 80 (1881600)
I1021 23:15:39.535630 25759 net.cpp:165] Memory required for data: 7143650916
I1021 23:15:39.535636 25759 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p3
I1021 23:15:39.535645 25759 net.cpp:100] Creating Layer psroipooled_cls_rois_p3
I1021 23:15:39.535650 25759 net.cpp:444] psroipooled_cls_rois_p3 <- rfcn_cls_p3
I1021 23:15:39.535653 25759 net.cpp:444] psroipooled_cls_rois_p3 <- rois_p3_roi-data_1_split_0
I1021 23:15:39.535660 25759 net.cpp:418] psroipooled_cls_rois_p3 -> psroipooled_cls_rois_p3
I1021 23:15:39.535682 25759 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1021 23:15:39.535761 25759 net.cpp:150] Setting up psroipooled_cls_rois_p3
I1021 23:15:39.535768 25759 net.cpp:157] Top shape: 1 2 7 7 (98)
I1021 23:15:39.535771 25759 net.cpp:165] Memory required for data: 7143651308
I1021 23:15:39.535774 25759 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p3
I1021 23:15:39.535781 25759 net.cpp:100] Creating Layer ave_cls_score_rois_p3
I1021 23:15:39.535785 25759 net.cpp:444] ave_cls_score_rois_p3 <- psroipooled_cls_rois_p3
I1021 23:15:39.535791 25759 net.cpp:418] ave_cls_score_rois_p3 -> cls_score_p3
I1021 23:15:39.536036 25759 net.cpp:150] Setting up ave_cls_score_rois_p3
I1021 23:15:39.536046 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.536047 25759 net.cpp:165] Memory required for data: 7143651316
I1021 23:15:39.536051 25759 layer_factory.hpp:77] Creating layer cls_score_p3_ave_cls_score_rois_p3_0_split
I1021 23:15:39.536056 25759 net.cpp:100] Creating Layer cls_score_p3_ave_cls_score_rois_p3_0_split
I1021 23:15:39.536058 25759 net.cpp:444] cls_score_p3_ave_cls_score_rois_p3_0_split <- cls_score_p3
I1021 23:15:39.536065 25759 net.cpp:418] cls_score_p3_ave_cls_score_rois_p3_0_split -> cls_score_p3_ave_cls_score_rois_p3_0_split_0
I1021 23:15:39.536072 25759 net.cpp:418] cls_score_p3_ave_cls_score_rois_p3_0_split -> cls_score_p3_ave_cls_score_rois_p3_0_split_1
I1021 23:15:39.536078 25759 net.cpp:418] cls_score_p3_ave_cls_score_rois_p3_0_split -> cls_score_p3_ave_cls_score_rois_p3_0_split_2
I1021 23:15:39.536181 25759 net.cpp:150] Setting up cls_score_p3_ave_cls_score_rois_p3_0_split
I1021 23:15:39.536188 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.536192 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.536195 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.536197 25759 net.cpp:165] Memory required for data: 7143651340
I1021 23:15:39.536200 25759 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p3
I1021 23:15:39.536206 25759 net.cpp:100] Creating Layer psroipooled_loc_rois_p3
I1021 23:15:39.536209 25759 net.cpp:444] psroipooled_loc_rois_p3 <- rfcn_bbox_p3
I1021 23:15:39.536213 25759 net.cpp:444] psroipooled_loc_rois_p3 <- rois_p3_roi-data_1_split_1
I1021 23:15:39.536233 25759 net.cpp:418] psroipooled_loc_rois_p3 -> psroipooled_loc_rois_p3
I1021 23:15:39.536239 25759 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1021 23:15:39.536312 25759 net.cpp:150] Setting up psroipooled_loc_rois_p3
I1021 23:15:39.536319 25759 net.cpp:157] Top shape: 1 8 7 7 (392)
I1021 23:15:39.536322 25759 net.cpp:165] Memory required for data: 7143652908
I1021 23:15:39.536324 25759 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p3
I1021 23:15:39.536331 25759 net.cpp:100] Creating Layer ave_bbox_pred_rois_p3
I1021 23:15:39.536334 25759 net.cpp:444] ave_bbox_pred_rois_p3 <- psroipooled_loc_rois_p3
I1021 23:15:39.536339 25759 net.cpp:418] ave_bbox_pred_rois_p3 -> bbox_pred_p3
I1021 23:15:39.536595 25759 net.cpp:150] Setting up ave_bbox_pred_rois_p3
I1021 23:15:39.536604 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.536607 25759 net.cpp:165] Memory required for data: 7143652940
I1021 23:15:39.536614 25759 layer_factory.hpp:77] Creating layer bbox_pred_p3_ave_bbox_pred_rois_p3_0_split
I1021 23:15:39.536630 25759 net.cpp:100] Creating Layer bbox_pred_p3_ave_bbox_pred_rois_p3_0_split
I1021 23:15:39.536633 25759 net.cpp:444] bbox_pred_p3_ave_bbox_pred_rois_p3_0_split <- bbox_pred_p3
I1021 23:15:39.536638 25759 net.cpp:418] bbox_pred_p3_ave_bbox_pred_rois_p3_0_split -> bbox_pred_p3_ave_bbox_pred_rois_p3_0_split_0
I1021 23:15:39.536646 25759 net.cpp:418] bbox_pred_p3_ave_bbox_pred_rois_p3_0_split -> bbox_pred_p3_ave_bbox_pred_rois_p3_0_split_1
I1021 23:15:39.536736 25759 net.cpp:150] Setting up bbox_pred_p3_ave_bbox_pred_rois_p3_0_split
I1021 23:15:39.536742 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.536746 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.536747 25759 net.cpp:165] Memory required for data: 7143653004
I1021 23:15:39.536751 25759 layer_factory.hpp:77] Creating layer per_roi_loss_cls_p3
I1021 23:15:39.536756 25759 net.cpp:100] Creating Layer per_roi_loss_cls_p3
I1021 23:15:39.536759 25759 net.cpp:444] per_roi_loss_cls_p3 <- cls_score_p3_ave_cls_score_rois_p3_0_split_0
I1021 23:15:39.536763 25759 net.cpp:444] per_roi_loss_cls_p3 <- labels_p3_roi-data_3_split_0
I1021 23:15:39.536770 25759 net.cpp:418] per_roi_loss_cls_p3 -> temp_loss_cls_p3
I1021 23:15:39.536777 25759 net.cpp:418] per_roi_loss_cls_p3 -> temp_prob_cls_p3
I1021 23:15:39.536782 25759 net.cpp:418] per_roi_loss_cls_p3 -> per_roi_loss_cls_p3
I1021 23:15:39.536790 25759 layer_factory.hpp:77] Creating layer per_roi_loss_cls_p3
I1021 23:15:39.537201 25759 net.cpp:150] Setting up per_roi_loss_cls_p3
I1021 23:15:39.537209 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.537214 25759 net.cpp:157] Top shape: 1 2 1 1 (2)
I1021 23:15:39.537231 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.537233 25759 net.cpp:165] Memory required for data: 7143653020
I1021 23:15:39.537236 25759 layer_factory.hpp:77] Creating layer per_roi_loss_bbox_p3
I1021 23:15:39.537243 25759 net.cpp:100] Creating Layer per_roi_loss_bbox_p3
I1021 23:15:39.537248 25759 net.cpp:444] per_roi_loss_bbox_p3 <- bbox_pred_p3_ave_bbox_pred_rois_p3_0_split_0
I1021 23:15:39.537252 25759 net.cpp:444] per_roi_loss_bbox_p3 <- bbox_targets_p3_roi-data_5_split_0
I1021 23:15:39.537256 25759 net.cpp:444] per_roi_loss_bbox_p3 <- bbox_inside_weights_p3_roi-data_7_split_0
I1021 23:15:39.537261 25759 net.cpp:418] per_roi_loss_bbox_p3 -> temp_loss_bbox_p3
I1021 23:15:39.537267 25759 net.cpp:418] per_roi_loss_bbox_p3 -> per_roi_loss_bbox_p3
I1021 23:15:39.537385 25759 net.cpp:150] Setting up per_roi_loss_bbox_p3
I1021 23:15:39.537391 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.537395 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.537397 25759 net.cpp:165] Memory required for data: 7143653028
I1021 23:15:39.537400 25759 layer_factory.hpp:77] Creating layer per_roi_loss_p3
I1021 23:15:39.537405 25759 net.cpp:100] Creating Layer per_roi_loss_p3
I1021 23:15:39.537408 25759 net.cpp:444] per_roi_loss_p3 <- per_roi_loss_cls_p3
I1021 23:15:39.537412 25759 net.cpp:444] per_roi_loss_p3 <- per_roi_loss_bbox_p3
I1021 23:15:39.537418 25759 net.cpp:418] per_roi_loss_p3 -> per_roi_loss_p3
I1021 23:15:39.537461 25759 net.cpp:150] Setting up per_roi_loss_p3
I1021 23:15:39.537467 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.537469 25759 net.cpp:165] Memory required for data: 7143653032
I1021 23:15:39.537472 25759 layer_factory.hpp:77] Creating layer annotator_detector_p3
I1021 23:15:39.537479 25759 net.cpp:100] Creating Layer annotator_detector_p3
I1021 23:15:39.537483 25759 net.cpp:444] annotator_detector_p3 <- rois_p3_roi-data_1_split_2
I1021 23:15:39.537487 25759 net.cpp:444] annotator_detector_p3 <- per_roi_loss_p3
I1021 23:15:39.537490 25759 net.cpp:444] annotator_detector_p3 <- labels_p3_roi-data_3_split_1
I1021 23:15:39.537494 25759 net.cpp:444] annotator_detector_p3 <- bbox_inside_weights_p3_roi-data_7_split_1
I1021 23:15:39.537499 25759 net.cpp:418] annotator_detector_p3 -> labels_ohem_p3
I1021 23:15:39.537508 25759 net.cpp:418] annotator_detector_p3 -> bbox_loss_weights_ohem_p3
I1021 23:15:39.537576 25759 net.cpp:150] Setting up annotator_detector_p3
I1021 23:15:39.537582 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.537586 25759 net.cpp:157] Top shape: 1 8 1 1 (8)
I1021 23:15:39.537588 25759 net.cpp:165] Memory required for data: 7143653068
I1021 23:15:39.537591 25759 layer_factory.hpp:77] Creating layer labels_ohem_p3_annotator_detector_p3_0_split
I1021 23:15:39.537596 25759 net.cpp:100] Creating Layer labels_ohem_p3_annotator_detector_p3_0_split
I1021 23:15:39.537600 25759 net.cpp:444] labels_ohem_p3_annotator_detector_p3_0_split <- labels_ohem_p3
I1021 23:15:39.537606 25759 net.cpp:418] labels_ohem_p3_annotator_detector_p3_0_split -> labels_ohem_p3_annotator_detector_p3_0_split_0
I1021 23:15:39.537611 25759 net.cpp:418] labels_ohem_p3_annotator_detector_p3_0_split -> labels_ohem_p3_annotator_detector_p3_0_split_1
I1021 23:15:39.537678 25759 net.cpp:150] Setting up labels_ohem_p3_annotator_detector_p3_0_split
I1021 23:15:39.537683 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.537686 25759 net.cpp:157] Top shape: 1 1 1 1 (1)
I1021 23:15:39.537688 25759 net.cpp:165] Memory required for data: 7143653076
I1021 23:15:39.537691 25759 layer_factory.hpp:77] Creating layer loss_p2
I1021 23:15:39.537696 25759 net.cpp:100] Creating Layer loss_p2
I1021 23:15:39.537699 25759 net.cpp:444] loss_p2 <- cls_score_p2_ave_cls_score_rois_p2_0_split_1
I1021 23:15:39.537703 25759 net.cpp:444] loss_p2 <- labels_ohem_p2_annotator_detector_p2_0_split_0
I1021 23:15:39.537710 25759 net.cpp:418] loss_p2 -> loss_cls_p2
I1021 23:15:39.537716 25759 layer_factory.hpp:77] Creating layer loss_p2
I1021 23:15:39.538842 25759 net.cpp:150] Setting up loss_p2
I1021 23:15:39.538853 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.538856 25759 net.cpp:160]     with loss weight 1
I1021 23:15:39.538861 25759 net.cpp:165] Memory required for data: 7143653080
I1021 23:15:39.538863 25759 layer_factory.hpp:77] Creating layer loss_p3
I1021 23:15:39.538872 25759 net.cpp:100] Creating Layer loss_p3
I1021 23:15:39.538874 25759 net.cpp:444] loss_p3 <- cls_score_p3_ave_cls_score_rois_p3_0_split_1
I1021 23:15:39.538879 25759 net.cpp:444] loss_p3 <- labels_ohem_p3_annotator_detector_p3_0_split_0
I1021 23:15:39.538884 25759 net.cpp:418] loss_p3 -> loss_cls_p3
I1021 23:15:39.538890 25759 layer_factory.hpp:77] Creating layer loss_p3
I1021 23:15:39.539291 25759 net.cpp:150] Setting up loss_p3
I1021 23:15:39.539301 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.539304 25759 net.cpp:160]     with loss weight 1
I1021 23:15:39.539324 25759 net.cpp:165] Memory required for data: 7143653084
I1021 23:15:39.539326 25759 layer_factory.hpp:77] Creating layer accuarcy_p2
I1021 23:15:39.539332 25759 net.cpp:100] Creating Layer accuarcy_p2
I1021 23:15:39.539335 25759 net.cpp:444] accuarcy_p2 <- cls_score_p2_ave_cls_score_rois_p2_0_split_2
I1021 23:15:39.539340 25759 net.cpp:444] accuarcy_p2 <- labels_ohem_p2_annotator_detector_p2_0_split_1
I1021 23:15:39.539345 25759 net.cpp:418] accuarcy_p2 -> accuarcy_p2
I1021 23:15:39.539383 25759 net.cpp:150] Setting up accuarcy_p2
I1021 23:15:39.539387 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.539391 25759 net.cpp:165] Memory required for data: 7143653088
I1021 23:15:39.539392 25759 layer_factory.hpp:77] Creating layer accuarcy_p3
I1021 23:15:39.539397 25759 net.cpp:100] Creating Layer accuarcy_p3
I1021 23:15:39.539399 25759 net.cpp:444] accuarcy_p3 <- cls_score_p3_ave_cls_score_rois_p3_0_split_2
I1021 23:15:39.539403 25759 net.cpp:444] accuarcy_p3 <- labels_ohem_p3_annotator_detector_p3_0_split_1
I1021 23:15:39.539407 25759 net.cpp:418] accuarcy_p3 -> accuarcy_p3
I1021 23:15:39.539413 25759 net.cpp:150] Setting up accuarcy_p3
I1021 23:15:39.539417 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.539419 25759 net.cpp:165] Memory required for data: 7143653092
I1021 23:15:39.539422 25759 layer_factory.hpp:77] Creating layer loss_bbox_p2
I1021 23:15:39.539427 25759 net.cpp:100] Creating Layer loss_bbox_p2
I1021 23:15:39.539429 25759 net.cpp:444] loss_bbox_p2 <- bbox_pred_p2_ave_bbox_pred_rois_p2_0_split_1
I1021 23:15:39.539433 25759 net.cpp:444] loss_bbox_p2 <- bbox_targets_p2_roi-data_4_split_1
I1021 23:15:39.539438 25759 net.cpp:444] loss_bbox_p2 <- bbox_loss_weights_ohem_p2
I1021 23:15:39.539443 25759 net.cpp:418] loss_bbox_p2 -> loss_bbox_p2
I1021 23:15:39.539544 25759 net.cpp:150] Setting up loss_bbox_p2
I1021 23:15:39.539551 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.539553 25759 net.cpp:160]     with loss weight 1
I1021 23:15:39.539557 25759 net.cpp:165] Memory required for data: 7143653096
I1021 23:15:39.539561 25759 layer_factory.hpp:77] Creating layer loss_bbox_p3
I1021 23:15:39.539566 25759 net.cpp:100] Creating Layer loss_bbox_p3
I1021 23:15:39.539568 25759 net.cpp:444] loss_bbox_p3 <- bbox_pred_p3_ave_bbox_pred_rois_p3_0_split_1
I1021 23:15:39.539572 25759 net.cpp:444] loss_bbox_p3 <- bbox_targets_p3_roi-data_5_split_1
I1021 23:15:39.539575 25759 net.cpp:444] loss_bbox_p3 <- bbox_loss_weights_ohem_p3
I1021 23:15:39.539582 25759 net.cpp:418] loss_bbox_p3 -> loss_bbox_p3
I1021 23:15:39.539685 25759 net.cpp:150] Setting up loss_bbox_p3
I1021 23:15:39.539691 25759 net.cpp:157] Top shape: (1)
I1021 23:15:39.539695 25759 net.cpp:160]     with loss weight 1
I1021 23:15:39.539698 25759 net.cpp:165] Memory required for data: 7143653100
I1021 23:15:39.539700 25759 layer_factory.hpp:77] Creating layer silence
I1021 23:15:39.539708 25759 net.cpp:100] Creating Layer silence
I1021 23:15:39.539711 25759 net.cpp:444] silence <- bbox_outside_weights_p2
I1021 23:15:39.539716 25759 net.cpp:444] silence <- bbox_outside_weights_p3
I1021 23:15:39.539719 25759 net.cpp:444] silence <- temp_loss_cls_p2
I1021 23:15:39.539723 25759 net.cpp:444] silence <- temp_prob_cls_p2
I1021 23:15:39.539726 25759 net.cpp:444] silence <- temp_loss_bbox_p2
I1021 23:15:39.539729 25759 net.cpp:444] silence <- temp_loss_cls_p3
I1021 23:15:39.539732 25759 net.cpp:444] silence <- temp_prob_cls_p3
I1021 23:15:39.539736 25759 net.cpp:444] silence <- temp_loss_bbox_p3
I1021 23:15:39.539739 25759 net.cpp:150] Setting up silence
I1021 23:15:39.539741 25759 net.cpp:165] Memory required for data: 7143653100
I1021 23:15:39.539744 25759 net.cpp:228] silence does not need backward computation.
I1021 23:15:39.539750 25759 net.cpp:226] loss_bbox_p3 needs backward computation.
I1021 23:15:39.539754 25759 net.cpp:226] loss_bbox_p2 needs backward computation.
I1021 23:15:39.539758 25759 net.cpp:228] accuarcy_p3 does not need backward computation.
I1021 23:15:39.539763 25759 net.cpp:228] accuarcy_p2 does not need backward computation.
I1021 23:15:39.539767 25759 net.cpp:226] loss_p3 needs backward computation.
I1021 23:15:39.539769 25759 net.cpp:226] loss_p2 needs backward computation.
I1021 23:15:39.539773 25759 net.cpp:228] labels_ohem_p3_annotator_detector_p3_0_split does not need backward computation.
I1021 23:15:39.539777 25759 net.cpp:228] annotator_detector_p3 does not need backward computation.
I1021 23:15:39.539783 25759 net.cpp:228] per_roi_loss_p3 does not need backward computation.
I1021 23:15:39.539788 25759 net.cpp:228] per_roi_loss_bbox_p3 does not need backward computation.
I1021 23:15:39.539793 25759 net.cpp:228] per_roi_loss_cls_p3 does not need backward computation.
I1021 23:15:39.539798 25759 net.cpp:226] bbox_pred_p3_ave_bbox_pred_rois_p3_0_split needs backward computation.
I1021 23:15:39.539801 25759 net.cpp:226] ave_bbox_pred_rois_p3 needs backward computation.
I1021 23:15:39.539804 25759 net.cpp:226] psroipooled_loc_rois_p3 needs backward computation.
I1021 23:15:39.539808 25759 net.cpp:226] cls_score_p3_ave_cls_score_rois_p3_0_split needs backward computation.
I1021 23:15:39.539811 25759 net.cpp:226] ave_cls_score_rois_p3 needs backward computation.
I1021 23:15:39.539814 25759 net.cpp:226] psroipooled_cls_rois_p3 needs backward computation.
I1021 23:15:39.539816 25759 net.cpp:226] rfcn_bbox_p3 needs backward computation.
I1021 23:15:39.539819 25759 net.cpp:226] rfcn_cls_p3 needs backward computation.
I1021 23:15:39.539822 25759 net.cpp:226] conv_new_p3_conv_new_p3_relu_0_split needs backward computation.
I1021 23:15:39.539825 25759 net.cpp:226] conv_new_p3_relu needs backward computation.
I1021 23:15:39.539829 25759 net.cpp:226] conv_new_p3 needs backward computation.
I1021 23:15:39.539831 25759 net.cpp:228] labels_ohem_p2_annotator_detector_p2_0_split does not need backward computation.
I1021 23:15:39.539835 25759 net.cpp:228] annotator_detector_p2 does not need backward computation.
I1021 23:15:39.539842 25759 net.cpp:228] per_roi_loss_p2 does not need backward computation.
I1021 23:15:39.539846 25759 net.cpp:228] per_roi_loss_bbox_p2 does not need backward computation.
I1021 23:15:39.539851 25759 net.cpp:228] per_roi_loss_cls_p2 does not need backward computation.
I1021 23:15:39.539857 25759 net.cpp:226] bbox_pred_p2_ave_bbox_pred_rois_p2_0_split needs backward computation.
I1021 23:15:39.539860 25759 net.cpp:226] ave_bbox_pred_rois_p2 needs backward computation.
I1021 23:15:39.539863 25759 net.cpp:226] psroipooled_loc_rois_p2 needs backward computation.
I1021 23:15:39.539867 25759 net.cpp:226] cls_score_p2_ave_cls_score_rois_p2_0_split needs backward computation.
I1021 23:15:39.539870 25759 net.cpp:226] ave_cls_score_rois_p2 needs backward computation.
I1021 23:15:39.539873 25759 net.cpp:226] psroipooled_cls_rois_p2 needs backward computation.
I1021 23:15:39.539876 25759 net.cpp:226] rfcn_bbox_p2 needs backward computation.
I1021 23:15:39.539880 25759 net.cpp:226] rfcn_cls_p2 needs backward computation.
I1021 23:15:39.539882 25759 net.cpp:226] conv_new_p2_conv_new_p2_relu_0_split needs backward computation.
I1021 23:15:39.539885 25759 net.cpp:226] conv_new_p2_relu needs backward computation.
I1021 23:15:39.539887 25759 net.cpp:226] conv_new_p2 needs backward computation.
I1021 23:15:39.539891 25759 net.cpp:228] bbox_inside_weights_p3_roi-data_7_split does not need backward computation.
I1021 23:15:39.539894 25759 net.cpp:228] bbox_inside_weights_p2_roi-data_6_split does not need backward computation.
I1021 23:15:39.539898 25759 net.cpp:228] bbox_targets_p3_roi-data_5_split does not need backward computation.
I1021 23:15:39.539901 25759 net.cpp:228] bbox_targets_p2_roi-data_4_split does not need backward computation.
I1021 23:15:39.539906 25759 net.cpp:228] labels_p3_roi-data_3_split does not need backward computation.
I1021 23:15:39.539909 25759 net.cpp:228] labels_p2_roi-data_2_split does not need backward computation.
I1021 23:15:39.539912 25759 net.cpp:226] rois_p3_roi-data_1_split needs backward computation.
I1021 23:15:39.539916 25759 net.cpp:226] rois_p2_roi-data_0_split needs backward computation.
I1021 23:15:39.539918 25759 net.cpp:226] roi-data needs backward computation.
I1021 23:15:39.539923 25759 net.cpp:226] proposal needs backward computation.
I1021 23:15:39.539928 25759 net.cpp:226] rpn_loss_bbox_p3 needs backward computation.
I1021 23:15:39.539933 25759 net.cpp:226] rpn_loss_cls_p3 needs backward computation.
I1021 23:15:39.539937 25759 net.cpp:226] rpn_loss_bbox_p2 needs backward computation.
I1021 23:15:39.539942 25759 net.cpp:226] rpn_loss_cls_p2 needs backward computation.
I1021 23:15:39.539947 25759 net.cpp:226] rpn-data needs backward computation.
I1021 23:15:39.539952 25759 net.cpp:226] rpn_cls_prob_reshape_p3 needs backward computation.
I1021 23:15:39.539954 25759 net.cpp:226] rpn_cls_prob_p3 needs backward computation.
I1021 23:15:39.539958 25759 net.cpp:226] rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split needs backward computation.
I1021 23:15:39.539963 25759 net.cpp:226] rpn_cls_score_reshape_p3 needs backward computation.
I1021 23:15:39.539965 25759 net.cpp:226] rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split needs backward computation.
I1021 23:15:39.539968 25759 net.cpp:226] rpn_bbox_pred_p3 needs backward computation.
I1021 23:15:39.539973 25759 net.cpp:226] rpn_cls_score_p3_rpn_cls_score_p3_0_split needs backward computation.
I1021 23:15:39.539975 25759 net.cpp:226] rpn_cls_score_p3 needs backward computation.
I1021 23:15:39.539978 25759 net.cpp:226] rpn/output_p3_rpn_relu/3x3_p3_0_split needs backward computation.
I1021 23:15:39.539981 25759 net.cpp:226] rpn_relu/3x3_p3 needs backward computation.
I1021 23:15:39.539985 25759 net.cpp:226] rpn_conv/3x3_p3 needs backward computation.
I1021 23:15:39.539988 25759 net.cpp:226] rpn_cls_prob_reshape_p2 needs backward computation.
I1021 23:15:39.539991 25759 net.cpp:226] rpn_cls_prob_p2 needs backward computation.
I1021 23:15:39.539994 25759 net.cpp:226] rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split needs backward computation.
I1021 23:15:39.539999 25759 net.cpp:226] rpn_cls_score_reshape_p2 needs backward computation.
I1021 23:15:39.540004 25759 net.cpp:226] rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split needs backward computation.
I1021 23:15:39.540007 25759 net.cpp:226] rpn_bbox_pred_p2 needs backward computation.
I1021 23:15:39.540010 25759 net.cpp:226] rpn_cls_score_p2_rpn_cls_score_p2_0_split needs backward computation.
I1021 23:15:39.540014 25759 net.cpp:226] rpn_cls_score_p2 needs backward computation.
I1021 23:15:39.540017 25759 net.cpp:226] rpn/output_p2_rpn_relu/3x3_p2_0_split needs backward computation.
I1021 23:15:39.540020 25759 net.cpp:226] rpn_relu/3x3_p2 needs backward computation.
I1021 23:15:39.540024 25759 net.cpp:226] rpn_conv/3x3_p2 needs backward computation.
I1021 23:15:39.540026 25759 net.cpp:226] p2_p2_relu_0_split needs backward computation.
I1021 23:15:39.540030 25759 net.cpp:226] p2_relu needs backward computation.
I1021 23:15:39.540032 25759 net.cpp:226] p2 needs backward computation.
I1021 23:15:39.540035 25759 net.cpp:226] bn_eltwise_2_2_scale needs backward computation.
I1021 23:15:39.540038 25759 net.cpp:226] bn_eltwise_2_2_bn needs backward computation.
I1021 23:15:39.540041 25759 net.cpp:226] bn_eltwise_2_2_conv needs backward computation.
I1021 23:15:39.540045 25759 net.cpp:226] bn_eltwise_2_1_ReLU needs backward computation.
I1021 23:15:39.540047 25759 net.cpp:226] bn_eltwise_2_1_scale needs backward computation.
I1021 23:15:39.540050 25759 net.cpp:226] bn_eltwise_2_1_bn needs backward computation.
I1021 23:15:39.540052 25759 net.cpp:226] bn_eltwise_2_1_conv needs backward computation.
I1021 23:15:39.540055 25759 net.cpp:226] bnp3_ReLU needs backward computation.
I1021 23:15:39.540058 25759 net.cpp:226] bnp3_scale needs backward computation.
I1021 23:15:39.540061 25759 net.cpp:226] bnp3_bn needs backward computation.
I1021 23:15:39.540064 25759 net.cpp:226] bnp3_conv needs backward computation.
I1021 23:15:39.540067 25759 net.cpp:226] skip_eltwise2_eltwise_bnc3_bnp3_0_split needs backward computation.
I1021 23:15:39.540071 25759 net.cpp:226] eltwise_bnc3_bnp3 needs backward computation.
I1021 23:15:39.540074 25759 net.cpp:226] upP3 needs backward computation.
I1021 23:15:39.540077 25759 net.cpp:226] newC3 needs backward computation.
I1021 23:15:39.540081 25759 net.cpp:226] p3_p3_relu_0_split needs backward computation.
I1021 23:15:39.540083 25759 net.cpp:226] p3_relu needs backward computation.
I1021 23:15:39.540086 25759 net.cpp:226] p3 needs backward computation.
I1021 23:15:39.540091 25759 net.cpp:226] bn_eltwise_1_2_scale needs backward computation.
I1021 23:15:39.540093 25759 net.cpp:226] bn_eltwise_1_2_bn needs backward computation.
I1021 23:15:39.540096 25759 net.cpp:226] bn_eltwise_1_2_conv needs backward computation.
I1021 23:15:39.540098 25759 net.cpp:226] bn_eltwise_1_1_ReLU needs backward computation.
I1021 23:15:39.540102 25759 net.cpp:226] bn_eltwise_1_1_scale needs backward computation.
I1021 23:15:39.540104 25759 net.cpp:226] bn_eltwise_1_1_bn needs backward computation.
I1021 23:15:39.540107 25759 net.cpp:226] bn_eltwise_1_1_conv needs backward computation.
I1021 23:15:39.540110 25759 net.cpp:226] bnp4_ReLU needs backward computation.
I1021 23:15:39.540112 25759 net.cpp:226] bnp4_scale needs backward computation.
I1021 23:15:39.540115 25759 net.cpp:226] bnp4_bn needs backward computation.
I1021 23:15:39.540118 25759 net.cpp:226] bnp4_conv needs backward computation.
I1021 23:15:39.540122 25759 net.cpp:226] skip_eltwise1_eltwise_bnc4_bnp4_0_split needs backward computation.
I1021 23:15:39.540124 25759 net.cpp:226] eltwise_bnc4_bnp4 needs backward computation.
I1021 23:15:39.540127 25759 net.cpp:226] newC4 needs backward computation.
I1021 23:15:39.540132 25759 net.cpp:226] upP4 needs backward computation.
I1021 23:15:39.540134 25759 net.cpp:226] res5c_relu needs backward computation.
I1021 23:15:39.540138 25759 net.cpp:226] res5c needs backward computation.
I1021 23:15:39.540141 25759 net.cpp:226] scale5c_branch2c needs backward computation.
I1021 23:15:39.540143 25759 net.cpp:226] bn5c_branch2c needs backward computation.
I1021 23:15:39.540148 25759 net.cpp:226] res5c_branch2c needs backward computation.
I1021 23:15:39.540150 25759 net.cpp:226] res5c_branch2b_relu needs backward computation.
I1021 23:15:39.540153 25759 net.cpp:226] scale5c_branch2b needs backward computation.
I1021 23:15:39.540155 25759 net.cpp:226] bn5c_branch2b needs backward computation.
I1021 23:15:39.540158 25759 net.cpp:226] res5c_branch2b needs backward computation.
I1021 23:15:39.540161 25759 net.cpp:226] res5c_branch2a_relu needs backward computation.
I1021 23:15:39.540164 25759 net.cpp:226] scale5c_branch2a needs backward computation.
I1021 23:15:39.540166 25759 net.cpp:226] bn5c_branch2a needs backward computation.
I1021 23:15:39.540169 25759 net.cpp:226] res5c_branch2a needs backward computation.
I1021 23:15:39.540172 25759 net.cpp:226] res5b_res5b_relu_0_split needs backward computation.
I1021 23:15:39.540175 25759 net.cpp:226] res5b_relu needs backward computation.
I1021 23:15:39.540179 25759 net.cpp:226] res5b needs backward computation.
I1021 23:15:39.540181 25759 net.cpp:226] scale5b_branch2c needs backward computation.
I1021 23:15:39.540184 25759 net.cpp:226] bn5b_branch2c needs backward computation.
I1021 23:15:39.540187 25759 net.cpp:226] res5b_branch2c needs backward computation.
I1021 23:15:39.540190 25759 net.cpp:226] res5b_branch2b_relu needs backward computation.
I1021 23:15:39.540194 25759 net.cpp:226] scale5b_branch2b needs backward computation.
I1021 23:15:39.540195 25759 net.cpp:226] bn5b_branch2b needs backward computation.
I1021 23:15:39.540199 25759 net.cpp:226] res5b_branch2b needs backward computation.
I1021 23:15:39.540201 25759 net.cpp:226] res5b_branch2a_relu needs backward computation.
I1021 23:15:39.540205 25759 net.cpp:226] scale5b_branch2a needs backward computation.
I1021 23:15:39.540206 25759 net.cpp:226] bn5b_branch2a needs backward computation.
I1021 23:15:39.540210 25759 net.cpp:226] res5b_branch2a needs backward computation.
I1021 23:15:39.540212 25759 net.cpp:226] res5a_res5a_relu_0_split needs backward computation.
I1021 23:15:39.540217 25759 net.cpp:226] res5a_relu needs backward computation.
I1021 23:15:39.540220 25759 net.cpp:226] res5a needs backward computation.
I1021 23:15:39.540223 25759 net.cpp:226] scale5a_branch2c needs backward computation.
I1021 23:15:39.540226 25759 net.cpp:226] bn5a_branch2c needs backward computation.
I1021 23:15:39.540230 25759 net.cpp:226] res5a_branch2c needs backward computation.
I1021 23:15:39.540233 25759 net.cpp:226] res5a_branch2b_relu needs backward computation.
I1021 23:15:39.540236 25759 net.cpp:226] scale5a_branch2b needs backward computation.
I1021 23:15:39.540238 25759 net.cpp:226] bn5a_branch2b needs backward computation.
I1021 23:15:39.540242 25759 net.cpp:226] res5a_branch2b needs backward computation.
I1021 23:15:39.540244 25759 net.cpp:226] res5a_branch2a_relu needs backward computation.
I1021 23:15:39.540247 25759 net.cpp:226] scale5a_branch2a needs backward computation.
I1021 23:15:39.540251 25759 net.cpp:226] bn5a_branch2a needs backward computation.
I1021 23:15:39.540253 25759 net.cpp:226] res5a_branch2a needs backward computation.
I1021 23:15:39.540257 25759 net.cpp:226] scale5a_branch1 needs backward computation.
I1021 23:15:39.540259 25759 net.cpp:226] bn5a_branch1 needs backward computation.
I1021 23:15:39.540262 25759 net.cpp:226] res5a_branch1 needs backward computation.
I1021 23:15:39.540266 25759 net.cpp:226] res4f_res4f_relu_0_split needs backward computation.
I1021 23:15:39.540269 25759 net.cpp:226] res4f_relu needs backward computation.
I1021 23:15:39.540271 25759 net.cpp:226] res4f needs backward computation.
I1021 23:15:39.540275 25759 net.cpp:226] scale4f_branch2c needs backward computation.
I1021 23:15:39.540278 25759 net.cpp:226] bn4f_branch2c needs backward computation.
I1021 23:15:39.540282 25759 net.cpp:226] res4f_branch2c needs backward computation.
I1021 23:15:39.540284 25759 net.cpp:226] res4f_branch2b_relu needs backward computation.
I1021 23:15:39.540287 25759 net.cpp:226] scale4f_branch2b needs backward computation.
I1021 23:15:39.540289 25759 net.cpp:226] bn4f_branch2b needs backward computation.
I1021 23:15:39.540292 25759 net.cpp:226] res4f_branch2b needs backward computation.
I1021 23:15:39.540295 25759 net.cpp:226] res4f_branch2a_relu needs backward computation.
I1021 23:15:39.540298 25759 net.cpp:226] scale4f_branch2a needs backward computation.
I1021 23:15:39.540302 25759 net.cpp:226] bn4f_branch2a needs backward computation.
I1021 23:15:39.540303 25759 net.cpp:226] res4f_branch2a needs backward computation.
I1021 23:15:39.540307 25759 net.cpp:226] res4e_res4e_relu_0_split needs backward computation.
I1021 23:15:39.540309 25759 net.cpp:226] res4e_relu needs backward computation.
I1021 23:15:39.540313 25759 net.cpp:226] res4e needs backward computation.
I1021 23:15:39.540315 25759 net.cpp:226] scale4e_branch2c needs backward computation.
I1021 23:15:39.540319 25759 net.cpp:226] bn4e_branch2c needs backward computation.
I1021 23:15:39.540321 25759 net.cpp:226] res4e_branch2c needs backward computation.
I1021 23:15:39.540324 25759 net.cpp:226] res4e_branch2b_relu needs backward computation.
I1021 23:15:39.540328 25759 net.cpp:226] scale4e_branch2b needs backward computation.
I1021 23:15:39.540346 25759 net.cpp:226] bn4e_branch2b needs backward computation.
I1021 23:15:39.540349 25759 net.cpp:226] res4e_branch2b needs backward computation.
I1021 23:15:39.540352 25759 net.cpp:226] res4e_branch2a_relu needs backward computation.
I1021 23:15:39.540354 25759 net.cpp:226] scale4e_branch2a needs backward computation.
I1021 23:15:39.540357 25759 net.cpp:226] bn4e_branch2a needs backward computation.
I1021 23:15:39.540360 25759 net.cpp:226] res4e_branch2a needs backward computation.
I1021 23:15:39.540364 25759 net.cpp:226] res4d_res4d_relu_0_split needs backward computation.
I1021 23:15:39.540369 25759 net.cpp:226] res4d_relu needs backward computation.
I1021 23:15:39.540371 25759 net.cpp:226] res4d needs backward computation.
I1021 23:15:39.540374 25759 net.cpp:226] scale4d_branch2c needs backward computation.
I1021 23:15:39.540379 25759 net.cpp:226] bn4d_branch2c needs backward computation.
I1021 23:15:39.540380 25759 net.cpp:226] res4d_branch2c needs backward computation.
I1021 23:15:39.540383 25759 net.cpp:226] res4d_branch2b_relu needs backward computation.
I1021 23:15:39.540386 25759 net.cpp:226] scale4d_branch2b needs backward computation.
I1021 23:15:39.540390 25759 net.cpp:226] bn4d_branch2b needs backward computation.
I1021 23:15:39.540392 25759 net.cpp:226] res4d_branch2b needs backward computation.
I1021 23:15:39.540395 25759 net.cpp:226] res4d_branch2a_relu needs backward computation.
I1021 23:15:39.540398 25759 net.cpp:226] scale4d_branch2a needs backward computation.
I1021 23:15:39.540401 25759 net.cpp:226] bn4d_branch2a needs backward computation.
I1021 23:15:39.540403 25759 net.cpp:226] res4d_branch2a needs backward computation.
I1021 23:15:39.540406 25759 net.cpp:226] res4c_res4c_relu_0_split needs backward computation.
I1021 23:15:39.540410 25759 net.cpp:226] res4c_relu needs backward computation.
I1021 23:15:39.540413 25759 net.cpp:226] res4c needs backward computation.
I1021 23:15:39.540416 25759 net.cpp:226] scale4c_branch2c needs backward computation.
I1021 23:15:39.540419 25759 net.cpp:226] bn4c_branch2c needs backward computation.
I1021 23:15:39.540421 25759 net.cpp:226] res4c_branch2c needs backward computation.
I1021 23:15:39.540426 25759 net.cpp:226] res4c_branch2b_relu needs backward computation.
I1021 23:15:39.540428 25759 net.cpp:226] scale4c_branch2b needs backward computation.
I1021 23:15:39.540431 25759 net.cpp:226] bn4c_branch2b needs backward computation.
I1021 23:15:39.540433 25759 net.cpp:226] res4c_branch2b needs backward computation.
I1021 23:15:39.540436 25759 net.cpp:226] res4c_branch2a_relu needs backward computation.
I1021 23:15:39.540439 25759 net.cpp:226] scale4c_branch2a needs backward computation.
I1021 23:15:39.540442 25759 net.cpp:226] bn4c_branch2a needs backward computation.
I1021 23:15:39.540444 25759 net.cpp:226] res4c_branch2a needs backward computation.
I1021 23:15:39.540448 25759 net.cpp:226] res4b_res4b_relu_0_split needs backward computation.
I1021 23:15:39.540452 25759 net.cpp:226] res4b_relu needs backward computation.
I1021 23:15:39.540454 25759 net.cpp:226] res4b needs backward computation.
I1021 23:15:39.540457 25759 net.cpp:226] scale4b_branch2c needs backward computation.
I1021 23:15:39.540460 25759 net.cpp:226] bn4b_branch2c needs backward computation.
I1021 23:15:39.540463 25759 net.cpp:226] res4b_branch2c needs backward computation.
I1021 23:15:39.540467 25759 net.cpp:226] res4b_branch2b_relu needs backward computation.
I1021 23:15:39.540469 25759 net.cpp:226] scale4b_branch2b needs backward computation.
I1021 23:15:39.540472 25759 net.cpp:226] bn4b_branch2b needs backward computation.
I1021 23:15:39.540475 25759 net.cpp:226] res4b_branch2b needs backward computation.
I1021 23:15:39.540478 25759 net.cpp:226] res4b_branch2a_relu needs backward computation.
I1021 23:15:39.540480 25759 net.cpp:226] scale4b_branch2a needs backward computation.
I1021 23:15:39.540483 25759 net.cpp:226] bn4b_branch2a needs backward computation.
I1021 23:15:39.540486 25759 net.cpp:226] res4b_branch2a needs backward computation.
I1021 23:15:39.540489 25759 net.cpp:226] res4a_res4a_relu_0_split needs backward computation.
I1021 23:15:39.540493 25759 net.cpp:226] res4a_relu needs backward computation.
I1021 23:15:39.540495 25759 net.cpp:226] res4a needs backward computation.
I1021 23:15:39.540498 25759 net.cpp:226] scale4a_branch2c needs backward computation.
I1021 23:15:39.540501 25759 net.cpp:226] bn4a_branch2c needs backward computation.
I1021 23:15:39.540504 25759 net.cpp:226] res4a_branch2c needs backward computation.
I1021 23:15:39.540508 25759 net.cpp:226] res4a_branch2b_relu needs backward computation.
I1021 23:15:39.540510 25759 net.cpp:226] scale4a_branch2b needs backward computation.
I1021 23:15:39.540513 25759 net.cpp:226] bn4a_branch2b needs backward computation.
I1021 23:15:39.540516 25759 net.cpp:226] res4a_branch2b needs backward computation.
I1021 23:15:39.540519 25759 net.cpp:226] res4a_branch2a_relu needs backward computation.
I1021 23:15:39.540522 25759 net.cpp:226] scale4a_branch2a needs backward computation.
I1021 23:15:39.540524 25759 net.cpp:226] bn4a_branch2a needs backward computation.
I1021 23:15:39.540527 25759 net.cpp:226] res4a_branch2a needs backward computation.
I1021 23:15:39.540531 25759 net.cpp:226] scale4a_branch1 needs backward computation.
I1021 23:15:39.540534 25759 net.cpp:226] bn4a_branch1 needs backward computation.
I1021 23:15:39.540537 25759 net.cpp:226] res4a_branch1 needs backward computation.
I1021 23:15:39.540541 25759 net.cpp:226] res3d_res3d_relu_0_split needs backward computation.
I1021 23:15:39.540545 25759 net.cpp:226] res3d_relu needs backward computation.
I1021 23:15:39.540549 25759 net.cpp:226] res3d needs backward computation.
I1021 23:15:39.540551 25759 net.cpp:226] scale3d_branch2c needs backward computation.
I1021 23:15:39.540555 25759 net.cpp:226] bn3d_branch2c needs backward computation.
I1021 23:15:39.540557 25759 net.cpp:226] res3d_branch2c needs backward computation.
I1021 23:15:39.540560 25759 net.cpp:226] res3d_branch2b_relu needs backward computation.
I1021 23:15:39.540563 25759 net.cpp:226] scale3d_branch2b needs backward computation.
I1021 23:15:39.540566 25759 net.cpp:226] bn3d_branch2b needs backward computation.
I1021 23:15:39.540570 25759 net.cpp:226] res3d_branch2b needs backward computation.
I1021 23:15:39.540572 25759 net.cpp:226] res3d_branch2a_relu needs backward computation.
I1021 23:15:39.540575 25759 net.cpp:226] scale3d_branch2a needs backward computation.
I1021 23:15:39.540577 25759 net.cpp:226] bn3d_branch2a needs backward computation.
I1021 23:15:39.540580 25759 net.cpp:226] res3d_branch2a needs backward computation.
I1021 23:15:39.540583 25759 net.cpp:226] res3c_res3c_relu_0_split needs backward computation.
I1021 23:15:39.540587 25759 net.cpp:226] res3c_relu needs backward computation.
I1021 23:15:39.540590 25759 net.cpp:226] res3c needs backward computation.
I1021 23:15:39.540593 25759 net.cpp:226] scale3c_branch2c needs backward computation.
I1021 23:15:39.540596 25759 net.cpp:226] bn3c_branch2c needs backward computation.
I1021 23:15:39.540599 25759 net.cpp:226] res3c_branch2c needs backward computation.
I1021 23:15:39.540602 25759 net.cpp:226] res3c_branch2b_relu needs backward computation.
I1021 23:15:39.540606 25759 net.cpp:226] scale3c_branch2b needs backward computation.
I1021 23:15:39.540616 25759 net.cpp:226] bn3c_branch2b needs backward computation.
I1021 23:15:39.540621 25759 net.cpp:226] res3c_branch2b needs backward computation.
I1021 23:15:39.540623 25759 net.cpp:226] res3c_branch2a_relu needs backward computation.
I1021 23:15:39.540627 25759 net.cpp:226] scale3c_branch2a needs backward computation.
I1021 23:15:39.540629 25759 net.cpp:226] bn3c_branch2a needs backward computation.
I1021 23:15:39.540632 25759 net.cpp:226] res3c_branch2a needs backward computation.
I1021 23:15:39.540635 25759 net.cpp:226] res3b_res3b_relu_0_split needs backward computation.
I1021 23:15:39.540639 25759 net.cpp:226] res3b_relu needs backward computation.
I1021 23:15:39.540642 25759 net.cpp:226] res3b needs backward computation.
I1021 23:15:39.540645 25759 net.cpp:226] scale3b_branch2c needs backward computation.
I1021 23:15:39.540648 25759 net.cpp:226] bn3b_branch2c needs backward computation.
I1021 23:15:39.540652 25759 net.cpp:226] res3b_branch2c needs backward computation.
I1021 23:15:39.540654 25759 net.cpp:226] res3b_branch2b_relu needs backward computation.
I1021 23:15:39.540657 25759 net.cpp:226] scale3b_branch2b needs backward computation.
I1021 23:15:39.540659 25759 net.cpp:226] bn3b_branch2b needs backward computation.
I1021 23:15:39.540663 25759 net.cpp:226] res3b_branch2b needs backward computation.
I1021 23:15:39.540666 25759 net.cpp:226] res3b_branch2a_relu needs backward computation.
I1021 23:15:39.540669 25759 net.cpp:226] scale3b_branch2a needs backward computation.
I1021 23:15:39.540673 25759 net.cpp:226] bn3b_branch2a needs backward computation.
I1021 23:15:39.540675 25759 net.cpp:226] res3b_branch2a needs backward computation.
I1021 23:15:39.540678 25759 net.cpp:226] res3a_res3a_relu_0_split needs backward computation.
I1021 23:15:39.540681 25759 net.cpp:226] res3a_relu needs backward computation.
I1021 23:15:39.540684 25759 net.cpp:226] res3a needs backward computation.
I1021 23:15:39.540688 25759 net.cpp:226] scale3a_branch2c needs backward computation.
I1021 23:15:39.540691 25759 net.cpp:226] bn3a_branch2c needs backward computation.
I1021 23:15:39.540693 25759 net.cpp:226] res3a_branch2c needs backward computation.
I1021 23:15:39.540696 25759 net.cpp:226] res3a_branch2b_relu needs backward computation.
I1021 23:15:39.540699 25759 net.cpp:226] scale3a_branch2b needs backward computation.
I1021 23:15:39.540702 25759 net.cpp:226] bn3a_branch2b needs backward computation.
I1021 23:15:39.540705 25759 net.cpp:226] res3a_branch2b needs backward computation.
I1021 23:15:39.540707 25759 net.cpp:226] res3a_branch2a_relu needs backward computation.
I1021 23:15:39.540711 25759 net.cpp:226] scale3a_branch2a needs backward computation.
I1021 23:15:39.540714 25759 net.cpp:226] bn3a_branch2a needs backward computation.
I1021 23:15:39.540717 25759 net.cpp:226] res3a_branch2a needs backward computation.
I1021 23:15:39.540721 25759 net.cpp:226] scale3a_branch1 needs backward computation.
I1021 23:15:39.540724 25759 net.cpp:226] bn3a_branch1 needs backward computation.
I1021 23:15:39.540727 25759 net.cpp:226] res3a_branch1 needs backward computation.
I1021 23:15:39.540731 25759 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I1021 23:15:39.540735 25759 net.cpp:228] res2c_relu does not need backward computation.
I1021 23:15:39.540738 25759 net.cpp:228] res2c does not need backward computation.
I1021 23:15:39.540742 25759 net.cpp:228] scale2c_branch2c does not need backward computation.
I1021 23:15:39.540745 25759 net.cpp:228] bn2c_branch2c does not need backward computation.
I1021 23:15:39.540748 25759 net.cpp:228] res2c_branch2c does not need backward computation.
I1021 23:15:39.540752 25759 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I1021 23:15:39.540755 25759 net.cpp:228] scale2c_branch2b does not need backward computation.
I1021 23:15:39.540757 25759 net.cpp:228] bn2c_branch2b does not need backward computation.
I1021 23:15:39.540760 25759 net.cpp:228] res2c_branch2b does not need backward computation.
I1021 23:15:39.540765 25759 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I1021 23:15:39.540767 25759 net.cpp:228] scale2c_branch2a does not need backward computation.
I1021 23:15:39.540771 25759 net.cpp:228] bn2c_branch2a does not need backward computation.
I1021 23:15:39.540773 25759 net.cpp:228] res2c_branch2a does not need backward computation.
I1021 23:15:39.540777 25759 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I1021 23:15:39.540781 25759 net.cpp:228] res2b_relu does not need backward computation.
I1021 23:15:39.540783 25759 net.cpp:228] res2b does not need backward computation.
I1021 23:15:39.540789 25759 net.cpp:228] scale2b_branch2c does not need backward computation.
I1021 23:15:39.540793 25759 net.cpp:228] bn2b_branch2c does not need backward computation.
I1021 23:15:39.540796 25759 net.cpp:228] res2b_branch2c does not need backward computation.
I1021 23:15:39.540799 25759 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I1021 23:15:39.540802 25759 net.cpp:228] scale2b_branch2b does not need backward computation.
I1021 23:15:39.540805 25759 net.cpp:228] bn2b_branch2b does not need backward computation.
I1021 23:15:39.540808 25759 net.cpp:228] res2b_branch2b does not need backward computation.
I1021 23:15:39.540812 25759 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I1021 23:15:39.540815 25759 net.cpp:228] scale2b_branch2a does not need backward computation.
I1021 23:15:39.540818 25759 net.cpp:228] bn2b_branch2a does not need backward computation.
I1021 23:15:39.540822 25759 net.cpp:228] res2b_branch2a does not need backward computation.
I1021 23:15:39.540825 25759 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I1021 23:15:39.540829 25759 net.cpp:228] res2a_relu does not need backward computation.
I1021 23:15:39.540832 25759 net.cpp:228] res2a does not need backward computation.
I1021 23:15:39.540838 25759 net.cpp:228] scale2a_branch2c does not need backward computation.
I1021 23:15:39.540840 25759 net.cpp:228] bn2a_branch2c does not need backward computation.
I1021 23:15:39.540843 25759 net.cpp:228] res2a_branch2c does not need backward computation.
I1021 23:15:39.540846 25759 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I1021 23:15:39.540849 25759 net.cpp:228] scale2a_branch2b does not need backward computation.
I1021 23:15:39.540853 25759 net.cpp:228] bn2a_branch2b does not need backward computation.
I1021 23:15:39.540855 25759 net.cpp:228] res2a_branch2b does not need backward computation.
I1021 23:15:39.540859 25759 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I1021 23:15:39.540863 25759 net.cpp:228] scale2a_branch2a does not need backward computation.
I1021 23:15:39.540865 25759 net.cpp:228] bn2a_branch2a does not need backward computation.
I1021 23:15:39.540868 25759 net.cpp:228] res2a_branch2a does not need backward computation.
I1021 23:15:39.540872 25759 net.cpp:228] scale2a_branch1 does not need backward computation.
I1021 23:15:39.540875 25759 net.cpp:228] bn2a_branch1 does not need backward computation.
I1021 23:15:39.540879 25759 net.cpp:228] res2a_branch1 does not need backward computation.
I1021 23:15:39.540882 25759 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I1021 23:15:39.540886 25759 net.cpp:228] pool1 does not need backward computation.
I1021 23:15:39.540890 25759 net.cpp:228] conv1_relu does not need backward computation.
I1021 23:15:39.540894 25759 net.cpp:228] scale_conv1 does not need backward computation.
I1021 23:15:39.540896 25759 net.cpp:228] bn_conv1 does not need backward computation.
I1021 23:15:39.540899 25759 net.cpp:228] conv1 does not need backward computation.
I1021 23:15:39.540904 25759 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I1021 23:15:39.540908 25759 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I1021 23:15:39.540912 25759 net.cpp:228] data_input-data_0_split does not need backward computation.
I1021 23:15:39.540917 25759 net.cpp:228] input-data does not need backward computation.
I1021 23:15:39.540920 25759 net.cpp:270] This network produces output accuarcy_p2
I1021 23:15:39.540922 25759 net.cpp:270] This network produces output accuarcy_p3
I1021 23:15:39.540925 25759 net.cpp:270] This network produces output loss_bbox_p2
I1021 23:15:39.540930 25759 net.cpp:270] This network produces output loss_bbox_p3
I1021 23:15:39.540931 25759 net.cpp:270] This network produces output loss_cls_p2
I1021 23:15:39.540935 25759 net.cpp:270] This network produces output loss_cls_p3
I1021 23:15:39.540937 25759 net.cpp:270] This network produces output rpn_cls_loss_p2
I1021 23:15:39.540940 25759 net.cpp:270] This network produces output rpn_cls_loss_p3
I1021 23:15:39.540943 25759 net.cpp:270] This network produces output rpn_loss_bbox_p2
I1021 23:15:39.540946 25759 net.cpp:270] This network produces output rpn_loss_bbox_p3
I1021 23:15:39.541157 25759 net.cpp:283] Network initialization done.
I1021 23:15:39.541972 25759 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/ResNet-50-model.caffemodel
I1021 23:15:39.639025 25759 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/ResNet-50-model.caffemodel
I1021 23:15:39.639048 25759 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W1021 23:15:39.639066 25759 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I1021 23:15:39.639071 25759 net.cpp:774] Copying source layer conv1
I1021 23:15:39.639091 25759 net.cpp:774] Copying source layer bn_conv1
I1021 23:15:39.639094 25759 net.cpp:774] Copying source layer scale_conv1
I1021 23:15:39.639099 25759 net.cpp:774] Copying source layer conv1_relu
I1021 23:15:39.639101 25759 net.cpp:774] Copying source layer pool1
I1021 23:15:39.639103 25759 net.cpp:774] Copying source layer pool1_pool1_0_split
I1021 23:15:39.639106 25759 net.cpp:774] Copying source layer res2a_branch1
I1021 23:15:39.639147 25759 net.cpp:774] Copying source layer bn2a_branch1
I1021 23:15:39.639151 25759 net.cpp:774] Copying source layer scale2a_branch1
I1021 23:15:39.639155 25759 net.cpp:774] Copying source layer res2a_branch2a
I1021 23:15:39.639179 25759 net.cpp:774] Copying source layer bn2a_branch2a
I1021 23:15:39.639184 25759 net.cpp:774] Copying source layer scale2a_branch2a
I1021 23:15:39.639187 25759 net.cpp:774] Copying source layer res2a_branch2a_relu
I1021 23:15:39.639190 25759 net.cpp:774] Copying source layer res2a_branch2b
I1021 23:15:39.639233 25759 net.cpp:774] Copying source layer bn2a_branch2b
I1021 23:15:39.639240 25759 net.cpp:774] Copying source layer scale2a_branch2b
I1021 23:15:39.639245 25759 net.cpp:774] Copying source layer res2a_branch2b_relu
I1021 23:15:39.639247 25759 net.cpp:774] Copying source layer res2a_branch2c
I1021 23:15:39.639271 25759 net.cpp:774] Copying source layer bn2a_branch2c
I1021 23:15:39.639276 25759 net.cpp:774] Copying source layer scale2a_branch2c
I1021 23:15:39.639281 25759 net.cpp:774] Copying source layer res2a
I1021 23:15:39.639284 25759 net.cpp:774] Copying source layer res2a_relu
I1021 23:15:39.639287 25759 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I1021 23:15:39.639289 25759 net.cpp:774] Copying source layer res2b_branch2a
I1021 23:15:39.639314 25759 net.cpp:774] Copying source layer bn2b_branch2a
I1021 23:15:39.639320 25759 net.cpp:774] Copying source layer scale2b_branch2a
I1021 23:15:39.639325 25759 net.cpp:774] Copying source layer res2b_branch2a_relu
I1021 23:15:39.639328 25759 net.cpp:774] Copying source layer res2b_branch2b
I1021 23:15:39.639389 25759 net.cpp:774] Copying source layer bn2b_branch2b
I1021 23:15:39.639396 25759 net.cpp:774] Copying source layer scale2b_branch2b
I1021 23:15:39.639400 25759 net.cpp:774] Copying source layer res2b_branch2b_relu
I1021 23:15:39.639403 25759 net.cpp:774] Copying source layer res2b_branch2c
I1021 23:15:39.639428 25759 net.cpp:774] Copying source layer bn2b_branch2c
I1021 23:15:39.639436 25759 net.cpp:774] Copying source layer scale2b_branch2c
I1021 23:15:39.639441 25759 net.cpp:774] Copying source layer res2b
I1021 23:15:39.639443 25759 net.cpp:774] Copying source layer res2b_relu
I1021 23:15:39.639446 25759 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I1021 23:15:39.639449 25759 net.cpp:774] Copying source layer res2c_branch2a
I1021 23:15:39.639474 25759 net.cpp:774] Copying source layer bn2c_branch2a
I1021 23:15:39.639482 25759 net.cpp:774] Copying source layer scale2c_branch2a
I1021 23:15:39.639485 25759 net.cpp:774] Copying source layer res2c_branch2a_relu
I1021 23:15:39.639488 25759 net.cpp:774] Copying source layer res2c_branch2b
I1021 23:15:39.639534 25759 net.cpp:774] Copying source layer bn2c_branch2b
I1021 23:15:39.639540 25759 net.cpp:774] Copying source layer scale2c_branch2b
I1021 23:15:39.639545 25759 net.cpp:774] Copying source layer res2c_branch2b_relu
I1021 23:15:39.639549 25759 net.cpp:774] Copying source layer res2c_branch2c
I1021 23:15:39.639572 25759 net.cpp:774] Copying source layer bn2c_branch2c
I1021 23:15:39.639580 25759 net.cpp:774] Copying source layer scale2c_branch2c
I1021 23:15:39.639585 25759 net.cpp:774] Copying source layer res2c
I1021 23:15:39.639587 25759 net.cpp:774] Copying source layer res2c_relu
I1021 23:15:39.639590 25759 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I1021 23:15:39.639593 25759 net.cpp:774] Copying source layer res3a_branch1
I1021 23:15:39.639734 25759 net.cpp:774] Copying source layer bn3a_branch1
I1021 23:15:39.639741 25759 net.cpp:774] Copying source layer scale3a_branch1
I1021 23:15:39.639747 25759 net.cpp:774] Copying source layer res3a_branch2a
I1021 23:15:39.639786 25759 net.cpp:774] Copying source layer bn3a_branch2a
I1021 23:15:39.639794 25759 net.cpp:774] Copying source layer scale3a_branch2a
I1021 23:15:39.639801 25759 net.cpp:774] Copying source layer res3a_branch2a_relu
I1021 23:15:39.639802 25759 net.cpp:774] Copying source layer res3a_branch2b
I1021 23:15:39.639941 25759 net.cpp:774] Copying source layer bn3a_branch2b
I1021 23:15:39.639950 25759 net.cpp:774] Copying source layer scale3a_branch2b
I1021 23:15:39.639955 25759 net.cpp:774] Copying source layer res3a_branch2b_relu
I1021 23:15:39.639957 25759 net.cpp:774] Copying source layer res3a_branch2c
I1021 23:15:39.640023 25759 net.cpp:774] Copying source layer bn3a_branch2c
I1021 23:15:39.640033 25759 net.cpp:774] Copying source layer scale3a_branch2c
I1021 23:15:39.640038 25759 net.cpp:774] Copying source layer res3a
I1021 23:15:39.640041 25759 net.cpp:774] Copying source layer res3a_relu
I1021 23:15:39.640043 25759 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I1021 23:15:39.640046 25759 net.cpp:774] Copying source layer res3b_branch2a
I1021 23:15:39.640117 25759 net.cpp:774] Copying source layer bn3b_branch2a
I1021 23:15:39.640125 25759 net.cpp:774] Copying source layer scale3b_branch2a
I1021 23:15:39.640130 25759 net.cpp:774] Copying source layer res3b_branch2a_relu
I1021 23:15:39.640132 25759 net.cpp:774] Copying source layer res3b_branch2b
I1021 23:15:39.640286 25759 net.cpp:774] Copying source layer bn3b_branch2b
I1021 23:15:39.640295 25759 net.cpp:774] Copying source layer scale3b_branch2b
I1021 23:15:39.640300 25759 net.cpp:774] Copying source layer res3b_branch2b_relu
I1021 23:15:39.640302 25759 net.cpp:774] Copying source layer res3b_branch2c
I1021 23:15:39.640367 25759 net.cpp:774] Copying source layer bn3b_branch2c
I1021 23:15:39.640375 25759 net.cpp:774] Copying source layer scale3b_branch2c
I1021 23:15:39.640381 25759 net.cpp:774] Copying source layer res3b
I1021 23:15:39.640384 25759 net.cpp:774] Copying source layer res3b_relu
I1021 23:15:39.640388 25759 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I1021 23:15:39.640389 25759 net.cpp:774] Copying source layer res3c_branch2a
I1021 23:15:39.640455 25759 net.cpp:774] Copying source layer bn3c_branch2a
I1021 23:15:39.640463 25759 net.cpp:774] Copying source layer scale3c_branch2a
I1021 23:15:39.640467 25759 net.cpp:774] Copying source layer res3c_branch2a_relu
I1021 23:15:39.640470 25759 net.cpp:774] Copying source layer res3c_branch2b
I1021 23:15:39.640624 25759 net.cpp:774] Copying source layer bn3c_branch2b
I1021 23:15:39.640630 25759 net.cpp:774] Copying source layer scale3c_branch2b
I1021 23:15:39.640635 25759 net.cpp:774] Copying source layer res3c_branch2b_relu
I1021 23:15:39.640638 25759 net.cpp:774] Copying source layer res3c_branch2c
I1021 23:15:39.640705 25759 net.cpp:774] Copying source layer bn3c_branch2c
I1021 23:15:39.640714 25759 net.cpp:774] Copying source layer scale3c_branch2c
I1021 23:15:39.640722 25759 net.cpp:774] Copying source layer res3c
I1021 23:15:39.640724 25759 net.cpp:774] Copying source layer res3c_relu
I1021 23:15:39.640727 25759 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I1021 23:15:39.640730 25759 net.cpp:774] Copying source layer res3d_branch2a
I1021 23:15:39.640801 25759 net.cpp:774] Copying source layer bn3d_branch2a
I1021 23:15:39.640810 25759 net.cpp:774] Copying source layer scale3d_branch2a
I1021 23:15:39.640813 25759 net.cpp:774] Copying source layer res3d_branch2a_relu
I1021 23:15:39.640816 25759 net.cpp:774] Copying source layer res3d_branch2b
I1021 23:15:39.640954 25759 net.cpp:774] Copying source layer bn3d_branch2b
I1021 23:15:39.640960 25759 net.cpp:774] Copying source layer scale3d_branch2b
I1021 23:15:39.640965 25759 net.cpp:774] Copying source layer res3d_branch2b_relu
I1021 23:15:39.640969 25759 net.cpp:774] Copying source layer res3d_branch2c
I1021 23:15:39.641036 25759 net.cpp:774] Copying source layer bn3d_branch2c
I1021 23:15:39.641043 25759 net.cpp:774] Copying source layer scale3d_branch2c
I1021 23:15:39.641049 25759 net.cpp:774] Copying source layer res3d
I1021 23:15:39.641052 25759 net.cpp:774] Copying source layer res3d_relu
I1021 23:15:39.641055 25759 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I1021 23:15:39.641058 25759 net.cpp:774] Copying source layer res4a_branch1
I1021 23:15:39.641538 25759 net.cpp:774] Copying source layer bn4a_branch1
I1021 23:15:39.641549 25759 net.cpp:774] Copying source layer scale4a_branch1
I1021 23:15:39.641567 25759 net.cpp:774] Copying source layer res4a_branch2a
I1021 23:15:39.641700 25759 net.cpp:774] Copying source layer bn4a_branch2a
I1021 23:15:39.641708 25759 net.cpp:774] Copying source layer scale4a_branch2a
I1021 23:15:39.641714 25759 net.cpp:774] Copying source layer res4a_branch2a_relu
I1021 23:15:39.641716 25759 net.cpp:774] Copying source layer res4a_branch2b
I1021 23:15:39.642274 25759 net.cpp:774] Copying source layer bn4a_branch2b
I1021 23:15:39.642283 25759 net.cpp:774] Copying source layer scale4a_branch2b
I1021 23:15:39.642299 25759 net.cpp:774] Copying source layer res4a_branch2b_relu
I1021 23:15:39.642302 25759 net.cpp:774] Copying source layer res4a_branch2c
I1021 23:15:39.642554 25759 net.cpp:774] Copying source layer bn4a_branch2c
I1021 23:15:39.642563 25759 net.cpp:774] Copying source layer scale4a_branch2c
I1021 23:15:39.642571 25759 net.cpp:774] Copying source layer res4a
I1021 23:15:39.642575 25759 net.cpp:774] Copying source layer res4a_relu
I1021 23:15:39.642577 25759 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I1021 23:15:39.642580 25759 net.cpp:774] Copying source layer res4b_branch2a
I1021 23:15:39.642813 25759 net.cpp:774] Copying source layer bn4b_branch2a
I1021 23:15:39.642822 25759 net.cpp:774] Copying source layer scale4b_branch2a
I1021 23:15:39.642827 25759 net.cpp:774] Copying source layer res4b_branch2a_relu
I1021 23:15:39.642830 25759 net.cpp:774] Copying source layer res4b_branch2b
I1021 23:15:39.643385 25759 net.cpp:774] Copying source layer bn4b_branch2b
I1021 23:15:39.643393 25759 net.cpp:774] Copying source layer scale4b_branch2b
I1021 23:15:39.643409 25759 net.cpp:774] Copying source layer res4b_branch2b_relu
I1021 23:15:39.643411 25759 net.cpp:774] Copying source layer res4b_branch2c
I1021 23:15:39.643662 25759 net.cpp:774] Copying source layer bn4b_branch2c
I1021 23:15:39.643674 25759 net.cpp:774] Copying source layer scale4b_branch2c
I1021 23:15:39.643682 25759 net.cpp:774] Copying source layer res4b
I1021 23:15:39.643684 25759 net.cpp:774] Copying source layer res4b_relu
I1021 23:15:39.643687 25759 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I1021 23:15:39.643692 25759 net.cpp:774] Copying source layer res4c_branch2a
I1021 23:15:39.643937 25759 net.cpp:774] Copying source layer bn4c_branch2a
I1021 23:15:39.643945 25759 net.cpp:774] Copying source layer scale4c_branch2a
I1021 23:15:39.643951 25759 net.cpp:774] Copying source layer res4c_branch2a_relu
I1021 23:15:39.643954 25759 net.cpp:774] Copying source layer res4c_branch2b
I1021 23:15:39.644510 25759 net.cpp:774] Copying source layer bn4c_branch2b
I1021 23:15:39.644518 25759 net.cpp:774] Copying source layer scale4c_branch2b
I1021 23:15:39.644536 25759 net.cpp:774] Copying source layer res4c_branch2b_relu
I1021 23:15:39.644538 25759 net.cpp:774] Copying source layer res4c_branch2c
I1021 23:15:39.644804 25759 net.cpp:774] Copying source layer bn4c_branch2c
I1021 23:15:39.644816 25759 net.cpp:774] Copying source layer scale4c_branch2c
I1021 23:15:39.644824 25759 net.cpp:774] Copying source layer res4c
I1021 23:15:39.644826 25759 net.cpp:774] Copying source layer res4c_relu
I1021 23:15:39.644829 25759 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I1021 23:15:39.644832 25759 net.cpp:774] Copying source layer res4d_branch2a
I1021 23:15:39.645064 25759 net.cpp:774] Copying source layer bn4d_branch2a
I1021 23:15:39.645072 25759 net.cpp:774] Copying source layer scale4d_branch2a
I1021 23:15:39.645084 25759 net.cpp:774] Copying source layer res4d_branch2a_relu
I1021 23:15:39.645087 25759 net.cpp:774] Copying source layer res4d_branch2b
I1021 23:15:39.645614 25759 net.cpp:774] Copying source layer bn4d_branch2b
I1021 23:15:39.645622 25759 net.cpp:774] Copying source layer scale4d_branch2b
I1021 23:15:39.645637 25759 net.cpp:774] Copying source layer res4d_branch2b_relu
I1021 23:15:39.645640 25759 net.cpp:774] Copying source layer res4d_branch2c
I1021 23:15:39.645889 25759 net.cpp:774] Copying source layer bn4d_branch2c
I1021 23:15:39.645900 25759 net.cpp:774] Copying source layer scale4d_branch2c
I1021 23:15:39.645906 25759 net.cpp:774] Copying source layer res4d
I1021 23:15:39.645910 25759 net.cpp:774] Copying source layer res4d_relu
I1021 23:15:39.645912 25759 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I1021 23:15:39.645915 25759 net.cpp:774] Copying source layer res4e_branch2a
I1021 23:15:39.646145 25759 net.cpp:774] Copying source layer bn4e_branch2a
I1021 23:15:39.646154 25759 net.cpp:774] Copying source layer scale4e_branch2a
I1021 23:15:39.646160 25759 net.cpp:774] Copying source layer res4e_branch2a_relu
I1021 23:15:39.646163 25759 net.cpp:774] Copying source layer res4e_branch2b
I1021 23:15:39.646695 25759 net.cpp:774] Copying source layer bn4e_branch2b
I1021 23:15:39.646703 25759 net.cpp:774] Copying source layer scale4e_branch2b
I1021 23:15:39.646709 25759 net.cpp:774] Copying source layer res4e_branch2b_relu
I1021 23:15:39.646711 25759 net.cpp:774] Copying source layer res4e_branch2c
I1021 23:15:39.646958 25759 net.cpp:774] Copying source layer bn4e_branch2c
I1021 23:15:39.646968 25759 net.cpp:774] Copying source layer scale4e_branch2c
I1021 23:15:39.646975 25759 net.cpp:774] Copying source layer res4e
I1021 23:15:39.646978 25759 net.cpp:774] Copying source layer res4e_relu
I1021 23:15:39.646981 25759 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I1021 23:15:39.646984 25759 net.cpp:774] Copying source layer res4f_branch2a
I1021 23:15:39.647210 25759 net.cpp:774] Copying source layer bn4f_branch2a
I1021 23:15:39.647219 25759 net.cpp:774] Copying source layer scale4f_branch2a
I1021 23:15:39.647224 25759 net.cpp:774] Copying source layer res4f_branch2a_relu
I1021 23:15:39.647228 25759 net.cpp:774] Copying source layer res4f_branch2b
I1021 23:15:39.647770 25759 net.cpp:774] Copying source layer bn4f_branch2b
I1021 23:15:39.647778 25759 net.cpp:774] Copying source layer scale4f_branch2b
I1021 23:15:39.647799 25759 net.cpp:774] Copying source layer res4f_branch2b_relu
I1021 23:15:39.647801 25759 net.cpp:774] Copying source layer res4f_branch2c
I1021 23:15:39.648059 25759 net.cpp:774] Copying source layer bn4f_branch2c
I1021 23:15:39.648069 25759 net.cpp:774] Copying source layer scale4f_branch2c
I1021 23:15:39.648077 25759 net.cpp:774] Copying source layer res4f
I1021 23:15:39.648078 25759 net.cpp:774] Copying source layer res4f_relu
I1021 23:15:39.648082 25759 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I1021 23:15:39.648085 25759 net.cpp:774] Copying source layer res5a_branch1
I1021 23:15:39.649868 25759 net.cpp:774] Copying source layer bn5a_branch1
I1021 23:15:39.649900 25759 net.cpp:774] Copying source layer scale5a_branch1
I1021 23:15:39.649911 25759 net.cpp:774] Copying source layer res5a_branch2a
I1021 23:15:39.650429 25759 net.cpp:774] Copying source layer bn5a_branch2a
I1021 23:15:39.650437 25759 net.cpp:774] Copying source layer scale5a_branch2a
I1021 23:15:39.650458 25759 net.cpp:774] Copying source layer res5a_branch2a_relu
I1021 23:15:39.650461 25759 net.cpp:774] Copying source layer res5a_branch2b
I1021 23:15:39.652423 25759 net.cpp:774] Copying source layer bn5a_branch2b
I1021 23:15:39.652437 25759 net.cpp:774] Copying source layer scale5a_branch2b
I1021 23:15:39.652458 25759 net.cpp:774] Copying source layer res5a_branch2b_relu
I1021 23:15:39.652462 25759 net.cpp:774] Copying source layer res5a_branch2c
I1021 23:15:39.653412 25759 net.cpp:774] Copying source layer bn5a_branch2c
I1021 23:15:39.653441 25759 net.cpp:774] Copying source layer scale5a_branch2c
I1021 23:15:39.653450 25759 net.cpp:774] Copying source layer res5a
I1021 23:15:39.653453 25759 net.cpp:774] Copying source layer res5a_relu
I1021 23:15:39.653460 25759 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I1021 23:15:39.653461 25759 net.cpp:774] Copying source layer res5b_branch2a
I1021 23:15:39.654397 25759 net.cpp:774] Copying source layer bn5b_branch2a
I1021 23:15:39.654407 25759 net.cpp:774] Copying source layer scale5b_branch2a
I1021 23:15:39.654429 25759 net.cpp:774] Copying source layer res5b_branch2a_relu
I1021 23:15:39.654433 25759 net.cpp:774] Copying source layer res5b_branch2b
I1021 23:15:39.656435 25759 net.cpp:774] Copying source layer bn5b_branch2b
I1021 23:15:39.656463 25759 net.cpp:774] Copying source layer scale5b_branch2b
I1021 23:15:39.656471 25759 net.cpp:774] Copying source layer res5b_branch2b_relu
I1021 23:15:39.656472 25759 net.cpp:774] Copying source layer res5b_branch2c
I1021 23:15:39.657426 25759 net.cpp:774] Copying source layer bn5b_branch2c
I1021 23:15:39.657456 25759 net.cpp:774] Copying source layer scale5b_branch2c
I1021 23:15:39.657465 25759 net.cpp:774] Copying source layer res5b
I1021 23:15:39.657469 25759 net.cpp:774] Copying source layer res5b_relu
I1021 23:15:39.657472 25759 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I1021 23:15:39.657475 25759 net.cpp:774] Copying source layer res5c_branch2a
I1021 23:15:39.658396 25759 net.cpp:774] Copying source layer bn5c_branch2a
I1021 23:15:39.658406 25759 net.cpp:774] Copying source layer scale5c_branch2a
I1021 23:15:39.658427 25759 net.cpp:774] Copying source layer res5c_branch2a_relu
I1021 23:15:39.658432 25759 net.cpp:774] Copying source layer res5c_branch2b
I1021 23:15:39.660413 25759 net.cpp:774] Copying source layer bn5c_branch2b
I1021 23:15:39.660425 25759 net.cpp:774] Copying source layer scale5c_branch2b
I1021 23:15:39.660449 25759 net.cpp:774] Copying source layer res5c_branch2b_relu
I1021 23:15:39.660451 25759 net.cpp:774] Copying source layer res5c_branch2c
I1021 23:15:39.661424 25759 net.cpp:774] Copying source layer bn5c_branch2c
I1021 23:15:39.661456 25759 net.cpp:774] Copying source layer scale5c_branch2c
I1021 23:15:39.661464 25759 net.cpp:774] Copying source layer res5c
I1021 23:15:39.661468 25759 net.cpp:774] Copying source layer res5c_relu
I1021 23:15:39.661471 25759 net.cpp:771] Ignoring source layer pool5
I1021 23:15:39.661474 25759 net.cpp:771] Ignoring source layer fc1000
I1021 23:15:39.661476 25759 net.cpp:771] Ignoring source layer prob
Solving...
I1021 23:15:44.410909 25759 solver.cpp:228] Iteration 0, loss = 3.58679
I1021 23:15:44.410969 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.409091
I1021 23:15:44.410979 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.0189905
I1021 23:15:44.410989 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:15:44.410996 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:15:44.411003 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.69576 (* 1 = 0.69576 loss)
I1021 23:15:44.411026 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.713085 (* 1 = 0.713085 loss)
I1021 23:15:44.411034 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.721471 (* 1 = 0.721471 loss)
I1021 23:15:44.411043 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.710069 (* 1 = 0.710069 loss)
I1021 23:15:44.411067 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.491296 (* 1 = 0.491296 loss)
I1021 23:15:44.411092 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.325594 (* 1 = 0.325594 loss)
I1021 23:15:44.411100 25759 sgd_solver.cpp:106] Iteration 0, lr = 0.002
I1021 23:17:04.555105 25759 solver.cpp:228] Iteration 20, loss = 1.06045
I1021 23:17:04.555171 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:17:04.555178 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:17:04.555186 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:17:04.555192 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:17:04.555198 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0676838 (* 1 = 0.0676838 loss)
I1021 23:17:04.555204 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0857302 (* 1 = 0.0857302 loss)
I1021 23:17:04.555209 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.145207 (* 1 = 0.145207 loss)
I1021 23:17:04.555217 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.0189093 (* 1 = 0.0189093 loss)
I1021 23:17:04.555223 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.465378 (* 1 = 0.465378 loss)
I1021 23:17:04.555228 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.232713 (* 1 = 0.232713 loss)
I1021 23:17:04.555238 25759 sgd_solver.cpp:106] Iteration 20, lr = 0.002
I1021 23:18:26.690490 25759 solver.cpp:228] Iteration 40, loss = 0.906314
I1021 23:18:26.690542 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:18:26.690548 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:18:26.690556 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:18:26.690562 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:18:26.690567 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00977172 (* 1 = 0.00977172 loss)
I1021 23:18:26.690570 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.006296 (* 1 = 0.006296 loss)
I1021 23:18:26.690575 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0253693 (* 1 = 0.0253693 loss)
I1021 23:18:26.690580 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00291129 (* 1 = 0.00291129 loss)
I1021 23:18:26.690585 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.386227 (* 1 = 0.386227 loss)
I1021 23:18:26.690589 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.055679 (* 1 = 0.055679 loss)
I1021 23:18:26.690595 25759 sgd_solver.cpp:106] Iteration 40, lr = 0.002
I1021 23:19:50.535135 25759 solver.cpp:228] Iteration 60, loss = 0.848901
I1021 23:19:50.535182 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1021 23:19:50.535190 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:19:50.535199 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:19:50.535205 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:19:50.535212 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0177118 (* 1 = 0.0177118 loss)
I1021 23:19:50.535218 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00978574 (* 1 = 0.00978574 loss)
I1021 23:19:50.535223 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0324188 (* 1 = 0.0324188 loss)
I1021 23:19:50.535230 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000830318 (* 1 = 0.000830318 loss)
I1021 23:19:50.535236 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.200012 (* 1 = 0.200012 loss)
I1021 23:19:50.535241 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0177337 (* 1 = 0.0177337 loss)
I1021 23:19:50.535248 25759 sgd_solver.cpp:106] Iteration 60, lr = 0.002
I1021 23:21:15.438845 25759 solver.cpp:228] Iteration 80, loss = 0.844015
I1021 23:21:15.438899 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985121
I1021 23:21:15.438910 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992004
I1021 23:21:15.438921 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.242644 (* 1 = 0.242644 loss)
I1021 23:21:15.438933 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.190203 (* 1 = 0.190203 loss)
I1021 23:21:15.438942 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.116812 (* 1 = 0.116812 loss)
I1021 23:21:15.438951 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0642259 (* 1 = 0.0642259 loss)
I1021 23:21:15.438958 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.179012 (* 1 = 0.179012 loss)
I1021 23:21:15.438969 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000546708 (* 1 = 0.000546708 loss)
I1021 23:21:15.438982 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.906396 (* 1 = 0.906396 loss)
I1021 23:21:15.438989 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.017995 (* 1 = 0.017995 loss)
I1021 23:21:15.439000 25759 sgd_solver.cpp:106] Iteration 80, lr = 0.002
I1021 23:22:39.607537 25759 solver.cpp:228] Iteration 100, loss = 0.677416
I1021 23:22:39.607584 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985015
I1021 23:22:39.607592 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992008
I1021 23:22:39.607601 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.356408 (* 1 = 0.356408 loss)
I1021 23:22:39.607607 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.267246 (* 1 = 0.267246 loss)
I1021 23:22:39.607614 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0660253 (* 1 = 0.0660253 loss)
I1021 23:22:39.607620 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0396914 (* 1 = 0.0396914 loss)
I1021 23:22:39.607625 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0307098 (* 1 = 0.0307098 loss)
I1021 23:22:39.607632 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.73043e-05 (* 1 = 7.73043e-05 loss)
I1021 23:22:39.607638 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.131965 (* 1 = 0.131965 loss)
I1021 23:22:39.607643 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.033326 (* 1 = 0.033326 loss)
I1021 23:22:39.607655 25759 sgd_solver.cpp:106] Iteration 100, lr = 0.002
I1021 23:24:04.958938 25759 solver.cpp:228] Iteration 120, loss = 1.05623
I1021 23:24:04.958993 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:24:04.958999 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:24:04.959007 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:24:04.959013 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:24:04.959018 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00939146 (* 1 = 0.00939146 loss)
I1021 23:24:04.959022 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00612625 (* 1 = 0.00612625 loss)
I1021 23:24:04.959028 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0140081 (* 1 = 0.0140081 loss)
I1021 23:24:04.959033 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000137838 (* 1 = 0.000137838 loss)
I1021 23:24:04.959038 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0367354 (* 1 = 0.0367354 loss)
I1021 23:24:04.959043 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0142364 (* 1 = 0.0142364 loss)
I1021 23:24:04.959050 25759 sgd_solver.cpp:106] Iteration 120, lr = 0.002
I1021 23:25:28.744282 25759 solver.cpp:228] Iteration 140, loss = 0.604038
I1021 23:25:28.744352 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1021 23:25:28.744365 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1021 23:25:28.744376 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0900811 (* 1 = 0.0900811 loss)
I1021 23:25:28.744381 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0213301 (* 1 = 0.0213301 loss)
I1021 23:25:28.744386 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0259195 (* 1 = 0.0259195 loss)
I1021 23:25:28.744390 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0118477 (* 1 = 0.0118477 loss)
I1021 23:25:28.744395 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0137496 (* 1 = 0.0137496 loss)
I1021 23:25:28.744400 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.37436e-05 (* 1 = 9.37436e-05 loss)
I1021 23:25:28.744405 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0251104 (* 1 = 0.0251104 loss)
I1021 23:25:28.744410 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0117833 (* 1 = 0.0117833 loss)
I1021 23:25:28.744415 25759 sgd_solver.cpp:106] Iteration 140, lr = 0.002
I1021 23:26:51.826331 25759 solver.cpp:228] Iteration 160, loss = 0.813818
I1021 23:26:51.826386 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.967049
I1021 23:26:51.826393 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.985022
I1021 23:26:51.826400 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.579429 (* 1 = 0.579429 loss)
I1021 23:26:51.826408 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.241689 (* 1 = 0.241689 loss)
I1021 23:26:51.826413 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.122668 (* 1 = 0.122668 loss)
I1021 23:26:51.826418 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0649467 (* 1 = 0.0649467 loss)
I1021 23:26:51.826422 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0412146 (* 1 = 0.0412146 loss)
I1021 23:26:51.826429 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00014668 (* 1 = 0.00014668 loss)
I1021 23:26:51.826434 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.163201 (* 1 = 0.163201 loss)
I1021 23:26:51.826439 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0229298 (* 1 = 0.0229298 loss)
I1021 23:26:51.826448 25759 sgd_solver.cpp:106] Iteration 160, lr = 0.002
I1021 23:28:16.587400 25759 solver.cpp:228] Iteration 180, loss = 0.623525
I1021 23:28:16.587447 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:28:16.587455 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:28:16.587463 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:28:16.587469 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:28:16.587476 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00872881 (* 1 = 0.00872881 loss)
I1021 23:28:16.587481 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00523685 (* 1 = 0.00523685 loss)
I1021 23:28:16.587487 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0132732 (* 1 = 0.0132732 loss)
I1021 23:28:16.587494 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000629585 (* 1 = 0.000629585 loss)
I1021 23:28:16.587501 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00516085 (* 1 = 0.00516085 loss)
I1021 23:28:16.587505 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0189002 (* 1 = 0.0189002 loss)
I1021 23:28:16.587512 25759 sgd_solver.cpp:106] Iteration 180, lr = 0.002
speed: 4.180s / iter
I1021 23:29:40.168470 25759 solver.cpp:228] Iteration 200, loss = 0.668758
I1021 23:29:40.168534 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:29:40.168541 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:29:40.168548 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:29:40.168555 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:29:40.168560 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0049927 (* 1 = 0.0049927 loss)
I1021 23:29:40.168566 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00340154 (* 1 = 0.00340154 loss)
I1021 23:29:40.168570 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000824962 (* 1 = 0.000824962 loss)
I1021 23:29:40.168576 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000129797 (* 1 = 0.000129797 loss)
I1021 23:29:40.168581 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00310888 (* 1 = 0.00310888 loss)
I1021 23:29:40.168586 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0104944 (* 1 = 0.0104944 loss)
I1021 23:29:40.168593 25759 sgd_solver.cpp:106] Iteration 200, lr = 0.002
I1021 23:31:04.154803 25759 solver.cpp:228] Iteration 220, loss = 0.508855
I1021 23:31:04.154876 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:31:04.154887 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:31:04.154901 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:31:04.154909 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:31:04.154919 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0113812 (* 1 = 0.0113812 loss)
I1021 23:31:04.154928 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00652407 (* 1 = 0.00652407 loss)
I1021 23:31:04.154937 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0143911 (* 1 = 0.0143911 loss)
I1021 23:31:04.154965 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.71511e-05 (* 1 = 9.71511e-05 loss)
I1021 23:31:04.154978 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0402222 (* 1 = 0.0402222 loss)
I1021 23:31:04.154985 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0176753 (* 1 = 0.0176753 loss)
I1021 23:31:04.155001 25759 sgd_solver.cpp:106] Iteration 220, lr = 0.002
I1021 23:32:29.309527 25759 solver.cpp:228] Iteration 240, loss = 0.389784
I1021 23:32:29.309566 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1021 23:32:29.309571 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:32:29.309578 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:32:29.309582 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:32:29.309587 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00985521 (* 1 = 0.00985521 loss)
I1021 23:32:29.309592 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00686717 (* 1 = 0.00686717 loss)
I1021 23:32:29.309595 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00541644 (* 1 = 0.00541644 loss)
I1021 23:32:29.309600 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000147132 (* 1 = 0.000147132 loss)
I1021 23:32:29.309604 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0212859 (* 1 = 0.0212859 loss)
I1021 23:32:29.309608 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0221558 (* 1 = 0.0221558 loss)
I1021 23:32:29.309617 25759 sgd_solver.cpp:106] Iteration 240, lr = 0.002
I1021 23:33:55.363582 25759 solver.cpp:228] Iteration 260, loss = 0.628925
I1021 23:33:55.363621 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.961877
I1021 23:33:55.363626 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.977545
I1021 23:33:55.363634 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.708194 (* 1 = 0.708194 loss)
I1021 23:33:55.363639 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.391618 (* 1 = 0.391618 loss)
I1021 23:33:55.363643 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.105222 (* 1 = 0.105222 loss)
I1021 23:33:55.363647 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0884303 (* 1 = 0.0884303 loss)
I1021 23:33:55.363652 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0150399 (* 1 = 0.0150399 loss)
I1021 23:33:55.363658 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.36306e-05 (* 1 = 6.36306e-05 loss)
I1021 23:33:55.363662 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.190022 (* 1 = 0.190022 loss)
I1021 23:33:55.363667 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0130045 (* 1 = 0.0130045 loss)
I1021 23:33:55.363672 25759 sgd_solver.cpp:106] Iteration 260, lr = 0.002
I1021 23:35:17.575106 25759 solver.cpp:228] Iteration 280, loss = 0.913182
I1021 23:35:17.575152 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:35:17.575160 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:35:17.575168 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:35:17.575175 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:35:17.575181 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0139814 (* 1 = 0.0139814 loss)
I1021 23:35:17.575187 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00608928 (* 1 = 0.00608928 loss)
I1021 23:35:17.575192 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00192738 (* 1 = 0.00192738 loss)
I1021 23:35:17.575201 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000188988 (* 1 = 0.000188988 loss)
I1021 23:35:17.575206 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.046641 (* 1 = 0.046641 loss)
I1021 23:35:17.575212 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0254697 (* 1 = 0.0254697 loss)
I1021 23:35:17.575218 25759 sgd_solver.cpp:106] Iteration 280, lr = 0.002
I1021 23:36:42.258895 25759 solver.cpp:228] Iteration 300, loss = 0.977143
I1021 23:36:42.258936 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.956608
I1021 23:36:42.258942 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.975561
I1021 23:36:42.258949 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.59291 (* 1 = 0.59291 loss)
I1021 23:36:42.258955 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.401045 (* 1 = 0.401045 loss)
I1021 23:36:42.258958 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.135398 (* 1 = 0.135398 loss)
I1021 23:36:42.258962 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.085579 (* 1 = 0.085579 loss)
I1021 23:36:42.258970 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0170105 (* 1 = 0.0170105 loss)
I1021 23:36:42.258975 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000284202 (* 1 = 0.000284202 loss)
I1021 23:36:42.258978 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.255148 (* 1 = 0.255148 loss)
I1021 23:36:42.258982 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00504899 (* 1 = 0.00504899 loss)
I1021 23:36:42.258991 25759 sgd_solver.cpp:106] Iteration 300, lr = 0.002
I1021 23:38:06.175850 25759 solver.cpp:228] Iteration 320, loss = 0.404076
I1021 23:38:06.175896 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993503
I1021 23:38:06.175904 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1021 23:38:06.175914 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0703194 (* 1 = 0.0703194 loss)
I1021 23:38:06.175920 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00650767 (* 1 = 0.00650767 loss)
I1021 23:38:06.175926 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0250033 (* 1 = 0.0250033 loss)
I1021 23:38:06.175931 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00912493 (* 1 = 0.00912493 loss)
I1021 23:38:06.175937 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0137264 (* 1 = 0.0137264 loss)
I1021 23:38:06.175945 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.05823e-05 (* 1 = 4.05823e-05 loss)
I1021 23:38:06.175951 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0378355 (* 1 = 0.0378355 loss)
I1021 23:38:06.175956 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0140977 (* 1 = 0.0140977 loss)
I1021 23:38:06.175963 25759 sgd_solver.cpp:106] Iteration 320, lr = 0.002
I1021 23:39:31.364353 25759 solver.cpp:228] Iteration 340, loss = 0.774604
I1021 23:39:31.364398 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:39:31.364406 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:39:31.364414 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:39:31.364420 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:39:31.364426 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00674934 (* 1 = 0.00674934 loss)
I1021 23:39:31.364432 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00587012 (* 1 = 0.00587012 loss)
I1021 23:39:31.364439 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00862351 (* 1 = 0.00862351 loss)
I1021 23:39:31.364445 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.5623e-05 (* 1 = 7.5623e-05 loss)
I1021 23:39:31.364451 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0212074 (* 1 = 0.0212074 loss)
I1021 23:39:31.364457 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0129987 (* 1 = 0.0129987 loss)
I1021 23:39:31.364464 25759 sgd_solver.cpp:106] Iteration 340, lr = 0.002
I1021 23:40:55.975690 25759 solver.cpp:228] Iteration 360, loss = 0.3621
I1021 23:40:55.975755 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.981019
I1021 23:40:55.975764 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99051
I1021 23:40:55.975773 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.287354 (* 1 = 0.287354 loss)
I1021 23:40:55.975781 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.1334 (* 1 = 0.1334 loss)
I1021 23:40:55.975787 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0536921 (* 1 = 0.0536921 loss)
I1021 23:40:55.975793 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0366532 (* 1 = 0.0366532 loss)
I1021 23:40:55.975800 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0283439 (* 1 = 0.0283439 loss)
I1021 23:40:55.975807 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.44958e-05 (* 1 = 6.44958e-05 loss)
I1021 23:40:55.975814 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0411686 (* 1 = 0.0411686 loss)
I1021 23:40:55.975826 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0152176 (* 1 = 0.0152176 loss)
I1021 23:40:55.975832 25759 sgd_solver.cpp:106] Iteration 360, lr = 0.002
I1021 23:42:18.668640 25759 solver.cpp:228] Iteration 380, loss = 0.808696
I1021 23:42:18.668707 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.968051
I1021 23:42:18.668715 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.978022
I1021 23:42:18.668723 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.275283 (* 1 = 0.275283 loss)
I1021 23:42:18.668728 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.22579 (* 1 = 0.22579 loss)
I1021 23:42:18.668733 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.1306 (* 1 = 0.1306 loss)
I1021 23:42:18.668738 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0920289 (* 1 = 0.0920289 loss)
I1021 23:42:18.668743 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0358704 (* 1 = 0.0358704 loss)
I1021 23:42:18.668750 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.65416e-05 (* 1 = 3.65416e-05 loss)
I1021 23:42:18.668754 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 1.02655 (* 1 = 1.02655 loss)
I1021 23:42:18.668761 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00394399 (* 1 = 0.00394399 loss)
I1021 23:42:18.668771 25759 sgd_solver.cpp:106] Iteration 380, lr = 0.002
speed: 4.193s / iter
I1021 23:43:40.989079 25759 solver.cpp:228] Iteration 400, loss = 0.319393
I1021 23:43:40.989136 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989006
I1021 23:43:40.989145 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993503
I1021 23:43:40.989157 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0346813 (* 1 = 0.0346813 loss)
I1021 23:43:40.989166 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0601397 (* 1 = 0.0601397 loss)
I1021 23:43:40.989171 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0305492 (* 1 = 0.0305492 loss)
I1021 23:43:40.989178 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0219452 (* 1 = 0.0219452 loss)
I1021 23:43:40.989197 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00364086 (* 1 = 0.00364086 loss)
I1021 23:43:40.989207 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.52124e-05 (* 1 = 3.52124e-05 loss)
I1021 23:43:40.989217 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0701326 (* 1 = 0.0701326 loss)
I1021 23:43:40.989224 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0171949 (* 1 = 0.0171949 loss)
I1021 23:43:40.989233 25759 sgd_solver.cpp:106] Iteration 400, lr = 0.002
I1021 23:45:05.942554 25759 solver.cpp:228] Iteration 420, loss = 0.298821
I1021 23:45:05.942600 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1021 23:45:05.942617 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:45:05.942626 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:45:05.942632 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:45:05.942638 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00362917 (* 1 = 0.00362917 loss)
I1021 23:45:05.942644 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00537004 (* 1 = 0.00537004 loss)
I1021 23:45:05.942651 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000492771 (* 1 = 0.000492771 loss)
I1021 23:45:05.942658 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.0538e-05 (* 1 = 4.0538e-05 loss)
I1021 23:45:05.942664 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0171638 (* 1 = 0.0171638 loss)
I1021 23:45:05.942669 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00714029 (* 1 = 0.00714029 loss)
I1021 23:45:05.942680 25759 sgd_solver.cpp:106] Iteration 420, lr = 0.002
I1021 23:46:31.095809 25759 solver.cpp:228] Iteration 440, loss = 0.290278
I1021 23:46:31.095857 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990471
I1021 23:46:31.095865 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994503
I1021 23:46:31.095875 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0506125 (* 1 = 0.0506125 loss)
I1021 23:46:31.095880 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0569619 (* 1 = 0.0569619 loss)
I1021 23:46:31.095888 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0202938 (* 1 = 0.0202938 loss)
I1021 23:46:31.095893 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0169839 (* 1 = 0.0169839 loss)
I1021 23:46:31.095899 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00093903 (* 1 = 0.00093903 loss)
I1021 23:46:31.095906 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.16805e-05 (* 1 = 5.16805e-05 loss)
I1021 23:46:31.095912 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0276039 (* 1 = 0.0276039 loss)
I1021 23:46:31.095918 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00333646 (* 1 = 0.00333646 loss)
I1021 23:46:31.095926 25759 sgd_solver.cpp:106] Iteration 440, lr = 0.002
I1021 23:47:54.042994 25759 solver.cpp:228] Iteration 460, loss = 0.432505
I1021 23:47:54.043051 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.98371
I1021 23:47:54.043057 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1021 23:47:54.043066 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.183456 (* 1 = 0.183456 loss)
I1021 23:47:54.043071 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0630911 (* 1 = 0.0630911 loss)
I1021 23:47:54.043074 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0541512 (* 1 = 0.0541512 loss)
I1021 23:47:54.043078 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0257144 (* 1 = 0.0257144 loss)
I1021 23:47:54.043083 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00805327 (* 1 = 0.00805327 loss)
I1021 23:47:54.043089 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.27235e-05 (* 1 = 2.27235e-05 loss)
I1021 23:47:54.043093 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0263451 (* 1 = 0.0263451 loss)
I1021 23:47:54.043098 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000665604 (* 1 = 0.000665604 loss)
I1021 23:47:54.043105 25759 sgd_solver.cpp:106] Iteration 460, lr = 0.002
I1021 23:49:19.532373 25759 solver.cpp:228] Iteration 480, loss = 0.457311
I1021 23:49:19.532428 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:49:19.532438 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:49:19.532449 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:49:19.532459 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:49:19.532465 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0112207 (* 1 = 0.0112207 loss)
I1021 23:49:19.532474 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00764306 (* 1 = 0.00764306 loss)
I1021 23:49:19.532481 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00770884 (* 1 = 0.00770884 loss)
I1021 23:49:19.532491 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.6487e-05 (* 1 = 2.6487e-05 loss)
I1021 23:49:19.532510 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0132389 (* 1 = 0.0132389 loss)
I1021 23:49:19.532521 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00766435 (* 1 = 0.00766435 loss)
I1021 23:49:19.532536 25759 sgd_solver.cpp:106] Iteration 480, lr = 0.002
I1021 23:50:45.275985 25759 solver.cpp:228] Iteration 500, loss = 0.525049
I1021 23:50:45.276055 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993003
I1021 23:50:45.276074 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1021 23:50:45.276091 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.100805 (* 1 = 0.100805 loss)
I1021 23:50:45.276104 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.022073 (* 1 = 0.022073 loss)
I1021 23:50:45.276115 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0206782 (* 1 = 0.0206782 loss)
I1021 23:50:45.276129 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00936584 (* 1 = 0.00936584 loss)
I1021 23:50:45.276141 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00270547 (* 1 = 0.00270547 loss)
I1021 23:50:45.276156 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.19818e-05 (* 1 = 6.19818e-05 loss)
I1021 23:50:45.276170 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0364597 (* 1 = 0.0364597 loss)
I1021 23:50:45.276183 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00552684 (* 1 = 0.00552684 loss)
I1021 23:50:45.276196 25759 sgd_solver.cpp:106] Iteration 500, lr = 0.002
I1021 23:52:09.458487 25759 solver.cpp:228] Iteration 520, loss = 0.335433
I1021 23:52:09.458531 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.976489
I1021 23:52:09.458539 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.981528
I1021 23:52:09.458549 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.27887 (* 1 = 0.27887 loss)
I1021 23:52:09.458555 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.211447 (* 1 = 0.211447 loss)
I1021 23:52:09.458561 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0797656 (* 1 = 0.0797656 loss)
I1021 23:52:09.458566 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0552763 (* 1 = 0.0552763 loss)
I1021 23:52:09.458572 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00433193 (* 1 = 0.00433193 loss)
I1021 23:52:09.458580 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.74829e-05 (* 1 = 6.74829e-05 loss)
I1021 23:52:09.458586 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0975292 (* 1 = 0.0975292 loss)
I1021 23:52:09.458592 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00579714 (* 1 = 0.00579714 loss)
I1021 23:52:09.458601 25759 sgd_solver.cpp:106] Iteration 520, lr = 0.002
I1021 23:53:34.410212 25759 solver.cpp:228] Iteration 540, loss = 0.290894
I1021 23:53:34.410266 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.972222
I1021 23:53:34.410272 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.987013
I1021 23:53:34.410279 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.248013 (* 1 = 0.248013 loss)
I1021 23:53:34.410286 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.189283 (* 1 = 0.189283 loss)
I1021 23:53:34.410291 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0771749 (* 1 = 0.0771749 loss)
I1021 23:53:34.410295 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0445205 (* 1 = 0.0445205 loss)
I1021 23:53:34.410300 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0256115 (* 1 = 0.0256115 loss)
I1021 23:53:34.410306 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.50729e-05 (* 1 = 5.50729e-05 loss)
I1021 23:53:34.410310 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.347152 (* 1 = 0.347152 loss)
I1021 23:53:34.410315 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000523573 (* 1 = 0.000523573 loss)
I1021 23:53:34.410321 25759 sgd_solver.cpp:106] Iteration 540, lr = 0.002
I1021 23:54:59.031816 25759 solver.cpp:228] Iteration 560, loss = 0.182962
I1021 23:54:59.031880 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1021 23:54:59.031888 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:54:59.031898 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:54:59.031903 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:54:59.031909 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00600493 (* 1 = 0.00600493 loss)
I1021 23:54:59.031915 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0074298 (* 1 = 0.0074298 loss)
I1021 23:54:59.031921 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00429807 (* 1 = 0.00429807 loss)
I1021 23:54:59.031929 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.67652e-05 (* 1 = 1.67652e-05 loss)
I1021 23:54:59.031934 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0343001 (* 1 = 0.0343001 loss)
I1021 23:54:59.031940 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00557905 (* 1 = 0.00557905 loss)
I1021 23:54:59.031951 25759 sgd_solver.cpp:106] Iteration 560, lr = 0.002
I1021 23:56:24.736356 25759 solver.cpp:228] Iteration 580, loss = 0.379947
I1021 23:56:24.736416 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988006
I1021 23:56:24.736429 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995502
I1021 23:56:24.736444 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.134377 (* 1 = 0.134377 loss)
I1021 23:56:24.736457 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0576521 (* 1 = 0.0576521 loss)
I1021 23:56:24.736469 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0260967 (* 1 = 0.0260967 loss)
I1021 23:56:24.736479 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0126493 (* 1 = 0.0126493 loss)
I1021 23:56:24.736490 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00208334 (* 1 = 0.00208334 loss)
I1021 23:56:24.736515 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.89612e-05 (* 1 = 9.89612e-05 loss)
I1021 23:56:24.736524 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0342164 (* 1 = 0.0342164 loss)
I1021 23:56:24.736538 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00388342 (* 1 = 0.00388342 loss)
I1021 23:56:24.736554 25759 sgd_solver.cpp:106] Iteration 580, lr = 0.002
speed: 4.209s / iter
I1021 23:57:49.367074 25759 solver.cpp:228] Iteration 600, loss = 0.208603
I1021 23:57:49.367107 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:57:49.367113 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:57:49.367120 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:57:49.367125 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:57:49.367128 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00798935 (* 1 = 0.00798935 loss)
I1021 23:57:49.367133 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00609547 (* 1 = 0.00609547 loss)
I1021 23:57:49.367137 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00558061 (* 1 = 0.00558061 loss)
I1021 23:57:49.367142 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.79572e-05 (* 1 = 2.79572e-05 loss)
I1021 23:57:49.367146 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00312695 (* 1 = 0.00312695 loss)
I1021 23:57:49.367151 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00392715 (* 1 = 0.00392715 loss)
I1021 23:57:49.367156 25759 sgd_solver.cpp:106] Iteration 600, lr = 0.002
I1021 23:59:15.214231 25759 solver.cpp:228] Iteration 620, loss = 0.27208
I1021 23:59:15.214309 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1021 23:59:15.214323 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1021 23:59:15.214336 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1021 23:59:15.214346 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1021 23:59:15.214356 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00967916 (* 1 = 0.00967916 loss)
I1021 23:59:15.214367 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00652278 (* 1 = 0.00652278 loss)
I1021 23:59:15.214380 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000347835 (* 1 = 0.000347835 loss)
I1021 23:59:15.214395 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.36109e-05 (* 1 = 4.36109e-05 loss)
I1021 23:59:15.214404 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0035482 (* 1 = 0.0035482 loss)
I1021 23:59:15.214416 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00835509 (* 1 = 0.00835509 loss)
I1021 23:59:15.214432 25759 sgd_solver.cpp:106] Iteration 620, lr = 0.002
I1022 00:00:38.255149 25759 solver.cpp:228] Iteration 640, loss = 0.162026
I1022 00:00:38.255205 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993003
I1022 00:00:38.255213 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 00:00:38.255223 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0612681 (* 1 = 0.0612681 loss)
I1022 00:00:38.255229 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0281419 (* 1 = 0.0281419 loss)
I1022 00:00:38.255235 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0241851 (* 1 = 0.0241851 loss)
I1022 00:00:38.255240 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0143625 (* 1 = 0.0143625 loss)
I1022 00:00:38.255246 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000276277 (* 1 = 0.000276277 loss)
I1022 00:00:38.255254 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.23597e-05 (* 1 = 3.23597e-05 loss)
I1022 00:00:38.255260 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0111726 (* 1 = 0.0111726 loss)
I1022 00:00:38.255266 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00557788 (* 1 = 0.00557788 loss)
I1022 00:00:38.255273 25759 sgd_solver.cpp:106] Iteration 640, lr = 0.002
I1022 00:02:00.940207 25759 solver.cpp:228] Iteration 660, loss = 0.804982
I1022 00:02:00.940246 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 00:02:00.940253 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:02:00.940263 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:02:00.940268 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:02:00.940274 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00904575 (* 1 = 0.00904575 loss)
I1022 00:02:00.940280 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00621111 (* 1 = 0.00621111 loss)
I1022 00:02:00.940286 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00293553 (* 1 = 0.00293553 loss)
I1022 00:02:00.940294 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00103608 (* 1 = 0.00103608 loss)
I1022 00:02:00.940299 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00705218 (* 1 = 0.00705218 loss)
I1022 00:02:00.940305 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00431661 (* 1 = 0.00431661 loss)
I1022 00:02:00.940312 25759 sgd_solver.cpp:106] Iteration 660, lr = 0.002
I1022 00:03:25.106711 25759 solver.cpp:228] Iteration 680, loss = 0.226759
I1022 00:03:25.106773 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990005
I1022 00:03:25.106783 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993503
I1022 00:03:25.106796 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0702373 (* 1 = 0.0702373 loss)
I1022 00:03:25.106806 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0720606 (* 1 = 0.0720606 loss)
I1022 00:03:25.106813 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0238621 (* 1 = 0.0238621 loss)
I1022 00:03:25.106822 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.020605 (* 1 = 0.020605 loss)
I1022 00:03:25.106830 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00631878 (* 1 = 0.00631878 loss)
I1022 00:03:25.106843 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.47126e-05 (* 1 = 3.47126e-05 loss)
I1022 00:03:25.106855 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0723129 (* 1 = 0.0723129 loss)
I1022 00:03:25.106864 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000347711 (* 1 = 0.000347711 loss)
I1022 00:03:25.106875 25759 sgd_solver.cpp:106] Iteration 680, lr = 0.002
I1022 00:04:49.418463 25759 solver.cpp:228] Iteration 700, loss = 0.391539
I1022 00:04:49.418510 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.950166
I1022 00:04:49.418516 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.974564
I1022 00:04:49.418524 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.57896 (* 1 = 0.57896 loss)
I1022 00:04:49.418529 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.301433 (* 1 = 0.301433 loss)
I1022 00:04:49.418534 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.140218 (* 1 = 0.140218 loss)
I1022 00:04:49.418537 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.074305 (* 1 = 0.074305 loss)
I1022 00:04:49.418541 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0247921 (* 1 = 0.0247921 loss)
I1022 00:04:49.418546 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.70118e-05 (* 1 = 5.70118e-05 loss)
I1022 00:04:49.418551 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.313914 (* 1 = 0.313914 loss)
I1022 00:04:49.418556 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00326433 (* 1 = 0.00326433 loss)
I1022 00:04:49.418561 25759 sgd_solver.cpp:106] Iteration 700, lr = 0.002
I1022 00:06:13.719058 25759 solver.cpp:228] Iteration 720, loss = 0.255041
I1022 00:06:13.719111 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996979
I1022 00:06:13.719116 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 00:06:13.719123 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.107723 (* 1 = 0.107723 loss)
I1022 00:06:13.719130 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00647347 (* 1 = 0.00647347 loss)
I1022 00:06:13.719135 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.02658 (* 1 = 0.02658 loss)
I1022 00:06:13.719138 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00979246 (* 1 = 0.00979246 loss)
I1022 00:06:13.719143 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.120355 (* 1 = 0.120355 loss)
I1022 00:06:13.719148 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.60234e-06 (* 1 = 9.60234e-06 loss)
I1022 00:06:13.719153 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0318937 (* 1 = 0.0318937 loss)
I1022 00:06:13.719157 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00769222 (* 1 = 0.00769222 loss)
I1022 00:06:13.719168 25759 sgd_solver.cpp:106] Iteration 720, lr = 0.002
I1022 00:07:38.027654 25759 solver.cpp:228] Iteration 740, loss = 0.917031
I1022 00:07:38.027704 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.928653
I1022 00:07:38.027709 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.965139
I1022 00:07:38.027716 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.938473 (* 1 = 0.938473 loss)
I1022 00:07:38.027721 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.500178 (* 1 = 0.500178 loss)
I1022 00:07:38.027725 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.164067 (* 1 = 0.164067 loss)
I1022 00:07:38.027729 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.106848 (* 1 = 0.106848 loss)
I1022 00:07:38.027734 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0285979 (* 1 = 0.0285979 loss)
I1022 00:07:38.027740 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.15658e-05 (* 1 = 4.15658e-05 loss)
I1022 00:07:38.027745 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.464232 (* 1 = 0.464232 loss)
I1022 00:07:38.027748 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00354037 (* 1 = 0.00354037 loss)
I1022 00:07:38.027755 25759 sgd_solver.cpp:106] Iteration 740, lr = 0.002
I1022 00:09:02.282292 25759 solver.cpp:228] Iteration 760, loss = 0.330934
I1022 00:09:02.282331 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993003
I1022 00:09:02.282346 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995003
I1022 00:09:02.282356 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0339955 (* 1 = 0.0339955 loss)
I1022 00:09:02.282363 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0181393 (* 1 = 0.0181393 loss)
I1022 00:09:02.282369 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0223058 (* 1 = 0.0223058 loss)
I1022 00:09:02.282374 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0144935 (* 1 = 0.0144935 loss)
I1022 00:09:02.282380 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00895181 (* 1 = 0.00895181 loss)
I1022 00:09:02.282387 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.0464e-05 (* 1 = 3.0464e-05 loss)
I1022 00:09:02.282393 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.144985 (* 1 = 0.144985 loss)
I1022 00:09:02.282399 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.012243 (* 1 = 0.012243 loss)
I1022 00:09:02.282407 25759 sgd_solver.cpp:106] Iteration 760, lr = 0.002
I1022 00:10:25.291872 25759 solver.cpp:228] Iteration 780, loss = 0.684513
I1022 00:10:25.291919 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992004
I1022 00:10:25.291924 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994003
I1022 00:10:25.291932 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0884109 (* 1 = 0.0884109 loss)
I1022 00:10:25.291937 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0482636 (* 1 = 0.0482636 loss)
I1022 00:10:25.291941 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0267563 (* 1 = 0.0267563 loss)
I1022 00:10:25.291945 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0181521 (* 1 = 0.0181521 loss)
I1022 00:10:25.291950 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00347398 (* 1 = 0.00347398 loss)
I1022 00:10:25.291955 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00205732 (* 1 = 0.00205732 loss)
I1022 00:10:25.291960 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0622635 (* 1 = 0.0622635 loss)
I1022 00:10:25.291965 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0113317 (* 1 = 0.0113317 loss)
I1022 00:10:25.291970 25759 sgd_solver.cpp:106] Iteration 780, lr = 0.002
speed: 4.205s / iter
I1022 00:11:47.743073 25759 solver.cpp:228] Iteration 800, loss = 0.589051
I1022 00:11:47.743167 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991005
I1022 00:11:47.743178 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995003
I1022 00:11:47.743194 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.125416 (* 1 = 0.125416 loss)
I1022 00:11:47.743206 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0561814 (* 1 = 0.0561814 loss)
I1022 00:11:47.743216 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0323066 (* 1 = 0.0323066 loss)
I1022 00:11:47.743229 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0205822 (* 1 = 0.0205822 loss)
I1022 00:11:47.743242 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0107467 (* 1 = 0.0107467 loss)
I1022 00:11:47.743257 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.45482e-05 (* 1 = 1.45482e-05 loss)
I1022 00:11:47.743269 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0469094 (* 1 = 0.0469094 loss)
I1022 00:11:47.743281 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0019008 (* 1 = 0.0019008 loss)
I1022 00:11:47.743296 25759 sgd_solver.cpp:106] Iteration 800, lr = 0.002
I1022 00:13:11.907876 25759 solver.cpp:228] Iteration 820, loss = 0.308023
I1022 00:13:11.907936 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.982027
I1022 00:13:11.907943 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.985022
I1022 00:13:11.907950 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.235621 (* 1 = 0.235621 loss)
I1022 00:13:11.907958 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.288589 (* 1 = 0.288589 loss)
I1022 00:13:11.907963 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0468756 (* 1 = 0.0468756 loss)
I1022 00:13:11.907968 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0403972 (* 1 = 0.0403972 loss)
I1022 00:13:11.907971 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0342482 (* 1 = 0.0342482 loss)
I1022 00:13:11.907977 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000113813 (* 1 = 0.000113813 loss)
I1022 00:13:11.907982 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0974632 (* 1 = 0.0974632 loss)
I1022 00:13:11.907987 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0186758 (* 1 = 0.0186758 loss)
I1022 00:13:11.907996 25759 sgd_solver.cpp:106] Iteration 820, lr = 0.002
I1022 00:14:34.642138 25759 solver.cpp:228] Iteration 840, loss = 0.712753
I1022 00:14:34.642189 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 00:14:34.642194 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:14:34.642202 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:14:34.642207 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:14:34.642212 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00471805 (* 1 = 0.00471805 loss)
I1022 00:14:34.642216 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00526581 (* 1 = 0.00526581 loss)
I1022 00:14:34.642221 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00879549 (* 1 = 0.00879549 loss)
I1022 00:14:34.642226 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.3287e-05 (* 1 = 1.3287e-05 loss)
I1022 00:14:34.642232 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0066433 (* 1 = 0.0066433 loss)
I1022 00:14:34.642238 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00370009 (* 1 = 0.00370009 loss)
I1022 00:14:34.642244 25759 sgd_solver.cpp:106] Iteration 840, lr = 0.002
I1022 00:15:59.510759 25759 solver.cpp:228] Iteration 860, loss = 0.312873
I1022 00:15:59.510815 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986513
I1022 00:15:59.510823 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995504
I1022 00:15:59.510833 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.263284 (* 1 = 0.263284 loss)
I1022 00:15:59.510840 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0400175 (* 1 = 0.0400175 loss)
I1022 00:15:59.510848 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0530606 (* 1 = 0.0530606 loss)
I1022 00:15:59.510854 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0153193 (* 1 = 0.0153193 loss)
I1022 00:15:59.510859 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0391072 (* 1 = 0.0391072 loss)
I1022 00:15:59.510867 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.77821e-05 (* 1 = 5.77821e-05 loss)
I1022 00:15:59.510874 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.100919 (* 1 = 0.100919 loss)
I1022 00:15:59.510880 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00277654 (* 1 = 0.00277654 loss)
I1022 00:15:59.510891 25759 sgd_solver.cpp:106] Iteration 860, lr = 0.002
I1022 00:17:22.970885 25759 solver.cpp:228] Iteration 880, loss = 0.382422
I1022 00:17:22.970932 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.954115
I1022 00:17:22.970938 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.978554
I1022 00:17:22.970945 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.72273 (* 1 = 0.72273 loss)
I1022 00:17:22.970953 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.399421 (* 1 = 0.399421 loss)
I1022 00:17:22.970958 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.131466 (* 1 = 0.131466 loss)
I1022 00:17:22.970963 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0669298 (* 1 = 0.0669298 loss)
I1022 00:17:22.970968 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00600699 (* 1 = 0.00600699 loss)
I1022 00:17:22.970973 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.81199e-05 (* 1 = 7.81199e-05 loss)
I1022 00:17:22.970976 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.11309 (* 1 = 0.11309 loss)
I1022 00:17:22.970981 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00644569 (* 1 = 0.00644569 loss)
I1022 00:17:22.970986 25759 sgd_solver.cpp:106] Iteration 880, lr = 0.002
I1022 00:18:47.247128 25759 solver.cpp:228] Iteration 900, loss = 0.469194
I1022 00:18:47.247164 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.983516
I1022 00:18:47.247171 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.982018
I1022 00:18:47.247180 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.073352 (* 1 = 0.073352 loss)
I1022 00:18:47.247187 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0879505 (* 1 = 0.0879505 loss)
I1022 00:18:47.247193 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0472474 (* 1 = 0.0472474 loss)
I1022 00:18:47.247201 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.045494 (* 1 = 0.045494 loss)
I1022 00:18:47.247207 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0197378 (* 1 = 0.0197378 loss)
I1022 00:18:47.247213 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.18307e-05 (* 1 = 7.18307e-05 loss)
I1022 00:18:47.247220 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.338573 (* 1 = 0.338573 loss)
I1022 00:18:47.247225 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00469077 (* 1 = 0.00469077 loss)
I1022 00:18:47.247236 25759 sgd_solver.cpp:106] Iteration 900, lr = 0.002
I1022 00:20:11.752022 25759 solver.cpp:228] Iteration 920, loss = 1.06358
I1022 00:20:11.752068 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988439
I1022 00:20:11.752074 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.989006
I1022 00:20:11.752084 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.040228 (* 1 = 0.040228 loss)
I1022 00:20:11.752091 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0857919 (* 1 = 0.0857919 loss)
I1022 00:20:11.752100 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0462692 (* 1 = 0.0462692 loss)
I1022 00:20:11.752106 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0415803 (* 1 = 0.0415803 loss)
I1022 00:20:11.752111 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0330487 (* 1 = 0.0330487 loss)
I1022 00:20:11.752118 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.78804e-05 (* 1 = 9.78804e-05 loss)
I1022 00:20:11.752125 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.644483 (* 1 = 0.644483 loss)
I1022 00:20:11.752131 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00716624 (* 1 = 0.00716624 loss)
I1022 00:20:11.752140 25759 sgd_solver.cpp:106] Iteration 920, lr = 0.002
I1022 00:21:36.019021 25759 solver.cpp:228] Iteration 940, loss = 0.937078
I1022 00:21:36.019069 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.958147
I1022 00:21:36.019075 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.976084
I1022 00:21:36.019083 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.481132 (* 1 = 0.481132 loss)
I1022 00:21:36.019088 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.340211 (* 1 = 0.340211 loss)
I1022 00:21:36.019093 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.114006 (* 1 = 0.114006 loss)
I1022 00:21:36.019096 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.076385 (* 1 = 0.076385 loss)
I1022 00:21:36.019101 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00768369 (* 1 = 0.00768369 loss)
I1022 00:21:36.019106 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.86673e-05 (* 1 = 3.86673e-05 loss)
I1022 00:21:36.019111 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.164471 (* 1 = 0.164471 loss)
I1022 00:21:36.019117 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00904312 (* 1 = 0.00904312 loss)
I1022 00:21:36.019124 25759 sgd_solver.cpp:106] Iteration 940, lr = 0.002
I1022 00:22:59.314882 25759 solver.cpp:228] Iteration 960, loss = 0.486146
I1022 00:22:59.314936 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986513
I1022 00:22:59.314942 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993007
I1022 00:22:59.314950 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.163857 (* 1 = 0.163857 loss)
I1022 00:22:59.314959 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.104866 (* 1 = 0.104866 loss)
I1022 00:22:59.314962 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0363758 (* 1 = 0.0363758 loss)
I1022 00:22:59.314967 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0219532 (* 1 = 0.0219532 loss)
I1022 00:22:59.314972 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000498079 (* 1 = 0.000498079 loss)
I1022 00:22:59.314977 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000104211 (* 1 = 0.000104211 loss)
I1022 00:22:59.314981 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.030025 (* 1 = 0.030025 loss)
I1022 00:22:59.314986 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00505134 (* 1 = 0.00505134 loss)
I1022 00:22:59.314993 25759 sgd_solver.cpp:106] Iteration 960, lr = 0.002
I1022 00:24:23.222999 25759 solver.cpp:228] Iteration 980, loss = 0.574014
I1022 00:24:23.223047 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988006
I1022 00:24:23.223057 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991504
I1022 00:24:23.223069 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.214583 (* 1 = 0.214583 loss)
I1022 00:24:23.223079 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.109561 (* 1 = 0.109561 loss)
I1022 00:24:23.223088 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0404903 (* 1 = 0.0404903 loss)
I1022 00:24:23.223096 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0325833 (* 1 = 0.0325833 loss)
I1022 00:24:23.223105 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0531662 (* 1 = 0.0531662 loss)
I1022 00:24:23.223115 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.1397e-05 (* 1 = 3.1397e-05 loss)
I1022 00:24:23.223124 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.35079 (* 1 = 0.35079 loss)
I1022 00:24:23.223150 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00873397 (* 1 = 0.00873397 loss)
I1022 00:24:23.223168 25759 sgd_solver.cpp:106] Iteration 980, lr = 0.002
speed: 4.203s / iter
I1022 00:25:47.324717 25759 solver.cpp:228] Iteration 1000, loss = 0.332672
I1022 00:25:47.324764 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.970272
I1022 00:25:47.324781 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.983034
I1022 00:25:47.324791 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.381785 (* 1 = 0.381785 loss)
I1022 00:25:47.324800 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.257577 (* 1 = 0.257577 loss)
I1022 00:25:47.324807 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0790577 (* 1 = 0.0790577 loss)
I1022 00:25:47.324815 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0528721 (* 1 = 0.0528721 loss)
I1022 00:25:47.324821 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.040603 (* 1 = 0.040603 loss)
I1022 00:25:47.324829 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.92267e-05 (* 1 = 3.92267e-05 loss)
I1022 00:25:47.324836 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.145466 (* 1 = 0.145466 loss)
I1022 00:25:47.324862 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00663153 (* 1 = 0.00663153 loss)
I1022 00:25:47.324870 25759 sgd_solver.cpp:106] Iteration 1000, lr = 0.002
I1022 00:27:12.866480 25759 solver.cpp:228] Iteration 1020, loss = 0.337923
I1022 00:27:12.866525 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 00:27:12.866530 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 00:27:12.866539 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0310422 (* 1 = 0.0310422 loss)
I1022 00:27:12.866544 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0380875 (* 1 = 0.0380875 loss)
I1022 00:27:12.866549 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0185488 (* 1 = 0.0185488 loss)
I1022 00:27:12.866554 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0118199 (* 1 = 0.0118199 loss)
I1022 00:27:12.866557 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0114979 (* 1 = 0.0114979 loss)
I1022 00:27:12.866562 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000154312 (* 1 = 0.000154312 loss)
I1022 00:27:12.866567 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00159385 (* 1 = 0.00159385 loss)
I1022 00:27:12.866572 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0133279 (* 1 = 0.0133279 loss)
I1022 00:27:12.866581 25759 sgd_solver.cpp:106] Iteration 1020, lr = 0.002
I1022 00:28:38.677049 25759 solver.cpp:228] Iteration 1040, loss = 0.358133
I1022 00:28:38.677088 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990566
I1022 00:28:38.677094 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994006
I1022 00:28:38.677103 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0970866 (* 1 = 0.0970866 loss)
I1022 00:28:38.677110 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0741774 (* 1 = 0.0741774 loss)
I1022 00:28:38.677115 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0262233 (* 1 = 0.0262233 loss)
I1022 00:28:38.677121 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0223617 (* 1 = 0.0223617 loss)
I1022 00:28:38.677127 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00437743 (* 1 = 0.00437743 loss)
I1022 00:28:38.677134 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.93866e-05 (* 1 = 1.93866e-05 loss)
I1022 00:28:38.677139 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0496174 (* 1 = 0.0496174 loss)
I1022 00:28:38.677145 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00227974 (* 1 = 0.00227974 loss)
I1022 00:28:38.677153 25759 sgd_solver.cpp:106] Iteration 1040, lr = 0.002
I1022 00:30:03.554600 25759 solver.cpp:228] Iteration 1060, loss = 0.441618
I1022 00:30:03.554661 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 00:30:03.554672 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:30:03.554687 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:30:03.554699 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:30:03.554711 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00520916 (* 1 = 0.00520916 loss)
I1022 00:30:03.554723 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00503554 (* 1 = 0.00503554 loss)
I1022 00:30:03.554735 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00101496 (* 1 = 0.00101496 loss)
I1022 00:30:03.554750 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.68115e-05 (* 1 = 3.68115e-05 loss)
I1022 00:30:03.557044 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00585956 (* 1 = 0.00585956 loss)
I1022 00:30:03.557062 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00933223 (* 1 = 0.00933223 loss)
I1022 00:30:03.557080 25759 sgd_solver.cpp:106] Iteration 1060, lr = 0.002
I1022 00:31:29.185688 25759 solver.cpp:228] Iteration 1080, loss = 0.219896
I1022 00:31:29.185729 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 00:31:29.185734 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:31:29.185745 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:31:29.185750 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:31:29.185756 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00908796 (* 1 = 0.00908796 loss)
I1022 00:31:29.185762 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00639287 (* 1 = 0.00639287 loss)
I1022 00:31:29.185768 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0060091 (* 1 = 0.0060091 loss)
I1022 00:31:29.185775 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.05505e-05 (* 1 = 2.05505e-05 loss)
I1022 00:31:29.185781 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000792473 (* 1 = 0.000792473 loss)
I1022 00:31:29.185786 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00452928 (* 1 = 0.00452928 loss)
I1022 00:31:29.185796 25759 sgd_solver.cpp:106] Iteration 1080, lr = 0.002
I1022 00:32:54.642290 25759 solver.cpp:228] Iteration 1100, loss = 0.260465
I1022 00:32:54.642331 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986032
I1022 00:32:54.642338 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995003
I1022 00:32:54.642347 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.11775 (* 1 = 0.11775 loss)
I1022 00:32:54.642354 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0315264 (* 1 = 0.0315264 loss)
I1022 00:32:54.642361 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0406804 (* 1 = 0.0406804 loss)
I1022 00:32:54.642367 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0195674 (* 1 = 0.0195674 loss)
I1022 00:32:54.642374 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00441864 (* 1 = 0.00441864 loss)
I1022 00:32:54.642380 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.79212e-05 (* 1 = 2.79212e-05 loss)
I1022 00:32:54.642386 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0431455 (* 1 = 0.0431455 loss)
I1022 00:32:54.642392 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00363497 (* 1 = 0.00363497 loss)
I1022 00:32:54.642400 25759 sgd_solver.cpp:106] Iteration 1100, lr = 0.002
I1022 00:34:19.734540 25759 solver.cpp:228] Iteration 1120, loss = 0.217728
I1022 00:34:19.734611 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.979531
I1022 00:34:19.734618 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.989016
I1022 00:34:19.734629 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.20934 (* 1 = 0.20934 loss)
I1022 00:34:19.734637 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.138179 (* 1 = 0.138179 loss)
I1022 00:34:19.734643 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0517185 (* 1 = 0.0517185 loss)
I1022 00:34:19.734649 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0346059 (* 1 = 0.0346059 loss)
I1022 00:34:19.734657 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00144976 (* 1 = 0.00144976 loss)
I1022 00:34:19.734663 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.98542e-05 (* 1 = 2.98542e-05 loss)
I1022 00:34:19.734669 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.072596 (* 1 = 0.072596 loss)
I1022 00:34:19.734676 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00258213 (* 1 = 0.00258213 loss)
I1022 00:34:19.734689 25759 sgd_solver.cpp:106] Iteration 1120, lr = 0.002
I1022 00:35:45.132660 25759 solver.cpp:228] Iteration 1140, loss = 0.437699
I1022 00:35:45.132722 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985816
I1022 00:35:45.132732 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.988012
I1022 00:35:45.132745 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.177611 (* 1 = 0.177611 loss)
I1022 00:35:45.132757 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0935755 (* 1 = 0.0935755 loss)
I1022 00:35:45.132766 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.044834 (* 1 = 0.044834 loss)
I1022 00:35:45.132776 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0347822 (* 1 = 0.0347822 loss)
I1022 00:35:45.132786 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00395965 (* 1 = 0.00395965 loss)
I1022 00:35:45.132797 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.24311e-05 (* 1 = 3.24311e-05 loss)
I1022 00:35:45.132807 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.249746 (* 1 = 0.249746 loss)
I1022 00:35:45.132815 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.012721 (* 1 = 0.012721 loss)
I1022 00:35:45.132825 25759 sgd_solver.cpp:106] Iteration 1140, lr = 0.002
I1022 00:37:09.610718 25759 solver.cpp:228] Iteration 1160, loss = 0.382205
I1022 00:37:09.610762 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 00:37:09.610769 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994003
I1022 00:37:09.610780 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0528302 (* 1 = 0.0528302 loss)
I1022 00:37:09.610786 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0511362 (* 1 = 0.0511362 loss)
I1022 00:37:09.610792 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0139958 (* 1 = 0.0139958 loss)
I1022 00:37:09.610798 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0142685 (* 1 = 0.0142685 loss)
I1022 00:37:09.610805 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00110838 (* 1 = 0.00110838 loss)
I1022 00:37:09.610811 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.8846e-05 (* 1 = 1.8846e-05 loss)
I1022 00:37:09.610817 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00965605 (* 1 = 0.00965605 loss)
I1022 00:37:09.610823 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000987017 (* 1 = 0.000987017 loss)
I1022 00:37:09.610831 25759 sgd_solver.cpp:106] Iteration 1160, lr = 0.002
I1022 00:38:35.053751 25759 solver.cpp:228] Iteration 1180, loss = 0.291425
I1022 00:38:35.053793 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 00:38:35.053800 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 00:38:35.053812 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0540541 (* 1 = 0.0540541 loss)
I1022 00:38:35.053818 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0240958 (* 1 = 0.0240958 loss)
I1022 00:38:35.053825 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0184505 (* 1 = 0.0184505 loss)
I1022 00:38:35.053833 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0136861 (* 1 = 0.0136861 loss)
I1022 00:38:35.053839 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000164217 (* 1 = 0.000164217 loss)
I1022 00:38:35.053846 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.19161e-05 (* 1 = 4.19161e-05 loss)
I1022 00:38:35.053854 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0229547 (* 1 = 0.0229547 loss)
I1022 00:38:35.053861 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00309551 (* 1 = 0.00309551 loss)
I1022 00:38:35.053874 25759 sgd_solver.cpp:106] Iteration 1180, lr = 0.002
speed: 4.212s / iter
I1022 00:39:58.590904 25759 solver.cpp:228] Iteration 1200, loss = 0.349497
I1022 00:39:58.590955 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 00:39:58.590960 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:39:58.590966 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:39:58.590971 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:39:58.590977 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00615978 (* 1 = 0.00615978 loss)
I1022 00:39:58.590982 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00552673 (* 1 = 0.00552673 loss)
I1022 00:39:58.590987 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000179411 (* 1 = 0.000179411 loss)
I1022 00:39:58.590992 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.19056e-06 (* 1 = 9.19056e-06 loss)
I1022 00:39:58.590997 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0098155 (* 1 = 0.0098155 loss)
I1022 00:39:58.591002 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00116441 (* 1 = 0.00116441 loss)
I1022 00:39:58.591008 25759 sgd_solver.cpp:106] Iteration 1200, lr = 0.002
I1022 00:41:23.679286 25759 solver.cpp:228] Iteration 1220, loss = 0.355065
I1022 00:41:23.679318 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 00:41:23.679338 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:41:23.679345 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:41:23.679350 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:41:23.679356 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00537698 (* 1 = 0.00537698 loss)
I1022 00:41:23.679361 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00462498 (* 1 = 0.00462498 loss)
I1022 00:41:23.679365 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000339415 (* 1 = 0.000339415 loss)
I1022 00:41:23.679370 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.43552e-05 (* 1 = 3.43552e-05 loss)
I1022 00:41:23.679375 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00138384 (* 1 = 0.00138384 loss)
I1022 00:41:23.679379 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00202109 (* 1 = 0.00202109 loss)
I1022 00:41:23.679388 25759 sgd_solver.cpp:106] Iteration 1220, lr = 0.002
I1022 00:42:48.107143 25759 solver.cpp:228] Iteration 1240, loss = 0.513686
I1022 00:42:48.107182 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993503
I1022 00:42:48.107187 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995502
I1022 00:42:48.107197 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.134881 (* 1 = 0.134881 loss)
I1022 00:42:48.107203 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0499904 (* 1 = 0.0499904 loss)
I1022 00:42:48.107209 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0190315 (* 1 = 0.0190315 loss)
I1022 00:42:48.107215 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0145424 (* 1 = 0.0145424 loss)
I1022 00:42:48.107223 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00020182 (* 1 = 0.00020182 loss)
I1022 00:42:48.107228 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.38532e-05 (* 1 = 7.38532e-05 loss)
I1022 00:42:48.107234 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0492232 (* 1 = 0.0492232 loss)
I1022 00:42:48.107240 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00294765 (* 1 = 0.00294765 loss)
I1022 00:42:48.107247 25759 sgd_solver.cpp:106] Iteration 1240, lr = 0.002
I1022 00:44:11.295624 25759 solver.cpp:228] Iteration 1260, loss = 0.256603
I1022 00:44:11.295677 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 00:44:11.295683 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:44:11.295693 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:44:11.295701 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:44:11.295708 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00429496 (* 1 = 0.00429496 loss)
I1022 00:44:11.295714 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00467955 (* 1 = 0.00467955 loss)
I1022 00:44:11.295722 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000126113 (* 1 = 0.000126113 loss)
I1022 00:44:11.295729 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.23701e-05 (* 1 = 4.23701e-05 loss)
I1022 00:44:11.295737 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00237248 (* 1 = 0.00237248 loss)
I1022 00:44:11.295743 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0116293 (* 1 = 0.0116293 loss)
I1022 00:44:11.295754 25759 sgd_solver.cpp:106] Iteration 1260, lr = 0.002
I1022 00:45:32.449415 25759 solver.cpp:228] Iteration 1280, loss = 0.472971
I1022 00:45:32.449455 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 00:45:32.449462 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 00:45:32.449471 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0307779 (* 1 = 0.0307779 loss)
I1022 00:45:32.449478 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0343173 (* 1 = 0.0343173 loss)
I1022 00:45:32.449484 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0180504 (* 1 = 0.0180504 loss)
I1022 00:45:32.449491 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0118134 (* 1 = 0.0118134 loss)
I1022 00:45:32.449496 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000602052 (* 1 = 0.000602052 loss)
I1022 00:45:32.449502 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.84073e-05 (* 1 = 2.84073e-05 loss)
I1022 00:45:32.449508 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0128131 (* 1 = 0.0128131 loss)
I1022 00:45:32.449515 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00189421 (* 1 = 0.00189421 loss)
I1022 00:45:32.449522 25759 sgd_solver.cpp:106] Iteration 1280, lr = 0.002
I1022 00:46:55.176056 25759 solver.cpp:228] Iteration 1300, loss = 0.284137
I1022 00:46:55.176110 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 00:46:55.176115 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 00:46:55.176123 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0755074 (* 1 = 0.0755074 loss)
I1022 00:46:55.176132 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0687795 (* 1 = 0.0687795 loss)
I1022 00:46:55.176136 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0211861 (* 1 = 0.0211861 loss)
I1022 00:46:55.176141 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.012325 (* 1 = 0.012325 loss)
I1022 00:46:55.176146 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00890043 (* 1 = 0.00890043 loss)
I1022 00:46:55.176151 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.4761e-05 (* 1 = 3.4761e-05 loss)
I1022 00:46:55.176156 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0115087 (* 1 = 0.0115087 loss)
I1022 00:46:55.176160 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000682262 (* 1 = 0.000682262 loss)
I1022 00:46:55.176167 25759 sgd_solver.cpp:106] Iteration 1300, lr = 0.002
I1022 00:48:18.790328 25759 solver.cpp:228] Iteration 1320, loss = 0.461804
I1022 00:48:18.790382 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.948379
I1022 00:48:18.790392 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.976072
I1022 00:48:18.790408 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.340071 (* 1 = 0.340071 loss)
I1022 00:48:18.790421 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.201855 (* 1 = 0.201855 loss)
I1022 00:48:18.790431 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.108283 (* 1 = 0.108283 loss)
I1022 00:48:18.790441 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0639979 (* 1 = 0.0639979 loss)
I1022 00:48:18.790452 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0079492 (* 1 = 0.0079492 loss)
I1022 00:48:18.790465 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00039923 (* 1 = 0.00039923 loss)
I1022 00:48:18.790477 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.219577 (* 1 = 0.219577 loss)
I1022 00:48:18.790490 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00538936 (* 1 = 0.00538936 loss)
I1022 00:48:18.790501 25759 sgd_solver.cpp:106] Iteration 1320, lr = 0.002
I1022 00:49:40.611522 25759 solver.cpp:228] Iteration 1340, loss = 0.348562
I1022 00:49:40.611584 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 00:49:40.611593 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 00:49:40.611606 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0703471 (* 1 = 0.0703471 loss)
I1022 00:49:40.611616 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0373947 (* 1 = 0.0373947 loss)
I1022 00:49:40.611625 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0186359 (* 1 = 0.0186359 loss)
I1022 00:49:40.611634 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00903733 (* 1 = 0.00903733 loss)
I1022 00:49:40.611655 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00017475 (* 1 = 0.00017475 loss)
I1022 00:49:40.611666 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.20321e-05 (* 1 = 3.20321e-05 loss)
I1022 00:49:40.611677 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0182524 (* 1 = 0.0182524 loss)
I1022 00:49:40.611687 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00496311 (* 1 = 0.00496311 loss)
I1022 00:49:40.611698 25759 sgd_solver.cpp:106] Iteration 1340, lr = 0.002
I1022 00:51:04.961220 25759 solver.cpp:228] Iteration 1360, loss = 0.475741
I1022 00:51:04.961266 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.987519
I1022 00:51:04.961284 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990514
I1022 00:51:04.961294 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.214592 (* 1 = 0.214592 loss)
I1022 00:51:04.961304 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.189186 (* 1 = 0.189186 loss)
I1022 00:51:04.961311 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0394844 (* 1 = 0.0394844 loss)
I1022 00:51:04.961318 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0303086 (* 1 = 0.0303086 loss)
I1022 00:51:04.961324 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00492902 (* 1 = 0.00492902 loss)
I1022 00:51:04.961331 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.40793e-05 (* 1 = 2.40793e-05 loss)
I1022 00:51:04.961338 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0538418 (* 1 = 0.0538418 loss)
I1022 00:51:04.961345 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0100602 (* 1 = 0.0100602 loss)
I1022 00:51:04.961362 25759 sgd_solver.cpp:106] Iteration 1360, lr = 0.002
I1022 00:52:30.158104 25759 solver.cpp:228] Iteration 1380, loss = 0.320618
I1022 00:52:30.158149 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 00:52:30.158157 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:52:30.158169 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:52:30.158176 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:52:30.158186 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00535667 (* 1 = 0.00535667 loss)
I1022 00:52:30.158195 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00488236 (* 1 = 0.00488236 loss)
I1022 00:52:30.158202 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000255571 (* 1 = 0.000255571 loss)
I1022 00:52:30.158211 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.5374e-05 (* 1 = 2.5374e-05 loss)
I1022 00:52:30.158219 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00249193 (* 1 = 0.00249193 loss)
I1022 00:52:30.158231 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00280423 (* 1 = 0.00280423 loss)
I1022 00:52:30.158239 25759 sgd_solver.cpp:106] Iteration 1380, lr = 0.002
speed: 4.209s / iter
I1022 00:53:55.902318 25759 solver.cpp:228] Iteration 1400, loss = 0.250204
I1022 00:53:55.902374 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993503
I1022 00:53:55.902379 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995502
I1022 00:53:55.902387 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0940518 (* 1 = 0.0940518 loss)
I1022 00:53:55.902395 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0338962 (* 1 = 0.0338962 loss)
I1022 00:53:55.902400 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0172516 (* 1 = 0.0172516 loss)
I1022 00:53:55.902403 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0123077 (* 1 = 0.0123077 loss)
I1022 00:53:55.902408 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00302424 (* 1 = 0.00302424 loss)
I1022 00:53:55.902415 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.7144e-05 (* 1 = 1.7144e-05 loss)
I1022 00:53:55.902420 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0309416 (* 1 = 0.0309416 loss)
I1022 00:53:55.902423 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00093659 (* 1 = 0.00093659 loss)
I1022 00:53:55.902431 25759 sgd_solver.cpp:106] Iteration 1400, lr = 0.002
I1022 00:55:21.214036 25759 solver.cpp:228] Iteration 1420, loss = 0.31132
I1022 00:55:21.214087 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 00:55:21.214097 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:55:21.214109 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:55:21.214120 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:55:21.214129 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00491193 (* 1 = 0.00491193 loss)
I1022 00:55:21.214138 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00359293 (* 1 = 0.00359293 loss)
I1022 00:55:21.214148 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000192671 (* 1 = 0.000192671 loss)
I1022 00:55:21.214157 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.35133e-05 (* 1 = 1.35133e-05 loss)
I1022 00:55:21.214170 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0120398 (* 1 = 0.0120398 loss)
I1022 00:55:21.214181 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000737563 (* 1 = 0.000737563 loss)
I1022 00:55:21.214195 25759 sgd_solver.cpp:106] Iteration 1420, lr = 0.002
I1022 00:56:44.648614 25759 solver.cpp:228] Iteration 1440, loss = 0.285251
I1022 00:56:44.648664 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 00:56:44.648669 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 00:56:44.648676 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 00:56:44.648680 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 00:56:44.648687 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0108478 (* 1 = 0.0108478 loss)
I1022 00:56:44.648692 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00740646 (* 1 = 0.00740646 loss)
I1022 00:56:44.648696 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00293399 (* 1 = 0.00293399 loss)
I1022 00:56:44.648701 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.75264e-05 (* 1 = 6.75264e-05 loss)
I1022 00:56:44.648706 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0102753 (* 1 = 0.0102753 loss)
I1022 00:56:44.648710 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00360162 (* 1 = 0.00360162 loss)
I1022 00:56:44.648716 25759 sgd_solver.cpp:106] Iteration 1440, lr = 0.002
I1022 00:58:07.579006 25759 solver.cpp:228] Iteration 1460, loss = 0.676435
I1022 00:58:07.579066 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985015
I1022 00:58:07.579074 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.986014
I1022 00:58:07.579087 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.336923 (* 1 = 0.336923 loss)
I1022 00:58:07.579097 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.234995 (* 1 = 0.234995 loss)
I1022 00:58:07.579104 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0445286 (* 1 = 0.0445286 loss)
I1022 00:58:07.579113 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0379672 (* 1 = 0.0379672 loss)
I1022 00:58:07.579121 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0150975 (* 1 = 0.0150975 loss)
I1022 00:58:07.579131 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.34586e-05 (* 1 = 1.34586e-05 loss)
I1022 00:58:07.579139 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.194605 (* 1 = 0.194605 loss)
I1022 00:58:07.579149 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00114039 (* 1 = 0.00114039 loss)
I1022 00:58:07.579171 25759 sgd_solver.cpp:106] Iteration 1460, lr = 0.002
I1022 00:59:33.828392 25759 solver.cpp:228] Iteration 1480, loss = 0.26321
I1022 00:59:33.828430 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 00:59:33.828436 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 00:59:33.828447 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0248434 (* 1 = 0.0248434 loss)
I1022 00:59:33.828454 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0651315 (* 1 = 0.0651315 loss)
I1022 00:59:33.828459 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0151096 (* 1 = 0.0151096 loss)
I1022 00:59:33.828465 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0122732 (* 1 = 0.0122732 loss)
I1022 00:59:33.828471 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00157639 (* 1 = 0.00157639 loss)
I1022 00:59:33.828478 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.32887e-05 (* 1 = 4.32887e-05 loss)
I1022 00:59:33.828483 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.017966 (* 1 = 0.017966 loss)
I1022 00:59:33.828490 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00303359 (* 1 = 0.00303359 loss)
I1022 00:59:33.828496 25759 sgd_solver.cpp:106] Iteration 1480, lr = 0.002
I1022 01:00:54.797451 25759 solver.cpp:228] Iteration 1500, loss = 0.186685
I1022 01:00:54.797483 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 01:00:54.797488 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:00:54.797495 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:00:54.797499 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:00:54.797504 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.01582 (* 1 = 0.01582 loss)
I1022 01:00:54.797508 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00870179 (* 1 = 0.00870179 loss)
I1022 01:00:54.797515 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000730649 (* 1 = 0.000730649 loss)
I1022 01:00:54.797520 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.50344e-05 (* 1 = 2.50344e-05 loss)
I1022 01:00:54.797524 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00281062 (* 1 = 0.00281062 loss)
I1022 01:00:54.797528 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00413274 (* 1 = 0.00413274 loss)
I1022 01:00:54.797538 25759 sgd_solver.cpp:106] Iteration 1500, lr = 0.002
I1022 01:02:17.098618 25759 solver.cpp:228] Iteration 1520, loss = 0.183242
I1022 01:02:17.098675 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:02:17.098686 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:02:17.098702 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:02:17.098714 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:02:17.098726 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0046869 (* 1 = 0.0046869 loss)
I1022 01:02:17.098737 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00449821 (* 1 = 0.00449821 loss)
I1022 01:02:17.098755 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000132132 (* 1 = 0.000132132 loss)
I1022 01:02:17.098769 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.84125e-05 (* 1 = 1.84125e-05 loss)
I1022 01:02:17.098783 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0117278 (* 1 = 0.0117278 loss)
I1022 01:02:17.098794 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00436239 (* 1 = 0.00436239 loss)
I1022 01:02:17.098812 25759 sgd_solver.cpp:106] Iteration 1520, lr = 0.002
I1022 01:03:40.774662 25759 solver.cpp:228] Iteration 1540, loss = 0.263572
I1022 01:03:40.774695 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 01:03:40.774715 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:03:40.774722 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:03:40.774727 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:03:40.774734 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0130661 (* 1 = 0.0130661 loss)
I1022 01:03:40.774739 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00672869 (* 1 = 0.00672869 loss)
I1022 01:03:40.774744 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00150925 (* 1 = 0.00150925 loss)
I1022 01:03:40.774749 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.82101e-05 (* 1 = 3.82101e-05 loss)
I1022 01:03:40.774754 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0150676 (* 1 = 0.0150676 loss)
I1022 01:03:40.774758 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00681935 (* 1 = 0.00681935 loss)
I1022 01:03:40.774763 25759 sgd_solver.cpp:106] Iteration 1540, lr = 0.002
I1022 01:05:02.436269 25759 solver.cpp:228] Iteration 1560, loss = 0.105087
I1022 01:05:02.436316 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992008
I1022 01:05:02.436321 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 01:05:02.436328 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0382068 (* 1 = 0.0382068 loss)
I1022 01:05:02.436333 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0358254 (* 1 = 0.0358254 loss)
I1022 01:05:02.436337 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0255569 (* 1 = 0.0255569 loss)
I1022 01:05:02.436342 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0178486 (* 1 = 0.0178486 loss)
I1022 01:05:02.436347 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00127078 (* 1 = 0.00127078 loss)
I1022 01:05:02.436352 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.75229e-05 (* 1 = 6.75229e-05 loss)
I1022 01:05:02.436357 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0608363 (* 1 = 0.0608363 loss)
I1022 01:05:02.436360 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0024193 (* 1 = 0.0024193 loss)
I1022 01:05:02.436369 25759 sgd_solver.cpp:106] Iteration 1560, lr = 0.002
I1022 01:06:22.997737 25759 solver.cpp:228] Iteration 1580, loss = 0.20619
I1022 01:06:22.997794 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 01:06:22.997800 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 01:06:22.997808 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.063758 (* 1 = 0.063758 loss)
I1022 01:06:22.997817 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0198122 (* 1 = 0.0198122 loss)
I1022 01:06:22.997822 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0151598 (* 1 = 0.0151598 loss)
I1022 01:06:22.997825 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0106636 (* 1 = 0.0106636 loss)
I1022 01:06:22.997831 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00424236 (* 1 = 0.00424236 loss)
I1022 01:06:22.997836 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.97025e-05 (* 1 = 2.97025e-05 loss)
I1022 01:06:22.997841 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0196583 (* 1 = 0.0196583 loss)
I1022 01:06:22.997846 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00316671 (* 1 = 0.00316671 loss)
I1022 01:06:22.997853 25759 sgd_solver.cpp:106] Iteration 1580, lr = 0.002
speed: 4.201s / iter
I1022 01:07:45.828773 25759 solver.cpp:228] Iteration 1600, loss = 0.270692
I1022 01:07:45.828814 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:07:45.828831 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:07:45.828840 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:07:45.828846 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:07:45.828852 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00464515 (* 1 = 0.00464515 loss)
I1022 01:07:45.828858 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00458625 (* 1 = 0.00458625 loss)
I1022 01:07:45.828864 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000246441 (* 1 = 0.000246441 loss)
I1022 01:07:45.828871 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.39091e-05 (* 1 = 3.39091e-05 loss)
I1022 01:07:45.828877 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00770688 (* 1 = 0.00770688 loss)
I1022 01:07:45.828882 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00463142 (* 1 = 0.00463142 loss)
I1022 01:07:45.828893 25759 sgd_solver.cpp:106] Iteration 1600, lr = 0.002
I1022 01:09:10.073801 25759 solver.cpp:228] Iteration 1620, loss = 0.324737
I1022 01:09:10.073843 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990019
I1022 01:09:10.073850 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993003
I1022 01:09:10.073861 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0643688 (* 1 = 0.0643688 loss)
I1022 01:09:10.073869 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0214742 (* 1 = 0.0214742 loss)
I1022 01:09:10.073879 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0343889 (* 1 = 0.0343889 loss)
I1022 01:09:10.073885 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0256436 (* 1 = 0.0256436 loss)
I1022 01:09:10.073892 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0286345 (* 1 = 0.0286345 loss)
I1022 01:09:10.073900 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.34783e-05 (* 1 = 3.34783e-05 loss)
I1022 01:09:10.073907 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.8088 (* 1 = 0.8088 loss)
I1022 01:09:10.073915 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00509091 (* 1 = 0.00509091 loss)
I1022 01:09:10.073927 25759 sgd_solver.cpp:106] Iteration 1620, lr = 0.002
I1022 01:10:35.175403 25759 solver.cpp:228] Iteration 1640, loss = 0.20227
I1022 01:10:35.175452 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985022
I1022 01:10:35.175457 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992511
I1022 01:10:35.175464 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.279719 (* 1 = 0.279719 loss)
I1022 01:10:35.175469 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.10424 (* 1 = 0.10424 loss)
I1022 01:10:35.175474 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0431617 (* 1 = 0.0431617 loss)
I1022 01:10:35.175478 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0244443 (* 1 = 0.0244443 loss)
I1022 01:10:35.175482 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00362855 (* 1 = 0.00362855 loss)
I1022 01:10:35.175488 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.80203e-05 (* 1 = 3.80203e-05 loss)
I1022 01:10:35.175493 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0716462 (* 1 = 0.0716462 loss)
I1022 01:10:35.175498 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00287545 (* 1 = 0.00287545 loss)
I1022 01:10:35.175503 25759 sgd_solver.cpp:106] Iteration 1640, lr = 0.002
I1022 01:11:59.826778 25759 solver.cpp:228] Iteration 1660, loss = 0.245138
I1022 01:11:59.826810 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:11:59.826815 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:11:59.826822 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:11:59.826827 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:11:59.826831 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00458836 (* 1 = 0.00458836 loss)
I1022 01:11:59.826835 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00404808 (* 1 = 0.00404808 loss)
I1022 01:11:59.826839 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000198876 (* 1 = 0.000198876 loss)
I1022 01:11:59.826844 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.25333e-05 (* 1 = 2.25333e-05 loss)
I1022 01:11:59.826848 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000740922 (* 1 = 0.000740922 loss)
I1022 01:11:59.826853 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00443231 (* 1 = 0.00443231 loss)
I1022 01:11:59.826861 25759 sgd_solver.cpp:106] Iteration 1660, lr = 0.002
I1022 01:13:24.402205 25759 solver.cpp:228] Iteration 1680, loss = 0.354577
I1022 01:13:24.402242 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:13:24.402248 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:13:24.402257 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:13:24.402263 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:13:24.402269 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00482321 (* 1 = 0.00482321 loss)
I1022 01:13:24.402278 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0053436 (* 1 = 0.0053436 loss)
I1022 01:13:24.402284 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.3986e-05 (* 1 = 8.3986e-05 loss)
I1022 01:13:24.402290 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.09802e-05 (* 1 = 3.09802e-05 loss)
I1022 01:13:24.402297 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00248555 (* 1 = 0.00248555 loss)
I1022 01:13:24.402302 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000706844 (* 1 = 0.000706844 loss)
I1022 01:13:24.402308 25759 sgd_solver.cpp:106] Iteration 1680, lr = 0.002
I1022 01:14:50.512254 25759 solver.cpp:228] Iteration 1700, loss = 0.252978
I1022 01:14:50.512318 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991504
I1022 01:14:50.512329 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 01:14:50.512346 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.156572 (* 1 = 0.156572 loss)
I1022 01:14:50.512357 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.043242 (* 1 = 0.043242 loss)
I1022 01:14:50.512368 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0216855 (* 1 = 0.0216855 loss)
I1022 01:14:50.512379 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0091183 (* 1 = 0.0091183 loss)
I1022 01:14:50.512390 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000140117 (* 1 = 0.000140117 loss)
I1022 01:14:50.512404 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.5747e-05 (* 1 = 4.5747e-05 loss)
I1022 01:14:50.512415 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0164075 (* 1 = 0.0164075 loss)
I1022 01:14:50.512428 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00124723 (* 1 = 0.00124723 loss)
I1022 01:14:50.512447 25759 sgd_solver.cpp:106] Iteration 1700, lr = 0.002
I1022 01:16:15.490959 25759 solver.cpp:228] Iteration 1720, loss = 0.380099
I1022 01:16:15.491003 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:16:15.491010 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:16:15.491019 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:16:15.491026 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:16:15.491032 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00844805 (* 1 = 0.00844805 loss)
I1022 01:16:15.491039 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00582852 (* 1 = 0.00582852 loss)
I1022 01:16:15.491045 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000862333 (* 1 = 0.000862333 loss)
I1022 01:16:15.491052 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.59688e-05 (* 1 = 1.59688e-05 loss)
I1022 01:16:15.491058 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00428487 (* 1 = 0.00428487 loss)
I1022 01:16:15.491065 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00401201 (* 1 = 0.00401201 loss)
I1022 01:16:15.491075 25759 sgd_solver.cpp:106] Iteration 1720, lr = 0.002
I1022 01:17:40.350220 25759 solver.cpp:228] Iteration 1740, loss = 0.146745
I1022 01:17:40.350253 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.984515
I1022 01:17:40.350273 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.988512
I1022 01:17:40.350281 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.093776 (* 1 = 0.093776 loss)
I1022 01:17:40.350287 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0943946 (* 1 = 0.0943946 loss)
I1022 01:17:40.350291 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0374476 (* 1 = 0.0374476 loss)
I1022 01:17:40.350296 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0283388 (* 1 = 0.0283388 loss)
I1022 01:17:40.350301 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0047353 (* 1 = 0.0047353 loss)
I1022 01:17:40.350306 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.12098e-05 (* 1 = 3.12098e-05 loss)
I1022 01:17:40.350311 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0774186 (* 1 = 0.0774186 loss)
I1022 01:17:40.350316 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00709746 (* 1 = 0.00709746 loss)
I1022 01:17:40.350324 25759 sgd_solver.cpp:106] Iteration 1740, lr = 0.002
I1022 01:19:06.698551 25759 solver.cpp:228] Iteration 1760, loss = 0.333498
I1022 01:19:06.698591 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993506
I1022 01:19:06.698597 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993007
I1022 01:19:06.698607 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0402305 (* 1 = 0.0402305 loss)
I1022 01:19:06.698614 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.107811 (* 1 = 0.107811 loss)
I1022 01:19:06.698621 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0225258 (* 1 = 0.0225258 loss)
I1022 01:19:06.698627 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0221608 (* 1 = 0.0221608 loss)
I1022 01:19:06.698633 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00023966 (* 1 = 0.00023966 loss)
I1022 01:19:06.698640 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.11968e-05 (* 1 = 1.11968e-05 loss)
I1022 01:19:06.698647 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0660796 (* 1 = 0.0660796 loss)
I1022 01:19:06.698653 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00656335 (* 1 = 0.00656335 loss)
I1022 01:19:06.698660 25759 sgd_solver.cpp:106] Iteration 1760, lr = 0.002
I1022 01:20:32.042425 25759 solver.cpp:228] Iteration 1780, loss = 0.163034
I1022 01:20:32.042464 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994223
I1022 01:20:32.042480 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 01:20:32.042490 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0250507 (* 1 = 0.0250507 loss)
I1022 01:20:32.042496 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0372422 (* 1 = 0.0372422 loss)
I1022 01:20:32.042502 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0227762 (* 1 = 0.0227762 loss)
I1022 01:20:32.042507 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0152553 (* 1 = 0.0152553 loss)
I1022 01:20:32.042513 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0548112 (* 1 = 0.0548112 loss)
I1022 01:20:32.042520 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.64409e-05 (* 1 = 4.64409e-05 loss)
I1022 01:20:32.042526 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0234996 (* 1 = 0.0234996 loss)
I1022 01:20:32.042532 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0052719 (* 1 = 0.0052719 loss)
I1022 01:20:32.042538 25759 sgd_solver.cpp:106] Iteration 1780, lr = 0.002
speed: 4.207s / iter
I1022 01:21:56.697266 25759 solver.cpp:228] Iteration 1800, loss = 0.413383
I1022 01:21:56.697301 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995978
I1022 01:21:56.697306 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 01:21:56.697314 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0336588 (* 1 = 0.0336588 loss)
I1022 01:21:56.697319 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0476163 (* 1 = 0.0476163 loss)
I1022 01:21:56.697324 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00922735 (* 1 = 0.00922735 loss)
I1022 01:21:56.697327 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0112657 (* 1 = 0.0112657 loss)
I1022 01:21:56.697335 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00141504 (* 1 = 0.00141504 loss)
I1022 01:21:56.697338 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000153729 (* 1 = 0.000153729 loss)
I1022 01:21:56.697343 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00964339 (* 1 = 0.00964339 loss)
I1022 01:21:56.697347 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0127354 (* 1 = 0.0127354 loss)
I1022 01:21:56.697355 25759 sgd_solver.cpp:106] Iteration 1800, lr = 0.002
I1022 01:23:20.683063 25759 solver.cpp:228] Iteration 1820, loss = 0.617432
I1022 01:23:20.683111 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:23:20.683116 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:23:20.683123 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:23:20.683128 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:23:20.683133 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00505959 (* 1 = 0.00505959 loss)
I1022 01:23:20.683137 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00507759 (* 1 = 0.00507759 loss)
I1022 01:23:20.683142 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000170472 (* 1 = 0.000170472 loss)
I1022 01:23:20.683147 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.06262e-05 (* 1 = 3.06262e-05 loss)
I1022 01:23:20.683152 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0173868 (* 1 = 0.0173868 loss)
I1022 01:23:20.683157 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00181285 (* 1 = 0.00181285 loss)
I1022 01:23:20.683162 25759 sgd_solver.cpp:106] Iteration 1820, lr = 0.002
I1022 01:24:45.882392 25759 solver.cpp:228] Iteration 1840, loss = 0.710442
I1022 01:24:45.882426 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.971429
I1022 01:24:45.882447 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.985022
I1022 01:24:45.882453 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.203577 (* 1 = 0.203577 loss)
I1022 01:24:45.882458 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.19752 (* 1 = 0.19752 loss)
I1022 01:24:45.882463 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0876407 (* 1 = 0.0876407 loss)
I1022 01:24:45.882467 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0472555 (* 1 = 0.0472555 loss)
I1022 01:24:45.882472 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00206247 (* 1 = 0.00206247 loss)
I1022 01:24:45.882477 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.61644e-05 (* 1 = 2.61644e-05 loss)
I1022 01:24:45.882481 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.238945 (* 1 = 0.238945 loss)
I1022 01:24:45.882485 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0115771 (* 1 = 0.0115771 loss)
I1022 01:24:45.882491 25759 sgd_solver.cpp:106] Iteration 1840, lr = 0.002
I1022 01:26:09.743713 25759 solver.cpp:228] Iteration 1860, loss = 0.249612
I1022 01:26:09.743765 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988736
I1022 01:26:09.743777 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994003
I1022 01:26:09.743791 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0613576 (* 1 = 0.0613576 loss)
I1022 01:26:09.743803 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0747172 (* 1 = 0.0747172 loss)
I1022 01:26:09.743813 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0358659 (* 1 = 0.0358659 loss)
I1022 01:26:09.743824 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0203015 (* 1 = 0.0203015 loss)
I1022 01:26:09.743834 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000237236 (* 1 = 0.000237236 loss)
I1022 01:26:09.743850 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.08856e-05 (* 1 = 2.08856e-05 loss)
I1022 01:26:09.743862 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0270436 (* 1 = 0.0270436 loss)
I1022 01:26:09.743875 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00102142 (* 1 = 0.00102142 loss)
I1022 01:26:09.743886 25759 sgd_solver.cpp:106] Iteration 1860, lr = 0.002
I1022 01:27:31.832573 25759 solver.cpp:228] Iteration 1880, loss = 0.119946
I1022 01:27:31.832614 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 01:27:31.832620 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:27:31.832643 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:27:31.832648 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:27:31.832651 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00241672 (* 1 = 0.00241672 loss)
I1022 01:27:31.832659 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00505477 (* 1 = 0.00505477 loss)
I1022 01:27:31.832664 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000422697 (* 1 = 0.000422697 loss)
I1022 01:27:31.832667 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.50805e-05 (* 1 = 2.50805e-05 loss)
I1022 01:27:31.832672 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00219437 (* 1 = 0.00219437 loss)
I1022 01:27:31.832676 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000462971 (* 1 = 0.000462971 loss)
I1022 01:27:31.832685 25759 sgd_solver.cpp:106] Iteration 1880, lr = 0.002
I1022 01:28:55.407385 25759 solver.cpp:228] Iteration 1900, loss = 0.221297
I1022 01:28:55.407439 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.983667
I1022 01:28:55.407446 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991013
I1022 01:28:55.407455 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.157189 (* 1 = 0.157189 loss)
I1022 01:28:55.407464 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0831655 (* 1 = 0.0831655 loss)
I1022 01:28:55.407470 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0427469 (* 1 = 0.0427469 loss)
I1022 01:28:55.407476 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0342585 (* 1 = 0.0342585 loss)
I1022 01:28:55.407483 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00405772 (* 1 = 0.00405772 loss)
I1022 01:28:55.407491 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.75764e-05 (* 1 = 1.75764e-05 loss)
I1022 01:28:55.407497 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0869361 (* 1 = 0.0869361 loss)
I1022 01:28:55.407510 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00402003 (* 1 = 0.00402003 loss)
I1022 01:28:55.407517 25759 sgd_solver.cpp:106] Iteration 1900, lr = 0.002
I1022 01:30:17.157405 25759 solver.cpp:228] Iteration 1920, loss = 0.223988
I1022 01:30:17.157454 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992872
I1022 01:30:17.157459 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993506
I1022 01:30:17.157467 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0747008 (* 1 = 0.0747008 loss)
I1022 01:30:17.157472 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0725609 (* 1 = 0.0725609 loss)
I1022 01:30:17.157477 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0241632 (* 1 = 0.0241632 loss)
I1022 01:30:17.157481 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0243415 (* 1 = 0.0243415 loss)
I1022 01:30:17.157486 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000296904 (* 1 = 0.000296904 loss)
I1022 01:30:17.157491 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.15443e-05 (* 1 = 1.15443e-05 loss)
I1022 01:30:17.157496 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.042941 (* 1 = 0.042941 loss)
I1022 01:30:17.157501 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000886414 (* 1 = 0.000886414 loss)
I1022 01:30:17.157506 25759 sgd_solver.cpp:106] Iteration 1920, lr = 0.002
I1022 01:31:37.137110 25759 solver.cpp:228] Iteration 1940, loss = 0.279735
I1022 01:31:37.137142 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995863
I1022 01:31:37.137147 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 01:31:37.137154 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0480622 (* 1 = 0.0480622 loss)
I1022 01:31:37.137159 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0112453 (* 1 = 0.0112453 loss)
I1022 01:31:37.137163 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0143282 (* 1 = 0.0143282 loss)
I1022 01:31:37.137167 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0128335 (* 1 = 0.0128335 loss)
I1022 01:31:37.137171 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00178122 (* 1 = 0.00178122 loss)
I1022 01:31:37.137176 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.10234e-05 (* 1 = 4.10234e-05 loss)
I1022 01:31:37.137181 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0637994 (* 1 = 0.0637994 loss)
I1022 01:31:37.137184 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00812484 (* 1 = 0.00812484 loss)
I1022 01:31:37.137189 25759 sgd_solver.cpp:106] Iteration 1940, lr = 0.002
I1022 01:32:58.200520 25759 solver.cpp:228] Iteration 1960, loss = 0.358212
I1022 01:32:58.200557 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:32:58.200564 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:32:58.200572 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:32:58.200578 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:32:58.200585 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00439381 (* 1 = 0.00439381 loss)
I1022 01:32:58.200592 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00413915 (* 1 = 0.00413915 loss)
I1022 01:32:58.200598 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000167264 (* 1 = 0.000167264 loss)
I1022 01:32:58.200603 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.49889e-05 (* 1 = 1.49889e-05 loss)
I1022 01:32:58.200614 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0150886 (* 1 = 0.0150886 loss)
I1022 01:32:58.200620 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0106333 (* 1 = 0.0106333 loss)
I1022 01:32:58.200628 25759 sgd_solver.cpp:106] Iteration 1960, lr = 0.002
I1022 01:34:21.745915 25759 solver.cpp:228] Iteration 1980, loss = 0.211527
I1022 01:34:21.745955 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.981166
I1022 01:34:21.745961 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.984523
I1022 01:34:21.745970 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.172731 (* 1 = 0.172731 loss)
I1022 01:34:21.745977 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.157326 (* 1 = 0.157326 loss)
I1022 01:34:21.745983 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0676469 (* 1 = 0.0676469 loss)
I1022 01:34:21.745992 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0501541 (* 1 = 0.0501541 loss)
I1022 01:34:21.745997 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00425874 (* 1 = 0.00425874 loss)
I1022 01:34:21.746004 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.33496e-05 (* 1 = 5.33496e-05 loss)
I1022 01:34:21.746011 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.342119 (* 1 = 0.342119 loss)
I1022 01:34:21.746016 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000821306 (* 1 = 0.000821306 loss)
I1022 01:34:21.746023 25759 sgd_solver.cpp:106] Iteration 1980, lr = 0.002
speed: 4.201s / iter
bbbb
aaaa
Wrote snapshot to: /home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_2000.caffemodel
I1022 01:35:46.694016 25759 solver.cpp:228] Iteration 2000, loss = 0.482803
I1022 01:35:46.694067 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 01:35:46.694072 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995003
I1022 01:35:46.694079 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0245787 (* 1 = 0.0245787 loss)
I1022 01:35:46.694084 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0348989 (* 1 = 0.0348989 loss)
I1022 01:35:46.694089 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0176671 (* 1 = 0.0176671 loss)
I1022 01:35:46.694093 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0135763 (* 1 = 0.0135763 loss)
I1022 01:35:46.694097 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000124622 (* 1 = 0.000124622 loss)
I1022 01:35:46.694103 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.88814e-05 (* 1 = 1.88814e-05 loss)
I1022 01:35:46.694108 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.059356 (* 1 = 0.059356 loss)
I1022 01:35:46.694113 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00148462 (* 1 = 0.00148462 loss)
I1022 01:35:46.694118 25759 sgd_solver.cpp:106] Iteration 2000, lr = 0.002
I1022 01:37:09.298624 25759 solver.cpp:228] Iteration 2020, loss = 0.176156
I1022 01:37:09.298672 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993503
I1022 01:37:09.298677 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 01:37:09.298683 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:37:09.298688 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:37:09.298693 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0183229 (* 1 = 0.0183229 loss)
I1022 01:37:09.298697 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00891899 (* 1 = 0.00891899 loss)
I1022 01:37:09.298702 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.26467e-05 (* 1 = 8.26467e-05 loss)
I1022 01:37:09.298707 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.14345e-05 (* 1 = 2.14345e-05 loss)
I1022 01:37:09.298712 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00784266 (* 1 = 0.00784266 loss)
I1022 01:37:09.298717 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.015191 (* 1 = 0.015191 loss)
I1022 01:37:09.298722 25759 sgd_solver.cpp:106] Iteration 2020, lr = 0.002
I1022 01:38:29.908748 25759 solver.cpp:228] Iteration 2040, loss = 0.510905
I1022 01:38:29.908785 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994003
I1022 01:38:29.908805 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 01:38:29.908813 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0283391 (* 1 = 0.0283391 loss)
I1022 01:38:29.908818 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.039662 (* 1 = 0.039662 loss)
I1022 01:38:29.908823 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0122397 (* 1 = 0.0122397 loss)
I1022 01:38:29.908828 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0101166 (* 1 = 0.0101166 loss)
I1022 01:38:29.908831 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000146666 (* 1 = 0.000146666 loss)
I1022 01:38:29.908836 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00652727 (* 1 = 0.00652727 loss)
I1022 01:38:29.908840 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00371437 (* 1 = 0.00371437 loss)
I1022 01:38:29.908845 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00630139 (* 1 = 0.00630139 loss)
I1022 01:38:29.908854 25759 sgd_solver.cpp:106] Iteration 2040, lr = 0.002
I1022 01:39:52.299021 25759 solver.cpp:228] Iteration 2060, loss = 0.284048
I1022 01:39:52.299060 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 01:39:52.299067 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 01:39:52.299077 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0830707 (* 1 = 0.0830707 loss)
I1022 01:39:52.299083 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0307194 (* 1 = 0.0307194 loss)
I1022 01:39:52.299089 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0240674 (* 1 = 0.0240674 loss)
I1022 01:39:52.299094 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0126458 (* 1 = 0.0126458 loss)
I1022 01:39:52.299100 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00395274 (* 1 = 0.00395274 loss)
I1022 01:39:52.299106 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000150408 (* 1 = 0.000150408 loss)
I1022 01:39:52.299113 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0312242 (* 1 = 0.0312242 loss)
I1022 01:39:52.299118 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00158103 (* 1 = 0.00158103 loss)
I1022 01:39:52.299125 25759 sgd_solver.cpp:106] Iteration 2060, lr = 0.002
I1022 01:41:14.631109 25759 solver.cpp:228] Iteration 2080, loss = 0.350667
I1022 01:41:14.631157 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988018
I1022 01:41:14.631162 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992012
I1022 01:41:14.631170 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.149746 (* 1 = 0.149746 loss)
I1022 01:41:14.631175 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0967981 (* 1 = 0.0967981 loss)
I1022 01:41:14.631180 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0370776 (* 1 = 0.0370776 loss)
I1022 01:41:14.631183 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0275825 (* 1 = 0.0275825 loss)
I1022 01:41:14.631188 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00103539 (* 1 = 0.00103539 loss)
I1022 01:41:14.631193 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.96445e-05 (* 1 = 2.96445e-05 loss)
I1022 01:41:14.631198 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0419032 (* 1 = 0.0419032 loss)
I1022 01:41:14.631202 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00784661 (* 1 = 0.00784661 loss)
I1022 01:41:14.631211 25759 sgd_solver.cpp:106] Iteration 2080, lr = 0.002
I1022 01:42:36.743993 25759 solver.cpp:228] Iteration 2100, loss = 0.278949
I1022 01:42:36.744026 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.960827
I1022 01:42:36.744031 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.984539
I1022 01:42:36.744038 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.291165 (* 1 = 0.291165 loss)
I1022 01:42:36.744043 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.166049 (* 1 = 0.166049 loss)
I1022 01:42:36.744047 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.080677 (* 1 = 0.080677 loss)
I1022 01:42:36.744051 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0574035 (* 1 = 0.0574035 loss)
I1022 01:42:36.744055 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0231137 (* 1 = 0.0231137 loss)
I1022 01:42:36.744060 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.05594e-05 (* 1 = 3.05594e-05 loss)
I1022 01:42:36.744065 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.109077 (* 1 = 0.109077 loss)
I1022 01:42:36.744068 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00564378 (* 1 = 0.00564378 loss)
I1022 01:42:36.744074 25759 sgd_solver.cpp:106] Iteration 2100, lr = 0.002
I1022 01:44:00.962245 25759 solver.cpp:228] Iteration 2120, loss = 0.195087
I1022 01:44:00.962313 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991849
I1022 01:44:00.962324 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 01:44:00.962339 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0535832 (* 1 = 0.0535832 loss)
I1022 01:44:00.962350 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0449209 (* 1 = 0.0449209 loss)
I1022 01:44:00.962360 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0178707 (* 1 = 0.0178707 loss)
I1022 01:44:00.962370 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0181535 (* 1 = 0.0181535 loss)
I1022 01:44:00.962380 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000353747 (* 1 = 0.000353747 loss)
I1022 01:44:00.962393 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.23727e-05 (* 1 = 7.23727e-05 loss)
I1022 01:44:00.962406 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0311684 (* 1 = 0.0311684 loss)
I1022 01:44:00.962419 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00159391 (* 1 = 0.00159391 loss)
I1022 01:44:00.962430 25759 sgd_solver.cpp:106] Iteration 2120, lr = 0.002
I1022 01:45:25.511096 25759 solver.cpp:228] Iteration 2140, loss = 0.1644
I1022 01:45:25.511135 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 01:45:25.511142 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 01:45:25.511152 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0737594 (* 1 = 0.0737594 loss)
I1022 01:45:25.511157 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0499204 (* 1 = 0.0499204 loss)
I1022 01:45:25.511164 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0119549 (* 1 = 0.0119549 loss)
I1022 01:45:25.511169 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00971896 (* 1 = 0.00971896 loss)
I1022 01:45:25.511175 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000122726 (* 1 = 0.000122726 loss)
I1022 01:45:25.511181 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.30292e-05 (* 1 = 2.30292e-05 loss)
I1022 01:45:25.511188 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0145962 (* 1 = 0.0145962 loss)
I1022 01:45:25.511193 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000700586 (* 1 = 0.000700586 loss)
I1022 01:45:25.511201 25759 sgd_solver.cpp:106] Iteration 2140, lr = 0.002
I1022 01:46:51.450588 25759 solver.cpp:228] Iteration 2160, loss = 0.319939
I1022 01:46:51.450672 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991009
I1022 01:46:51.450683 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1022 01:46:51.450700 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0920902 (* 1 = 0.0920902 loss)
I1022 01:46:51.450712 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0980111 (* 1 = 0.0980111 loss)
I1022 01:46:51.450722 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0269502 (* 1 = 0.0269502 loss)
I1022 01:46:51.450732 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0212955 (* 1 = 0.0212955 loss)
I1022 01:46:51.450747 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000325823 (* 1 = 0.000325823 loss)
I1022 01:46:51.450759 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.69888e-05 (* 1 = 2.69888e-05 loss)
I1022 01:46:51.450770 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.015927 (* 1 = 0.015927 loss)
I1022 01:46:51.450783 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00329783 (* 1 = 0.00329783 loss)
I1022 01:46:51.450796 25759 sgd_solver.cpp:106] Iteration 2160, lr = 0.002
I1022 01:48:15.562361 25759 solver.cpp:228] Iteration 2180, loss = 0.241229
I1022 01:48:15.562408 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.983034
I1022 01:48:15.562413 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.987525
I1022 01:48:15.562420 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.22931 (* 1 = 0.22931 loss)
I1022 01:48:15.562425 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.178016 (* 1 = 0.178016 loss)
I1022 01:48:15.562431 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0694858 (* 1 = 0.0694858 loss)
I1022 01:48:15.562435 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0468896 (* 1 = 0.0468896 loss)
I1022 01:48:15.562439 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.090328 (* 1 = 0.090328 loss)
I1022 01:48:15.562444 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.1805e-05 (* 1 = 1.1805e-05 loss)
I1022 01:48:15.562449 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0714053 (* 1 = 0.0714053 loss)
I1022 01:48:15.562454 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00195088 (* 1 = 0.00195088 loss)
I1022 01:48:15.562459 25759 sgd_solver.cpp:106] Iteration 2180, lr = 0.002
speed: 4.198s / iter
I1022 01:49:39.727252 25759 solver.cpp:228] Iteration 2200, loss = 0.11633
I1022 01:49:39.727283 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 01:49:39.727288 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:49:39.727294 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:49:39.727299 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:49:39.727303 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00775174 (* 1 = 0.00775174 loss)
I1022 01:49:39.727308 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00528005 (* 1 = 0.00528005 loss)
I1022 01:49:39.727313 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000303327 (* 1 = 0.000303327 loss)
I1022 01:49:39.727319 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.92983e-05 (* 1 = 1.92983e-05 loss)
I1022 01:49:39.727322 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000773902 (* 1 = 0.000773902 loss)
I1022 01:49:39.727326 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000593609 (* 1 = 0.000593609 loss)
I1022 01:49:39.727334 25759 sgd_solver.cpp:106] Iteration 2200, lr = 0.002
I1022 01:51:01.104061 25759 solver.cpp:228] Iteration 2220, loss = 0.29043
I1022 01:51:01.104112 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 01:51:01.104123 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 01:51:01.104138 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.101662 (* 1 = 0.101662 loss)
I1022 01:51:01.104151 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0313566 (* 1 = 0.0313566 loss)
I1022 01:51:01.104161 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0171421 (* 1 = 0.0171421 loss)
I1022 01:51:01.104171 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.011336 (* 1 = 0.011336 loss)
I1022 01:51:01.104182 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000472514 (* 1 = 0.000472514 loss)
I1022 01:51:01.104197 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.3468e-05 (* 1 = 1.3468e-05 loss)
I1022 01:51:01.104210 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0375291 (* 1 = 0.0375291 loss)
I1022 01:51:01.104220 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00558812 (* 1 = 0.00558812 loss)
I1022 01:51:01.104238 25759 sgd_solver.cpp:106] Iteration 2220, lr = 0.002
I1022 01:52:23.830794 25759 solver.cpp:228] Iteration 2240, loss = 0.108566
I1022 01:52:23.830832 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:52:23.830845 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:52:23.830854 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:52:23.830860 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:52:23.830869 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00541333 (* 1 = 0.00541333 loss)
I1022 01:52:23.830874 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00478296 (* 1 = 0.00478296 loss)
I1022 01:52:23.830880 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000215594 (* 1 = 0.000215594 loss)
I1022 01:52:23.830888 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.50665e-05 (* 1 = 7.50665e-05 loss)
I1022 01:52:23.830893 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0112906 (* 1 = 0.0112906 loss)
I1022 01:52:23.830899 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0106853 (* 1 = 0.0106853 loss)
I1022 01:52:23.830906 25759 sgd_solver.cpp:106] Iteration 2240, lr = 0.002
I1022 01:53:45.686878 25759 solver.cpp:228] Iteration 2260, loss = 0.174603
I1022 01:53:45.686928 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:53:45.686933 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:53:45.686940 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:53:45.686944 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:53:45.686951 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00467379 (* 1 = 0.00467379 loss)
I1022 01:53:45.686955 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00437392 (* 1 = 0.00437392 loss)
I1022 01:53:45.686960 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000209439 (* 1 = 0.000209439 loss)
I1022 01:53:45.686965 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.25228e-05 (* 1 = 2.25228e-05 loss)
I1022 01:53:45.686970 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0102 (* 1 = 0.0102 loss)
I1022 01:53:45.686975 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00388053 (* 1 = 0.00388053 loss)
I1022 01:53:45.686980 25759 sgd_solver.cpp:106] Iteration 2260, lr = 0.002
I1022 01:55:07.252617 25759 solver.cpp:228] Iteration 2280, loss = 0.163513
I1022 01:55:07.252665 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 01:55:07.252672 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 01:55:07.252683 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 01:55:07.252691 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 01:55:07.252698 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0041135 (* 1 = 0.0041135 loss)
I1022 01:55:07.252705 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00431673 (* 1 = 0.00431673 loss)
I1022 01:55:07.252713 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.71297e-05 (* 1 = 7.71297e-05 loss)
I1022 01:55:07.252722 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.7891e-06 (* 1 = 9.7891e-06 loss)
I1022 01:55:07.252728 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0161613 (* 1 = 0.0161613 loss)
I1022 01:55:07.252737 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000272151 (* 1 = 0.000272151 loss)
I1022 01:55:07.252746 25759 sgd_solver.cpp:106] Iteration 2280, lr = 0.002
I1022 01:56:31.853610 25759 solver.cpp:228] Iteration 2300, loss = 0.207325
I1022 01:56:31.853659 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.981037
I1022 01:56:31.853664 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.986028
I1022 01:56:31.853672 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.109066 (* 1 = 0.109066 loss)
I1022 01:56:31.853677 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.143615 (* 1 = 0.143615 loss)
I1022 01:56:31.853682 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0554567 (* 1 = 0.0554567 loss)
I1022 01:56:31.853685 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0471948 (* 1 = 0.0471948 loss)
I1022 01:56:31.853690 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00770223 (* 1 = 0.00770223 loss)
I1022 01:56:31.853695 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.70459e-05 (* 1 = 1.70459e-05 loss)
I1022 01:56:31.853700 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.105708 (* 1 = 0.105708 loss)
I1022 01:56:31.853705 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000688391 (* 1 = 0.000688391 loss)
I1022 01:56:31.853711 25759 sgd_solver.cpp:106] Iteration 2300, lr = 0.002
I1022 01:57:56.430579 25759 solver.cpp:228] Iteration 2320, loss = 0.173119
I1022 01:57:56.430645 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991508
I1022 01:57:56.430652 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995504
I1022 01:57:56.430663 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0899715 (* 1 = 0.0899715 loss)
I1022 01:57:56.430670 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.052608 (* 1 = 0.052608 loss)
I1022 01:57:56.430676 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0264622 (* 1 = 0.0264622 loss)
I1022 01:57:56.430682 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0166846 (* 1 = 0.0166846 loss)
I1022 01:57:56.430688 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00471285 (* 1 = 0.00471285 loss)
I1022 01:57:56.430696 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.1582e-05 (* 1 = 3.1582e-05 loss)
I1022 01:57:56.430702 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0310156 (* 1 = 0.0310156 loss)
I1022 01:57:56.430709 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00135569 (* 1 = 0.00135569 loss)
I1022 01:57:56.430721 25759 sgd_solver.cpp:106] Iteration 2320, lr = 0.002
I1022 01:59:23.127348 25759 solver.cpp:228] Iteration 2340, loss = 0.229106
I1022 01:59:23.127387 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994003
I1022 01:59:23.127393 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994503
I1022 01:59:23.127403 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0352176 (* 1 = 0.0352176 loss)
I1022 01:59:23.127408 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0318935 (* 1 = 0.0318935 loss)
I1022 01:59:23.127414 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0186772 (* 1 = 0.0186772 loss)
I1022 01:59:23.127419 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0143573 (* 1 = 0.0143573 loss)
I1022 01:59:23.127425 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000225612 (* 1 = 0.000225612 loss)
I1022 01:59:23.127432 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00168104 (* 1 = 0.00168104 loss)
I1022 01:59:23.127437 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0305618 (* 1 = 0.0305618 loss)
I1022 01:59:23.127444 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00592226 (* 1 = 0.00592226 loss)
I1022 01:59:23.127451 25759 sgd_solver.cpp:106] Iteration 2340, lr = 0.002
I1022 02:00:48.216486 25759 solver.cpp:228] Iteration 2360, loss = 0.253091
I1022 02:00:48.216524 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992508
I1022 02:00:48.216531 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993506
I1022 02:00:48.216539 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.145251 (* 1 = 0.145251 loss)
I1022 02:00:48.216547 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.116406 (* 1 = 0.116406 loss)
I1022 02:00:48.216552 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0282515 (* 1 = 0.0282515 loss)
I1022 02:00:48.216558 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.023634 (* 1 = 0.023634 loss)
I1022 02:00:48.216563 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00188901 (* 1 = 0.00188901 loss)
I1022 02:00:48.216570 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.81011e-05 (* 1 = 1.81011e-05 loss)
I1022 02:00:48.216576 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0421918 (* 1 = 0.0421918 loss)
I1022 02:00:48.216581 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00575416 (* 1 = 0.00575416 loss)
I1022 02:00:48.216591 25759 sgd_solver.cpp:106] Iteration 2360, lr = 0.002
I1022 02:02:09.160804 25759 solver.cpp:228] Iteration 2380, loss = 0.490843
I1022 02:02:09.160842 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989801
I1022 02:02:09.160859 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993506
I1022 02:02:09.160871 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0558986 (* 1 = 0.0558986 loss)
I1022 02:02:09.160877 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0591634 (* 1 = 0.0591634 loss)
I1022 02:02:09.160883 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0290366 (* 1 = 0.0290366 loss)
I1022 02:02:09.160889 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0214898 (* 1 = 0.0214898 loss)
I1022 02:02:09.160894 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0156499 (* 1 = 0.0156499 loss)
I1022 02:02:09.160902 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.02601e-05 (* 1 = 2.02601e-05 loss)
I1022 02:02:09.160907 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0300896 (* 1 = 0.0300896 loss)
I1022 02:02:09.160914 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00106047 (* 1 = 0.00106047 loss)
I1022 02:02:09.160930 25759 sgd_solver.cpp:106] Iteration 2380, lr = 0.002
speed: 4.195s / iter
I1022 02:03:31.398537 25759 solver.cpp:228] Iteration 2400, loss = 0.407829
I1022 02:03:31.398577 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:03:31.398583 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:03:31.398592 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:03:31.398598 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:03:31.398604 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00559042 (* 1 = 0.00559042 loss)
I1022 02:03:31.398610 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00469988 (* 1 = 0.00469988 loss)
I1022 02:03:31.398615 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000398638 (* 1 = 0.000398638 loss)
I1022 02:03:31.398622 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.17146e-05 (* 1 = 6.17146e-05 loss)
I1022 02:03:31.398627 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00271486 (* 1 = 0.00271486 loss)
I1022 02:03:31.398633 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00175728 (* 1 = 0.00175728 loss)
I1022 02:03:31.398654 25759 sgd_solver.cpp:106] Iteration 2400, lr = 0.002
I1022 02:04:54.397114 25759 solver.cpp:228] Iteration 2420, loss = 0.141219
I1022 02:04:54.397147 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:04:54.397152 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:04:54.397159 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:04:54.397163 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:04:54.397168 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00271455 (* 1 = 0.00271455 loss)
I1022 02:04:54.397172 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00439837 (* 1 = 0.00439837 loss)
I1022 02:04:54.397176 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.81684e-05 (* 1 = 8.81684e-05 loss)
I1022 02:04:54.397182 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.39553e-05 (* 1 = 1.39553e-05 loss)
I1022 02:04:54.397187 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00354763 (* 1 = 0.00354763 loss)
I1022 02:04:54.397192 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00654705 (* 1 = 0.00654705 loss)
I1022 02:04:54.397197 25759 sgd_solver.cpp:106] Iteration 2420, lr = 0.002
I1022 02:06:16.042539 25759 solver.cpp:228] Iteration 2440, loss = 0.101353
I1022 02:06:16.042589 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:06:16.042595 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:06:16.042601 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:06:16.042606 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:06:16.042611 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0066794 (* 1 = 0.0066794 loss)
I1022 02:06:16.042616 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00534503 (* 1 = 0.00534503 loss)
I1022 02:06:16.042621 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000307694 (* 1 = 0.000307694 loss)
I1022 02:06:16.042626 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000130529 (* 1 = 0.000130529 loss)
I1022 02:06:16.042631 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0124539 (* 1 = 0.0124539 loss)
I1022 02:06:16.042636 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00331516 (* 1 = 0.00331516 loss)
I1022 02:06:16.042642 25759 sgd_solver.cpp:106] Iteration 2440, lr = 0.002
I1022 02:07:38.236927 25759 solver.cpp:228] Iteration 2460, loss = 0.126618
I1022 02:07:38.236966 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:07:38.236974 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:07:38.236981 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:07:38.236989 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:07:38.236994 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00439957 (* 1 = 0.00439957 loss)
I1022 02:07:38.237002 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00439814 (* 1 = 0.00439814 loss)
I1022 02:07:38.237009 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000171159 (* 1 = 0.000171159 loss)
I1022 02:07:38.237020 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.03988e-05 (* 1 = 1.03988e-05 loss)
I1022 02:07:38.237025 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0026909 (* 1 = 0.0026909 loss)
I1022 02:07:38.237030 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0063085 (* 1 = 0.0063085 loss)
I1022 02:07:38.237040 25759 sgd_solver.cpp:106] Iteration 2460, lr = 0.002
I1022 02:09:02.821995 25759 solver.cpp:228] Iteration 2480, loss = 0.294173
I1022 02:09:02.822032 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 02:09:02.822038 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 02:09:02.822048 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0275766 (* 1 = 0.0275766 loss)
I1022 02:09:02.822055 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0290395 (* 1 = 0.0290395 loss)
I1022 02:09:02.822062 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00959394 (* 1 = 0.00959394 loss)
I1022 02:09:02.822068 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0106285 (* 1 = 0.0106285 loss)
I1022 02:09:02.822074 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000281436 (* 1 = 0.000281436 loss)
I1022 02:09:02.822080 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.14493e-05 (* 1 = 1.14493e-05 loss)
I1022 02:09:02.822087 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0128864 (* 1 = 0.0128864 loss)
I1022 02:09:02.822093 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00546763 (* 1 = 0.00546763 loss)
I1022 02:09:02.822099 25759 sgd_solver.cpp:106] Iteration 2480, lr = 0.002
I1022 02:10:27.836267 25759 solver.cpp:228] Iteration 2500, loss = 0.643557
I1022 02:10:27.836324 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.951462
I1022 02:10:27.836331 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.960736
I1022 02:10:27.836338 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.688052 (* 1 = 0.688052 loss)
I1022 02:10:27.836345 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.577053 (* 1 = 0.577053 loss)
I1022 02:10:27.836349 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.113923 (* 1 = 0.113923 loss)
I1022 02:10:27.836354 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.108825 (* 1 = 0.108825 loss)
I1022 02:10:27.836359 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.003107 (* 1 = 0.003107 loss)
I1022 02:10:27.836364 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.43491e-05 (* 1 = 2.43491e-05 loss)
I1022 02:10:27.836369 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.265799 (* 1 = 0.265799 loss)
I1022 02:10:27.836374 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00189539 (* 1 = 0.00189539 loss)
I1022 02:10:27.836380 25759 sgd_solver.cpp:106] Iteration 2500, lr = 0.002
I1022 02:11:52.388254 25759 solver.cpp:228] Iteration 2520, loss = 0.245914
I1022 02:11:52.388317 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988012
I1022 02:11:52.388325 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 02:11:52.388337 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0476746 (* 1 = 0.0476746 loss)
I1022 02:11:52.388346 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.032914 (* 1 = 0.032914 loss)
I1022 02:11:52.388353 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0303429 (* 1 = 0.0303429 loss)
I1022 02:11:52.388360 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0159484 (* 1 = 0.0159484 loss)
I1022 02:11:52.388367 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000468036 (* 1 = 0.000468036 loss)
I1022 02:11:52.388375 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00189167 (* 1 = 0.00189167 loss)
I1022 02:11:52.388382 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0286047 (* 1 = 0.0286047 loss)
I1022 02:11:52.388389 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00173297 (* 1 = 0.00173297 loss)
I1022 02:11:52.388403 25759 sgd_solver.cpp:106] Iteration 2520, lr = 0.002
I1022 02:13:19.494951 25759 solver.cpp:228] Iteration 2540, loss = 0.291058
I1022 02:13:19.495007 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988102
I1022 02:13:19.495013 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.988018
I1022 02:13:19.495023 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0734002 (* 1 = 0.0734002 loss)
I1022 02:13:19.495031 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0699589 (* 1 = 0.0699589 loss)
I1022 02:13:19.495036 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.033835 (* 1 = 0.033835 loss)
I1022 02:13:19.495043 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0371572 (* 1 = 0.0371572 loss)
I1022 02:13:19.495049 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00414546 (* 1 = 0.00414546 loss)
I1022 02:13:19.495055 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.44474e-05 (* 1 = 1.44474e-05 loss)
I1022 02:13:19.495062 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.200806 (* 1 = 0.200806 loss)
I1022 02:13:19.495069 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0038985 (* 1 = 0.0038985 loss)
I1022 02:13:19.495075 25759 sgd_solver.cpp:106] Iteration 2540, lr = 0.002
I1022 02:14:46.701874 25759 solver.cpp:228] Iteration 2560, loss = 0.349759
I1022 02:14:46.701921 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990982
I1022 02:14:46.701927 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 02:14:46.701934 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0873749 (* 1 = 0.0873749 loss)
I1022 02:14:46.701941 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0749578 (* 1 = 0.0749578 loss)
I1022 02:14:46.701944 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0240924 (* 1 = 0.0240924 loss)
I1022 02:14:46.701948 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0193732 (* 1 = 0.0193732 loss)
I1022 02:14:46.701952 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00054223 (* 1 = 0.00054223 loss)
I1022 02:14:46.701957 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.01948e-05 (* 1 = 3.01948e-05 loss)
I1022 02:14:46.701962 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0463073 (* 1 = 0.0463073 loss)
I1022 02:14:46.701967 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00507673 (* 1 = 0.00507673 loss)
I1022 02:14:46.701977 25759 sgd_solver.cpp:106] Iteration 2560, lr = 0.002
I1022 02:16:12.265159 25759 solver.cpp:228] Iteration 2580, loss = 0.155561
I1022 02:16:12.265208 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 02:16:12.265213 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 02:16:12.265224 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0519642 (* 1 = 0.0519642 loss)
I1022 02:16:12.265230 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0342072 (* 1 = 0.0342072 loss)
I1022 02:16:12.265238 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0162323 (* 1 = 0.0162323 loss)
I1022 02:16:12.265244 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0109146 (* 1 = 0.0109146 loss)
I1022 02:16:12.265249 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.84631e-05 (* 1 = 9.84631e-05 loss)
I1022 02:16:12.265256 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.17519e-05 (* 1 = 2.17519e-05 loss)
I1022 02:16:12.265262 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.014287 (* 1 = 0.014287 loss)
I1022 02:16:12.265269 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00426031 (* 1 = 0.00426031 loss)
I1022 02:16:12.265277 25759 sgd_solver.cpp:106] Iteration 2580, lr = 0.002
speed: 4.198s / iter
I1022 02:17:38.119544 25759 solver.cpp:228] Iteration 2600, loss = 0.297485
I1022 02:17:38.119585 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 02:17:38.119601 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994503
I1022 02:17:38.119609 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0356815 (* 1 = 0.0356815 loss)
I1022 02:17:38.119616 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0534902 (* 1 = 0.0534902 loss)
I1022 02:17:38.119622 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0125604 (* 1 = 0.0125604 loss)
I1022 02:17:38.119627 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0127423 (* 1 = 0.0127423 loss)
I1022 02:17:38.119633 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000127384 (* 1 = 0.000127384 loss)
I1022 02:17:38.119640 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.65421e-05 (* 1 = 5.65421e-05 loss)
I1022 02:17:38.119647 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0222604 (* 1 = 0.0222604 loss)
I1022 02:17:38.119652 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00155668 (* 1 = 0.00155668 loss)
I1022 02:17:38.119666 25759 sgd_solver.cpp:106] Iteration 2600, lr = 0.002
I1022 02:19:02.440564 25759 solver.cpp:228] Iteration 2620, loss = 0.158886
I1022 02:19:02.440616 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 02:19:02.440639 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 02:19:02.440646 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0121017 (* 1 = 0.0121017 loss)
I1022 02:19:02.440652 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.018317 (* 1 = 0.018317 loss)
I1022 02:19:02.440656 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0103047 (* 1 = 0.0103047 loss)
I1022 02:19:02.440660 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00693591 (* 1 = 0.00693591 loss)
I1022 02:19:02.440666 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000708841 (* 1 = 0.000708841 loss)
I1022 02:19:02.440671 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.69317e-05 (* 1 = 2.69317e-05 loss)
I1022 02:19:02.440675 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00591691 (* 1 = 0.00591691 loss)
I1022 02:19:02.440680 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00074967 (* 1 = 0.00074967 loss)
I1022 02:19:02.440690 25759 sgd_solver.cpp:106] Iteration 2620, lr = 0.002
I1022 02:20:26.853818 25759 solver.cpp:228] Iteration 2640, loss = 0.118333
I1022 02:20:26.853890 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 02:20:26.853901 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 02:20:26.853919 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0474036 (* 1 = 0.0474036 loss)
I1022 02:20:26.853930 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0280147 (* 1 = 0.0280147 loss)
I1022 02:20:26.853940 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0152117 (* 1 = 0.0152117 loss)
I1022 02:20:26.853951 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0136637 (* 1 = 0.0136637 loss)
I1022 02:20:26.853962 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000422205 (* 1 = 0.000422205 loss)
I1022 02:20:26.853976 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.73245e-05 (* 1 = 1.73245e-05 loss)
I1022 02:20:26.853989 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0753578 (* 1 = 0.0753578 loss)
I1022 02:20:26.854003 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0111307 (* 1 = 0.0111307 loss)
I1022 02:20:26.854022 25759 sgd_solver.cpp:106] Iteration 2640, lr = 0.002
I1022 02:21:52.083400 25759 solver.cpp:228] Iteration 2660, loss = 0.127327
I1022 02:21:52.083461 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985022
I1022 02:21:52.083470 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990015
I1022 02:21:52.083487 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.116639 (* 1 = 0.116639 loss)
I1022 02:21:52.083498 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.105842 (* 1 = 0.105842 loss)
I1022 02:21:52.083508 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0451972 (* 1 = 0.0451972 loss)
I1022 02:21:52.083518 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0309783 (* 1 = 0.0309783 loss)
I1022 02:21:52.083528 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00116493 (* 1 = 0.00116493 loss)
I1022 02:21:52.083542 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.45595e-05 (* 1 = 2.45595e-05 loss)
I1022 02:21:52.083555 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.121802 (* 1 = 0.121802 loss)
I1022 02:21:52.083567 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0192379 (* 1 = 0.0192379 loss)
I1022 02:21:52.083580 25759 sgd_solver.cpp:106] Iteration 2660, lr = 0.002
I1022 02:23:18.541888 25759 solver.cpp:228] Iteration 2680, loss = 0.347499
I1022 02:23:18.541929 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 02:23:18.541935 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 02:23:18.541945 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0163783 (* 1 = 0.0163783 loss)
I1022 02:23:18.541952 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0203312 (* 1 = 0.0203312 loss)
I1022 02:23:18.541959 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0111099 (* 1 = 0.0111099 loss)
I1022 02:23:18.541965 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00822763 (* 1 = 0.00822763 loss)
I1022 02:23:18.541970 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000136177 (* 1 = 0.000136177 loss)
I1022 02:23:18.541977 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.96649e-06 (* 1 = 8.96649e-06 loss)
I1022 02:23:18.541983 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00523564 (* 1 = 0.00523564 loss)
I1022 02:23:18.541990 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00817249 (* 1 = 0.00817249 loss)
I1022 02:23:18.542001 25759 sgd_solver.cpp:106] Iteration 2680, lr = 0.002
I1022 02:24:45.303932 25759 solver.cpp:228] Iteration 2700, loss = 0.169365
I1022 02:24:45.303974 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.974078
I1022 02:24:45.303982 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.981555
I1022 02:24:45.303992 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.18747 (* 1 = 0.18747 loss)
I1022 02:24:45.303998 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.128318 (* 1 = 0.128318 loss)
I1022 02:24:45.304008 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0715022 (* 1 = 0.0715022 loss)
I1022 02:24:45.304013 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0543227 (* 1 = 0.0543227 loss)
I1022 02:24:45.304019 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00186731 (* 1 = 0.00186731 loss)
I1022 02:24:45.304026 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.87678e-05 (* 1 = 3.87678e-05 loss)
I1022 02:24:45.304033 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.165372 (* 1 = 0.165372 loss)
I1022 02:24:45.304040 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00568332 (* 1 = 0.00568332 loss)
I1022 02:24:45.304050 25759 sgd_solver.cpp:106] Iteration 2700, lr = 0.002
I1022 02:26:10.807356 25759 solver.cpp:228] Iteration 2720, loss = 0.450061
I1022 02:26:10.807395 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986329
I1022 02:26:10.807413 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.98951
I1022 02:26:10.807423 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0995454 (* 1 = 0.0995454 loss)
I1022 02:26:10.807430 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0575669 (* 1 = 0.0575669 loss)
I1022 02:26:10.807435 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0364854 (* 1 = 0.0364854 loss)
I1022 02:26:10.807440 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0300276 (* 1 = 0.0300276 loss)
I1022 02:26:10.807446 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000911779 (* 1 = 0.000911779 loss)
I1022 02:26:10.807453 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.63641e-05 (* 1 = 3.63641e-05 loss)
I1022 02:26:10.807458 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0799073 (* 1 = 0.0799073 loss)
I1022 02:26:10.807464 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00055756 (* 1 = 0.00055756 loss)
I1022 02:26:10.807476 25759 sgd_solver.cpp:106] Iteration 2720, lr = 0.002
I1022 02:27:36.563848 25759 solver.cpp:228] Iteration 2740, loss = 0.392786
I1022 02:27:36.563921 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986924
I1022 02:27:36.563928 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992508
I1022 02:27:36.563941 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0584559 (* 1 = 0.0584559 loss)
I1022 02:27:36.563947 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0646564 (* 1 = 0.0646564 loss)
I1022 02:27:36.563953 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0349297 (* 1 = 0.0349297 loss)
I1022 02:27:36.563961 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0263366 (* 1 = 0.0263366 loss)
I1022 02:27:36.563967 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00127699 (* 1 = 0.00127699 loss)
I1022 02:27:36.563976 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.91033e-05 (* 1 = 6.91033e-05 loss)
I1022 02:27:36.563982 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0404934 (* 1 = 0.0404934 loss)
I1022 02:27:36.563988 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00492948 (* 1 = 0.00492948 loss)
I1022 02:27:36.564002 25759 sgd_solver.cpp:106] Iteration 2740, lr = 0.002
I1022 02:29:02.059650 25759 solver.cpp:228] Iteration 2760, loss = 0.147977
I1022 02:29:02.059702 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 02:29:02.059707 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 02:29:02.059715 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0831278 (* 1 = 0.0831278 loss)
I1022 02:29:02.059723 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0415634 (* 1 = 0.0415634 loss)
I1022 02:29:02.059728 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0291277 (* 1 = 0.0291277 loss)
I1022 02:29:02.059732 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0126318 (* 1 = 0.0126318 loss)
I1022 02:29:02.059737 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00996923 (* 1 = 0.00996923 loss)
I1022 02:29:02.059742 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.70828e-05 (* 1 = 2.70828e-05 loss)
I1022 02:29:02.059747 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0183342 (* 1 = 0.0183342 loss)
I1022 02:29:02.059752 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00701938 (* 1 = 0.00701938 loss)
I1022 02:29:02.059757 25759 sgd_solver.cpp:106] Iteration 2760, lr = 0.002
I1022 02:30:27.105234 25759 solver.cpp:228] Iteration 2780, loss = 0.316404
I1022 02:30:27.105268 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988356
I1022 02:30:27.105273 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 02:30:27.105279 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0842996 (* 1 = 0.0842996 loss)
I1022 02:30:27.105283 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0424843 (* 1 = 0.0424843 loss)
I1022 02:30:27.105288 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0426169 (* 1 = 0.0426169 loss)
I1022 02:30:27.105293 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.030702 (* 1 = 0.030702 loss)
I1022 02:30:27.105296 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0104474 (* 1 = 0.0104474 loss)
I1022 02:30:27.105301 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.46018e-05 (* 1 = 7.46018e-05 loss)
I1022 02:30:27.105305 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.369964 (* 1 = 0.369964 loss)
I1022 02:30:27.105310 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00023523 (* 1 = 0.00023523 loss)
I1022 02:30:27.105315 25759 sgd_solver.cpp:106] Iteration 2780, lr = 0.002
speed: 4.203s / iter
I1022 02:31:51.953846 25759 solver.cpp:228] Iteration 2800, loss = 0.201326
I1022 02:31:51.953899 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99001
I1022 02:31:51.953905 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996503
I1022 02:31:51.953913 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.133671 (* 1 = 0.133671 loss)
I1022 02:31:51.953918 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0329353 (* 1 = 0.0329353 loss)
I1022 02:31:51.953923 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0442654 (* 1 = 0.0442654 loss)
I1022 02:31:51.953927 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0174405 (* 1 = 0.0174405 loss)
I1022 02:31:51.953933 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00780707 (* 1 = 0.00780707 loss)
I1022 02:31:51.953938 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.38477e-06 (* 1 = 8.38477e-06 loss)
I1022 02:31:51.953943 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0334249 (* 1 = 0.0334249 loss)
I1022 02:31:51.953948 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000770017 (* 1 = 0.000770017 loss)
I1022 02:31:51.953954 25759 sgd_solver.cpp:106] Iteration 2800, lr = 0.002
I1022 02:33:16.895638 25759 solver.cpp:228] Iteration 2820, loss = 0.388035
I1022 02:33:16.895680 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997342
I1022 02:33:16.895697 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 02:33:16.895707 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0246381 (* 1 = 0.0246381 loss)
I1022 02:33:16.895714 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0361237 (* 1 = 0.0361237 loss)
I1022 02:33:16.895720 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0133216 (* 1 = 0.0133216 loss)
I1022 02:33:16.895725 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0136101 (* 1 = 0.0136101 loss)
I1022 02:33:16.895731 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000918313 (* 1 = 0.000918313 loss)
I1022 02:33:16.895738 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.02875e-05 (* 1 = 1.02875e-05 loss)
I1022 02:33:16.895745 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.142567 (* 1 = 0.142567 loss)
I1022 02:33:16.895761 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00840223 (* 1 = 0.00840223 loss)
I1022 02:33:16.895768 25759 sgd_solver.cpp:106] Iteration 2820, lr = 0.002
I1022 02:34:43.097889 25759 solver.cpp:228] Iteration 2840, loss = 0.163892
I1022 02:34:43.097935 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994006
I1022 02:34:43.097942 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 02:34:43.097952 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.121119 (* 1 = 0.121119 loss)
I1022 02:34:43.097959 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0502093 (* 1 = 0.0502093 loss)
I1022 02:34:43.097967 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0223031 (* 1 = 0.0223031 loss)
I1022 02:34:43.097973 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0142482 (* 1 = 0.0142482 loss)
I1022 02:34:43.097980 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000741342 (* 1 = 0.000741342 loss)
I1022 02:34:43.097987 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.78594e-05 (* 1 = 1.78594e-05 loss)
I1022 02:34:43.097993 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.051715 (* 1 = 0.051715 loss)
I1022 02:34:43.098001 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00206851 (* 1 = 0.00206851 loss)
I1022 02:34:43.098009 25759 sgd_solver.cpp:106] Iteration 2840, lr = 0.002
I1022 02:36:09.466915 25759 solver.cpp:228] Iteration 2860, loss = 0.204658
I1022 02:36:09.466956 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:36:09.466964 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:36:09.466972 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:36:09.466979 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:36:09.466986 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00609292 (* 1 = 0.00609292 loss)
I1022 02:36:09.466992 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00483245 (* 1 = 0.00483245 loss)
I1022 02:36:09.466998 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000264968 (* 1 = 0.000264968 loss)
I1022 02:36:09.467005 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.0874e-05 (* 1 = 5.0874e-05 loss)
I1022 02:36:09.467011 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0269067 (* 1 = 0.0269067 loss)
I1022 02:36:09.467017 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00025987 (* 1 = 0.00025987 loss)
I1022 02:36:09.467025 25759 sgd_solver.cpp:106] Iteration 2860, lr = 0.002
I1022 02:37:35.689342 25759 solver.cpp:228] Iteration 2880, loss = 0.4899
I1022 02:37:35.689380 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:37:35.689397 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:37:35.689406 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:37:35.689412 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:37:35.689419 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00414702 (* 1 = 0.00414702 loss)
I1022 02:37:35.689424 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450903 (* 1 = 0.00450903 loss)
I1022 02:37:35.689430 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000147938 (* 1 = 0.000147938 loss)
I1022 02:37:35.689436 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.76919e-05 (* 1 = 1.76919e-05 loss)
I1022 02:37:35.689442 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0305757 (* 1 = 0.0305757 loss)
I1022 02:37:35.689448 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00206957 (* 1 = 0.00206957 loss)
I1022 02:37:35.689455 25759 sgd_solver.cpp:106] Iteration 2880, lr = 0.002
I1022 02:38:59.832752 25759 solver.cpp:228] Iteration 2900, loss = 0.137338
I1022 02:38:59.832793 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:38:59.832799 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:38:59.832808 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:38:59.832813 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:38:59.832818 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00489031 (* 1 = 0.00489031 loss)
I1022 02:38:59.832823 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00373548 (* 1 = 0.00373548 loss)
I1022 02:38:59.832828 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000315173 (* 1 = 0.000315173 loss)
I1022 02:38:59.832834 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000135693 (* 1 = 0.000135693 loss)
I1022 02:38:59.832839 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0028041 (* 1 = 0.0028041 loss)
I1022 02:38:59.832844 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00977697 (* 1 = 0.00977697 loss)
I1022 02:38:59.832855 25759 sgd_solver.cpp:106] Iteration 2900, lr = 0.002
I1022 02:40:25.387913 25759 solver.cpp:228] Iteration 2920, loss = 0.503716
I1022 02:40:25.387964 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 02:40:25.387970 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:40:25.387977 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:40:25.387981 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:40:25.387986 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.012026 (* 1 = 0.012026 loss)
I1022 02:40:25.387990 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00623157 (* 1 = 0.00623157 loss)
I1022 02:40:25.387995 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.54687e-05 (* 1 = 8.54687e-05 loss)
I1022 02:40:25.388000 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.76606e-06 (* 1 = 9.76606e-06 loss)
I1022 02:40:25.388005 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00741231 (* 1 = 0.00741231 loss)
I1022 02:40:25.388011 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00177142 (* 1 = 0.00177142 loss)
I1022 02:40:25.388017 25759 sgd_solver.cpp:106] Iteration 2920, lr = 0.002
I1022 02:41:47.697881 25759 solver.cpp:228] Iteration 2940, loss = 0.227812
I1022 02:41:47.697922 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995916
I1022 02:41:47.697939 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995502
I1022 02:41:47.697952 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0201142 (* 1 = 0.0201142 loss)
I1022 02:41:47.697959 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.021527 (* 1 = 0.021527 loss)
I1022 02:41:47.697965 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0128207 (* 1 = 0.0128207 loss)
I1022 02:41:47.697971 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0128109 (* 1 = 0.0128109 loss)
I1022 02:41:47.697978 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000465907 (* 1 = 0.000465907 loss)
I1022 02:41:47.697988 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.26776e-05 (* 1 = 3.26776e-05 loss)
I1022 02:41:47.697996 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0449867 (* 1 = 0.0449867 loss)
I1022 02:41:47.698004 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00743198 (* 1 = 0.00743198 loss)
I1022 02:41:47.698017 25759 sgd_solver.cpp:106] Iteration 2940, lr = 0.002
I1022 02:43:09.182351 25759 solver.cpp:228] Iteration 2960, loss = 0.224957
I1022 02:43:09.182390 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:43:09.182396 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:43:09.182405 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:43:09.182411 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:43:09.182417 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00495181 (* 1 = 0.00495181 loss)
I1022 02:43:09.182423 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00417552 (* 1 = 0.00417552 loss)
I1022 02:43:09.182430 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00395666 (* 1 = 0.00395666 loss)
I1022 02:43:09.182435 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.59356e-05 (* 1 = 2.59356e-05 loss)
I1022 02:43:09.182441 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00090628 (* 1 = 0.00090628 loss)
I1022 02:43:09.182446 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00510263 (* 1 = 0.00510263 loss)
I1022 02:43:09.182453 25759 sgd_solver.cpp:106] Iteration 2960, lr = 0.002
I1022 02:44:29.778939 25759 solver.cpp:228] Iteration 2980, loss = 0.110082
I1022 02:44:29.779017 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:44:29.779029 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:44:29.779045 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:44:29.779057 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:44:29.779069 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.005511 (* 1 = 0.005511 loss)
I1022 02:44:29.779088 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00440102 (* 1 = 0.00440102 loss)
I1022 02:44:29.779100 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000142845 (* 1 = 0.000142845 loss)
I1022 02:44:29.779116 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.62582e-06 (* 1 = 9.62582e-06 loss)
I1022 02:44:29.779129 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00374194 (* 1 = 0.00374194 loss)
I1022 02:44:29.779144 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00966436 (* 1 = 0.00966436 loss)
I1022 02:44:29.779157 25759 sgd_solver.cpp:106] Iteration 2980, lr = 0.002
speed: 4.203s / iter
I1022 02:45:52.568763 25759 solver.cpp:228] Iteration 3000, loss = 0.19221
I1022 02:45:52.568796 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99121
I1022 02:45:52.568802 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990005
I1022 02:45:52.568810 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0653264 (* 1 = 0.0653264 loss)
I1022 02:45:52.568815 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0452304 (* 1 = 0.0452304 loss)
I1022 02:45:52.568819 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0219885 (* 1 = 0.0219885 loss)
I1022 02:45:52.568825 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0225177 (* 1 = 0.0225177 loss)
I1022 02:45:52.568828 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00942778 (* 1 = 0.00942778 loss)
I1022 02:45:52.568833 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.21944e-05 (* 1 = 1.21944e-05 loss)
I1022 02:45:52.568838 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.505385 (* 1 = 0.505385 loss)
I1022 02:45:52.568845 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00161321 (* 1 = 0.00161321 loss)
I1022 02:45:52.568850 25759 sgd_solver.cpp:106] Iteration 3000, lr = 0.002
I1022 02:47:16.933820 25759 solver.cpp:228] Iteration 3020, loss = 0.164923
I1022 02:47:16.933867 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988006
I1022 02:47:16.933873 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993003
I1022 02:47:16.933883 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0254124 (* 1 = 0.0254124 loss)
I1022 02:47:16.933892 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0329396 (* 1 = 0.0329396 loss)
I1022 02:47:16.933897 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0248397 (* 1 = 0.0248397 loss)
I1022 02:47:16.933903 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.018135 (* 1 = 0.018135 loss)
I1022 02:47:16.933909 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00670365 (* 1 = 0.00670365 loss)
I1022 02:47:16.933917 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.26097e-05 (* 1 = 1.26097e-05 loss)
I1022 02:47:16.933924 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0157625 (* 1 = 0.0157625 loss)
I1022 02:47:16.933931 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00559959 (* 1 = 0.00559959 loss)
I1022 02:47:16.933940 25759 sgd_solver.cpp:106] Iteration 3020, lr = 0.002
I1022 02:48:41.950953 25759 solver.cpp:228] Iteration 3040, loss = 0.165336
I1022 02:48:41.951019 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996004
I1022 02:48:41.951028 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995504
I1022 02:48:41.951045 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0225743 (* 1 = 0.0225743 loss)
I1022 02:48:41.951056 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.039593 (* 1 = 0.039593 loss)
I1022 02:48:41.951066 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0179466 (* 1 = 0.0179466 loss)
I1022 02:48:41.951076 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0171936 (* 1 = 0.0171936 loss)
I1022 02:48:41.951090 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0053516 (* 1 = 0.0053516 loss)
I1022 02:48:41.951103 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.6664e-05 (* 1 = 1.6664e-05 loss)
I1022 02:48:41.951114 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0155151 (* 1 = 0.0155151 loss)
I1022 02:48:41.951125 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00292464 (* 1 = 0.00292464 loss)
I1022 02:48:41.951138 25759 sgd_solver.cpp:106] Iteration 3040, lr = 0.002
I1022 02:50:06.691895 25759 solver.cpp:228] Iteration 3060, loss = 0.177627
I1022 02:50:06.691931 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993007
I1022 02:50:06.691938 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1022 02:50:06.691947 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0383207 (* 1 = 0.0383207 loss)
I1022 02:50:06.691953 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0333806 (* 1 = 0.0333806 loss)
I1022 02:50:06.691959 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0289805 (* 1 = 0.0289805 loss)
I1022 02:50:06.691965 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0222364 (* 1 = 0.0222364 loss)
I1022 02:50:06.691972 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00460675 (* 1 = 0.00460675 loss)
I1022 02:50:06.691977 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.5022e-05 (* 1 = 2.5022e-05 loss)
I1022 02:50:06.691983 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0732967 (* 1 = 0.0732967 loss)
I1022 02:50:06.691989 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000271037 (* 1 = 0.000271037 loss)
I1022 02:50:06.691996 25759 sgd_solver.cpp:106] Iteration 3060, lr = 0.002
I1022 02:51:32.043666 25759 solver.cpp:228] Iteration 3080, loss = 0.142504
I1022 02:51:32.043705 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994006
I1022 02:51:32.043711 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 02:51:32.043721 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0399616 (* 1 = 0.0399616 loss)
I1022 02:51:32.043727 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0646282 (* 1 = 0.0646282 loss)
I1022 02:51:32.043733 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0234249 (* 1 = 0.0234249 loss)
I1022 02:51:32.043740 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0205189 (* 1 = 0.0205189 loss)
I1022 02:51:32.043745 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000799503 (* 1 = 0.000799503 loss)
I1022 02:51:32.043751 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.62931e-05 (* 1 = 2.62931e-05 loss)
I1022 02:51:32.043757 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0466903 (* 1 = 0.0466903 loss)
I1022 02:51:32.043762 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000190463 (* 1 = 0.000190463 loss)
I1022 02:51:32.043771 25759 sgd_solver.cpp:106] Iteration 3080, lr = 0.002
I1022 02:52:56.916115 25759 solver.cpp:228] Iteration 3100, loss = 0.263373
I1022 02:52:56.916162 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:52:56.916167 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:52:56.916175 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:52:56.916182 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:52:56.916187 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.004697 (* 1 = 0.004697 loss)
I1022 02:52:56.916191 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00426776 (* 1 = 0.00426776 loss)
I1022 02:52:56.916196 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.95663e-05 (* 1 = 5.95663e-05 loss)
I1022 02:52:56.916201 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.18767e-06 (* 1 = 8.18767e-06 loss)
I1022 02:52:56.916205 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0020136 (* 1 = 0.0020136 loss)
I1022 02:52:56.916210 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00207253 (* 1 = 0.00207253 loss)
I1022 02:52:56.916216 25759 sgd_solver.cpp:106] Iteration 3100, lr = 0.002
I1022 02:54:22.667901 25759 solver.cpp:228] Iteration 3120, loss = 0.174574
I1022 02:54:22.667958 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 02:54:22.667970 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:54:22.667987 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:54:22.667999 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:54:22.668015 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00457838 (* 1 = 0.00457838 loss)
I1022 02:54:22.668028 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00448202 (* 1 = 0.00448202 loss)
I1022 02:54:22.668040 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.85671e-05 (* 1 = 6.85671e-05 loss)
I1022 02:54:22.668053 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.08686e-06 (* 1 = 7.08686e-06 loss)
I1022 02:54:22.668066 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00368403 (* 1 = 0.00368403 loss)
I1022 02:54:22.668081 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0054131 (* 1 = 0.0054131 loss)
I1022 02:54:22.668094 25759 sgd_solver.cpp:106] Iteration 3120, lr = 0.002
I1022 02:55:48.245996 25759 solver.cpp:228] Iteration 3140, loss = 0.129462
I1022 02:55:48.246053 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 02:55:48.246060 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 02:55:48.246073 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:55:48.246078 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:55:48.246084 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00843998 (* 1 = 0.00843998 loss)
I1022 02:55:48.246090 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00468697 (* 1 = 0.00468697 loss)
I1022 02:55:48.246098 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00145499 (* 1 = 0.00145499 loss)
I1022 02:55:48.246106 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.08053e-05 (* 1 = 3.08053e-05 loss)
I1022 02:55:48.246114 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00889495 (* 1 = 0.00889495 loss)
I1022 02:55:48.246120 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00522218 (* 1 = 0.00522218 loss)
I1022 02:55:48.246129 25759 sgd_solver.cpp:106] Iteration 3140, lr = 0.002
I1022 02:57:13.800581 25759 solver.cpp:228] Iteration 3160, loss = 0.174158
I1022 02:57:13.800627 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 02:57:13.800634 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 02:57:13.800644 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0207947 (* 1 = 0.0207947 loss)
I1022 02:57:13.800652 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0442712 (* 1 = 0.0442712 loss)
I1022 02:57:13.800657 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0108736 (* 1 = 0.0108736 loss)
I1022 02:57:13.800664 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00940867 (* 1 = 0.00940867 loss)
I1022 02:57:13.800670 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000176761 (* 1 = 0.000176761 loss)
I1022 02:57:13.800678 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.45152e-05 (* 1 = 1.45152e-05 loss)
I1022 02:57:13.800685 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.014313 (* 1 = 0.014313 loss)
I1022 02:57:13.800693 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0104969 (* 1 = 0.0104969 loss)
I1022 02:57:13.800701 25759 sgd_solver.cpp:106] Iteration 3160, lr = 0.002
I1022 02:58:38.971562 25759 solver.cpp:228] Iteration 3180, loss = 0.131123
I1022 02:58:38.971616 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 02:58:38.971621 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 02:58:38.971629 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 02:58:38.971634 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 02:58:38.971638 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00905478 (* 1 = 0.00905478 loss)
I1022 02:58:38.971643 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0063409 (* 1 = 0.0063409 loss)
I1022 02:58:38.971648 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000384529 (* 1 = 0.000384529 loss)
I1022 02:58:38.971653 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.19422e-05 (* 1 = 1.19422e-05 loss)
I1022 02:58:38.971658 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00831707 (* 1 = 0.00831707 loss)
I1022 02:58:38.971663 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00798959 (* 1 = 0.00798959 loss)
I1022 02:58:38.971668 25759 sgd_solver.cpp:106] Iteration 3180, lr = 0.002
speed: 4.206s / iter
I1022 03:00:02.601128 25759 solver.cpp:228] Iteration 3200, loss = 0.0972105
I1022 03:00:02.601202 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 03:00:02.601215 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 03:00:02.601231 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0279288 (* 1 = 0.0279288 loss)
I1022 03:00:02.601243 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0236075 (* 1 = 0.0236075 loss)
I1022 03:00:02.601256 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0155168 (* 1 = 0.0155168 loss)
I1022 03:00:02.601267 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0118807 (* 1 = 0.0118807 loss)
I1022 03:00:02.601280 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000157969 (* 1 = 0.000157969 loss)
I1022 03:00:02.601294 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.85291e-05 (* 1 = 1.85291e-05 loss)
I1022 03:00:02.601306 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0557021 (* 1 = 0.0557021 loss)
I1022 03:00:02.601318 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00766279 (* 1 = 0.00766279 loss)
I1022 03:00:02.601331 25759 sgd_solver.cpp:106] Iteration 3200, lr = 0.002
I1022 03:01:26.392174 25759 solver.cpp:228] Iteration 3220, loss = 0.192087
I1022 03:01:26.392230 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 03:01:26.392237 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 03:01:26.392248 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0147575 (* 1 = 0.0147575 loss)
I1022 03:01:26.392256 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0305096 (* 1 = 0.0305096 loss)
I1022 03:01:26.392263 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0140227 (* 1 = 0.0140227 loss)
I1022 03:01:26.392271 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00989803 (* 1 = 0.00989803 loss)
I1022 03:01:26.392277 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000215217 (* 1 = 0.000215217 loss)
I1022 03:01:26.392288 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.87027e-05 (* 1 = 1.87027e-05 loss)
I1022 03:01:26.392295 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.017082 (* 1 = 0.017082 loss)
I1022 03:01:26.392304 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00367633 (* 1 = 0.00367633 loss)
I1022 03:01:26.392318 25759 sgd_solver.cpp:106] Iteration 3220, lr = 0.002
I1022 03:02:51.390079 25759 solver.cpp:228] Iteration 3240, loss = 0.148556
I1022 03:02:51.390136 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.984024
I1022 03:02:51.390141 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992012
I1022 03:02:51.390149 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.106205 (* 1 = 0.106205 loss)
I1022 03:02:51.390158 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.102674 (* 1 = 0.102674 loss)
I1022 03:02:51.390162 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.043112 (* 1 = 0.043112 loss)
I1022 03:02:51.390167 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0282139 (* 1 = 0.0282139 loss)
I1022 03:02:51.390172 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000947366 (* 1 = 0.000947366 loss)
I1022 03:02:51.390177 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.95145e-05 (* 1 = 2.95145e-05 loss)
I1022 03:02:51.390182 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0426021 (* 1 = 0.0426021 loss)
I1022 03:02:51.390187 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00233715 (* 1 = 0.00233715 loss)
I1022 03:02:51.390193 25759 sgd_solver.cpp:106] Iteration 3240, lr = 0.002
I1022 03:04:11.829267 25759 solver.cpp:228] Iteration 3260, loss = 0.121118
I1022 03:04:11.829308 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995005
I1022 03:04:11.829314 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993506
I1022 03:04:11.829324 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0745372 (* 1 = 0.0745372 loss)
I1022 03:04:11.829329 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0533922 (* 1 = 0.0533922 loss)
I1022 03:04:11.829335 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0206036 (* 1 = 0.0206036 loss)
I1022 03:04:11.829341 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0205102 (* 1 = 0.0205102 loss)
I1022 03:04:11.829346 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000195874 (* 1 = 0.000195874 loss)
I1022 03:04:11.829354 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.12631e-05 (* 1 = 2.12631e-05 loss)
I1022 03:04:11.829360 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0339182 (* 1 = 0.0339182 loss)
I1022 03:04:11.829365 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00374303 (* 1 = 0.00374303 loss)
I1022 03:04:11.829376 25759 sgd_solver.cpp:106] Iteration 3260, lr = 0.002
I1022 03:05:33.362090 25759 solver.cpp:228] Iteration 3280, loss = 0.263059
I1022 03:05:33.362141 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993003
I1022 03:05:33.362146 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 03:05:33.362154 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.019467 (* 1 = 0.019467 loss)
I1022 03:05:33.362161 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0338264 (* 1 = 0.0338264 loss)
I1022 03:05:33.362165 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0184137 (* 1 = 0.0184137 loss)
I1022 03:05:33.362169 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0103867 (* 1 = 0.0103867 loss)
I1022 03:05:33.362174 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00541958 (* 1 = 0.00541958 loss)
I1022 03:05:33.362179 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.96572e-05 (* 1 = 1.96572e-05 loss)
I1022 03:05:33.362185 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.013088 (* 1 = 0.013088 loss)
I1022 03:05:33.362188 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00497265 (* 1 = 0.00497265 loss)
I1022 03:05:33.362196 25759 sgd_solver.cpp:106] Iteration 3280, lr = 0.002
I1022 03:06:53.273185 25759 solver.cpp:228] Iteration 3300, loss = 0.217914
I1022 03:06:53.273243 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 03:06:53.273249 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 03:06:53.273257 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0117889 (* 1 = 0.0117889 loss)
I1022 03:06:53.273262 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0322408 (* 1 = 0.0322408 loss)
I1022 03:06:53.273267 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0132481 (* 1 = 0.0132481 loss)
I1022 03:06:53.273272 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0107604 (* 1 = 0.0107604 loss)
I1022 03:06:53.273277 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00013746 (* 1 = 0.00013746 loss)
I1022 03:06:53.273283 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.04882e-05 (* 1 = 6.04882e-05 loss)
I1022 03:06:53.273288 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0294143 (* 1 = 0.0294143 loss)
I1022 03:06:53.273293 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00159748 (* 1 = 0.00159748 loss)
I1022 03:06:53.273299 25759 sgd_solver.cpp:106] Iteration 3300, lr = 0.002
I1022 03:08:17.215013 25759 solver.cpp:228] Iteration 3320, loss = 0.204597
I1022 03:08:17.215078 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989006
I1022 03:08:17.215085 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 03:08:17.215093 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0400531 (* 1 = 0.0400531 loss)
I1022 03:08:17.215098 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0264777 (* 1 = 0.0264777 loss)
I1022 03:08:17.215103 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0259718 (* 1 = 0.0259718 loss)
I1022 03:08:17.215107 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0107243 (* 1 = 0.0107243 loss)
I1022 03:08:17.215113 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000602404 (* 1 = 0.000602404 loss)
I1022 03:08:17.215119 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.26717e-05 (* 1 = 2.26717e-05 loss)
I1022 03:08:17.215124 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0136372 (* 1 = 0.0136372 loss)
I1022 03:08:17.215129 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00381141 (* 1 = 0.00381141 loss)
I1022 03:08:17.215137 25759 sgd_solver.cpp:106] Iteration 3320, lr = 0.002
I1022 03:09:38.843813 25759 solver.cpp:228] Iteration 3340, loss = 0.165775
I1022 03:09:38.843850 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 03:09:38.843865 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 03:09:38.843874 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00938986 (* 1 = 0.00938986 loss)
I1022 03:09:38.843881 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0130044 (* 1 = 0.0130044 loss)
I1022 03:09:38.843886 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0126783 (* 1 = 0.0126783 loss)
I1022 03:09:38.843892 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00983123 (* 1 = 0.00983123 loss)
I1022 03:09:38.843899 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000249957 (* 1 = 0.000249957 loss)
I1022 03:09:38.843904 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.34707e-05 (* 1 = 1.34707e-05 loss)
I1022 03:09:38.843911 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0200764 (* 1 = 0.0200764 loss)
I1022 03:09:38.843917 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00970083 (* 1 = 0.00970083 loss)
I1022 03:09:38.843924 25759 sgd_solver.cpp:106] Iteration 3340, lr = 0.002
I1022 03:11:01.030354 25759 solver.cpp:228] Iteration 3360, loss = 0.24578
I1022 03:11:01.030405 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988012
I1022 03:11:01.030411 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993007
I1022 03:11:01.030418 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0568482 (* 1 = 0.0568482 loss)
I1022 03:11:01.030423 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.123007 (* 1 = 0.123007 loss)
I1022 03:11:01.030427 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0359399 (* 1 = 0.0359399 loss)
I1022 03:11:01.030432 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0225693 (* 1 = 0.0225693 loss)
I1022 03:11:01.030436 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00154286 (* 1 = 0.00154286 loss)
I1022 03:11:01.030441 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.15872e-05 (* 1 = 2.15872e-05 loss)
I1022 03:11:01.030447 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0606325 (* 1 = 0.0606325 loss)
I1022 03:11:01.030452 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00527442 (* 1 = 0.00527442 loss)
I1022 03:11:01.030458 25759 sgd_solver.cpp:106] Iteration 3360, lr = 0.002
I1022 03:12:22.261168 25759 solver.cpp:228] Iteration 3380, loss = 0.225209
I1022 03:12:22.261216 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.987019
I1022 03:12:22.261221 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990514
I1022 03:12:22.261229 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0744849 (* 1 = 0.0744849 loss)
I1022 03:12:22.261235 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0783142 (* 1 = 0.0783142 loss)
I1022 03:12:22.261240 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0354052 (* 1 = 0.0354052 loss)
I1022 03:12:22.261243 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0274135 (* 1 = 0.0274135 loss)
I1022 03:12:22.261248 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000525009 (* 1 = 0.000525009 loss)
I1022 03:12:22.261253 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.98759e-05 (* 1 = 1.98759e-05 loss)
I1022 03:12:22.261257 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0496837 (* 1 = 0.0496837 loss)
I1022 03:12:22.261262 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00267617 (* 1 = 0.00267617 loss)
I1022 03:12:22.261268 25759 sgd_solver.cpp:106] Iteration 3380, lr = 0.002
speed: 4.201s / iter
I1022 03:13:45.826041 25759 solver.cpp:228] Iteration 3400, loss = 0.290891
I1022 03:13:45.826092 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:13:45.826097 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:13:45.826102 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:13:45.826107 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:13:45.826112 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00496098 (* 1 = 0.00496098 loss)
I1022 03:13:45.826117 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00451606 (* 1 = 0.00451606 loss)
I1022 03:13:45.826122 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00018027 (* 1 = 0.00018027 loss)
I1022 03:13:45.826126 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.91834e-05 (* 1 = 2.91834e-05 loss)
I1022 03:13:45.826130 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.003873 (* 1 = 0.003873 loss)
I1022 03:13:45.826135 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00277367 (* 1 = 0.00277367 loss)
I1022 03:13:45.826141 25759 sgd_solver.cpp:106] Iteration 3400, lr = 0.002
I1022 03:15:07.640085 25759 solver.cpp:228] Iteration 3420, loss = 0.185987
I1022 03:15:07.640117 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994006
I1022 03:15:07.640122 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1022 03:15:07.640130 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0385389 (* 1 = 0.0385389 loss)
I1022 03:15:07.640134 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0423646 (* 1 = 0.0423646 loss)
I1022 03:15:07.640138 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0185716 (* 1 = 0.0185716 loss)
I1022 03:15:07.640142 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0177935 (* 1 = 0.0177935 loss)
I1022 03:15:07.640147 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00167308 (* 1 = 0.00167308 loss)
I1022 03:15:07.640152 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.72215e-05 (* 1 = 2.72215e-05 loss)
I1022 03:15:07.640156 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0241843 (* 1 = 0.0241843 loss)
I1022 03:15:07.640161 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00205153 (* 1 = 0.00205153 loss)
I1022 03:15:07.640166 25759 sgd_solver.cpp:106] Iteration 3420, lr = 0.002
I1022 03:16:30.484323 25759 solver.cpp:228] Iteration 3440, loss = 0.273228
I1022 03:16:30.484366 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:16:30.484374 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:16:30.484383 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:16:30.484390 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:16:30.484397 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00537755 (* 1 = 0.00537755 loss)
I1022 03:16:30.484405 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00508837 (* 1 = 0.00508837 loss)
I1022 03:16:30.484411 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000257684 (* 1 = 0.000257684 loss)
I1022 03:16:30.484418 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.74529e-05 (* 1 = 2.74529e-05 loss)
I1022 03:16:30.484424 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00316172 (* 1 = 0.00316172 loss)
I1022 03:16:30.484431 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000929475 (* 1 = 0.000929475 loss)
I1022 03:16:30.484444 25759 sgd_solver.cpp:106] Iteration 3440, lr = 0.002
I1022 03:17:55.834888 25759 solver.cpp:228] Iteration 3460, loss = 0.319225
I1022 03:17:55.834929 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 03:17:55.834935 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994503
I1022 03:17:55.834944 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0614669 (* 1 = 0.0614669 loss)
I1022 03:17:55.834951 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0386455 (* 1 = 0.0386455 loss)
I1022 03:17:55.834956 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0174415 (* 1 = 0.0174415 loss)
I1022 03:17:55.834962 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.01929 (* 1 = 0.01929 loss)
I1022 03:17:55.834969 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00167964 (* 1 = 0.00167964 loss)
I1022 03:17:55.834975 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.04885e-05 (* 1 = 2.04885e-05 loss)
I1022 03:17:55.834980 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.291062 (* 1 = 0.291062 loss)
I1022 03:17:55.834986 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000919298 (* 1 = 0.000919298 loss)
I1022 03:17:55.834998 25759 sgd_solver.cpp:106] Iteration 3460, lr = 0.002
I1022 03:19:18.635797 25759 solver.cpp:228] Iteration 3480, loss = 0.357204
I1022 03:19:18.635854 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992008
I1022 03:19:18.635859 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 03:19:18.635869 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.038605 (* 1 = 0.038605 loss)
I1022 03:19:18.635874 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0263762 (* 1 = 0.0263762 loss)
I1022 03:19:18.635879 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0203165 (* 1 = 0.0203165 loss)
I1022 03:19:18.635884 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0176656 (* 1 = 0.0176656 loss)
I1022 03:19:18.635888 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000352698 (* 1 = 0.000352698 loss)
I1022 03:19:18.635893 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.36682e-05 (* 1 = 1.36682e-05 loss)
I1022 03:19:18.635898 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0345231 (* 1 = 0.0345231 loss)
I1022 03:19:18.635905 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000827065 (* 1 = 0.000827065 loss)
I1022 03:19:18.635910 25759 sgd_solver.cpp:106] Iteration 3480, lr = 0.002
I1022 03:20:40.887948 25759 solver.cpp:228] Iteration 3500, loss = 0.165601
I1022 03:20:40.887986 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 03:20:40.887993 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 03:20:40.888002 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00994134 (* 1 = 0.00994134 loss)
I1022 03:20:40.888010 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00898762 (* 1 = 0.00898762 loss)
I1022 03:20:40.888015 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0106326 (* 1 = 0.0106326 loss)
I1022 03:20:40.888020 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00765141 (* 1 = 0.00765141 loss)
I1022 03:20:40.888026 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.50998e-05 (* 1 = 4.50998e-05 loss)
I1022 03:20:40.888032 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.34636e-05 (* 1 = 6.34636e-05 loss)
I1022 03:20:40.888038 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00311166 (* 1 = 0.00311166 loss)
I1022 03:20:40.888044 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00107154 (* 1 = 0.00107154 loss)
I1022 03:20:40.888051 25759 sgd_solver.cpp:106] Iteration 3500, lr = 0.002
I1022 03:22:06.535368 25759 solver.cpp:228] Iteration 3520, loss = 0.439193
I1022 03:22:06.535436 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 03:22:06.535447 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995003
I1022 03:22:06.535462 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.05338 (* 1 = 0.05338 loss)
I1022 03:22:06.535475 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0331537 (* 1 = 0.0331537 loss)
I1022 03:22:06.535485 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.023498 (* 1 = 0.023498 loss)
I1022 03:22:06.535493 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0201513 (* 1 = 0.0201513 loss)
I1022 03:22:06.535509 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0019251 (* 1 = 0.0019251 loss)
I1022 03:22:06.535522 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.75209e-05 (* 1 = 2.75209e-05 loss)
I1022 03:22:06.535534 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.167546 (* 1 = 0.167546 loss)
I1022 03:22:06.535544 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00131209 (* 1 = 0.00131209 loss)
I1022 03:22:06.535557 25759 sgd_solver.cpp:106] Iteration 3520, lr = 0.002
I1022 03:23:32.675779 25759 solver.cpp:228] Iteration 3540, loss = 0.3204
I1022 03:23:32.675843 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995005
I1022 03:23:32.675851 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 03:23:32.675865 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0551749 (* 1 = 0.0551749 loss)
I1022 03:23:32.675875 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0658959 (* 1 = 0.0658959 loss)
I1022 03:23:32.675884 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0189243 (* 1 = 0.0189243 loss)
I1022 03:23:32.675892 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0168005 (* 1 = 0.0168005 loss)
I1022 03:23:32.675907 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000825338 (* 1 = 0.000825338 loss)
I1022 03:23:32.675921 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.72444e-05 (* 1 = 4.72444e-05 loss)
I1022 03:23:32.675932 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.06383 (* 1 = 0.06383 loss)
I1022 03:23:32.675946 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00330396 (* 1 = 0.00330396 loss)
I1022 03:23:32.675957 25759 sgd_solver.cpp:106] Iteration 3540, lr = 0.002
I1022 03:24:57.430635 25759 solver.cpp:228] Iteration 3560, loss = 0.0824077
I1022 03:24:57.430673 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 03:24:57.430680 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:24:57.430687 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:24:57.430693 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:24:57.430699 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0108496 (* 1 = 0.0108496 loss)
I1022 03:24:57.430706 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0056345 (* 1 = 0.0056345 loss)
I1022 03:24:57.430711 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000618557 (* 1 = 0.000618557 loss)
I1022 03:24:57.430717 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.90471e-05 (* 1 = 1.90471e-05 loss)
I1022 03:24:57.430723 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00717263 (* 1 = 0.00717263 loss)
I1022 03:24:57.430729 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00171988 (* 1 = 0.00171988 loss)
I1022 03:24:57.430735 25759 sgd_solver.cpp:106] Iteration 3560, lr = 0.002
I1022 03:26:24.250262 25759 solver.cpp:228] Iteration 3580, loss = 0.0997278
I1022 03:26:24.250316 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:26:24.250324 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:26:24.250331 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:26:24.250340 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:26:24.250345 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0051511 (* 1 = 0.0051511 loss)
I1022 03:26:24.250352 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00467645 (* 1 = 0.00467645 loss)
I1022 03:26:24.250358 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000114687 (* 1 = 0.000114687 loss)
I1022 03:26:24.250365 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.81334e-05 (* 1 = 1.81334e-05 loss)
I1022 03:26:24.250371 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00413095 (* 1 = 0.00413095 loss)
I1022 03:26:24.250377 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000736414 (* 1 = 0.000736414 loss)
I1022 03:26:24.250385 25759 sgd_solver.cpp:106] Iteration 3580, lr = 0.002
speed: 4.202s / iter
I1022 03:27:50.236984 25759 solver.cpp:228] Iteration 3600, loss = 0.150439
I1022 03:27:50.237048 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 03:27:50.237054 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 03:27:50.237061 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0271147 (* 1 = 0.0271147 loss)
I1022 03:27:50.237068 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0375374 (* 1 = 0.0375374 loss)
I1022 03:27:50.237072 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0133655 (* 1 = 0.0133655 loss)
I1022 03:27:50.237077 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0153462 (* 1 = 0.0153462 loss)
I1022 03:27:50.237082 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000415636 (* 1 = 0.000415636 loss)
I1022 03:27:50.237087 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.9384e-05 (* 1 = 2.9384e-05 loss)
I1022 03:27:50.237092 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00763868 (* 1 = 0.00763868 loss)
I1022 03:27:50.237097 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00235432 (* 1 = 0.00235432 loss)
I1022 03:27:50.237102 25759 sgd_solver.cpp:106] Iteration 3600, lr = 0.002
I1022 03:29:17.178794 25759 solver.cpp:228] Iteration 3620, loss = 0.258097
I1022 03:29:17.178833 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991508
I1022 03:29:17.178838 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994006
I1022 03:29:17.178848 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0616479 (* 1 = 0.0616479 loss)
I1022 03:29:17.178854 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0614438 (* 1 = 0.0614438 loss)
I1022 03:29:17.178859 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.026527 (* 1 = 0.026527 loss)
I1022 03:29:17.178865 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0198872 (* 1 = 0.0198872 loss)
I1022 03:29:17.178871 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000286181 (* 1 = 0.000286181 loss)
I1022 03:29:17.178877 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.53709e-05 (* 1 = 1.53709e-05 loss)
I1022 03:29:17.178884 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0405489 (* 1 = 0.0405489 loss)
I1022 03:29:17.178889 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0076578 (* 1 = 0.0076578 loss)
I1022 03:29:17.178900 25759 sgd_solver.cpp:106] Iteration 3620, lr = 0.002
I1022 03:30:43.285392 25759 solver.cpp:228] Iteration 3640, loss = 0.209002
I1022 03:30:43.285435 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:30:43.285450 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:30:43.285459 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:30:43.285466 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:30:43.285473 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00457963 (* 1 = 0.00457963 loss)
I1022 03:30:43.285480 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00469411 (* 1 = 0.00469411 loss)
I1022 03:30:43.285485 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000120309 (* 1 = 0.000120309 loss)
I1022 03:30:43.285492 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.59487e-05 (* 1 = 1.59487e-05 loss)
I1022 03:30:43.285498 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0123165 (* 1 = 0.0123165 loss)
I1022 03:30:43.285506 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00565551 (* 1 = 0.00565551 loss)
I1022 03:30:43.285516 25759 sgd_solver.cpp:106] Iteration 3640, lr = 0.002
I1022 03:32:08.506546 25759 solver.cpp:228] Iteration 3660, loss = 0.220801
I1022 03:32:08.506592 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.983766
I1022 03:32:08.506599 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.987013
I1022 03:32:08.506609 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0565026 (* 1 = 0.0565026 loss)
I1022 03:32:08.506616 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0773575 (* 1 = 0.0773575 loss)
I1022 03:32:08.506623 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.036879 (* 1 = 0.036879 loss)
I1022 03:32:08.506629 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0354321 (* 1 = 0.0354321 loss)
I1022 03:32:08.506636 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0227255 (* 1 = 0.0227255 loss)
I1022 03:32:08.506644 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.45358e-05 (* 1 = 3.45358e-05 loss)
I1022 03:32:08.506649 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.412018 (* 1 = 0.412018 loss)
I1022 03:32:08.506657 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00145285 (* 1 = 0.00145285 loss)
I1022 03:32:08.506665 25759 sgd_solver.cpp:106] Iteration 3660, lr = 0.002
I1022 03:33:35.298183 25759 solver.cpp:228] Iteration 3680, loss = 0.127691
I1022 03:33:35.298230 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993003
I1022 03:33:35.298238 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995003
I1022 03:33:35.298249 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0103588 (* 1 = 0.0103588 loss)
I1022 03:33:35.298256 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0352445 (* 1 = 0.0352445 loss)
I1022 03:33:35.298264 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0179956 (* 1 = 0.0179956 loss)
I1022 03:33:35.298270 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0136249 (* 1 = 0.0136249 loss)
I1022 03:33:35.298277 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00093588 (* 1 = 0.00093588 loss)
I1022 03:33:35.298285 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.9884e-06 (* 1 = 9.9884e-06 loss)
I1022 03:33:35.298291 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0139573 (* 1 = 0.0139573 loss)
I1022 03:33:35.298298 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0036476 (* 1 = 0.0036476 loss)
I1022 03:33:35.298310 25759 sgd_solver.cpp:106] Iteration 3680, lr = 0.002
I1022 03:35:00.288645 25759 solver.cpp:228] Iteration 3700, loss = 0.180579
I1022 03:35:00.288687 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:35:00.288705 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:35:00.288715 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:35:00.288723 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:35:00.288731 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00628137 (* 1 = 0.00628137 loss)
I1022 03:35:00.288739 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00515338 (* 1 = 0.00515338 loss)
I1022 03:35:00.288748 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000188689 (* 1 = 0.000188689 loss)
I1022 03:35:00.288755 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.49967e-05 (* 1 = 2.49967e-05 loss)
I1022 03:35:00.288763 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00618088 (* 1 = 0.00618088 loss)
I1022 03:35:00.288771 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00472768 (* 1 = 0.00472768 loss)
I1022 03:35:00.288789 25759 sgd_solver.cpp:106] Iteration 3700, lr = 0.002
I1022 03:36:25.212811 25759 solver.cpp:228] Iteration 3720, loss = 0.139211
I1022 03:36:25.212859 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988517
I1022 03:36:25.212864 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990015
I1022 03:36:25.212872 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0451916 (* 1 = 0.0451916 loss)
I1022 03:36:25.212877 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0994969 (* 1 = 0.0994969 loss)
I1022 03:36:25.212882 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0325061 (* 1 = 0.0325061 loss)
I1022 03:36:25.212887 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.029321 (* 1 = 0.029321 loss)
I1022 03:36:25.212890 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00266363 (* 1 = 0.00266363 loss)
I1022 03:36:25.212895 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.61822e-05 (* 1 = 1.61822e-05 loss)
I1022 03:36:25.212900 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0482138 (* 1 = 0.0482138 loss)
I1022 03:36:25.212905 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00311341 (* 1 = 0.00311341 loss)
I1022 03:36:25.212911 25759 sgd_solver.cpp:106] Iteration 3720, lr = 0.002
I1022 03:37:45.978492 25759 solver.cpp:228] Iteration 3740, loss = 0.303824
I1022 03:37:45.978530 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 03:37:45.978536 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 03:37:45.978545 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0170599 (* 1 = 0.0170599 loss)
I1022 03:37:45.978552 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0171581 (* 1 = 0.0171581 loss)
I1022 03:37:45.978559 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0100958 (* 1 = 0.0100958 loss)
I1022 03:37:45.978566 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0102256 (* 1 = 0.0102256 loss)
I1022 03:37:45.978572 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000113112 (* 1 = 0.000113112 loss)
I1022 03:37:45.978579 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.88288e-06 (* 1 = 5.88288e-06 loss)
I1022 03:37:45.978585 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00732643 (* 1 = 0.00732643 loss)
I1022 03:37:45.978590 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00642388 (* 1 = 0.00642388 loss)
I1022 03:37:45.978597 25759 sgd_solver.cpp:106] Iteration 3740, lr = 0.002
I1022 03:39:11.150187 25759 solver.cpp:228] Iteration 3760, loss = 0.116111
I1022 03:39:11.150241 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 03:39:11.150246 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 03:39:11.150254 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0114233 (* 1 = 0.0114233 loss)
I1022 03:39:11.150260 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00934291 (* 1 = 0.00934291 loss)
I1022 03:39:11.150264 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00926761 (* 1 = 0.00926761 loss)
I1022 03:39:11.150269 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00919093 (* 1 = 0.00919093 loss)
I1022 03:39:11.150274 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000136131 (* 1 = 0.000136131 loss)
I1022 03:39:11.150279 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.04836e-06 (* 1 = 7.04836e-06 loss)
I1022 03:39:11.150283 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0399953 (* 1 = 0.0399953 loss)
I1022 03:39:11.150287 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0073491 (* 1 = 0.0073491 loss)
I1022 03:39:11.150295 25759 sgd_solver.cpp:106] Iteration 3760, lr = 0.002
I1022 03:40:34.562176 25759 solver.cpp:228] Iteration 3780, loss = 0.0975866
I1022 03:40:34.562209 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991009
I1022 03:40:34.562213 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 03:40:34.562222 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0376986 (* 1 = 0.0376986 loss)
I1022 03:40:34.562227 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0188564 (* 1 = 0.0188564 loss)
I1022 03:40:34.562230 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0214221 (* 1 = 0.0214221 loss)
I1022 03:40:34.562235 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0160102 (* 1 = 0.0160102 loss)
I1022 03:40:34.562239 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0010674 (* 1 = 0.0010674 loss)
I1022 03:40:34.562243 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.08637e-05 (* 1 = 1.08637e-05 loss)
I1022 03:40:34.562248 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0451833 (* 1 = 0.0451833 loss)
I1022 03:40:34.562252 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000349783 (* 1 = 0.000349783 loss)
I1022 03:40:34.562258 25759 sgd_solver.cpp:106] Iteration 3780, lr = 0.002
speed: 4.204s / iter
I1022 03:42:01.068608 25759 solver.cpp:228] Iteration 3800, loss = 0.0851273
I1022 03:42:01.068702 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:42:01.068716 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:42:01.068735 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:42:01.068748 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:42:01.068761 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00497222 (* 1 = 0.00497222 loss)
I1022 03:42:01.068778 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00417076 (* 1 = 0.00417076 loss)
I1022 03:42:01.068794 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.48712e-05 (* 1 = 5.48712e-05 loss)
I1022 03:42:01.068809 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.39537e-06 (* 1 = 9.39537e-06 loss)
I1022 03:42:01.068822 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0202539 (* 1 = 0.0202539 loss)
I1022 03:42:01.068837 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00140219 (* 1 = 0.00140219 loss)
I1022 03:42:01.068859 25759 sgd_solver.cpp:106] Iteration 3800, lr = 0.002
I1022 03:43:26.649096 25759 solver.cpp:228] Iteration 3820, loss = 0.0730376
I1022 03:43:26.649163 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:43:26.649174 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:43:26.649189 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:43:26.649201 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:43:26.649214 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00495102 (* 1 = 0.00495102 loss)
I1022 03:43:26.649224 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00459603 (* 1 = 0.00459603 loss)
I1022 03:43:26.649240 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.47577e-05 (* 1 = 5.47577e-05 loss)
I1022 03:43:26.649252 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.10258e-05 (* 1 = 1.10258e-05 loss)
I1022 03:43:26.649263 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00116393 (* 1 = 0.00116393 loss)
I1022 03:43:26.649276 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00191156 (* 1 = 0.00191156 loss)
I1022 03:43:26.649291 25759 sgd_solver.cpp:106] Iteration 3820, lr = 0.002
I1022 03:44:50.608696 25759 solver.cpp:228] Iteration 3840, loss = 0.156603
I1022 03:44:50.608744 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991504
I1022 03:44:50.608750 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 03:44:50.608757 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0200267 (* 1 = 0.0200267 loss)
I1022 03:44:50.608765 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0222675 (* 1 = 0.0222675 loss)
I1022 03:44:50.608769 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0204863 (* 1 = 0.0204863 loss)
I1022 03:44:50.608774 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0122977 (* 1 = 0.0122977 loss)
I1022 03:44:50.608778 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000118695 (* 1 = 0.000118695 loss)
I1022 03:44:50.608784 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.98516e-05 (* 1 = 1.98516e-05 loss)
I1022 03:44:50.608789 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0117095 (* 1 = 0.0117095 loss)
I1022 03:44:50.608793 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00203619 (* 1 = 0.00203619 loss)
I1022 03:44:50.608801 25759 sgd_solver.cpp:106] Iteration 3840, lr = 0.002
I1022 03:46:14.066548 25759 solver.cpp:228] Iteration 3860, loss = 0.184903
I1022 03:46:14.066624 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:46:14.066635 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:46:14.066649 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:46:14.066673 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:46:14.066684 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0043583 (* 1 = 0.0043583 loss)
I1022 03:46:14.066699 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00454053 (* 1 = 0.00454053 loss)
I1022 03:46:14.066710 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00159398 (* 1 = 0.00159398 loss)
I1022 03:46:14.066725 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.09363e-05 (* 1 = 1.09363e-05 loss)
I1022 03:46:14.066736 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00934344 (* 1 = 0.00934344 loss)
I1022 03:46:14.066749 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0044821 (* 1 = 0.0044821 loss)
I1022 03:46:14.066761 25759 sgd_solver.cpp:106] Iteration 3860, lr = 0.002
I1022 03:47:39.737512 25759 solver.cpp:228] Iteration 3880, loss = 0.121485
I1022 03:47:39.737550 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990505
I1022 03:47:39.737557 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 03:47:39.737566 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0382826 (* 1 = 0.0382826 loss)
I1022 03:47:39.737573 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0152963 (* 1 = 0.0152963 loss)
I1022 03:47:39.737578 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0198873 (* 1 = 0.0198873 loss)
I1022 03:47:39.737584 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0146875 (* 1 = 0.0146875 loss)
I1022 03:47:39.737591 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000252856 (* 1 = 0.000252856 loss)
I1022 03:47:39.737596 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.84162e-05 (* 1 = 1.84162e-05 loss)
I1022 03:47:39.737602 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0236136 (* 1 = 0.0236136 loss)
I1022 03:47:39.737608 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00152691 (* 1 = 0.00152691 loss)
I1022 03:47:39.737615 25759 sgd_solver.cpp:106] Iteration 3880, lr = 0.002
I1022 03:49:05.276902 25759 solver.cpp:228] Iteration 3900, loss = 0.19299
I1022 03:49:05.276937 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:49:05.276942 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:49:05.276947 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:49:05.276952 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:49:05.276957 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00490205 (* 1 = 0.00490205 loss)
I1022 03:49:05.276960 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00478915 (* 1 = 0.00478915 loss)
I1022 03:49:05.276964 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.892e-05 (* 1 = 4.892e-05 loss)
I1022 03:49:05.276969 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.60261e-05 (* 1 = 1.60261e-05 loss)
I1022 03:49:05.276974 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00436277 (* 1 = 0.00436277 loss)
I1022 03:49:05.276979 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0011273 (* 1 = 0.0011273 loss)
I1022 03:49:05.276988 25759 sgd_solver.cpp:106] Iteration 3900, lr = 0.002
I1022 03:50:30.881909 25759 solver.cpp:228] Iteration 3920, loss = 0.235526
I1022 03:50:30.881963 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988965
I1022 03:50:30.881968 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.988018
I1022 03:50:30.881974 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.142192 (* 1 = 0.142192 loss)
I1022 03:50:30.881980 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0659059 (* 1 = 0.0659059 loss)
I1022 03:50:30.881984 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.03241 (* 1 = 0.03241 loss)
I1022 03:50:30.881989 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0357382 (* 1 = 0.0357382 loss)
I1022 03:50:30.881994 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00959595 (* 1 = 0.00959595 loss)
I1022 03:50:30.881999 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.45724e-05 (* 1 = 8.45724e-05 loss)
I1022 03:50:30.882004 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.243285 (* 1 = 0.243285 loss)
I1022 03:50:30.882009 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00589454 (* 1 = 0.00589454 loss)
I1022 03:50:30.882016 25759 sgd_solver.cpp:106] Iteration 3920, lr = 0.002
I1022 03:51:55.659490 25759 solver.cpp:228] Iteration 3940, loss = 0.213845
I1022 03:51:55.659529 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 03:51:55.659536 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:51:55.659545 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:51:55.659552 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:51:55.659559 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0106783 (* 1 = 0.0106783 loss)
I1022 03:51:55.659565 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00636728 (* 1 = 0.00636728 loss)
I1022 03:51:55.659572 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.07567e-05 (* 1 = 6.07567e-05 loss)
I1022 03:51:55.659579 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.45318e-05 (* 1 = 1.45318e-05 loss)
I1022 03:51:55.659585 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00486521 (* 1 = 0.00486521 loss)
I1022 03:51:55.659591 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00981004 (* 1 = 0.00981004 loss)
I1022 03:51:55.659598 25759 sgd_solver.cpp:106] Iteration 3940, lr = 0.002
I1022 03:53:22.241063 25759 solver.cpp:228] Iteration 3960, loss = 0.191832
I1022 03:53:22.241111 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:53:22.241123 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:53:22.241132 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:53:22.241138 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:53:22.241144 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00458301 (* 1 = 0.00458301 loss)
I1022 03:53:22.241150 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00421756 (* 1 = 0.00421756 loss)
I1022 03:53:22.241156 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000109064 (* 1 = 0.000109064 loss)
I1022 03:53:22.241163 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.20892e-05 (* 1 = 3.20892e-05 loss)
I1022 03:53:22.241168 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00452002 (* 1 = 0.00452002 loss)
I1022 03:53:22.241175 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00482909 (* 1 = 0.00482909 loss)
I1022 03:53:22.241183 25759 sgd_solver.cpp:106] Iteration 3960, lr = 0.002
I1022 03:54:48.569793 25759 solver.cpp:228] Iteration 3980, loss = 0.142097
I1022 03:54:48.569846 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993007
I1022 03:54:48.569855 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994006
I1022 03:54:48.569869 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0285593 (* 1 = 0.0285593 loss)
I1022 03:54:48.569880 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0751772 (* 1 = 0.0751772 loss)
I1022 03:54:48.569887 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0244902 (* 1 = 0.0244902 loss)
I1022 03:54:48.569896 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.020556 (* 1 = 0.020556 loss)
I1022 03:54:48.569905 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000608187 (* 1 = 0.000608187 loss)
I1022 03:54:48.569916 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.07672e-05 (* 1 = 2.07672e-05 loss)
I1022 03:54:48.569931 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0322555 (* 1 = 0.0322555 loss)
I1022 03:54:48.569941 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00349485 (* 1 = 0.00349485 loss)
I1022 03:54:48.569952 25759 sgd_solver.cpp:106] Iteration 3980, lr = 0.002
speed: 4.208s / iter
bbbb
aaaa
Wrote snapshot to: /home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_4000.caffemodel
I1022 03:56:15.142875 25759 solver.cpp:228] Iteration 4000, loss = 0.0543339
I1022 03:56:15.142935 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 03:56:15.142943 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 03:56:15.142954 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 03:56:15.142961 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 03:56:15.142968 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00642649 (* 1 = 0.00642649 loss)
I1022 03:56:15.142976 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00494312 (* 1 = 0.00494312 loss)
I1022 03:56:15.142982 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000689359 (* 1 = 0.000689359 loss)
I1022 03:56:15.142990 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.06717e-05 (* 1 = 2.06717e-05 loss)
I1022 03:56:15.142997 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00846514 (* 1 = 0.00846514 loss)
I1022 03:56:15.143003 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000882906 (* 1 = 0.000882906 loss)
I1022 03:56:15.143018 25759 sgd_solver.cpp:106] Iteration 4000, lr = 0.002
I1022 03:57:40.116642 25759 solver.cpp:228] Iteration 4020, loss = 0.160554
I1022 03:57:40.116721 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993503
I1022 03:57:40.116744 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 03:57:40.116760 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0150074 (* 1 = 0.0150074 loss)
I1022 03:57:40.116773 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0140978 (* 1 = 0.0140978 loss)
I1022 03:57:40.116783 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0215684 (* 1 = 0.0215684 loss)
I1022 03:57:40.116793 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0130431 (* 1 = 0.0130431 loss)
I1022 03:57:40.116808 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00335607 (* 1 = 0.00335607 loss)
I1022 03:57:40.116822 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.49464e-05 (* 1 = 2.49464e-05 loss)
I1022 03:57:40.116833 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.126432 (* 1 = 0.126432 loss)
I1022 03:57:40.116845 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0025875 (* 1 = 0.0025875 loss)
I1022 03:57:40.116858 25759 sgd_solver.cpp:106] Iteration 4020, lr = 0.002
I1022 03:59:04.512290 25759 solver.cpp:228] Iteration 4040, loss = 0.178678
I1022 03:59:04.512339 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989016
I1022 03:59:04.512344 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990015
I1022 03:59:04.512353 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.041992 (* 1 = 0.041992 loss)
I1022 03:59:04.512358 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0498432 (* 1 = 0.0498432 loss)
I1022 03:59:04.512362 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0374465 (* 1 = 0.0374465 loss)
I1022 03:59:04.512367 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0318741 (* 1 = 0.0318741 loss)
I1022 03:59:04.512372 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00485821 (* 1 = 0.00485821 loss)
I1022 03:59:04.512377 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.65993e-05 (* 1 = 1.65993e-05 loss)
I1022 03:59:04.512383 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0671546 (* 1 = 0.0671546 loss)
I1022 03:59:04.512389 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00655202 (* 1 = 0.00655202 loss)
I1022 03:59:04.512398 25759 sgd_solver.cpp:106] Iteration 4040, lr = 0.002
I1022 04:00:30.165644 25759 solver.cpp:228] Iteration 4060, loss = 0.0794769
I1022 04:00:30.165690 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.987512
I1022 04:00:30.165700 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993506
I1022 04:00:30.165714 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0241727 (* 1 = 0.0241727 loss)
I1022 04:00:30.165722 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0143536 (* 1 = 0.0143536 loss)
I1022 04:00:30.165731 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0311152 (* 1 = 0.0311152 loss)
I1022 04:00:30.165740 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0199336 (* 1 = 0.0199336 loss)
I1022 04:00:30.165748 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0332333 (* 1 = 0.0332333 loss)
I1022 04:00:30.165758 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.52108e-05 (* 1 = 1.52108e-05 loss)
I1022 04:00:30.165771 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0695462 (* 1 = 0.0695462 loss)
I1022 04:00:30.165782 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00412464 (* 1 = 0.00412464 loss)
I1022 04:00:30.165793 25759 sgd_solver.cpp:106] Iteration 4060, lr = 0.002
I1022 04:01:55.470052 25759 solver.cpp:228] Iteration 4080, loss = 0.176218
I1022 04:01:55.470090 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993503
I1022 04:01:55.470096 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 04:01:55.470106 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0554686 (* 1 = 0.0554686 loss)
I1022 04:01:55.470113 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0132052 (* 1 = 0.0132052 loss)
I1022 04:01:55.470119 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0185678 (* 1 = 0.0185678 loss)
I1022 04:01:55.470124 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00779436 (* 1 = 0.00779436 loss)
I1022 04:01:55.470130 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00187233 (* 1 = 0.00187233 loss)
I1022 04:01:55.470137 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.78796e-06 (* 1 = 4.78796e-06 loss)
I1022 04:01:55.470142 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0266041 (* 1 = 0.0266041 loss)
I1022 04:01:55.470149 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0156539 (* 1 = 0.0156539 loss)
I1022 04:01:55.470155 25759 sgd_solver.cpp:106] Iteration 4080, lr = 0.002
I1022 04:03:17.332463 25759 solver.cpp:228] Iteration 4100, loss = 0.40658
I1022 04:03:17.332495 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.984539
I1022 04:03:17.332500 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.987531
I1022 04:03:17.332507 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.140264 (* 1 = 0.140264 loss)
I1022 04:03:17.332512 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.127197 (* 1 = 0.127197 loss)
I1022 04:03:17.332516 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.057378 (* 1 = 0.057378 loss)
I1022 04:03:17.332520 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0428509 (* 1 = 0.0428509 loss)
I1022 04:03:17.332525 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00196863 (* 1 = 0.00196863 loss)
I1022 04:03:17.332530 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.10267e-05 (* 1 = 1.10267e-05 loss)
I1022 04:03:17.332535 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.127429 (* 1 = 0.127429 loss)
I1022 04:03:17.332538 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00160965 (* 1 = 0.00160965 loss)
I1022 04:03:17.332545 25759 sgd_solver.cpp:106] Iteration 4100, lr = 0.002
I1022 04:04:39.705982 25759 solver.cpp:228] Iteration 4120, loss = 0.17811
I1022 04:04:39.706014 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:04:39.706019 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:04:39.706027 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:04:39.706030 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:04:39.706035 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00450606 (* 1 = 0.00450606 loss)
I1022 04:04:39.706039 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0047018 (* 1 = 0.0047018 loss)
I1022 04:04:39.706044 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.07205e-05 (* 1 = 7.07205e-05 loss)
I1022 04:04:39.706049 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.22105e-05 (* 1 = 1.22105e-05 loss)
I1022 04:04:39.706054 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0123018 (* 1 = 0.0123018 loss)
I1022 04:04:39.706058 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00107676 (* 1 = 0.00107676 loss)
I1022 04:04:39.706068 25759 sgd_solver.cpp:106] Iteration 4120, lr = 0.002
I1022 04:06:03.864480 25759 solver.cpp:228] Iteration 4140, loss = 0.175374
I1022 04:06:03.864537 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:06:03.864543 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:06:03.864552 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:06:03.864557 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:06:03.864562 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00457628 (* 1 = 0.00457628 loss)
I1022 04:06:03.864567 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00409204 (* 1 = 0.00409204 loss)
I1022 04:06:03.864572 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000139211 (* 1 = 0.000139211 loss)
I1022 04:06:03.864578 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.28938e-05 (* 1 = 1.28938e-05 loss)
I1022 04:06:03.864581 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00536926 (* 1 = 0.00536926 loss)
I1022 04:06:03.864588 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0104857 (* 1 = 0.0104857 loss)
I1022 04:06:03.864593 25759 sgd_solver.cpp:106] Iteration 4140, lr = 0.002
I1022 04:07:28.017537 25759 solver.cpp:228] Iteration 4160, loss = 0.302367
I1022 04:07:28.017590 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:07:28.017596 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:07:28.017606 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:07:28.017614 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:07:28.017621 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00481076 (* 1 = 0.00481076 loss)
I1022 04:07:28.017627 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00412246 (* 1 = 0.00412246 loss)
I1022 04:07:28.017632 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000384152 (* 1 = 0.000384152 loss)
I1022 04:07:28.017639 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.23412e-05 (* 1 = 5.23412e-05 loss)
I1022 04:07:28.017645 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00962048 (* 1 = 0.00962048 loss)
I1022 04:07:28.017652 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00052895 (* 1 = 0.00052895 loss)
I1022 04:07:28.017663 25759 sgd_solver.cpp:106] Iteration 4160, lr = 0.002
I1022 04:08:53.883539 25759 solver.cpp:228] Iteration 4180, loss = 0.184554
I1022 04:08:53.883576 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 04:08:53.883582 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:08:53.883591 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:08:53.883597 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:08:53.883603 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.006717 (* 1 = 0.006717 loss)
I1022 04:08:53.883610 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00444977 (* 1 = 0.00444977 loss)
I1022 04:08:53.883615 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.42275e-05 (* 1 = 6.42275e-05 loss)
I1022 04:08:53.883621 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.80375e-06 (* 1 = 8.80375e-06 loss)
I1022 04:08:53.883627 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00110505 (* 1 = 0.00110505 loss)
I1022 04:08:53.883633 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00913856 (* 1 = 0.00913856 loss)
I1022 04:08:53.883641 25759 sgd_solver.cpp:106] Iteration 4180, lr = 0.002
speed: 4.208s / iter
I1022 04:10:19.098201 25759 solver.cpp:228] Iteration 4200, loss = 0.254072
I1022 04:10:19.098261 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990015
I1022 04:10:19.098269 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990015
I1022 04:10:19.098281 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0831973 (* 1 = 0.0831973 loss)
I1022 04:10:19.098289 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.140614 (* 1 = 0.140614 loss)
I1022 04:10:19.098296 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0313533 (* 1 = 0.0313533 loss)
I1022 04:10:19.098304 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0263299 (* 1 = 0.0263299 loss)
I1022 04:10:19.098310 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0002044 (* 1 = 0.0002044 loss)
I1022 04:10:19.098320 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.27427e-05 (* 1 = 1.27427e-05 loss)
I1022 04:10:19.098335 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0329962 (* 1 = 0.0329962 loss)
I1022 04:10:19.098342 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00143412 (* 1 = 0.00143412 loss)
I1022 04:10:19.098351 25759 sgd_solver.cpp:106] Iteration 4200, lr = 0.002
I1022 04:11:43.109042 25759 solver.cpp:228] Iteration 4220, loss = 0.343178
I1022 04:11:43.109076 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.984462
I1022 04:11:43.109081 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.986527
I1022 04:11:43.109103 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.134458 (* 1 = 0.134458 loss)
I1022 04:11:43.109109 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.115368 (* 1 = 0.115368 loss)
I1022 04:11:43.109113 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.041517 (* 1 = 0.041517 loss)
I1022 04:11:43.109120 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0438111 (* 1 = 0.0438111 loss)
I1022 04:11:43.109124 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0167895 (* 1 = 0.0167895 loss)
I1022 04:11:43.109129 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.0657e-05 (* 1 = 1.0657e-05 loss)
I1022 04:11:43.109134 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.41855 (* 1 = 0.41855 loss)
I1022 04:11:43.109139 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00669724 (* 1 = 0.00669724 loss)
I1022 04:11:43.109148 25759 sgd_solver.cpp:106] Iteration 4220, lr = 0.002
I1022 04:13:08.126983 25759 solver.cpp:228] Iteration 4240, loss = 0.183007
I1022 04:13:08.127032 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.98951
I1022 04:13:08.127038 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991009
I1022 04:13:08.127045 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0447835 (* 1 = 0.0447835 loss)
I1022 04:13:08.127050 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0319973 (* 1 = 0.0319973 loss)
I1022 04:13:08.127054 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0235651 (* 1 = 0.0235651 loss)
I1022 04:13:08.127058 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0211637 (* 1 = 0.0211637 loss)
I1022 04:13:08.127063 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.002638 (* 1 = 0.002638 loss)
I1022 04:13:08.127068 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.42728e-05 (* 1 = 2.42728e-05 loss)
I1022 04:13:08.127072 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0692703 (* 1 = 0.0692703 loss)
I1022 04:13:08.127077 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00583854 (* 1 = 0.00583854 loss)
I1022 04:13:08.127082 25759 sgd_solver.cpp:106] Iteration 4240, lr = 0.002
I1022 04:14:31.727272 25759 solver.cpp:228] Iteration 4260, loss = 0.0576876
I1022 04:14:31.727326 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:14:31.727331 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:14:31.727339 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:14:31.727344 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:14:31.727349 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00464116 (* 1 = 0.00464116 loss)
I1022 04:14:31.727353 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00459867 (* 1 = 0.00459867 loss)
I1022 04:14:31.727357 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000144878 (* 1 = 0.000144878 loss)
I1022 04:14:31.727362 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.60203e-05 (* 1 = 1.60203e-05 loss)
I1022 04:14:31.727367 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00456049 (* 1 = 0.00456049 loss)
I1022 04:14:31.727372 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000755146 (* 1 = 0.000755146 loss)
I1022 04:14:31.727378 25759 sgd_solver.cpp:106] Iteration 4260, lr = 0.002
I1022 04:15:56.632807 25759 solver.cpp:228] Iteration 4280, loss = 0.161549
I1022 04:15:56.632845 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 04:15:56.632860 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 04:15:56.632870 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0357637 (* 1 = 0.0357637 loss)
I1022 04:15:56.632879 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0195101 (* 1 = 0.0195101 loss)
I1022 04:15:56.632884 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0152381 (* 1 = 0.0152381 loss)
I1022 04:15:56.632889 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00763081 (* 1 = 0.00763081 loss)
I1022 04:15:56.632895 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000366487 (* 1 = 0.000366487 loss)
I1022 04:15:56.632902 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.4148e-05 (* 1 = 2.4148e-05 loss)
I1022 04:15:56.632908 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.030914 (* 1 = 0.030914 loss)
I1022 04:15:56.632915 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0116338 (* 1 = 0.0116338 loss)
I1022 04:15:56.632931 25759 sgd_solver.cpp:106] Iteration 4280, lr = 0.002
I1022 04:17:21.504148 25759 solver.cpp:228] Iteration 4300, loss = 0.165008
I1022 04:17:21.504204 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.980682
I1022 04:17:21.504211 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.983042
I1022 04:17:21.504221 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.17461 (* 1 = 0.17461 loss)
I1022 04:17:21.504228 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.137582 (* 1 = 0.137582 loss)
I1022 04:17:21.504235 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0485059 (* 1 = 0.0485059 loss)
I1022 04:17:21.504240 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0550544 (* 1 = 0.0550544 loss)
I1022 04:17:21.504246 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0609398 (* 1 = 0.0609398 loss)
I1022 04:17:21.504253 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.10556e-05 (* 1 = 4.10556e-05 loss)
I1022 04:17:21.504259 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.338096 (* 1 = 0.338096 loss)
I1022 04:17:21.504266 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00835446 (* 1 = 0.00835446 loss)
I1022 04:17:21.504278 25759 sgd_solver.cpp:106] Iteration 4300, lr = 0.002
I1022 04:18:46.313601 25759 solver.cpp:228] Iteration 4320, loss = 0.2883
I1022 04:18:46.313668 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993506
I1022 04:18:46.313678 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 04:18:46.313695 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0384016 (* 1 = 0.0384016 loss)
I1022 04:18:46.313706 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.031336 (* 1 = 0.031336 loss)
I1022 04:18:46.313715 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0245122 (* 1 = 0.0245122 loss)
I1022 04:18:46.313724 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0164517 (* 1 = 0.0164517 loss)
I1022 04:18:46.313740 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00154165 (* 1 = 0.00154165 loss)
I1022 04:18:46.313751 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.68753e-05 (* 1 = 3.68753e-05 loss)
I1022 04:18:46.313762 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0214452 (* 1 = 0.0214452 loss)
I1022 04:18:46.313773 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00142188 (* 1 = 0.00142188 loss)
I1022 04:18:46.313783 25759 sgd_solver.cpp:106] Iteration 4320, lr = 0.002
I1022 04:20:09.318315 25759 solver.cpp:228] Iteration 4340, loss = 0.39066
I1022 04:20:09.318367 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992008
I1022 04:20:09.318372 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994006
I1022 04:20:09.318380 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0578232 (* 1 = 0.0578232 loss)
I1022 04:20:09.318385 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0879087 (* 1 = 0.0879087 loss)
I1022 04:20:09.318390 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0239164 (* 1 = 0.0239164 loss)
I1022 04:20:09.318394 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0195627 (* 1 = 0.0195627 loss)
I1022 04:20:09.318399 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0097455 (* 1 = 0.0097455 loss)
I1022 04:20:09.318404 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.71463e-06 (* 1 = 9.71463e-06 loss)
I1022 04:20:09.318409 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0232206 (* 1 = 0.0232206 loss)
I1022 04:20:09.318414 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00341244 (* 1 = 0.00341244 loss)
I1022 04:20:09.318419 25759 sgd_solver.cpp:106] Iteration 4340, lr = 0.002
I1022 04:21:30.355604 25759 solver.cpp:228] Iteration 4360, loss = 0.221032
I1022 04:21:30.355654 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 04:21:30.355659 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 04:21:30.355667 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.013692 (* 1 = 0.013692 loss)
I1022 04:21:30.355672 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.022663 (* 1 = 0.022663 loss)
I1022 04:21:30.355676 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0166968 (* 1 = 0.0166968 loss)
I1022 04:21:30.355680 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0122287 (* 1 = 0.0122287 loss)
I1022 04:21:30.355685 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000394808 (* 1 = 0.000394808 loss)
I1022 04:21:30.355690 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.80298e-05 (* 1 = 1.80298e-05 loss)
I1022 04:21:30.355695 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0371739 (* 1 = 0.0371739 loss)
I1022 04:21:30.355700 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00824465 (* 1 = 0.00824465 loss)
I1022 04:21:30.355708 25759 sgd_solver.cpp:106] Iteration 4360, lr = 0.002
I1022 04:22:54.326798 25759 solver.cpp:228] Iteration 4380, loss = 0.09743
I1022 04:22:54.326856 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:22:54.326861 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:22:54.326869 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:22:54.326874 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:22:54.326880 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00441444 (* 1 = 0.00441444 loss)
I1022 04:22:54.326885 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00442646 (* 1 = 0.00442646 loss)
I1022 04:22:54.326890 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000155258 (* 1 = 0.000155258 loss)
I1022 04:22:54.326895 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.28066e-05 (* 1 = 1.28066e-05 loss)
I1022 04:22:54.326900 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000365194 (* 1 = 0.000365194 loss)
I1022 04:22:54.326905 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00182001 (* 1 = 0.00182001 loss)
I1022 04:22:54.326912 25759 sgd_solver.cpp:106] Iteration 4380, lr = 0.002
speed: 4.208s / iter
I1022 04:24:18.875118 25759 solver.cpp:228] Iteration 4400, loss = 0.253577
I1022 04:24:18.875151 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991013
I1022 04:24:18.875156 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990015
I1022 04:24:18.875164 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.112254 (* 1 = 0.112254 loss)
I1022 04:24:18.875169 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.18236 (* 1 = 0.18236 loss)
I1022 04:24:18.875172 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.029287 (* 1 = 0.029287 loss)
I1022 04:24:18.875176 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0286524 (* 1 = 0.0286524 loss)
I1022 04:24:18.875180 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000714809 (* 1 = 0.000714809 loss)
I1022 04:24:18.875186 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.04255e-05 (* 1 = 7.04255e-05 loss)
I1022 04:24:18.875190 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0383616 (* 1 = 0.0383616 loss)
I1022 04:24:18.875195 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00762497 (* 1 = 0.00762497 loss)
I1022 04:24:18.875200 25759 sgd_solver.cpp:106] Iteration 4400, lr = 0.002
I1022 04:25:44.463912 25759 solver.cpp:228] Iteration 4420, loss = 0.208549
I1022 04:25:44.463951 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 04:25:44.463958 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 04:25:44.463968 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0133033 (* 1 = 0.0133033 loss)
I1022 04:25:44.463974 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0130925 (* 1 = 0.0130925 loss)
I1022 04:25:44.463979 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0103616 (* 1 = 0.0103616 loss)
I1022 04:25:44.463985 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00892202 (* 1 = 0.00892202 loss)
I1022 04:25:44.463991 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.62108e-05 (* 1 = 3.62108e-05 loss)
I1022 04:25:44.463997 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.26838e-05 (* 1 = 1.26838e-05 loss)
I1022 04:25:44.464004 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00439137 (* 1 = 0.00439137 loss)
I1022 04:25:44.464010 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000406087 (* 1 = 0.000406087 loss)
I1022 04:25:44.464016 25759 sgd_solver.cpp:106] Iteration 4420, lr = 0.002
I1022 04:27:08.524744 25759 solver.cpp:228] Iteration 4440, loss = 0.0990129
I1022 04:27:08.524792 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:27:08.524797 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:27:08.524803 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:27:08.524808 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:27:08.524813 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00457593 (* 1 = 0.00457593 loss)
I1022 04:27:08.524818 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450954 (* 1 = 0.00450954 loss)
I1022 04:27:08.524823 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.04481e-05 (* 1 = 9.04481e-05 loss)
I1022 04:27:08.524827 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.3816e-05 (* 1 = 2.3816e-05 loss)
I1022 04:27:08.524832 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0162107 (* 1 = 0.0162107 loss)
I1022 04:27:08.524837 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00120694 (* 1 = 0.00120694 loss)
I1022 04:27:08.524842 25759 sgd_solver.cpp:106] Iteration 4440, lr = 0.002
I1022 04:28:31.770756 25759 solver.cpp:228] Iteration 4460, loss = 0.191051
I1022 04:28:31.770828 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 04:28:31.770839 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995502
I1022 04:28:31.770854 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0154404 (* 1 = 0.0154404 loss)
I1022 04:28:31.770865 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0180929 (* 1 = 0.0180929 loss)
I1022 04:28:31.770875 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.021419 (* 1 = 0.021419 loss)
I1022 04:28:31.770885 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0133878 (* 1 = 0.0133878 loss)
I1022 04:28:31.770895 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000601765 (* 1 = 0.000601765 loss)
I1022 04:28:31.770906 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.7673e-05 (* 1 = 3.7673e-05 loss)
I1022 04:28:31.770936 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0170466 (* 1 = 0.0170466 loss)
I1022 04:28:31.770947 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.003781 (* 1 = 0.003781 loss)
I1022 04:28:31.770959 25759 sgd_solver.cpp:106] Iteration 4460, lr = 0.002
I1022 04:29:58.800644 25759 solver.cpp:228] Iteration 4480, loss = 0.384295
I1022 04:29:58.800683 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989924
I1022 04:29:58.800689 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991018
I1022 04:29:58.800698 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.116977 (* 1 = 0.116977 loss)
I1022 04:29:58.800705 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.090455 (* 1 = 0.090455 loss)
I1022 04:29:58.800711 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0280221 (* 1 = 0.0280221 loss)
I1022 04:29:58.800716 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0331126 (* 1 = 0.0331126 loss)
I1022 04:29:58.800722 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00155561 (* 1 = 0.00155561 loss)
I1022 04:29:58.800729 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.17324e-05 (* 1 = 3.17324e-05 loss)
I1022 04:29:58.800735 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.080909 (* 1 = 0.080909 loss)
I1022 04:29:58.800741 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00347003 (* 1 = 0.00347003 loss)
I1022 04:29:58.800748 25759 sgd_solver.cpp:106] Iteration 4480, lr = 0.002
I1022 04:31:24.693688 25759 solver.cpp:228] Iteration 4500, loss = 0.0952029
I1022 04:31:24.693773 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996824
I1022 04:31:24.693785 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 04:31:24.693804 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0164583 (* 1 = 0.0164583 loss)
I1022 04:31:24.693816 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0056517 (* 1 = 0.0056517 loss)
I1022 04:31:24.693828 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00931309 (* 1 = 0.00931309 loss)
I1022 04:31:24.693842 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0108003 (* 1 = 0.0108003 loss)
I1022 04:31:24.693856 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0005202 (* 1 = 0.0005202 loss)
I1022 04:31:24.693871 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.66617e-05 (* 1 = 2.66617e-05 loss)
I1022 04:31:24.693884 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0270263 (* 1 = 0.0270263 loss)
I1022 04:31:24.693897 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00755106 (* 1 = 0.00755106 loss)
I1022 04:31:24.693918 25759 sgd_solver.cpp:106] Iteration 4500, lr = 0.002
I1022 04:32:47.919395 25759 solver.cpp:228] Iteration 4520, loss = 0.269896
I1022 04:32:47.919446 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.98392
I1022 04:32:47.919451 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991009
I1022 04:32:47.919459 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0444084 (* 1 = 0.0444084 loss)
I1022 04:32:47.919466 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0362597 (* 1 = 0.0362597 loss)
I1022 04:32:47.919471 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0377092 (* 1 = 0.0377092 loss)
I1022 04:32:47.919474 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0289841 (* 1 = 0.0289841 loss)
I1022 04:32:47.919479 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0124268 (* 1 = 0.0124268 loss)
I1022 04:32:47.919484 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.14124e-05 (* 1 = 8.14124e-05 loss)
I1022 04:32:47.919488 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.223957 (* 1 = 0.223957 loss)
I1022 04:32:47.919493 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00090501 (* 1 = 0.00090501 loss)
I1022 04:32:47.919499 25759 sgd_solver.cpp:106] Iteration 4520, lr = 0.002
I1022 04:34:12.857596 25759 solver.cpp:228] Iteration 4540, loss = 0.101957
I1022 04:34:12.857635 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:34:12.857641 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:34:12.857650 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:34:12.857656 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:34:12.857661 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0043504 (* 1 = 0.0043504 loss)
I1022 04:34:12.857667 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00470088 (* 1 = 0.00470088 loss)
I1022 04:34:12.857673 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.74571e-05 (* 1 = 6.74571e-05 loss)
I1022 04:34:12.857679 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.00555e-05 (* 1 = 2.00555e-05 loss)
I1022 04:34:12.857684 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00337962 (* 1 = 0.00337962 loss)
I1022 04:34:12.857690 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0018614 (* 1 = 0.0018614 loss)
I1022 04:34:12.857697 25759 sgd_solver.cpp:106] Iteration 4540, lr = 0.002
I1022 04:35:36.031093 25759 solver.cpp:228] Iteration 4560, loss = 0.169772
I1022 04:35:36.031146 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:35:36.031157 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:35:36.031170 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:35:36.031181 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:35:36.031193 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00443627 (* 1 = 0.00443627 loss)
I1022 04:35:36.031203 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00465702 (* 1 = 0.00465702 loss)
I1022 04:35:36.031213 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.4169e-05 (* 1 = 8.4169e-05 loss)
I1022 04:35:36.031226 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.16502e-05 (* 1 = 1.16502e-05 loss)
I1022 04:35:36.031239 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00315113 (* 1 = 0.00315113 loss)
I1022 04:35:36.031250 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00453471 (* 1 = 0.00453471 loss)
I1022 04:35:36.031261 25759 sgd_solver.cpp:106] Iteration 4560, lr = 0.002
I1022 04:37:00.116478 25759 solver.cpp:228] Iteration 4580, loss = 0.152987
I1022 04:37:00.116518 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 04:37:00.116525 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 04:37:00.116534 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00748998 (* 1 = 0.00748998 loss)
I1022 04:37:00.116541 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0115075 (* 1 = 0.0115075 loss)
I1022 04:37:00.116547 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0118162 (* 1 = 0.0118162 loss)
I1022 04:37:00.116554 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00764233 (* 1 = 0.00764233 loss)
I1022 04:37:00.116559 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000167494 (* 1 = 0.000167494 loss)
I1022 04:37:00.116566 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.25583e-05 (* 1 = 2.25583e-05 loss)
I1022 04:37:00.116571 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0345852 (* 1 = 0.0345852 loss)
I1022 04:37:00.116577 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000367633 (* 1 = 0.000367633 loss)
I1022 04:37:00.116585 25759 sgd_solver.cpp:106] Iteration 4580, lr = 0.002
speed: 4.208s / iter
I1022 04:38:22.309653 25759 solver.cpp:228] Iteration 4600, loss = 0.0887391
I1022 04:38:22.309705 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 04:38:22.309716 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 04:38:22.309731 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.013163 (* 1 = 0.013163 loss)
I1022 04:38:22.309742 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.017951 (* 1 = 0.017951 loss)
I1022 04:38:22.309752 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0134634 (* 1 = 0.0134634 loss)
I1022 04:38:22.309780 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00959928 (* 1 = 0.00959928 loss)
I1022 04:38:22.309792 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000255562 (* 1 = 0.000255562 loss)
I1022 04:38:22.309805 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.99389e-05 (* 1 = 1.99389e-05 loss)
I1022 04:38:22.309818 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0594011 (* 1 = 0.0594011 loss)
I1022 04:38:22.309830 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00678242 (* 1 = 0.00678242 loss)
I1022 04:38:22.309842 25759 sgd_solver.cpp:106] Iteration 4600, lr = 0.002
I1022 04:39:43.860694 25759 solver.cpp:228] Iteration 4620, loss = 0.0992078
I1022 04:39:43.860728 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 04:39:43.860747 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:39:43.860754 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:39:43.860759 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:39:43.860765 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0101697 (* 1 = 0.0101697 loss)
I1022 04:39:43.860770 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00529005 (* 1 = 0.00529005 loss)
I1022 04:39:43.860774 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.46223e-05 (* 1 = 9.46223e-05 loss)
I1022 04:39:43.860780 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.32403e-05 (* 1 = 1.32403e-05 loss)
I1022 04:39:43.860783 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0198843 (* 1 = 0.0198843 loss)
I1022 04:39:43.860788 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000584274 (* 1 = 0.000584274 loss)
I1022 04:39:43.860795 25759 sgd_solver.cpp:106] Iteration 4620, lr = 0.002
I1022 04:41:05.315238 25759 solver.cpp:228] Iteration 4640, loss = 0.272007
I1022 04:41:05.315287 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.965689
I1022 04:41:05.315294 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.966186
I1022 04:41:05.315300 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.419517 (* 1 = 0.419517 loss)
I1022 04:41:05.315305 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.315835 (* 1 = 0.315835 loss)
I1022 04:41:05.315310 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0816399 (* 1 = 0.0816399 loss)
I1022 04:41:05.315315 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0945516 (* 1 = 0.0945516 loss)
I1022 04:41:05.315320 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00333561 (* 1 = 0.00333561 loss)
I1022 04:41:05.315325 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.15644e-05 (* 1 = 2.15644e-05 loss)
I1022 04:41:05.315328 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.132215 (* 1 = 0.132215 loss)
I1022 04:41:05.315333 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000211448 (* 1 = 0.000211448 loss)
I1022 04:41:05.315341 25759 sgd_solver.cpp:106] Iteration 4640, lr = 0.002
I1022 04:42:26.682677 25759 solver.cpp:228] Iteration 4660, loss = 0.0596386
I1022 04:42:26.682718 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 04:42:26.682726 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 04:42:26.682736 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00758121 (* 1 = 0.00758121 loss)
I1022 04:42:26.682744 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00930377 (* 1 = 0.00930377 loss)
I1022 04:42:26.682751 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0107926 (* 1 = 0.0107926 loss)
I1022 04:42:26.682760 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00989412 (* 1 = 0.00989412 loss)
I1022 04:42:26.682768 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000110717 (* 1 = 0.000110717 loss)
I1022 04:42:26.682776 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.52694e-05 (* 1 = 1.52694e-05 loss)
I1022 04:42:26.682785 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.015412 (* 1 = 0.015412 loss)
I1022 04:42:26.682792 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00078187 (* 1 = 0.00078187 loss)
I1022 04:42:26.682801 25759 sgd_solver.cpp:106] Iteration 4660, lr = 0.002
I1022 04:43:47.446951 25759 solver.cpp:228] Iteration 4680, loss = 0.38475
I1022 04:43:47.446985 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.983979
I1022 04:43:47.446990 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.981057
I1022 04:43:47.446996 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.231478 (* 1 = 0.231478 loss)
I1022 04:43:47.447000 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.180133 (* 1 = 0.180133 loss)
I1022 04:43:47.447005 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0403225 (* 1 = 0.0403225 loss)
I1022 04:43:47.447010 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0572594 (* 1 = 0.0572594 loss)
I1022 04:43:47.447013 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00296218 (* 1 = 0.00296218 loss)
I1022 04:43:47.447018 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.74124e-05 (* 1 = 1.74124e-05 loss)
I1022 04:43:47.447022 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.157764 (* 1 = 0.157764 loss)
I1022 04:43:47.447026 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000935695 (* 1 = 0.000935695 loss)
I1022 04:43:47.447031 25759 sgd_solver.cpp:106] Iteration 4680, lr = 0.002
I1022 04:45:12.398620 25759 solver.cpp:228] Iteration 4700, loss = 0.0905672
I1022 04:45:12.398664 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:45:12.398672 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:45:12.398682 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:45:12.398689 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:45:12.398696 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00435079 (* 1 = 0.00435079 loss)
I1022 04:45:12.398703 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00441245 (* 1 = 0.00441245 loss)
I1022 04:45:12.398710 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.1835e-05 (* 1 = 8.1835e-05 loss)
I1022 04:45:12.398717 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.37164e-05 (* 1 = 1.37164e-05 loss)
I1022 04:45:12.398725 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0175713 (* 1 = 0.0175713 loss)
I1022 04:45:12.398731 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000295635 (* 1 = 0.000295635 loss)
I1022 04:45:12.398739 25759 sgd_solver.cpp:106] Iteration 4700, lr = 0.002
I1022 04:46:34.498407 25759 solver.cpp:228] Iteration 4720, loss = 0.132392
I1022 04:46:34.498447 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 04:46:34.498453 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 04:46:34.498462 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0369126 (* 1 = 0.0369126 loss)
I1022 04:46:34.498469 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.016648 (* 1 = 0.016648 loss)
I1022 04:46:34.498474 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0120958 (* 1 = 0.0120958 loss)
I1022 04:46:34.498481 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00799656 (* 1 = 0.00799656 loss)
I1022 04:46:34.498486 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.3827e-05 (* 1 = 7.3827e-05 loss)
I1022 04:46:34.498492 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.32335e-06 (* 1 = 9.32335e-06 loss)
I1022 04:46:34.498498 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0238277 (* 1 = 0.0238277 loss)
I1022 04:46:34.498504 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00112921 (* 1 = 0.00112921 loss)
I1022 04:46:34.498512 25759 sgd_solver.cpp:106] Iteration 4720, lr = 0.002
I1022 04:47:57.243664 25759 solver.cpp:228] Iteration 4740, loss = 0.11713
I1022 04:47:57.243711 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:47:57.243716 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:47:57.243723 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:47:57.243728 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:47:57.243734 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00487826 (* 1 = 0.00487826 loss)
I1022 04:47:57.243739 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00445721 (* 1 = 0.00445721 loss)
I1022 04:47:57.243743 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000179112 (* 1 = 0.000179112 loss)
I1022 04:47:57.243748 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.24916e-05 (* 1 = 2.24916e-05 loss)
I1022 04:47:57.243752 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00311956 (* 1 = 0.00311956 loss)
I1022 04:47:57.243757 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00651568 (* 1 = 0.00651568 loss)
I1022 04:47:57.243762 25759 sgd_solver.cpp:106] Iteration 4740, lr = 0.002
I1022 04:49:21.018501 25759 solver.cpp:228] Iteration 4760, loss = 0.0458584
I1022 04:49:21.018539 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 04:49:21.018546 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:49:21.018555 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:49:21.018561 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:49:21.018568 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0120986 (* 1 = 0.0120986 loss)
I1022 04:49:21.018575 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00625528 (* 1 = 0.00625528 loss)
I1022 04:49:21.018581 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000107365 (* 1 = 0.000107365 loss)
I1022 04:49:21.018587 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.78844e-05 (* 1 = 1.78844e-05 loss)
I1022 04:49:21.018594 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00401115 (* 1 = 0.00401115 loss)
I1022 04:49:21.018599 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00201517 (* 1 = 0.00201517 loss)
I1022 04:49:21.018606 25759 sgd_solver.cpp:106] Iteration 4760, lr = 0.002
I1022 04:50:46.307288 25759 solver.cpp:228] Iteration 4780, loss = 0.299358
I1022 04:50:46.307365 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99899
I1022 04:50:46.307375 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 04:50:46.307394 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0183223 (* 1 = 0.0183223 loss)
I1022 04:50:46.307406 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0141276 (* 1 = 0.0141276 loss)
I1022 04:50:46.307418 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00461434 (* 1 = 0.00461434 loss)
I1022 04:50:46.307428 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00844049 (* 1 = 0.00844049 loss)
I1022 04:50:46.307440 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000284556 (* 1 = 0.000284556 loss)
I1022 04:50:46.307451 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.06431e-05 (* 1 = 1.06431e-05 loss)
I1022 04:50:46.307464 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0150847 (* 1 = 0.0150847 loss)
I1022 04:50:46.307477 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00122847 (* 1 = 0.00122847 loss)
I1022 04:50:46.307497 25759 sgd_solver.cpp:106] Iteration 4780, lr = 0.002
speed: 4.206s / iter
I1022 04:52:12.700017 25759 solver.cpp:228] Iteration 4800, loss = 0.126298
I1022 04:52:12.700071 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985442
I1022 04:52:12.700078 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991513
I1022 04:52:12.700088 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0804068 (* 1 = 0.0804068 loss)
I1022 04:52:12.700094 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0696246 (* 1 = 0.0696246 loss)
I1022 04:52:12.700100 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0372986 (* 1 = 0.0372986 loss)
I1022 04:52:12.700105 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0311158 (* 1 = 0.0311158 loss)
I1022 04:52:12.700111 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00212421 (* 1 = 0.00212421 loss)
I1022 04:52:12.700119 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.42409e-05 (* 1 = 1.42409e-05 loss)
I1022 04:52:12.700135 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0668583 (* 1 = 0.0668583 loss)
I1022 04:52:12.700143 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000343426 (* 1 = 0.000343426 loss)
I1022 04:52:12.700156 25759 sgd_solver.cpp:106] Iteration 4800, lr = 0.002
I1022 04:53:36.753098 25759 solver.cpp:228] Iteration 4820, loss = 0.297829
I1022 04:53:36.753129 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993503
I1022 04:53:36.753134 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 04:53:36.753141 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.237677 (* 1 = 0.237677 loss)
I1022 04:53:36.753146 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0617366 (* 1 = 0.0617366 loss)
I1022 04:53:36.753150 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0240642 (* 1 = 0.0240642 loss)
I1022 04:53:36.753156 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0107652 (* 1 = 0.0107652 loss)
I1022 04:53:36.753160 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0312981 (* 1 = 0.0312981 loss)
I1022 04:53:36.753165 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.41197e-05 (* 1 = 1.41197e-05 loss)
I1022 04:53:36.753168 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.212345 (* 1 = 0.212345 loss)
I1022 04:53:36.753173 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000268079 (* 1 = 0.000268079 loss)
I1022 04:53:36.753178 25759 sgd_solver.cpp:106] Iteration 4820, lr = 0.002
I1022 04:54:57.806813 25759 solver.cpp:228] Iteration 4840, loss = 0.266808
I1022 04:54:57.806861 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:54:57.806866 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:54:57.806874 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:54:57.806879 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:54:57.806883 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00489959 (* 1 = 0.00489959 loss)
I1022 04:54:57.806888 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00456554 (* 1 = 0.00456554 loss)
I1022 04:54:57.806893 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.51106e-05 (* 1 = 4.51106e-05 loss)
I1022 04:54:57.806898 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.00805e-05 (* 1 = 1.00805e-05 loss)
I1022 04:54:57.806902 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00989478 (* 1 = 0.00989478 loss)
I1022 04:54:57.806907 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00276879 (* 1 = 0.00276879 loss)
I1022 04:54:57.806913 25759 sgd_solver.cpp:106] Iteration 4840, lr = 0.002
I1022 04:56:18.400004 25759 solver.cpp:228] Iteration 4860, loss = 0.154307
I1022 04:56:18.400045 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992508
I1022 04:56:18.400051 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997503
I1022 04:56:18.400060 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0541975 (* 1 = 0.0541975 loss)
I1022 04:56:18.400068 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0347566 (* 1 = 0.0347566 loss)
I1022 04:56:18.400074 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0222714 (* 1 = 0.0222714 loss)
I1022 04:56:18.400079 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0150036 (* 1 = 0.0150036 loss)
I1022 04:56:18.400084 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000236738 (* 1 = 0.000236738 loss)
I1022 04:56:18.400090 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.73563e-05 (* 1 = 1.73563e-05 loss)
I1022 04:56:18.400096 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0227866 (* 1 = 0.0227866 loss)
I1022 04:56:18.400102 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00322828 (* 1 = 0.00322828 loss)
I1022 04:56:18.400110 25759 sgd_solver.cpp:106] Iteration 4860, lr = 0.002
I1022 04:57:41.382266 25759 solver.cpp:228] Iteration 4880, loss = 0.109537
I1022 04:57:41.382304 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990514
I1022 04:57:41.382310 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.989016
I1022 04:57:41.382319 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0476155 (* 1 = 0.0476155 loss)
I1022 04:57:41.382326 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0796831 (* 1 = 0.0796831 loss)
I1022 04:57:41.382333 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0330823 (* 1 = 0.0330823 loss)
I1022 04:57:41.382338 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0270727 (* 1 = 0.0270727 loss)
I1022 04:57:41.382344 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00105404 (* 1 = 0.00105404 loss)
I1022 04:57:41.382350 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.06421e-05 (* 1 = 9.06421e-05 loss)
I1022 04:57:41.382355 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0396291 (* 1 = 0.0396291 loss)
I1022 04:57:41.382362 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000363205 (* 1 = 0.000363205 loss)
I1022 04:57:41.382369 25759 sgd_solver.cpp:106] Iteration 4880, lr = 0.002
I1022 04:59:04.269886 25759 solver.cpp:228] Iteration 4900, loss = 0.110303
I1022 04:59:04.269934 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 04:59:04.269939 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 04:59:04.269946 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 04:59:04.269950 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 04:59:04.269955 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00518573 (* 1 = 0.00518573 loss)
I1022 04:59:04.269959 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00472092 (* 1 = 0.00472092 loss)
I1022 04:59:04.269964 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000161544 (* 1 = 0.000161544 loss)
I1022 04:59:04.269969 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.88673e-05 (* 1 = 4.88673e-05 loss)
I1022 04:59:04.269973 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.002374 (* 1 = 0.002374 loss)
I1022 04:59:04.269979 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00109038 (* 1 = 0.00109038 loss)
I1022 04:59:04.269987 25759 sgd_solver.cpp:106] Iteration 4900, lr = 0.002
I1022 05:00:28.082074 25759 solver.cpp:228] Iteration 4920, loss = 0.118587
I1022 05:00:28.082123 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992511
I1022 05:00:28.082129 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994009
I1022 05:00:28.082135 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0622055 (* 1 = 0.0622055 loss)
I1022 05:00:28.082142 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0426045 (* 1 = 0.0426045 loss)
I1022 05:00:28.082146 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0270183 (* 1 = 0.0270183 loss)
I1022 05:00:28.082150 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0227913 (* 1 = 0.0227913 loss)
I1022 05:00:28.082155 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00173272 (* 1 = 0.00173272 loss)
I1022 05:00:28.082160 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.5202e-05 (* 1 = 2.5202e-05 loss)
I1022 05:00:28.082165 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0450262 (* 1 = 0.0450262 loss)
I1022 05:00:28.082170 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000212473 (* 1 = 0.000212473 loss)
I1022 05:00:28.082176 25759 sgd_solver.cpp:106] Iteration 4920, lr = 0.002
I1022 05:01:50.713126 25759 solver.cpp:228] Iteration 4940, loss = 0.269508
I1022 05:01:50.713176 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 05:01:50.713181 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 05:01:50.713188 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00651742 (* 1 = 0.00651742 loss)
I1022 05:01:50.713194 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0078133 (* 1 = 0.0078133 loss)
I1022 05:01:50.713198 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00784926 (* 1 = 0.00784926 loss)
I1022 05:01:50.713202 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00759843 (* 1 = 0.00759843 loss)
I1022 05:01:50.713207 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.40966e-05 (* 1 = 4.40966e-05 loss)
I1022 05:01:50.713212 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.4129e-05 (* 1 = 2.4129e-05 loss)
I1022 05:01:50.713217 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00929869 (* 1 = 0.00929869 loss)
I1022 05:01:50.713222 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00118237 (* 1 = 0.00118237 loss)
I1022 05:01:50.713230 25759 sgd_solver.cpp:106] Iteration 4940, lr = 0.002
I1022 05:03:15.633565 25759 solver.cpp:228] Iteration 4960, loss = 0.0886641
I1022 05:03:15.633607 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 05:03:15.633613 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 05:03:15.633623 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00889766 (* 1 = 0.00889766 loss)
I1022 05:03:15.633630 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0156486 (* 1 = 0.0156486 loss)
I1022 05:03:15.633638 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0107631 (* 1 = 0.0107631 loss)
I1022 05:03:15.633644 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00836975 (* 1 = 0.00836975 loss)
I1022 05:03:15.633651 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.8127e-05 (* 1 = 7.8127e-05 loss)
I1022 05:03:15.633657 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.4166e-05 (* 1 = 1.4166e-05 loss)
I1022 05:03:15.633663 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00262379 (* 1 = 0.00262379 loss)
I1022 05:03:15.633671 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00397643 (* 1 = 0.00397643 loss)
I1022 05:03:15.633678 25759 sgd_solver.cpp:106] Iteration 4960, lr = 0.002
I1022 05:04:40.663076 25759 solver.cpp:228] Iteration 4980, loss = 0.0550186
I1022 05:04:40.663122 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 05:04:40.663127 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 05:04:40.663136 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00613786 (* 1 = 0.00613786 loss)
I1022 05:04:40.663141 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.010796 (* 1 = 0.010796 loss)
I1022 05:04:40.663146 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00983244 (* 1 = 0.00983244 loss)
I1022 05:04:40.663152 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00646159 (* 1 = 0.00646159 loss)
I1022 05:04:40.663156 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.34771e-05 (* 1 = 6.34771e-05 loss)
I1022 05:04:40.663162 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.22305e-05 (* 1 = 2.22305e-05 loss)
I1022 05:04:40.663167 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00422073 (* 1 = 0.00422073 loss)
I1022 05:04:40.663172 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0092507 (* 1 = 0.0092507 loss)
I1022 05:04:40.663179 25759 sgd_solver.cpp:106] Iteration 4980, lr = 0.002
speed: 4.204s / iter
I1022 05:06:05.899226 25759 solver.cpp:228] Iteration 5000, loss = 0.186644
I1022 05:06:05.899276 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985214
I1022 05:06:05.899282 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.986527
I1022 05:06:05.899292 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.125198 (* 1 = 0.125198 loss)
I1022 05:06:05.899299 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0625137 (* 1 = 0.0625137 loss)
I1022 05:06:05.899307 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0502 (* 1 = 0.0502 loss)
I1022 05:06:05.899312 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.043965 (* 1 = 0.043965 loss)
I1022 05:06:05.899319 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00591856 (* 1 = 0.00591856 loss)
I1022 05:06:05.899327 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.1557e-05 (* 1 = 7.1557e-05 loss)
I1022 05:06:05.899333 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.248521 (* 1 = 0.248521 loss)
I1022 05:06:05.899338 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00369432 (* 1 = 0.00369432 loss)
I1022 05:06:05.899350 25759 sgd_solver.cpp:106] Iteration 5000, lr = 0.002
I1022 05:07:30.130167 25759 solver.cpp:228] Iteration 5020, loss = 0.0821735
I1022 05:07:30.130200 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 05:07:30.130205 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 05:07:30.130213 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0118273 (* 1 = 0.0118273 loss)
I1022 05:07:30.130216 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0112037 (* 1 = 0.0112037 loss)
I1022 05:07:30.130221 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00936673 (* 1 = 0.00936673 loss)
I1022 05:07:30.130225 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00606729 (* 1 = 0.00606729 loss)
I1022 05:07:30.130229 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000115024 (* 1 = 0.000115024 loss)
I1022 05:07:30.130234 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.10698e-05 (* 1 = 1.10698e-05 loss)
I1022 05:07:30.130239 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0108813 (* 1 = 0.0108813 loss)
I1022 05:07:30.130242 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000704013 (* 1 = 0.000704013 loss)
I1022 05:07:30.130249 25759 sgd_solver.cpp:106] Iteration 5020, lr = 0.002
I1022 05:08:50.939227 25759 solver.cpp:228] Iteration 5040, loss = 0.199797
I1022 05:08:50.939260 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995005
I1022 05:08:50.939265 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 05:08:50.939272 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0365846 (* 1 = 0.0365846 loss)
I1022 05:08:50.939277 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0271109 (* 1 = 0.0271109 loss)
I1022 05:08:50.939281 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0183975 (* 1 = 0.0183975 loss)
I1022 05:08:50.939285 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0137531 (* 1 = 0.0137531 loss)
I1022 05:08:50.939290 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000200865 (* 1 = 0.000200865 loss)
I1022 05:08:50.939294 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.01912e-06 (* 1 = 9.01912e-06 loss)
I1022 05:08:50.939298 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0208539 (* 1 = 0.0208539 loss)
I1022 05:08:50.939303 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0035228 (* 1 = 0.0035228 loss)
I1022 05:08:50.939311 25759 sgd_solver.cpp:106] Iteration 5040, lr = 0.002
I1022 05:10:12.441584 25759 solver.cpp:228] Iteration 5060, loss = 0.156823
I1022 05:10:12.441623 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 05:10:12.441629 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 05:10:12.441639 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00911165 (* 1 = 0.00911165 loss)
I1022 05:10:12.441646 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00232837 (* 1 = 0.00232837 loss)
I1022 05:10:12.441651 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0106767 (* 1 = 0.0106767 loss)
I1022 05:10:12.441658 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00515653 (* 1 = 0.00515653 loss)
I1022 05:10:12.441663 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000125136 (* 1 = 0.000125136 loss)
I1022 05:10:12.441669 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.53382e-05 (* 1 = 1.53382e-05 loss)
I1022 05:10:12.441674 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00595415 (* 1 = 0.00595415 loss)
I1022 05:10:12.441680 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000224537 (* 1 = 0.000224537 loss)
I1022 05:10:12.441687 25759 sgd_solver.cpp:106] Iteration 5060, lr = 0.002
I1022 05:11:36.323200 25759 solver.cpp:228] Iteration 5080, loss = 0.171452
I1022 05:11:36.323258 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994508
I1022 05:11:36.323264 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995507
I1022 05:11:36.323272 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0471677 (* 1 = 0.0471677 loss)
I1022 05:11:36.323277 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0459965 (* 1 = 0.0459965 loss)
I1022 05:11:36.323282 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.023345 (* 1 = 0.023345 loss)
I1022 05:11:36.323287 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0208099 (* 1 = 0.0208099 loss)
I1022 05:11:36.323292 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000269995 (* 1 = 0.000269995 loss)
I1022 05:11:36.323297 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.58406e-05 (* 1 = 1.58406e-05 loss)
I1022 05:11:36.323302 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0159999 (* 1 = 0.0159999 loss)
I1022 05:11:36.323307 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000642229 (* 1 = 0.000642229 loss)
I1022 05:11:36.323313 25759 sgd_solver.cpp:106] Iteration 5080, lr = 0.002
I1022 05:13:02.581990 25759 solver.cpp:228] Iteration 5100, loss = 0.277675
I1022 05:13:02.582048 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989016
I1022 05:13:02.582059 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991013
I1022 05:13:02.582075 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0394098 (* 1 = 0.0394098 loss)
I1022 05:13:02.582088 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0522474 (* 1 = 0.0522474 loss)
I1022 05:13:02.582098 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0333046 (* 1 = 0.0333046 loss)
I1022 05:13:02.582108 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0259317 (* 1 = 0.0259317 loss)
I1022 05:13:02.582120 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000963322 (* 1 = 0.000963322 loss)
I1022 05:13:02.582131 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.95717e-05 (* 1 = 2.95717e-05 loss)
I1022 05:13:02.582142 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0398552 (* 1 = 0.0398552 loss)
I1022 05:13:02.582152 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000470856 (* 1 = 0.000470856 loss)
I1022 05:13:02.582166 25759 sgd_solver.cpp:106] Iteration 5100, lr = 0.002
I1022 05:14:26.576798 25759 solver.cpp:228] Iteration 5120, loss = 0.144769
I1022 05:14:26.576841 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 05:14:26.576848 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 05:14:26.576858 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00798593 (* 1 = 0.00798593 loss)
I1022 05:14:26.576864 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0124493 (* 1 = 0.0124493 loss)
I1022 05:14:26.576870 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00954359 (* 1 = 0.00954359 loss)
I1022 05:14:26.576875 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00828946 (* 1 = 0.00828946 loss)
I1022 05:14:26.576881 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.37059e-05 (* 1 = 8.37059e-05 loss)
I1022 05:14:26.576887 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.01919e-05 (* 1 = 1.01919e-05 loss)
I1022 05:14:26.576894 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00358154 (* 1 = 0.00358154 loss)
I1022 05:14:26.576900 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000565339 (* 1 = 0.000565339 loss)
I1022 05:14:26.576906 25759 sgd_solver.cpp:106] Iteration 5120, lr = 0.002
I1022 05:15:48.031081 25759 solver.cpp:228] Iteration 5140, loss = 0.0600941
I1022 05:15:48.031123 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 05:15:48.031131 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 05:15:48.031139 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0163936 (* 1 = 0.0163936 loss)
I1022 05:15:48.031147 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0228144 (* 1 = 0.0228144 loss)
I1022 05:15:48.031153 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0131521 (* 1 = 0.0131521 loss)
I1022 05:15:48.031159 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0109988 (* 1 = 0.0109988 loss)
I1022 05:15:48.031165 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000534572 (* 1 = 0.000534572 loss)
I1022 05:15:48.031172 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.35276e-05 (* 1 = 1.35276e-05 loss)
I1022 05:15:48.031178 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0229479 (* 1 = 0.0229479 loss)
I1022 05:15:48.031184 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00319143 (* 1 = 0.00319143 loss)
I1022 05:15:48.031191 25759 sgd_solver.cpp:106] Iteration 5140, lr = 0.002
I1022 05:17:10.690428 25759 solver.cpp:228] Iteration 5160, loss = 0.137545
I1022 05:17:10.690475 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991013
I1022 05:17:10.690481 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99351
I1022 05:17:10.690488 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.122472 (* 1 = 0.122472 loss)
I1022 05:17:10.690493 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0766959 (* 1 = 0.0766959 loss)
I1022 05:17:10.690498 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0228642 (* 1 = 0.0228642 loss)
I1022 05:17:10.690502 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0216937 (* 1 = 0.0216937 loss)
I1022 05:17:10.690507 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000234118 (* 1 = 0.000234118 loss)
I1022 05:17:10.690512 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.70993e-05 (* 1 = 1.70993e-05 loss)
I1022 05:17:10.690516 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0378162 (* 1 = 0.0378162 loss)
I1022 05:17:10.690521 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000203097 (* 1 = 0.000203097 loss)
I1022 05:17:10.690527 25759 sgd_solver.cpp:106] Iteration 5160, lr = 0.002
I1022 05:18:33.677588 25759 solver.cpp:228] Iteration 5180, loss = 0.0875405
I1022 05:18:33.677628 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 05:18:33.677634 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:18:33.677644 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:18:33.677649 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:18:33.677655 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00436323 (* 1 = 0.00436323 loss)
I1022 05:18:33.677664 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00448936 (* 1 = 0.00448936 loss)
I1022 05:18:33.677670 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.60258e-05 (* 1 = 7.60258e-05 loss)
I1022 05:18:33.677676 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.27957e-05 (* 1 = 1.27957e-05 loss)
I1022 05:18:33.677682 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00980705 (* 1 = 0.00980705 loss)
I1022 05:18:33.677688 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00351689 (* 1 = 0.00351689 loss)
I1022 05:18:33.677696 25759 sgd_solver.cpp:106] Iteration 5180, lr = 0.002
speed: 4.203s / iter
I1022 05:19:57.755431 25759 solver.cpp:228] Iteration 5200, loss = 0.0974839
I1022 05:19:57.755498 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994505
I1022 05:19:57.755504 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993007
I1022 05:19:57.755512 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0114837 (* 1 = 0.0114837 loss)
I1022 05:19:57.755517 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0267272 (* 1 = 0.0267272 loss)
I1022 05:19:57.755522 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0182669 (* 1 = 0.0182669 loss)
I1022 05:19:57.755527 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0181648 (* 1 = 0.0181648 loss)
I1022 05:19:57.755532 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000317405 (* 1 = 0.000317405 loss)
I1022 05:19:57.755537 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.8779e-05 (* 1 = 1.8779e-05 loss)
I1022 05:19:57.755543 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0159422 (* 1 = 0.0159422 loss)
I1022 05:19:57.755548 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00128272 (* 1 = 0.00128272 loss)
I1022 05:19:57.755558 25759 sgd_solver.cpp:106] Iteration 5200, lr = 0.002
I1022 05:21:21.587978 25759 solver.cpp:228] Iteration 5220, loss = 0.379863
I1022 05:21:21.588027 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 05:21:21.588033 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 05:21:21.588042 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00553946 (* 1 = 0.00553946 loss)
I1022 05:21:21.588049 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0161424 (* 1 = 0.0161424 loss)
I1022 05:21:21.588055 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0119125 (* 1 = 0.0119125 loss)
I1022 05:21:21.588062 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0112311 (* 1 = 0.0112311 loss)
I1022 05:21:21.588068 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00109277 (* 1 = 0.00109277 loss)
I1022 05:21:21.588074 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.25924e-05 (* 1 = 4.25924e-05 loss)
I1022 05:21:21.588079 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0625983 (* 1 = 0.0625983 loss)
I1022 05:21:21.588085 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00147827 (* 1 = 0.00147827 loss)
I1022 05:21:21.588093 25759 sgd_solver.cpp:106] Iteration 5220, lr = 0.002
I1022 05:22:47.003036 25759 solver.cpp:228] Iteration 5240, loss = 0.082132
I1022 05:22:47.003098 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989091
I1022 05:22:47.003110 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994006
I1022 05:22:47.003126 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0501216 (* 1 = 0.0501216 loss)
I1022 05:22:47.003151 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0369568 (* 1 = 0.0369568 loss)
I1022 05:22:47.003156 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0216549 (* 1 = 0.0216549 loss)
I1022 05:22:47.003162 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0193177 (* 1 = 0.0193177 loss)
I1022 05:22:47.003170 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00187848 (* 1 = 0.00187848 loss)
I1022 05:22:47.003180 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.55206e-05 (* 1 = 1.55206e-05 loss)
I1022 05:22:47.003187 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0974315 (* 1 = 0.0974315 loss)
I1022 05:22:47.003196 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00509719 (* 1 = 0.00509719 loss)
I1022 05:22:47.003203 25759 sgd_solver.cpp:106] Iteration 5240, lr = 0.002
I1022 05:24:11.351531 25759 solver.cpp:228] Iteration 5260, loss = 0.122355
I1022 05:24:11.351581 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 05:24:11.351588 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 05:24:11.351599 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0095241 (* 1 = 0.0095241 loss)
I1022 05:24:11.351606 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0247105 (* 1 = 0.0247105 loss)
I1022 05:24:11.351614 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00850103 (* 1 = 0.00850103 loss)
I1022 05:24:11.351620 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0102985 (* 1 = 0.0102985 loss)
I1022 05:24:11.351627 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.02776e-05 (* 1 = 9.02776e-05 loss)
I1022 05:24:11.351634 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.57793e-05 (* 1 = 2.57793e-05 loss)
I1022 05:24:11.351640 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00895995 (* 1 = 0.00895995 loss)
I1022 05:24:11.351646 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00130381 (* 1 = 0.00130381 loss)
I1022 05:24:11.351658 25759 sgd_solver.cpp:106] Iteration 5260, lr = 0.002
I1022 05:25:33.758635 25759 solver.cpp:228] Iteration 5280, loss = 0.0440803
I1022 05:25:33.758669 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 05:25:33.758674 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 05:25:33.758682 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00737619 (* 1 = 0.00737619 loss)
I1022 05:25:33.758685 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00649709 (* 1 = 0.00649709 loss)
I1022 05:25:33.758689 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00838716 (* 1 = 0.00838716 loss)
I1022 05:25:33.758693 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00667625 (* 1 = 0.00667625 loss)
I1022 05:25:33.758698 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000101135 (* 1 = 0.000101135 loss)
I1022 05:25:33.758704 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.001082 (* 1 = 0.001082 loss)
I1022 05:25:33.758708 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00639325 (* 1 = 0.00639325 loss)
I1022 05:25:33.758713 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00956395 (* 1 = 0.00956395 loss)
I1022 05:25:33.758718 25759 sgd_solver.cpp:106] Iteration 5280, lr = 0.002
I1022 05:26:57.139499 25759 solver.cpp:228] Iteration 5300, loss = 0.0946276
I1022 05:26:57.139549 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 05:26:57.139554 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 05:26:57.139561 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0175327 (* 1 = 0.0175327 loss)
I1022 05:26:57.139567 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0166324 (* 1 = 0.0166324 loss)
I1022 05:26:57.139571 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0136316 (* 1 = 0.0136316 loss)
I1022 05:26:57.139575 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0116842 (* 1 = 0.0116842 loss)
I1022 05:26:57.139580 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.33613e-05 (* 1 = 5.33613e-05 loss)
I1022 05:26:57.139585 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.94829e-05 (* 1 = 2.94829e-05 loss)
I1022 05:26:57.139590 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00785472 (* 1 = 0.00785472 loss)
I1022 05:26:57.139593 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.014631 (* 1 = 0.014631 loss)
I1022 05:26:57.139600 25759 sgd_solver.cpp:106] Iteration 5300, lr = 0.002
I1022 05:28:19.099010 25759 solver.cpp:228] Iteration 5320, loss = 0.163903
I1022 05:28:19.099052 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 05:28:19.099058 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:28:19.099066 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:28:19.099072 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:28:19.099078 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00469201 (* 1 = 0.00469201 loss)
I1022 05:28:19.099083 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0044532 (* 1 = 0.0044532 loss)
I1022 05:28:19.099095 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000102737 (* 1 = 0.000102737 loss)
I1022 05:28:19.099105 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.03895e-05 (* 1 = 1.03895e-05 loss)
I1022 05:28:19.099114 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00407885 (* 1 = 0.00407885 loss)
I1022 05:28:19.099123 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.011068 (* 1 = 0.011068 loss)
I1022 05:28:19.099133 25759 sgd_solver.cpp:106] Iteration 5320, lr = 0.002
I1022 05:29:43.770535 25759 solver.cpp:228] Iteration 5340, loss = 0.141314
I1022 05:29:43.770575 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994006
I1022 05:29:43.770581 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1022 05:29:43.770589 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0297797 (* 1 = 0.0297797 loss)
I1022 05:29:43.770596 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0295596 (* 1 = 0.0295596 loss)
I1022 05:29:43.770601 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0241344 (* 1 = 0.0241344 loss)
I1022 05:29:43.770607 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0219353 (* 1 = 0.0219353 loss)
I1022 05:29:43.770613 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0056441 (* 1 = 0.0056441 loss)
I1022 05:29:43.770619 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.50276e-05 (* 1 = 4.50276e-05 loss)
I1022 05:29:43.770625 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0684027 (* 1 = 0.0684027 loss)
I1022 05:29:43.770632 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00222669 (* 1 = 0.00222669 loss)
I1022 05:29:43.770638 25759 sgd_solver.cpp:106] Iteration 5340, lr = 0.002
I1022 05:31:07.248208 25759 solver.cpp:228] Iteration 5360, loss = 0.0970195
I1022 05:31:07.248247 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 05:31:07.248265 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 05:31:07.248275 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0133279 (* 1 = 0.0133279 loss)
I1022 05:31:07.248281 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0236106 (* 1 = 0.0236106 loss)
I1022 05:31:07.248286 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0115167 (* 1 = 0.0115167 loss)
I1022 05:31:07.248292 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00708374 (* 1 = 0.00708374 loss)
I1022 05:31:07.248298 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000105427 (* 1 = 0.000105427 loss)
I1022 05:31:07.248304 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.81295e-06 (* 1 = 9.81295e-06 loss)
I1022 05:31:07.248311 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00914766 (* 1 = 0.00914766 loss)
I1022 05:31:07.248317 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00327974 (* 1 = 0.00327974 loss)
I1022 05:31:07.248322 25759 sgd_solver.cpp:106] Iteration 5360, lr = 0.002
I1022 05:32:34.113425 25759 solver.cpp:228] Iteration 5380, loss = 0.128609
I1022 05:32:34.113474 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 05:32:34.113478 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 05:32:34.113485 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:32:34.113490 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:32:34.113495 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0108439 (* 1 = 0.0108439 loss)
I1022 05:32:34.113500 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00588679 (* 1 = 0.00588679 loss)
I1022 05:32:34.113504 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000175506 (* 1 = 0.000175506 loss)
I1022 05:32:34.113509 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.52269e-05 (* 1 = 1.52269e-05 loss)
I1022 05:32:34.113514 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0106022 (* 1 = 0.0106022 loss)
I1022 05:32:34.113518 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00640851 (* 1 = 0.00640851 loss)
I1022 05:32:34.113524 25759 sgd_solver.cpp:106] Iteration 5380, lr = 0.002
speed: 4.202s / iter
I1022 05:33:58.082466 25759 solver.cpp:228] Iteration 5400, loss = 0.0444379
I1022 05:33:58.082528 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 05:33:58.082535 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 05:33:58.082546 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00625525 (* 1 = 0.00625525 loss)
I1022 05:33:58.082553 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0139632 (* 1 = 0.0139632 loss)
I1022 05:33:58.082561 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0124961 (* 1 = 0.0124961 loss)
I1022 05:33:58.082566 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00994902 (* 1 = 0.00994902 loss)
I1022 05:33:58.082573 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000232429 (* 1 = 0.000232429 loss)
I1022 05:33:58.082581 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.17593e-05 (* 1 = 1.17593e-05 loss)
I1022 05:33:58.082588 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00761297 (* 1 = 0.00761297 loss)
I1022 05:33:58.082595 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00199263 (* 1 = 0.00199263 loss)
I1022 05:33:58.082603 25759 sgd_solver.cpp:106] Iteration 5400, lr = 0.002
I1022 05:35:22.492558 25759 solver.cpp:228] Iteration 5420, loss = 0.12176
I1022 05:35:22.492624 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 05:35:22.492635 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:35:22.492647 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:35:22.492658 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:35:22.492668 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00481666 (* 1 = 0.00481666 loss)
I1022 05:35:22.492678 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0046495 (* 1 = 0.0046495 loss)
I1022 05:35:22.492689 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.24434e-05 (* 1 = 8.24434e-05 loss)
I1022 05:35:22.492699 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.54361e-05 (* 1 = 1.54361e-05 loss)
I1022 05:35:22.492715 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00306308 (* 1 = 0.00306308 loss)
I1022 05:35:22.492727 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000900554 (* 1 = 0.000900554 loss)
I1022 05:35:22.492739 25759 sgd_solver.cpp:106] Iteration 5420, lr = 0.002
I1022 05:36:46.355113 25759 solver.cpp:228] Iteration 5440, loss = 0.0991033
I1022 05:36:46.355151 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 05:36:46.355157 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:36:46.355163 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:36:46.355168 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:36:46.355175 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00435991 (* 1 = 0.00435991 loss)
I1022 05:36:46.355180 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00436226 (* 1 = 0.00436226 loss)
I1022 05:36:46.355185 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.41799e-05 (* 1 = 8.41799e-05 loss)
I1022 05:36:46.355190 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.27558e-05 (* 1 = 1.27558e-05 loss)
I1022 05:36:46.355195 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0062256 (* 1 = 0.0062256 loss)
I1022 05:36:46.355199 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00224973 (* 1 = 0.00224973 loss)
I1022 05:36:46.355209 25759 sgd_solver.cpp:106] Iteration 5440, lr = 0.002
I1022 05:38:08.592707 25759 solver.cpp:228] Iteration 5460, loss = 0.185855
I1022 05:38:08.592756 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995504
I1022 05:38:08.592761 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995504
I1022 05:38:08.592767 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0344947 (* 1 = 0.0344947 loss)
I1022 05:38:08.592772 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0211539 (* 1 = 0.0211539 loss)
I1022 05:38:08.592777 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.013691 (* 1 = 0.013691 loss)
I1022 05:38:08.592780 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0156025 (* 1 = 0.0156025 loss)
I1022 05:38:08.592785 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000301794 (* 1 = 0.000301794 loss)
I1022 05:38:08.592790 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.50362e-06 (* 1 = 9.50362e-06 loss)
I1022 05:38:08.592794 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0165269 (* 1 = 0.0165269 loss)
I1022 05:38:08.592799 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00232955 (* 1 = 0.00232955 loss)
I1022 05:38:08.592808 25759 sgd_solver.cpp:106] Iteration 5460, lr = 0.002
I1022 05:39:31.071444 25759 solver.cpp:228] Iteration 5480, loss = 0.266807
I1022 05:39:31.071487 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 05:39:31.071496 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 05:39:31.071506 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0136817 (* 1 = 0.0136817 loss)
I1022 05:39:31.071513 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0168503 (* 1 = 0.0168503 loss)
I1022 05:39:31.071519 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0100891 (* 1 = 0.0100891 loss)
I1022 05:39:31.071527 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00675334 (* 1 = 0.00675334 loss)
I1022 05:39:31.071533 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000218312 (* 1 = 0.000218312 loss)
I1022 05:39:31.071540 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.39737e-05 (* 1 = 1.39737e-05 loss)
I1022 05:39:31.071547 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00809803 (* 1 = 0.00809803 loss)
I1022 05:39:31.071554 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0024732 (* 1 = 0.0024732 loss)
I1022 05:39:31.071561 25759 sgd_solver.cpp:106] Iteration 5480, lr = 0.002
I1022 05:40:52.672569 25759 solver.cpp:228] Iteration 5500, loss = 0.0813974
I1022 05:40:52.672621 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992508
I1022 05:40:52.672627 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992008
I1022 05:40:52.672634 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.044172 (* 1 = 0.044172 loss)
I1022 05:40:52.672639 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0519316 (* 1 = 0.0519316 loss)
I1022 05:40:52.672643 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0284496 (* 1 = 0.0284496 loss)
I1022 05:40:52.672647 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0235684 (* 1 = 0.0235684 loss)
I1022 05:40:52.672652 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00461983 (* 1 = 0.00461983 loss)
I1022 05:40:52.672657 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.30166e-05 (* 1 = 2.30166e-05 loss)
I1022 05:40:52.672662 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.128425 (* 1 = 0.128425 loss)
I1022 05:40:52.672667 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00176111 (* 1 = 0.00176111 loss)
I1022 05:40:52.672672 25759 sgd_solver.cpp:106] Iteration 5500, lr = 0.002
I1022 05:42:15.445569 25759 solver.cpp:228] Iteration 5520, loss = 0.259934
I1022 05:42:15.445611 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 05:42:15.445617 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:42:15.445626 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:42:15.445633 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:42:15.445641 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00807041 (* 1 = 0.00807041 loss)
I1022 05:42:15.445647 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00550439 (* 1 = 0.00550439 loss)
I1022 05:42:15.445652 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000571516 (* 1 = 0.000571516 loss)
I1022 05:42:15.445663 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.3523e-05 (* 1 = 1.3523e-05 loss)
I1022 05:42:15.445669 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000511284 (* 1 = 0.000511284 loss)
I1022 05:42:15.445677 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00331037 (* 1 = 0.00331037 loss)
I1022 05:42:15.445684 25759 sgd_solver.cpp:106] Iteration 5520, lr = 0.002
I1022 05:43:40.786484 25759 solver.cpp:228] Iteration 5540, loss = 0.0786052
I1022 05:43:40.786535 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.98404
I1022 05:43:40.786540 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990025
I1022 05:43:40.786547 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0597322 (* 1 = 0.0597322 loss)
I1022 05:43:40.786552 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.088422 (* 1 = 0.088422 loss)
I1022 05:43:40.786556 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0474626 (* 1 = 0.0474626 loss)
I1022 05:43:40.786561 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0404217 (* 1 = 0.0404217 loss)
I1022 05:43:40.786566 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000840079 (* 1 = 0.000840079 loss)
I1022 05:43:40.786571 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.55198e-05 (* 1 = 3.55198e-05 loss)
I1022 05:43:40.786576 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0343493 (* 1 = 0.0343493 loss)
I1022 05:43:40.786579 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000153592 (* 1 = 0.000153592 loss)
I1022 05:43:40.786604 25759 sgd_solver.cpp:106] Iteration 5540, lr = 0.002
I1022 05:45:04.072377 25759 solver.cpp:228] Iteration 5560, loss = 0.131057
I1022 05:45:04.072409 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 05:45:04.072414 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:45:04.072420 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:45:04.072425 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:45:04.072429 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00505598 (* 1 = 0.00505598 loss)
I1022 05:45:04.072433 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00422394 (* 1 = 0.00422394 loss)
I1022 05:45:04.072438 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000112295 (* 1 = 0.000112295 loss)
I1022 05:45:04.072443 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.83308e-06 (* 1 = 7.83308e-06 loss)
I1022 05:45:04.072448 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000532689 (* 1 = 0.000532689 loss)
I1022 05:45:04.072451 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000310441 (* 1 = 0.000310441 loss)
I1022 05:45:04.072456 25759 sgd_solver.cpp:106] Iteration 5560, lr = 0.002
I1022 05:46:28.822671 25759 solver.cpp:228] Iteration 5580, loss = 0.0749015
I1022 05:46:28.822722 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 05:46:28.822729 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:46:28.822739 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:46:28.822747 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:46:28.822754 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00471167 (* 1 = 0.00471167 loss)
I1022 05:46:28.822760 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00464963 (* 1 = 0.00464963 loss)
I1022 05:46:28.822767 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000238615 (* 1 = 0.000238615 loss)
I1022 05:46:28.822774 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.62682e-05 (* 1 = 1.62682e-05 loss)
I1022 05:46:28.822782 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00350385 (* 1 = 0.00350385 loss)
I1022 05:46:28.822793 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000659257 (* 1 = 0.000659257 loss)
I1022 05:46:28.822800 25759 sgd_solver.cpp:106] Iteration 5580, lr = 0.002
speed: 4.201s / iter
I1022 05:47:52.758324 25759 solver.cpp:228] Iteration 5600, loss = 0.134697
I1022 05:47:52.758373 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988849
I1022 05:47:52.758378 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990528
I1022 05:47:52.758385 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0565394 (* 1 = 0.0565394 loss)
I1022 05:47:52.758390 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0576267 (* 1 = 0.0576267 loss)
I1022 05:47:52.758394 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0327434 (* 1 = 0.0327434 loss)
I1022 05:47:52.758399 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0410468 (* 1 = 0.0410468 loss)
I1022 05:47:52.758402 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000672975 (* 1 = 0.000672975 loss)
I1022 05:47:52.758407 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.93467e-05 (* 1 = 1.93467e-05 loss)
I1022 05:47:52.758411 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0904509 (* 1 = 0.0904509 loss)
I1022 05:47:52.758416 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00085083 (* 1 = 0.00085083 loss)
I1022 05:47:52.758422 25759 sgd_solver.cpp:106] Iteration 5600, lr = 0.002
I1022 05:49:18.365281 25759 solver.cpp:228] Iteration 5620, loss = 0.136074
I1022 05:49:18.365329 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 05:49:18.365334 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 05:49:18.365341 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0127736 (* 1 = 0.0127736 loss)
I1022 05:49:18.365346 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00315147 (* 1 = 0.00315147 loss)
I1022 05:49:18.365351 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00761986 (* 1 = 0.00761986 loss)
I1022 05:49:18.365355 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00694821 (* 1 = 0.00694821 loss)
I1022 05:49:18.365360 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000214884 (* 1 = 0.000214884 loss)
I1022 05:49:18.365365 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.23244e-05 (* 1 = 1.23244e-05 loss)
I1022 05:49:18.365370 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0133812 (* 1 = 0.0133812 loss)
I1022 05:49:18.365373 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00169253 (* 1 = 0.00169253 loss)
I1022 05:49:18.365380 25759 sgd_solver.cpp:106] Iteration 5620, lr = 0.002
I1022 05:50:43.126108 25759 solver.cpp:228] Iteration 5640, loss = 0.0667898
I1022 05:50:43.126184 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 05:50:43.126195 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 05:50:43.126214 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0111153 (* 1 = 0.0111153 loss)
I1022 05:50:43.126226 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.011201 (* 1 = 0.011201 loss)
I1022 05:50:43.126238 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00874052 (* 1 = 0.00874052 loss)
I1022 05:50:43.126250 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00730041 (* 1 = 0.00730041 loss)
I1022 05:50:43.126263 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000143535 (* 1 = 0.000143535 loss)
I1022 05:50:43.126277 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.10971e-05 (* 1 = 1.10971e-05 loss)
I1022 05:50:43.126291 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0104712 (* 1 = 0.0104712 loss)
I1022 05:50:43.126304 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00312746 (* 1 = 0.00312746 loss)
I1022 05:50:43.126327 25759 sgd_solver.cpp:106] Iteration 5640, lr = 0.002
I1022 05:52:06.493166 25759 solver.cpp:228] Iteration 5660, loss = 0.0554227
I1022 05:52:06.493232 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 05:52:06.493254 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:52:06.493270 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:52:06.493283 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:52:06.493294 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00424463 (* 1 = 0.00424463 loss)
I1022 05:52:06.493305 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450563 (* 1 = 0.00450563 loss)
I1022 05:52:06.493330 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.0058e-05 (* 1 = 4.0058e-05 loss)
I1022 05:52:06.493345 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.09082e-05 (* 1 = 1.09082e-05 loss)
I1022 05:52:06.493358 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000621268 (* 1 = 0.000621268 loss)
I1022 05:52:06.493371 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000850655 (* 1 = 0.000850655 loss)
I1022 05:52:06.493391 25759 sgd_solver.cpp:106] Iteration 5660, lr = 0.002
I1022 05:53:29.658826 25759 solver.cpp:228] Iteration 5680, loss = 0.201429
I1022 05:53:29.658865 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 05:53:29.658871 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 05:53:29.658881 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 05:53:29.658887 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 05:53:29.658893 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0104015 (* 1 = 0.0104015 loss)
I1022 05:53:29.658900 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00538547 (* 1 = 0.00538547 loss)
I1022 05:53:29.658905 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0131484 (* 1 = 0.0131484 loss)
I1022 05:53:29.658911 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.24338e-06 (* 1 = 9.24338e-06 loss)
I1022 05:53:29.658917 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00181137 (* 1 = 0.00181137 loss)
I1022 05:53:29.658922 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00282557 (* 1 = 0.00282557 loss)
I1022 05:53:29.658929 25759 sgd_solver.cpp:106] Iteration 5680, lr = 0.002
I1022 05:54:52.277279 25759 solver.cpp:228] Iteration 5700, loss = 0.0734553
I1022 05:54:52.277340 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991005
I1022 05:54:52.277348 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 05:54:52.277359 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0341077 (* 1 = 0.0341077 loss)
I1022 05:54:52.277366 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.024793 (* 1 = 0.024793 loss)
I1022 05:54:52.277372 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0191947 (* 1 = 0.0191947 loss)
I1022 05:54:52.277379 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0119385 (* 1 = 0.0119385 loss)
I1022 05:54:52.277385 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000196502 (* 1 = 0.000196502 loss)
I1022 05:54:52.277392 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.0728e-05 (* 1 = 1.0728e-05 loss)
I1022 05:54:52.277398 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00239926 (* 1 = 0.00239926 loss)
I1022 05:54:52.277405 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00319889 (* 1 = 0.00319889 loss)
I1022 05:54:52.277412 25759 sgd_solver.cpp:106] Iteration 5700, lr = 0.002
I1022 05:56:17.071449 25759 solver.cpp:228] Iteration 5720, loss = 0.185868
I1022 05:56:17.071524 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986687
I1022 05:56:17.071532 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.986042
I1022 05:56:17.071543 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.117394 (* 1 = 0.117394 loss)
I1022 05:56:17.071550 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.133278 (* 1 = 0.133278 loss)
I1022 05:56:17.071557 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0362496 (* 1 = 0.0362496 loss)
I1022 05:56:17.071563 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0451703 (* 1 = 0.0451703 loss)
I1022 05:56:17.071570 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00652988 (* 1 = 0.00652988 loss)
I1022 05:56:17.071578 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.56129e-05 (* 1 = 2.56129e-05 loss)
I1022 05:56:17.071584 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.102951 (* 1 = 0.102951 loss)
I1022 05:56:17.071591 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00585634 (* 1 = 0.00585634 loss)
I1022 05:56:17.071600 25759 sgd_solver.cpp:106] Iteration 5720, lr = 0.002
I1022 05:57:44.747566 25759 solver.cpp:228] Iteration 5740, loss = 0.0882386
I1022 05:57:44.747606 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993503
I1022 05:57:44.747613 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 05:57:44.747622 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.051258 (* 1 = 0.051258 loss)
I1022 05:57:44.747629 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0141256 (* 1 = 0.0141256 loss)
I1022 05:57:44.747634 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0131597 (* 1 = 0.0131597 loss)
I1022 05:57:44.747642 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00801457 (* 1 = 0.00801457 loss)
I1022 05:57:44.747648 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00019237 (* 1 = 0.00019237 loss)
I1022 05:57:44.747654 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.51618e-06 (* 1 = 7.51618e-06 loss)
I1022 05:57:44.747660 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0166668 (* 1 = 0.0166668 loss)
I1022 05:57:44.747666 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000838164 (* 1 = 0.000838164 loss)
I1022 05:57:44.747675 25759 sgd_solver.cpp:106] Iteration 5740, lr = 0.002
I1022 05:59:09.455958 25759 solver.cpp:228] Iteration 5760, loss = 0.0747113
I1022 05:59:09.455991 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 05:59:09.455996 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 05:59:09.456002 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0112031 (* 1 = 0.0112031 loss)
I1022 05:59:09.456007 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00613082 (* 1 = 0.00613082 loss)
I1022 05:59:09.456012 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00735289 (* 1 = 0.00735289 loss)
I1022 05:59:09.456015 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00792264 (* 1 = 0.00792264 loss)
I1022 05:59:09.456019 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000158716 (* 1 = 0.000158716 loss)
I1022 05:59:09.456025 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.77632e-06 (* 1 = 5.77632e-06 loss)
I1022 05:59:09.456029 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0066374 (* 1 = 0.0066374 loss)
I1022 05:59:09.456033 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00549654 (* 1 = 0.00549654 loss)
I1022 05:59:09.456041 25759 sgd_solver.cpp:106] Iteration 5760, lr = 0.002
I1022 06:00:34.384382 25759 solver.cpp:228] Iteration 5780, loss = 0.178907
I1022 06:00:34.384429 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994505
I1022 06:00:34.384434 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995504
I1022 06:00:34.384443 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0651215 (* 1 = 0.0651215 loss)
I1022 06:00:34.384447 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0405606 (* 1 = 0.0405606 loss)
I1022 06:00:34.384451 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0242396 (* 1 = 0.0242396 loss)
I1022 06:00:34.384455 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0172284 (* 1 = 0.0172284 loss)
I1022 06:00:34.384459 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000395911 (* 1 = 0.000395911 loss)
I1022 06:00:34.384464 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.9308e-06 (* 1 = 5.9308e-06 loss)
I1022 06:00:34.384469 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0317774 (* 1 = 0.0317774 loss)
I1022 06:00:34.384474 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00603471 (* 1 = 0.00603471 loss)
I1022 06:00:34.384479 25759 sgd_solver.cpp:106] Iteration 5780, lr = 0.002
speed: 4.202s / iter
I1022 06:01:59.021482 25759 solver.cpp:228] Iteration 5800, loss = 0.0824529
I1022 06:01:59.021571 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 06:01:59.021584 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 06:01:59.021600 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00457636 (* 1 = 0.00457636 loss)
I1022 06:01:59.021613 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.011485 (* 1 = 0.011485 loss)
I1022 06:01:59.021625 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00754236 (* 1 = 0.00754236 loss)
I1022 06:01:59.021636 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00707359 (* 1 = 0.00707359 loss)
I1022 06:01:59.021654 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000108099 (* 1 = 0.000108099 loss)
I1022 06:01:59.021669 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.87627e-06 (* 1 = 8.87627e-06 loss)
I1022 06:01:59.021682 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00353106 (* 1 = 0.00353106 loss)
I1022 06:01:59.021697 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00214809 (* 1 = 0.00214809 loss)
I1022 06:01:59.021711 25759 sgd_solver.cpp:106] Iteration 5800, lr = 0.002
I1022 06:03:23.688890 25759 solver.cpp:228] Iteration 5820, loss = 0.11772
I1022 06:03:23.688954 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:03:23.688964 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:03:23.688978 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:03:23.688987 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:03:23.688998 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0053199 (* 1 = 0.0053199 loss)
I1022 06:03:23.689010 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00367577 (* 1 = 0.00367577 loss)
I1022 06:03:23.689021 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.89151e-05 (* 1 = 5.89151e-05 loss)
I1022 06:03:23.689033 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.75993e-06 (* 1 = 7.75993e-06 loss)
I1022 06:03:23.689043 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00103041 (* 1 = 0.00103041 loss)
I1022 06:03:23.689054 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00171994 (* 1 = 0.00171994 loss)
I1022 06:03:23.689065 25759 sgd_solver.cpp:106] Iteration 5820, lr = 0.002
I1022 06:04:49.001760 25759 solver.cpp:228] Iteration 5840, loss = 0.15154
I1022 06:04:49.001797 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991013
I1022 06:04:49.001803 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994508
I1022 06:04:49.001813 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0929783 (* 1 = 0.0929783 loss)
I1022 06:04:49.001819 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0785395 (* 1 = 0.0785395 loss)
I1022 06:04:49.001826 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0296782 (* 1 = 0.0296782 loss)
I1022 06:04:49.001830 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0213012 (* 1 = 0.0213012 loss)
I1022 06:04:49.001837 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000331923 (* 1 = 0.000331923 loss)
I1022 06:04:49.001843 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.13819e-05 (* 1 = 1.13819e-05 loss)
I1022 06:04:49.001849 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0362638 (* 1 = 0.0362638 loss)
I1022 06:04:49.001858 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00377582 (* 1 = 0.00377582 loss)
I1022 06:04:49.001866 25759 sgd_solver.cpp:106] Iteration 5840, lr = 0.002
I1022 06:06:13.942540 25759 solver.cpp:228] Iteration 5860, loss = 0.292097
I1022 06:06:13.942589 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 06:06:13.942593 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 06:06:13.942601 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00435665 (* 1 = 0.00435665 loss)
I1022 06:06:13.942608 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0049954 (* 1 = 0.0049954 loss)
I1022 06:06:13.942612 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00734691 (* 1 = 0.00734691 loss)
I1022 06:06:13.942617 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0057386 (* 1 = 0.0057386 loss)
I1022 06:06:13.942621 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000184325 (* 1 = 0.000184325 loss)
I1022 06:06:13.942627 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.30677e-05 (* 1 = 1.30677e-05 loss)
I1022 06:06:13.942631 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0092161 (* 1 = 0.0092161 loss)
I1022 06:06:13.942636 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00106415 (* 1 = 0.00106415 loss)
I1022 06:06:13.942646 25759 sgd_solver.cpp:106] Iteration 5860, lr = 0.002
I1022 06:07:38.558503 25759 solver.cpp:228] Iteration 5880, loss = 0.161364
I1022 06:07:38.558553 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:07:38.558559 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:07:38.558565 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:07:38.558570 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:07:38.558575 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0046268 (* 1 = 0.0046268 loss)
I1022 06:07:38.558580 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00455457 (* 1 = 0.00455457 loss)
I1022 06:07:38.558585 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.46051e-05 (* 1 = 5.46051e-05 loss)
I1022 06:07:38.558590 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.59828e-06 (* 1 = 6.59828e-06 loss)
I1022 06:07:38.558594 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000574203 (* 1 = 0.000574203 loss)
I1022 06:07:38.558599 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00491529 (* 1 = 0.00491529 loss)
I1022 06:07:38.558605 25759 sgd_solver.cpp:106] Iteration 5880, lr = 0.002
I1022 06:09:02.935879 25759 solver.cpp:228] Iteration 5900, loss = 0.135541
I1022 06:09:02.935922 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:09:02.935931 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:09:02.935943 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:09:02.935952 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:09:02.935962 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00423569 (* 1 = 0.00423569 loss)
I1022 06:09:02.935974 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0045166 (* 1 = 0.0045166 loss)
I1022 06:09:02.935986 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.11279e-05 (* 1 = 6.11279e-05 loss)
I1022 06:09:02.935997 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.42947e-05 (* 1 = 1.42947e-05 loss)
I1022 06:09:02.936008 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00128209 (* 1 = 0.00128209 loss)
I1022 06:09:02.936019 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000203448 (* 1 = 0.000203448 loss)
I1022 06:09:02.936034 25759 sgd_solver.cpp:106] Iteration 5900, lr = 0.002
I1022 06:10:29.250012 25759 solver.cpp:228] Iteration 5920, loss = 0.0856459
I1022 06:10:29.250072 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993506
I1022 06:10:29.250078 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 06:10:29.250088 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0262456 (* 1 = 0.0262456 loss)
I1022 06:10:29.250095 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0380752 (* 1 = 0.0380752 loss)
I1022 06:10:29.250102 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0247793 (* 1 = 0.0247793 loss)
I1022 06:10:29.250108 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0195127 (* 1 = 0.0195127 loss)
I1022 06:10:29.250113 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000137012 (* 1 = 0.000137012 loss)
I1022 06:10:29.250120 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.60865e-05 (* 1 = 4.60865e-05 loss)
I1022 06:10:29.250126 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.013185 (* 1 = 0.013185 loss)
I1022 06:10:29.250133 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000746558 (* 1 = 0.000746558 loss)
I1022 06:10:29.250139 25759 sgd_solver.cpp:106] Iteration 5920, lr = 0.002
I1022 06:11:53.537109 25759 solver.cpp:228] Iteration 5940, loss = 0.0796674
I1022 06:11:53.537168 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:11:53.537174 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:11:53.537181 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:11:53.537189 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:11:53.537194 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00568204 (* 1 = 0.00568204 loss)
I1022 06:11:53.537199 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00432214 (* 1 = 0.00432214 loss)
I1022 06:11:53.537204 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000683317 (* 1 = 0.000683317 loss)
I1022 06:11:53.537209 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.6472e-06 (* 1 = 7.6472e-06 loss)
I1022 06:11:53.537214 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00285891 (* 1 = 0.00285891 loss)
I1022 06:11:53.537219 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00116197 (* 1 = 0.00116197 loss)
I1022 06:11:53.537225 25759 sgd_solver.cpp:106] Iteration 5940, lr = 0.002
I1022 06:13:19.016511 25759 solver.cpp:228] Iteration 5960, loss = 0.0441047
I1022 06:13:19.016569 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 06:13:19.016575 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 06:13:19.016582 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00413922 (* 1 = 0.00413922 loss)
I1022 06:13:19.016588 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.010404 (* 1 = 0.010404 loss)
I1022 06:13:19.016593 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00913133 (* 1 = 0.00913133 loss)
I1022 06:13:19.016597 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00791531 (* 1 = 0.00791531 loss)
I1022 06:13:19.016602 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.40777e-05 (* 1 = 7.40777e-05 loss)
I1022 06:13:19.016611 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.16888e-05 (* 1 = 2.16888e-05 loss)
I1022 06:13:19.016633 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00360769 (* 1 = 0.00360769 loss)
I1022 06:13:19.016638 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00503216 (* 1 = 0.00503216 loss)
I1022 06:13:19.016645 25759 sgd_solver.cpp:106] Iteration 5960, lr = 0.002
I1022 06:14:41.070231 25759 solver.cpp:228] Iteration 5980, loss = 0.045882
I1022 06:14:41.070288 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992008
I1022 06:14:41.070297 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 06:14:41.070305 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0131888 (* 1 = 0.0131888 loss)
I1022 06:14:41.070314 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0114029 (* 1 = 0.0114029 loss)
I1022 06:14:41.070320 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0253275 (* 1 = 0.0253275 loss)
I1022 06:14:41.070327 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0129768 (* 1 = 0.0129768 loss)
I1022 06:14:41.070333 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000149297 (* 1 = 0.000149297 loss)
I1022 06:14:41.070340 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.06229e-05 (* 1 = 2.06229e-05 loss)
I1022 06:14:41.070346 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00900306 (* 1 = 0.00900306 loss)
I1022 06:14:41.070353 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00155521 (* 1 = 0.00155521 loss)
I1022 06:14:41.070360 25759 sgd_solver.cpp:106] Iteration 5980, lr = 0.002
speed: 4.203s / iter
bbbb
aaaa
Wrote snapshot to: /home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_6000.caffemodel
I1022 06:16:04.114377 25759 solver.cpp:228] Iteration 6000, loss = 0.11305
I1022 06:16:04.114428 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 06:16:04.114432 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995003
I1022 06:16:04.114440 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0284072 (* 1 = 0.0284072 loss)
I1022 06:16:04.114445 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0309483 (* 1 = 0.0309483 loss)
I1022 06:16:04.114449 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.017083 (* 1 = 0.017083 loss)
I1022 06:16:04.114454 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0130045 (* 1 = 0.0130045 loss)
I1022 06:16:04.114457 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000735926 (* 1 = 0.000735926 loss)
I1022 06:16:04.114462 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.99884e-06 (* 1 = 7.99884e-06 loss)
I1022 06:16:04.114467 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0547088 (* 1 = 0.0547088 loss)
I1022 06:16:04.114472 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00767623 (* 1 = 0.00767623 loss)
I1022 06:16:04.114481 25759 sgd_solver.cpp:106] Iteration 6000, lr = 0.002
I1022 06:17:29.525410 25759 solver.cpp:228] Iteration 6020, loss = 0.0511738
I1022 06:17:29.525460 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 06:17:29.525466 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 06:17:29.525473 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0107328 (* 1 = 0.0107328 loss)
I1022 06:17:29.525478 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00708727 (* 1 = 0.00708727 loss)
I1022 06:17:29.525483 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.011278 (* 1 = 0.011278 loss)
I1022 06:17:29.525487 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00746498 (* 1 = 0.00746498 loss)
I1022 06:17:29.525492 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000767555 (* 1 = 0.000767555 loss)
I1022 06:17:29.525497 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.14057e-06 (* 1 = 9.14057e-06 loss)
I1022 06:17:29.525501 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00938202 (* 1 = 0.00938202 loss)
I1022 06:17:29.525506 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00272105 (* 1 = 0.00272105 loss)
I1022 06:17:29.525516 25759 sgd_solver.cpp:106] Iteration 6020, lr = 0.002
I1022 06:18:51.079536 25759 solver.cpp:228] Iteration 6040, loss = 0.0716405
I1022 06:18:51.079584 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:18:51.079589 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:18:51.079597 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:18:51.079602 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:18:51.079607 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00443351 (* 1 = 0.00443351 loss)
I1022 06:18:51.079612 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00466052 (* 1 = 0.00466052 loss)
I1022 06:18:51.079617 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000127997 (* 1 = 0.000127997 loss)
I1022 06:18:51.079622 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.28894e-05 (* 1 = 1.28894e-05 loss)
I1022 06:18:51.079627 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0166465 (* 1 = 0.0166465 loss)
I1022 06:18:51.079632 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000923943 (* 1 = 0.000923943 loss)
I1022 06:18:51.079638 25759 sgd_solver.cpp:106] Iteration 6040, lr = 0.002
I1022 06:20:11.479776 25759 solver.cpp:228] Iteration 6060, loss = 0.156709
I1022 06:20:11.479823 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994009
I1022 06:20:11.479828 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995008
I1022 06:20:11.479836 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0593152 (* 1 = 0.0593152 loss)
I1022 06:20:11.479843 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0364196 (* 1 = 0.0364196 loss)
I1022 06:20:11.479847 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0249847 (* 1 = 0.0249847 loss)
I1022 06:20:11.479851 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0193415 (* 1 = 0.0193415 loss)
I1022 06:20:11.479856 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000804586 (* 1 = 0.000804586 loss)
I1022 06:20:11.479861 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.5655e-06 (* 1 = 9.5655e-06 loss)
I1022 06:20:11.479866 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0164662 (* 1 = 0.0164662 loss)
I1022 06:20:11.479871 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00871185 (* 1 = 0.00871185 loss)
I1022 06:20:11.479876 25759 sgd_solver.cpp:106] Iteration 6060, lr = 0.002
I1022 06:21:33.646497 25759 solver.cpp:228] Iteration 6080, loss = 0.218778
I1022 06:21:33.646544 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 06:21:33.646549 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:21:33.646556 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:21:33.646561 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:21:33.646566 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00668585 (* 1 = 0.00668585 loss)
I1022 06:21:33.646570 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00454723 (* 1 = 0.00454723 loss)
I1022 06:21:33.646575 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000183351 (* 1 = 0.000183351 loss)
I1022 06:21:33.646580 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.00973e-06 (* 1 = 8.00973e-06 loss)
I1022 06:21:33.646584 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00901485 (* 1 = 0.00901485 loss)
I1022 06:21:33.646589 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0045519 (* 1 = 0.0045519 loss)
I1022 06:21:33.646613 25759 sgd_solver.cpp:106] Iteration 6080, lr = 0.002
I1022 06:22:58.180335 25759 solver.cpp:228] Iteration 6100, loss = 0.237311
I1022 06:22:58.180377 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 06:22:58.180394 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 06:22:58.180405 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0125513 (* 1 = 0.0125513 loss)
I1022 06:22:58.180413 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0174802 (* 1 = 0.0174802 loss)
I1022 06:22:58.180420 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00960919 (* 1 = 0.00960919 loss)
I1022 06:22:58.180426 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00973706 (* 1 = 0.00973706 loss)
I1022 06:22:58.180433 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000453066 (* 1 = 0.000453066 loss)
I1022 06:22:58.180440 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.79952e-05 (* 1 = 1.79952e-05 loss)
I1022 06:22:58.180447 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0393555 (* 1 = 0.0393555 loss)
I1022 06:22:58.180454 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00442165 (* 1 = 0.00442165 loss)
I1022 06:22:58.180469 25759 sgd_solver.cpp:106] Iteration 6100, lr = 0.002
I1022 06:24:22.881726 25759 solver.cpp:228] Iteration 6120, loss = 0.231122
I1022 06:24:22.881775 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995504
I1022 06:24:22.881781 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995504
I1022 06:24:22.881788 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0383243 (* 1 = 0.0383243 loss)
I1022 06:24:22.881793 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0155272 (* 1 = 0.0155272 loss)
I1022 06:24:22.881798 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0153784 (* 1 = 0.0153784 loss)
I1022 06:24:22.881801 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0145263 (* 1 = 0.0145263 loss)
I1022 06:24:22.881806 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000112973 (* 1 = 0.000112973 loss)
I1022 06:24:22.881811 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.005216 (* 1 = 0.005216 loss)
I1022 06:24:22.881815 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0200319 (* 1 = 0.0200319 loss)
I1022 06:24:22.881820 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000583629 (* 1 = 0.000583629 loss)
I1022 06:24:22.881825 25759 sgd_solver.cpp:106] Iteration 6120, lr = 0.002
I1022 06:25:47.896893 25759 solver.cpp:228] Iteration 6140, loss = 0.15086
I1022 06:25:47.896982 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.934114
I1022 06:25:47.896998 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.975137
I1022 06:25:47.897014 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.22987 (* 1 = 0.22987 loss)
I1022 06:25:47.897027 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.170245 (* 1 = 0.170245 loss)
I1022 06:25:47.897037 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.14604 (* 1 = 0.14604 loss)
I1022 06:25:47.897049 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0734789 (* 1 = 0.0734789 loss)
I1022 06:25:47.897061 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0289292 (* 1 = 0.0289292 loss)
I1022 06:25:47.897076 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.01977e-05 (* 1 = 2.01977e-05 loss)
I1022 06:25:47.897089 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.242079 (* 1 = 0.242079 loss)
I1022 06:25:47.897101 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00607931 (* 1 = 0.00607931 loss)
I1022 06:25:47.897123 25759 sgd_solver.cpp:106] Iteration 6140, lr = 0.002
I1022 06:27:14.318586 25759 solver.cpp:228] Iteration 6160, loss = 0.143053
I1022 06:27:14.318624 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 06:27:14.318630 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 06:27:14.318639 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.01695 (* 1 = 0.01695 loss)
I1022 06:27:14.318646 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0127846 (* 1 = 0.0127846 loss)
I1022 06:27:14.318651 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0110797 (* 1 = 0.0110797 loss)
I1022 06:27:14.318657 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00817879 (* 1 = 0.00817879 loss)
I1022 06:27:14.318663 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.02019e-05 (* 1 = 5.02019e-05 loss)
I1022 06:27:14.318670 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.43985e-05 (* 1 = 3.43985e-05 loss)
I1022 06:27:14.318675 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0091885 (* 1 = 0.0091885 loss)
I1022 06:27:14.318681 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00251704 (* 1 = 0.00251704 loss)
I1022 06:27:14.318691 25759 sgd_solver.cpp:106] Iteration 6160, lr = 0.002
I1022 06:28:36.074422 25759 solver.cpp:228] Iteration 6180, loss = 0.140931
I1022 06:28:36.074471 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992511
I1022 06:28:36.074476 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995008
I1022 06:28:36.074484 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0359464 (* 1 = 0.0359464 loss)
I1022 06:28:36.074489 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.045551 (* 1 = 0.045551 loss)
I1022 06:28:36.074493 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0269228 (* 1 = 0.0269228 loss)
I1022 06:28:36.074497 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0204989 (* 1 = 0.0204989 loss)
I1022 06:28:36.074502 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00171609 (* 1 = 0.00171609 loss)
I1022 06:28:36.074507 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.72574e-05 (* 1 = 2.72574e-05 loss)
I1022 06:28:36.074512 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0326207 (* 1 = 0.0326207 loss)
I1022 06:28:36.074517 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00363696 (* 1 = 0.00363696 loss)
I1022 06:28:36.074525 25759 sgd_solver.cpp:106] Iteration 6180, lr = 0.002
speed: 4.202s / iter
I1022 06:29:59.685341 25759 solver.cpp:228] Iteration 6200, loss = 0.131754
I1022 06:29:59.685379 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993506
I1022 06:29:59.685385 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 06:29:59.685395 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0337615 (* 1 = 0.0337615 loss)
I1022 06:29:59.685401 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0328364 (* 1 = 0.0328364 loss)
I1022 06:29:59.685406 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0181308 (* 1 = 0.0181308 loss)
I1022 06:29:59.685412 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0119793 (* 1 = 0.0119793 loss)
I1022 06:29:59.685418 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.68663e-05 (* 1 = 8.68663e-05 loss)
I1022 06:29:59.685425 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.58046e-05 (* 1 = 1.58046e-05 loss)
I1022 06:29:59.685431 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00836559 (* 1 = 0.00836559 loss)
I1022 06:29:59.685436 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000269373 (* 1 = 0.000269373 loss)
I1022 06:29:59.685442 25759 sgd_solver.cpp:106] Iteration 6200, lr = 0.002
I1022 06:31:23.805742 25759 solver.cpp:228] Iteration 6220, loss = 0.0596912
I1022 06:31:23.808357 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992508
I1022 06:31:23.808377 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 06:31:23.808403 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.01567 (* 1 = 0.01567 loss)
I1022 06:31:23.808416 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0253998 (* 1 = 0.0253998 loss)
I1022 06:31:23.808428 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0235313 (* 1 = 0.0235313 loss)
I1022 06:31:23.808454 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0171156 (* 1 = 0.0171156 loss)
I1022 06:31:23.808473 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00165834 (* 1 = 0.00165834 loss)
I1022 06:31:23.808491 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.97921e-05 (* 1 = 3.97921e-05 loss)
I1022 06:31:23.808507 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0544244 (* 1 = 0.0544244 loss)
I1022 06:31:23.808524 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00266147 (* 1 = 0.00266147 loss)
I1022 06:31:23.808542 25759 sgd_solver.cpp:106] Iteration 6220, lr = 0.002
I1022 06:32:47.015051 25759 solver.cpp:228] Iteration 6240, loss = 0.0518783
I1022 06:32:47.015110 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992504
I1022 06:32:47.015116 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 06:32:47.015125 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0128616 (* 1 = 0.0128616 loss)
I1022 06:32:47.015132 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000970318 (* 1 = 0.000970318 loss)
I1022 06:32:47.015137 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0189648 (* 1 = 0.0189648 loss)
I1022 06:32:47.015141 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00574564 (* 1 = 0.00574564 loss)
I1022 06:32:47.015146 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000165486 (* 1 = 0.000165486 loss)
I1022 06:32:47.015152 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.29298e-05 (* 1 = 1.29298e-05 loss)
I1022 06:32:47.015156 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0103177 (* 1 = 0.0103177 loss)
I1022 06:32:47.015162 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000257205 (* 1 = 0.000257205 loss)
I1022 06:32:47.015183 25759 sgd_solver.cpp:106] Iteration 6240, lr = 0.002
I1022 06:34:08.926717 25759 solver.cpp:228] Iteration 6260, loss = 0.12123
I1022 06:34:08.926756 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995504
I1022 06:34:08.926764 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1022 06:34:08.926772 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0418117 (* 1 = 0.0418117 loss)
I1022 06:34:08.926779 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0319481 (* 1 = 0.0319481 loss)
I1022 06:34:08.926784 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0165425 (* 1 = 0.0165425 loss)
I1022 06:34:08.926790 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0155526 (* 1 = 0.0155526 loss)
I1022 06:34:08.926795 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00074485 (* 1 = 0.00074485 loss)
I1022 06:34:08.926802 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.23917e-05 (* 1 = 2.23917e-05 loss)
I1022 06:34:08.926807 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0261048 (* 1 = 0.0261048 loss)
I1022 06:34:08.926813 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000235773 (* 1 = 0.000235773 loss)
I1022 06:34:08.926821 25759 sgd_solver.cpp:106] Iteration 6260, lr = 0.002
I1022 06:35:32.168957 25759 solver.cpp:228] Iteration 6280, loss = 0.0962936
I1022 06:35:32.168999 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995504
I1022 06:35:32.169006 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 06:35:32.169015 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.01709 (* 1 = 0.01709 loss)
I1022 06:35:32.169023 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0341551 (* 1 = 0.0341551 loss)
I1022 06:35:32.169028 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0208888 (* 1 = 0.0208888 loss)
I1022 06:35:32.169032 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0183641 (* 1 = 0.0183641 loss)
I1022 06:35:32.169039 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000501785 (* 1 = 0.000501785 loss)
I1022 06:35:32.169045 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.16444e-06 (* 1 = 8.16444e-06 loss)
I1022 06:35:32.169050 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0408449 (* 1 = 0.0408449 loss)
I1022 06:35:32.169056 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000611213 (* 1 = 0.000611213 loss)
I1022 06:35:32.169064 25759 sgd_solver.cpp:106] Iteration 6280, lr = 0.002
I1022 06:36:56.745090 25759 solver.cpp:228] Iteration 6300, loss = 0.128912
I1022 06:36:56.745146 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 06:36:56.745152 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:36:56.745162 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0132607 (* 1 = 0.0132607 loss)
I1022 06:36:56.745170 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00187193 (* 1 = 0.00187193 loss)
I1022 06:36:56.745177 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00885143 (* 1 = 0.00885143 loss)
I1022 06:36:56.745182 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00490947 (* 1 = 0.00490947 loss)
I1022 06:36:56.745189 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000210248 (* 1 = 0.000210248 loss)
I1022 06:36:56.745196 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.7178e-05 (* 1 = 1.7178e-05 loss)
I1022 06:36:56.745203 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00627715 (* 1 = 0.00627715 loss)
I1022 06:36:56.745209 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00347379 (* 1 = 0.00347379 loss)
I1022 06:36:56.745218 25759 sgd_solver.cpp:106] Iteration 6300, lr = 0.002
I1022 06:38:22.557534 25759 solver.cpp:228] Iteration 6320, loss = 0.124132
I1022 06:38:22.557596 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:38:22.557605 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:38:22.557615 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:38:22.557622 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:38:22.557629 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00441671 (* 1 = 0.00441671 loss)
I1022 06:38:22.557636 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00424737 (* 1 = 0.00424737 loss)
I1022 06:38:22.557646 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.829e-05 (* 1 = 6.829e-05 loss)
I1022 06:38:22.557654 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.6838e-05 (* 1 = 2.6838e-05 loss)
I1022 06:38:22.557662 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00306699 (* 1 = 0.00306699 loss)
I1022 06:38:22.557670 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00369291 (* 1 = 0.00369291 loss)
I1022 06:38:22.557680 25759 sgd_solver.cpp:106] Iteration 6320, lr = 0.002
I1022 06:39:46.357813 25759 solver.cpp:228] Iteration 6340, loss = 0.139267
I1022 06:39:46.357880 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 06:39:46.357892 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 06:39:46.357910 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00728285 (* 1 = 0.00728285 loss)
I1022 06:39:46.357923 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00889657 (* 1 = 0.00889657 loss)
I1022 06:39:46.357933 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0117011 (* 1 = 0.0117011 loss)
I1022 06:39:46.357944 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00796695 (* 1 = 0.00796695 loss)
I1022 06:39:46.357957 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000101675 (* 1 = 0.000101675 loss)
I1022 06:39:46.357971 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.57012e-05 (* 1 = 2.57012e-05 loss)
I1022 06:39:46.357982 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0069752 (* 1 = 0.0069752 loss)
I1022 06:39:46.357995 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000461441 (* 1 = 0.000461441 loss)
I1022 06:39:46.358008 25759 sgd_solver.cpp:106] Iteration 6340, lr = 0.002
I1022 06:41:13.300352 25759 solver.cpp:228] Iteration 6360, loss = 0.0634969
I1022 06:41:13.300426 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 06:41:13.300438 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 06:41:13.300456 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00999497 (* 1 = 0.00999497 loss)
I1022 06:41:13.300468 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00384266 (* 1 = 0.00384266 loss)
I1022 06:41:13.300479 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00725543 (* 1 = 0.00725543 loss)
I1022 06:41:13.300490 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00568098 (* 1 = 0.00568098 loss)
I1022 06:41:13.300505 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000234844 (* 1 = 0.000234844 loss)
I1022 06:41:13.300520 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.68792e-05 (* 1 = 2.68792e-05 loss)
I1022 06:41:13.300534 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00282452 (* 1 = 0.00282452 loss)
I1022 06:41:13.300547 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00151108 (* 1 = 0.00151108 loss)
I1022 06:41:13.300559 25759 sgd_solver.cpp:106] Iteration 6360, lr = 0.002
I1022 06:42:40.222512 25759 solver.cpp:228] Iteration 6380, loss = 0.218827
I1022 06:42:40.222575 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99001
I1022 06:42:40.222585 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995504
I1022 06:42:40.222600 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0259602 (* 1 = 0.0259602 loss)
I1022 06:42:40.222612 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0310827 (* 1 = 0.0310827 loss)
I1022 06:42:40.222621 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0260947 (* 1 = 0.0260947 loss)
I1022 06:42:40.222631 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0143215 (* 1 = 0.0143215 loss)
I1022 06:42:40.222640 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000709928 (* 1 = 0.000709928 loss)
I1022 06:42:40.222651 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.51704e-05 (* 1 = 1.51704e-05 loss)
I1022 06:42:40.222666 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0167546 (* 1 = 0.0167546 loss)
I1022 06:42:40.222676 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00218946 (* 1 = 0.00218946 loss)
I1022 06:42:40.222695 25759 sgd_solver.cpp:106] Iteration 6380, lr = 0.002
speed: 4.203s / iter
I1022 06:44:05.201015 25759 solver.cpp:228] Iteration 6400, loss = 0.0577665
I1022 06:44:05.201069 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 06:44:05.201074 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 06:44:05.201082 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0084348 (* 1 = 0.0084348 loss)
I1022 06:44:05.201087 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0126716 (* 1 = 0.0126716 loss)
I1022 06:44:05.201092 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00753327 (* 1 = 0.00753327 loss)
I1022 06:44:05.201097 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00605407 (* 1 = 0.00605407 loss)
I1022 06:44:05.201100 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.58015e-05 (* 1 = 7.58015e-05 loss)
I1022 06:44:05.201105 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.54583e-06 (* 1 = 8.54583e-06 loss)
I1022 06:44:05.201109 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00539357 (* 1 = 0.00539357 loss)
I1022 06:44:05.201114 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000533545 (* 1 = 0.000533545 loss)
I1022 06:44:05.201120 25759 sgd_solver.cpp:106] Iteration 6400, lr = 0.002
I1022 06:45:26.515758 25759 solver.cpp:228] Iteration 6420, loss = 0.13902
I1022 06:45:26.515796 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:45:26.515802 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:45:26.515811 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:45:26.515817 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:45:26.515823 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00432632 (* 1 = 0.00432632 loss)
I1022 06:45:26.515830 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00425957 (* 1 = 0.00425957 loss)
I1022 06:45:26.515836 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0001367 (* 1 = 0.0001367 loss)
I1022 06:45:26.515842 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.58961e-06 (* 1 = 9.58961e-06 loss)
I1022 06:45:26.515847 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00133447 (* 1 = 0.00133447 loss)
I1022 06:45:26.515853 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000642621 (* 1 = 0.000642621 loss)
I1022 06:45:26.515861 25759 sgd_solver.cpp:106] Iteration 6420, lr = 0.002
I1022 06:46:47.371654 25759 solver.cpp:228] Iteration 6440, loss = 0.163417
I1022 06:46:47.371686 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:46:47.371691 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:46:47.371697 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:46:47.371702 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:46:47.371706 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00473476 (* 1 = 0.00473476 loss)
I1022 06:46:47.371711 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00451917 (* 1 = 0.00451917 loss)
I1022 06:46:47.371716 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.29303e-05 (* 1 = 6.29303e-05 loss)
I1022 06:46:47.371721 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.7108e-06 (* 1 = 5.7108e-06 loss)
I1022 06:46:47.371726 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00539965 (* 1 = 0.00539965 loss)
I1022 06:46:47.371729 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00305118 (* 1 = 0.00305118 loss)
I1022 06:46:47.371735 25759 sgd_solver.cpp:106] Iteration 6440, lr = 0.002
I1022 06:48:07.483050 25759 solver.cpp:228] Iteration 6460, loss = 0.122412
I1022 06:48:07.483084 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993506
I1022 06:48:07.483088 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 06:48:07.483096 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0242519 (* 1 = 0.0242519 loss)
I1022 06:48:07.483101 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0125724 (* 1 = 0.0125724 loss)
I1022 06:48:07.483105 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0216681 (* 1 = 0.0216681 loss)
I1022 06:48:07.483109 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0149507 (* 1 = 0.0149507 loss)
I1022 06:48:07.483114 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00193971 (* 1 = 0.00193971 loss)
I1022 06:48:07.483119 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.76107e-05 (* 1 = 1.76107e-05 loss)
I1022 06:48:07.483122 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0491349 (* 1 = 0.0491349 loss)
I1022 06:48:07.483126 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000281558 (* 1 = 0.000281558 loss)
I1022 06:48:07.483131 25759 sgd_solver.cpp:106] Iteration 6460, lr = 0.002
I1022 06:49:28.460415 25759 solver.cpp:228] Iteration 6480, loss = 0.066809
I1022 06:49:28.460485 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 06:49:28.460491 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 06:49:28.460500 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00835069 (* 1 = 0.00835069 loss)
I1022 06:49:28.460506 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00968684 (* 1 = 0.00968684 loss)
I1022 06:49:28.460510 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00965345 (* 1 = 0.00965345 loss)
I1022 06:49:28.460515 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00923985 (* 1 = 0.00923985 loss)
I1022 06:49:28.460520 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.05744e-05 (* 1 = 3.05744e-05 loss)
I1022 06:49:28.460525 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.58727e-05 (* 1 = 2.58727e-05 loss)
I1022 06:49:28.460530 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00338196 (* 1 = 0.00338196 loss)
I1022 06:49:28.460535 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00288957 (* 1 = 0.00288957 loss)
I1022 06:49:28.460543 25759 sgd_solver.cpp:106] Iteration 6480, lr = 0.002
I1022 06:50:50.633757 25759 solver.cpp:228] Iteration 6500, loss = 0.387353
I1022 06:50:50.633810 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99676
I1022 06:50:50.633821 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1022 06:50:50.633837 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0336602 (* 1 = 0.0336602 loss)
I1022 06:50:50.633848 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0326736 (* 1 = 0.0326736 loss)
I1022 06:50:50.633858 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0180902 (* 1 = 0.0180902 loss)
I1022 06:50:50.633868 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0243063 (* 1 = 0.0243063 loss)
I1022 06:50:50.633878 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00353416 (* 1 = 0.00353416 loss)
I1022 06:50:50.633890 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.52921e-05 (* 1 = 4.52921e-05 loss)
I1022 06:50:50.633913 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.174986 (* 1 = 0.174986 loss)
I1022 06:50:50.633926 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00619449 (* 1 = 0.00619449 loss)
I1022 06:50:50.633939 25759 sgd_solver.cpp:106] Iteration 6500, lr = 0.002
I1022 06:52:16.566854 25759 solver.cpp:228] Iteration 6520, loss = 0.0549525
I1022 06:52:16.566918 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:52:16.566925 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:52:16.566932 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:52:16.566937 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:52:16.566941 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00430917 (* 1 = 0.00430917 loss)
I1022 06:52:16.566946 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00469982 (* 1 = 0.00469982 loss)
I1022 06:52:16.566951 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.5924e-05 (* 1 = 5.5924e-05 loss)
I1022 06:52:16.566956 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.28641e-06 (* 1 = 9.28641e-06 loss)
I1022 06:52:16.566962 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00333102 (* 1 = 0.00333102 loss)
I1022 06:52:16.566967 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000112288 (* 1 = 0.000112288 loss)
I1022 06:52:16.566973 25759 sgd_solver.cpp:106] Iteration 6520, lr = 0.002
I1022 06:53:42.007508 25759 solver.cpp:228] Iteration 6540, loss = 0.123945
I1022 06:53:42.007565 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994003
I1022 06:53:42.007571 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 06:53:42.007582 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00702378 (* 1 = 0.00702378 loss)
I1022 06:53:42.007591 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00627116 (* 1 = 0.00627116 loss)
I1022 06:53:42.007596 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0148721 (* 1 = 0.0148721 loss)
I1022 06:53:42.007603 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00689417 (* 1 = 0.00689417 loss)
I1022 06:53:42.007611 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000373803 (* 1 = 0.000373803 loss)
I1022 06:53:42.007618 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.93022e-06 (* 1 = 3.93022e-06 loss)
I1022 06:53:42.007625 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.007409 (* 1 = 0.007409 loss)
I1022 06:53:42.007632 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00243748 (* 1 = 0.00243748 loss)
I1022 06:53:42.007644 25759 sgd_solver.cpp:106] Iteration 6540, lr = 0.002
I1022 06:55:08.068564 25759 solver.cpp:228] Iteration 6560, loss = 0.0766038
I1022 06:55:08.068598 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 06:55:08.068603 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:55:08.068614 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:55:08.068634 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:55:08.068639 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00715595 (* 1 = 0.00715595 loss)
I1022 06:55:08.068642 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00491496 (* 1 = 0.00491496 loss)
I1022 06:55:08.068647 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00012838 (* 1 = 0.00012838 loss)
I1022 06:55:08.068652 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.07338e-05 (* 1 = 1.07338e-05 loss)
I1022 06:55:08.068656 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00406946 (* 1 = 0.00406946 loss)
I1022 06:55:08.068661 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00143083 (* 1 = 0.00143083 loss)
I1022 06:55:08.068670 25759 sgd_solver.cpp:106] Iteration 6560, lr = 0.002
I1022 06:56:31.379014 25759 solver.cpp:228] Iteration 6580, loss = 0.0712492
I1022 06:56:31.379057 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990449
I1022 06:56:31.379065 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 06:56:31.379076 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0349467 (* 1 = 0.0349467 loss)
I1022 06:56:31.379084 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0119686 (* 1 = 0.0119686 loss)
I1022 06:56:31.379093 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.033306 (* 1 = 0.033306 loss)
I1022 06:56:31.379099 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0162346 (* 1 = 0.0162346 loss)
I1022 06:56:31.379106 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0186648 (* 1 = 0.0186648 loss)
I1022 06:56:31.379114 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.9946e-05 (* 1 = 3.9946e-05 loss)
I1022 06:56:31.379122 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0729004 (* 1 = 0.0729004 loss)
I1022 06:56:31.379129 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00445837 (* 1 = 0.00445837 loss)
I1022 06:56:31.379137 25759 sgd_solver.cpp:106] Iteration 6580, lr = 0.002
speed: 4.202s / iter
I1022 06:57:57.740787 25759 solver.cpp:228] Iteration 6600, loss = 0.070177
I1022 06:57:57.740837 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 06:57:57.740844 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:57:57.740852 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:57:57.740859 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:57:57.740864 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00440011 (* 1 = 0.00440011 loss)
I1022 06:57:57.740872 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00440838 (* 1 = 0.00440838 loss)
I1022 06:57:57.740880 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000215714 (* 1 = 0.000215714 loss)
I1022 06:57:57.740885 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.66249e-05 (* 1 = 1.66249e-05 loss)
I1022 06:57:57.740891 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0153283 (* 1 = 0.0153283 loss)
I1022 06:57:57.740897 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00518265 (* 1 = 0.00518265 loss)
I1022 06:57:57.740905 25759 sgd_solver.cpp:106] Iteration 6600, lr = 0.002
I1022 06:59:24.504439 25759 solver.cpp:228] Iteration 6620, loss = 0.133981
I1022 06:59:24.504519 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 06:59:24.504531 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 06:59:24.504546 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 06:59:24.504559 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 06:59:24.504570 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00105479 (* 1 = 0.00105479 loss)
I1022 06:59:24.504586 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0046208 (* 1 = 0.0046208 loss)
I1022 06:59:24.504601 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00335777 (* 1 = 0.00335777 loss)
I1022 06:59:24.504629 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.18443e-06 (* 1 = 9.18443e-06 loss)
I1022 06:59:24.504642 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000255537 (* 1 = 0.000255537 loss)
I1022 06:59:24.504655 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00526092 (* 1 = 0.00526092 loss)
I1022 06:59:24.504670 25759 sgd_solver.cpp:106] Iteration 6620, lr = 0.002
I1022 07:00:49.246330 25759 solver.cpp:228] Iteration 6640, loss = 0.0649207
I1022 07:00:49.246431 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:00:49.246443 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:00:49.246457 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:00:49.246469 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:00:49.246479 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00494676 (* 1 = 0.00494676 loss)
I1022 07:00:49.246492 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00445075 (* 1 = 0.00445075 loss)
I1022 07:00:49.246505 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000252489 (* 1 = 0.000252489 loss)
I1022 07:00:49.246517 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.27594e-05 (* 1 = 1.27594e-05 loss)
I1022 07:00:49.246531 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0013822 (* 1 = 0.0013822 loss)
I1022 07:00:49.246543 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000730938 (* 1 = 0.000730938 loss)
I1022 07:00:49.246562 25759 sgd_solver.cpp:106] Iteration 6640, lr = 0.002
I1022 07:02:14.951210 25759 solver.cpp:228] Iteration 6660, loss = 0.154576
I1022 07:02:14.951267 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 07:02:14.951274 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:02:14.951284 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:02:14.951292 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:02:14.951298 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00783315 (* 1 = 0.00783315 loss)
I1022 07:02:14.951304 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00527969 (* 1 = 0.00527969 loss)
I1022 07:02:14.951311 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000153733 (* 1 = 0.000153733 loss)
I1022 07:02:14.951318 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.56408e-05 (* 1 = 1.56408e-05 loss)
I1022 07:02:14.951324 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00663271 (* 1 = 0.00663271 loss)
I1022 07:02:14.951330 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000597409 (* 1 = 0.000597409 loss)
I1022 07:02:14.951344 25759 sgd_solver.cpp:106] Iteration 6660, lr = 0.002
I1022 07:03:41.869236 25759 solver.cpp:228] Iteration 6680, loss = 0.195676
I1022 07:03:41.869318 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.957871
I1022 07:03:41.869328 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.97069
I1022 07:03:41.869345 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.221071 (* 1 = 0.221071 loss)
I1022 07:03:41.869359 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.246464 (* 1 = 0.246464 loss)
I1022 07:03:41.869369 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.111378 (* 1 = 0.111378 loss)
I1022 07:03:41.869380 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0919529 (* 1 = 0.0919529 loss)
I1022 07:03:41.869395 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00648555 (* 1 = 0.00648555 loss)
I1022 07:03:41.869410 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.3721e-05 (* 1 = 1.3721e-05 loss)
I1022 07:03:41.869422 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.283324 (* 1 = 0.283324 loss)
I1022 07:03:41.869436 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00135994 (* 1 = 0.00135994 loss)
I1022 07:03:41.869454 25759 sgd_solver.cpp:106] Iteration 6680, lr = 0.002
I1022 07:05:06.055591 25759 solver.cpp:228] Iteration 6700, loss = 0.287061
I1022 07:05:06.055635 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:05:06.055644 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:05:06.055652 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:05:06.055660 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:05:06.055666 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00478662 (* 1 = 0.00478662 loss)
I1022 07:05:06.055673 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00406272 (* 1 = 0.00406272 loss)
I1022 07:05:06.055680 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.97889e-05 (* 1 = 7.97889e-05 loss)
I1022 07:05:06.055687 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.19437e-05 (* 1 = 1.19437e-05 loss)
I1022 07:05:06.055696 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0173841 (* 1 = 0.0173841 loss)
I1022 07:05:06.055703 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00020215 (* 1 = 0.00020215 loss)
I1022 07:05:06.055711 25759 sgd_solver.cpp:106] Iteration 6700, lr = 0.002
I1022 07:06:30.316363 25759 solver.cpp:228] Iteration 6720, loss = 0.0718722
I1022 07:06:30.316404 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:06:30.316411 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:06:30.316421 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:06:30.316426 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:06:30.316433 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00467591 (* 1 = 0.00467591 loss)
I1022 07:06:30.316442 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00444152 (* 1 = 0.00444152 loss)
I1022 07:06:30.316449 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.34736e-05 (* 1 = 6.34736e-05 loss)
I1022 07:06:30.316455 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.35384e-06 (* 1 = 6.35384e-06 loss)
I1022 07:06:30.316462 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00901827 (* 1 = 0.00901827 loss)
I1022 07:06:30.316468 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00348105 (* 1 = 0.00348105 loss)
I1022 07:06:30.316475 25759 sgd_solver.cpp:106] Iteration 6720, lr = 0.002
I1022 07:07:54.163789 25759 solver.cpp:228] Iteration 6740, loss = 0.144298
I1022 07:07:54.163838 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:07:54.163843 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:07:54.163851 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:07:54.163858 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:07:54.163862 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00451626 (* 1 = 0.00451626 loss)
I1022 07:07:54.163866 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00458805 (* 1 = 0.00458805 loss)
I1022 07:07:54.163872 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000126704 (* 1 = 0.000126704 loss)
I1022 07:07:54.163877 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.91856e-05 (* 1 = 1.91856e-05 loss)
I1022 07:07:54.163880 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00722917 (* 1 = 0.00722917 loss)
I1022 07:07:54.163885 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00216547 (* 1 = 0.00216547 loss)
I1022 07:07:54.163892 25759 sgd_solver.cpp:106] Iteration 6740, lr = 0.002
I1022 07:09:17.033030 25759 solver.cpp:228] Iteration 6760, loss = 0.0338872
I1022 07:09:17.033067 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998995
I1022 07:09:17.033072 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:09:17.033079 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0124751 (* 1 = 0.0124751 loss)
I1022 07:09:17.033084 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00839363 (* 1 = 0.00839363 loss)
I1022 07:09:17.033089 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00609423 (* 1 = 0.00609423 loss)
I1022 07:09:17.033093 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00737901 (* 1 = 0.00737901 loss)
I1022 07:09:17.033098 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000371753 (* 1 = 0.000371753 loss)
I1022 07:09:17.033103 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.97102e-05 (* 1 = 2.97102e-05 loss)
I1022 07:09:17.033107 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0105458 (* 1 = 0.0105458 loss)
I1022 07:09:17.033112 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00328329 (* 1 = 0.00328329 loss)
I1022 07:09:17.033118 25759 sgd_solver.cpp:106] Iteration 6760, lr = 0.002
I1022 07:10:42.334378 25759 solver.cpp:228] Iteration 6780, loss = 0.0742617
I1022 07:10:42.334440 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99069
I1022 07:10:42.334452 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99301
I1022 07:10:42.334468 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.044162 (* 1 = 0.044162 loss)
I1022 07:10:42.334481 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0441702 (* 1 = 0.0441702 loss)
I1022 07:10:42.334491 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.024217 (* 1 = 0.024217 loss)
I1022 07:10:42.334502 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0237363 (* 1 = 0.0237363 loss)
I1022 07:10:42.334513 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000173875 (* 1 = 0.000173875 loss)
I1022 07:10:42.334529 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.48748e-05 (* 1 = 1.48748e-05 loss)
I1022 07:10:42.334540 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0285387 (* 1 = 0.0285387 loss)
I1022 07:10:42.334554 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.001585 (* 1 = 0.001585 loss)
I1022 07:10:42.334568 25759 sgd_solver.cpp:106] Iteration 6780, lr = 0.002
speed: 4.203s / iter
I1022 07:12:07.730631 25759 solver.cpp:228] Iteration 6800, loss = 0.0764706
I1022 07:12:07.730680 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994124
I1022 07:12:07.730685 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 07:12:07.730693 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.092928 (* 1 = 0.092928 loss)
I1022 07:12:07.730698 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0345634 (* 1 = 0.0345634 loss)
I1022 07:12:07.730703 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0112325 (* 1 = 0.0112325 loss)
I1022 07:12:07.730707 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0101847 (* 1 = 0.0101847 loss)
I1022 07:12:07.730711 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000108352 (* 1 = 0.000108352 loss)
I1022 07:12:07.730717 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.66656e-05 (* 1 = 1.66656e-05 loss)
I1022 07:12:07.730721 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0302044 (* 1 = 0.0302044 loss)
I1022 07:12:07.730726 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00289308 (* 1 = 0.00289308 loss)
I1022 07:12:07.730734 25759 sgd_solver.cpp:106] Iteration 6800, lr = 0.002
I1022 07:13:31.431747 25759 solver.cpp:228] Iteration 6820, loss = 0.100075
I1022 07:13:31.431780 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:13:31.431802 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:13:31.431808 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:13:31.431813 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:13:31.431818 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00519929 (* 1 = 0.00519929 loss)
I1022 07:13:31.431821 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00438054 (* 1 = 0.00438054 loss)
I1022 07:13:31.431825 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.01152e-05 (* 1 = 8.01152e-05 loss)
I1022 07:13:31.431830 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.60648e-05 (* 1 = 1.60648e-05 loss)
I1022 07:13:31.431851 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00840137 (* 1 = 0.00840137 loss)
I1022 07:13:31.431855 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00241408 (* 1 = 0.00241408 loss)
I1022 07:13:31.431862 25759 sgd_solver.cpp:106] Iteration 6820, lr = 0.002
I1022 07:14:54.103896 25759 solver.cpp:228] Iteration 6840, loss = 0.235587
I1022 07:14:54.103929 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 07:14:54.103935 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:14:54.103941 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:14:54.103945 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:14:54.103950 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00573622 (* 1 = 0.00573622 loss)
I1022 07:14:54.103955 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00423969 (* 1 = 0.00423969 loss)
I1022 07:14:54.103961 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00245379 (* 1 = 0.00245379 loss)
I1022 07:14:54.103966 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.06591e-05 (* 1 = 1.06591e-05 loss)
I1022 07:14:54.103971 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0151354 (* 1 = 0.0151354 loss)
I1022 07:14:54.103974 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000208492 (* 1 = 0.000208492 loss)
I1022 07:14:54.103981 25759 sgd_solver.cpp:106] Iteration 6840, lr = 0.002
I1022 07:16:15.192955 25759 solver.cpp:228] Iteration 6860, loss = 0.191122
I1022 07:16:15.193006 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 07:16:15.193027 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 07:16:15.193034 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0158227 (* 1 = 0.0158227 loss)
I1022 07:16:15.193039 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00879584 (* 1 = 0.00879584 loss)
I1022 07:16:15.193043 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0113079 (* 1 = 0.0113079 loss)
I1022 07:16:15.193048 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00773263 (* 1 = 0.00773263 loss)
I1022 07:16:15.193053 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.69251e-05 (* 1 = 4.69251e-05 loss)
I1022 07:16:15.193058 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.05079e-06 (* 1 = 5.05079e-06 loss)
I1022 07:16:15.193063 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0105608 (* 1 = 0.0105608 loss)
I1022 07:16:15.193068 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00894126 (* 1 = 0.00894126 loss)
I1022 07:16:15.193076 25759 sgd_solver.cpp:106] Iteration 6860, lr = 0.002
I1022 07:17:39.142702 25759 solver.cpp:228] Iteration 6880, loss = 0.256824
I1022 07:17:39.142771 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 07:17:39.142778 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:17:39.142791 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:17:39.142797 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:17:39.142805 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00597112 (* 1 = 0.00597112 loss)
I1022 07:17:39.142813 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00436005 (* 1 = 0.00436005 loss)
I1022 07:17:39.142820 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.1133e-05 (* 1 = 6.1133e-05 loss)
I1022 07:17:39.142829 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.66035e-06 (* 1 = 5.66035e-06 loss)
I1022 07:17:39.142837 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00441563 (* 1 = 0.00441563 loss)
I1022 07:17:39.142844 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00270874 (* 1 = 0.00270874 loss)
I1022 07:17:39.142853 25759 sgd_solver.cpp:106] Iteration 6880, lr = 0.002
I1022 07:19:01.891247 25759 solver.cpp:228] Iteration 6900, loss = 0.0835773
I1022 07:19:01.891288 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:19:01.891295 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:19:01.891304 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:19:01.891310 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:19:01.891317 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00430403 (* 1 = 0.00430403 loss)
I1022 07:19:01.891327 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00436156 (* 1 = 0.00436156 loss)
I1022 07:19:01.891333 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.78383e-05 (* 1 = 6.78383e-05 loss)
I1022 07:19:01.891340 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.77834e-06 (* 1 = 8.77834e-06 loss)
I1022 07:19:01.891347 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000390793 (* 1 = 0.000390793 loss)
I1022 07:19:01.891353 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00481654 (* 1 = 0.00481654 loss)
I1022 07:19:01.891360 25759 sgd_solver.cpp:106] Iteration 6900, lr = 0.002
I1022 07:20:23.158771 25759 solver.cpp:228] Iteration 6920, loss = 0.161156
I1022 07:20:23.158812 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:20:23.158818 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:20:23.158824 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:20:23.158829 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:20:23.158833 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00440794 (* 1 = 0.00440794 loss)
I1022 07:20:23.158838 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00445459 (* 1 = 0.00445459 loss)
I1022 07:20:23.158843 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.55873e-05 (* 1 = 7.55873e-05 loss)
I1022 07:20:23.158850 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.64615e-06 (* 1 = 6.64615e-06 loss)
I1022 07:20:23.158854 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00153259 (* 1 = 0.00153259 loss)
I1022 07:20:23.158859 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000179827 (* 1 = 0.000179827 loss)
I1022 07:20:23.158865 25759 sgd_solver.cpp:106] Iteration 6920, lr = 0.002
I1022 07:21:49.447036 25759 solver.cpp:228] Iteration 6940, loss = 0.265088
I1022 07:21:49.447093 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996004
I1022 07:21:49.447099 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996503
I1022 07:21:49.447109 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0166953 (* 1 = 0.0166953 loss)
I1022 07:21:49.447118 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0260331 (* 1 = 0.0260331 loss)
I1022 07:21:49.447124 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0189294 (* 1 = 0.0189294 loss)
I1022 07:21:49.447129 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0162218 (* 1 = 0.0162218 loss)
I1022 07:21:49.447135 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00342546 (* 1 = 0.00342546 loss)
I1022 07:21:49.447142 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000331867 (* 1 = 0.000331867 loss)
I1022 07:21:49.447149 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.018159 (* 1 = 0.018159 loss)
I1022 07:21:49.447155 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000128301 (* 1 = 0.000128301 loss)
I1022 07:21:49.447162 25759 sgd_solver.cpp:106] Iteration 6940, lr = 0.002
I1022 07:23:16.467592 25759 solver.cpp:228] Iteration 6960, loss = 0.0812385
I1022 07:23:16.467648 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:23:16.467654 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 07:23:16.467664 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0063418 (* 1 = 0.0063418 loss)
I1022 07:23:16.467671 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.013888 (* 1 = 0.013888 loss)
I1022 07:23:16.467677 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00701334 (* 1 = 0.00701334 loss)
I1022 07:23:16.467684 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00640814 (* 1 = 0.00640814 loss)
I1022 07:23:16.467690 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.17742e-05 (* 1 = 2.17742e-05 loss)
I1022 07:23:16.467697 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.08449e-05 (* 1 = 1.08449e-05 loss)
I1022 07:23:16.467703 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00375158 (* 1 = 0.00375158 loss)
I1022 07:23:16.467710 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00048234 (* 1 = 0.00048234 loss)
I1022 07:23:16.467717 25759 sgd_solver.cpp:106] Iteration 6960, lr = 0.002
I1022 07:24:39.183990 25759 solver.cpp:228] Iteration 6980, loss = 0.132579
I1022 07:24:39.184023 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:24:39.184028 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:24:39.184036 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:24:39.184039 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:24:39.184044 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0040979 (* 1 = 0.0040979 loss)
I1022 07:24:39.184048 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00448868 (* 1 = 0.00448868 loss)
I1022 07:24:39.184053 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.86723e-05 (* 1 = 7.86723e-05 loss)
I1022 07:24:39.184057 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.44345e-05 (* 1 = 1.44345e-05 loss)
I1022 07:24:39.184062 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00851074 (* 1 = 0.00851074 loss)
I1022 07:24:39.184065 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00704103 (* 1 = 0.00704103 loss)
I1022 07:24:39.184075 25759 sgd_solver.cpp:106] Iteration 6980, lr = 0.002
speed: 4.203s / iter
I1022 07:26:03.600278 25759 solver.cpp:228] Iteration 7000, loss = 0.0878749
I1022 07:26:03.600324 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989521
I1022 07:26:03.600332 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991517
I1022 07:26:03.600340 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0628894 (* 1 = 0.0628894 loss)
I1022 07:26:03.600347 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.100435 (* 1 = 0.100435 loss)
I1022 07:26:03.600353 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.04087 (* 1 = 0.04087 loss)
I1022 07:26:03.600359 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0290778 (* 1 = 0.0290778 loss)
I1022 07:26:03.600365 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000998455 (* 1 = 0.000998455 loss)
I1022 07:26:03.600373 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.01266e-05 (* 1 = 1.01266e-05 loss)
I1022 07:26:03.600378 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0591324 (* 1 = 0.0591324 loss)
I1022 07:26:03.600384 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000374905 (* 1 = 0.000374905 loss)
I1022 07:26:03.600391 25759 sgd_solver.cpp:106] Iteration 7000, lr = 0.002
I1022 07:27:29.925731 25759 solver.cpp:228] Iteration 7020, loss = 0.0980552
I1022 07:27:29.925763 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990505
I1022 07:27:29.925768 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 07:27:29.925776 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0191813 (* 1 = 0.0191813 loss)
I1022 07:27:29.925781 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00806099 (* 1 = 0.00806099 loss)
I1022 07:27:29.925784 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0201521 (* 1 = 0.0201521 loss)
I1022 07:27:29.925789 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00724074 (* 1 = 0.00724074 loss)
I1022 07:27:29.925793 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000288654 (* 1 = 0.000288654 loss)
I1022 07:27:29.925797 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.20869e-05 (* 1 = 1.20869e-05 loss)
I1022 07:27:29.925802 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0123365 (* 1 = 0.0123365 loss)
I1022 07:27:29.925806 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00109693 (* 1 = 0.00109693 loss)
I1022 07:27:29.925812 25759 sgd_solver.cpp:106] Iteration 7020, lr = 0.002
I1022 07:28:55.357158 25759 solver.cpp:228] Iteration 7040, loss = 0.133355
I1022 07:28:55.357197 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 07:28:55.357203 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:28:55.357213 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:28:55.357218 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:28:55.357224 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0131122 (* 1 = 0.0131122 loss)
I1022 07:28:55.357230 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00448404 (* 1 = 0.00448404 loss)
I1022 07:28:55.357236 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00152605 (* 1 = 0.00152605 loss)
I1022 07:28:55.357242 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.65662e-06 (* 1 = 8.65662e-06 loss)
I1022 07:28:55.357249 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00204907 (* 1 = 0.00204907 loss)
I1022 07:28:55.357257 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00461268 (* 1 = 0.00461268 loss)
I1022 07:28:55.357264 25759 sgd_solver.cpp:106] Iteration 7040, lr = 0.002
I1022 07:30:19.958997 25759 solver.cpp:228] Iteration 7060, loss = 0.056364
I1022 07:30:19.959033 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 07:30:19.959039 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 07:30:19.959048 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0056216 (* 1 = 0.0056216 loss)
I1022 07:30:19.959055 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0114006 (* 1 = 0.0114006 loss)
I1022 07:30:19.959061 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00993013 (* 1 = 0.00993013 loss)
I1022 07:30:19.959067 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00614965 (* 1 = 0.00614965 loss)
I1022 07:30:19.959074 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000143263 (* 1 = 0.000143263 loss)
I1022 07:30:19.959079 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.11725e-06 (* 1 = 7.11725e-06 loss)
I1022 07:30:19.959085 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00808105 (* 1 = 0.00808105 loss)
I1022 07:30:19.959091 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00466285 (* 1 = 0.00466285 loss)
I1022 07:30:19.959098 25759 sgd_solver.cpp:106] Iteration 7060, lr = 0.002
I1022 07:31:43.997284 25759 solver.cpp:228] Iteration 7080, loss = 0.0480316
I1022 07:31:43.997323 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 07:31:43.997328 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 07:31:43.997339 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0445096 (* 1 = 0.0445096 loss)
I1022 07:31:43.997344 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0087782 (* 1 = 0.0087782 loss)
I1022 07:31:43.997350 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0110515 (* 1 = 0.0110515 loss)
I1022 07:31:43.997356 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0111337 (* 1 = 0.0111337 loss)
I1022 07:31:43.997362 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.10807e-05 (* 1 = 5.10807e-05 loss)
I1022 07:31:43.997368 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.8156e-06 (* 1 = 4.8156e-06 loss)
I1022 07:31:43.997373 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.011455 (* 1 = 0.011455 loss)
I1022 07:31:43.997380 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00347418 (* 1 = 0.00347418 loss)
I1022 07:31:43.997386 25759 sgd_solver.cpp:106] Iteration 7080, lr = 0.002
I1022 07:33:09.080528 25759 solver.cpp:228] Iteration 7100, loss = 0.114156
I1022 07:33:09.080569 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995507
I1022 07:33:09.080577 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99351
I1022 07:33:09.080588 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.029602 (* 1 = 0.029602 loss)
I1022 07:33:09.080597 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0410265 (* 1 = 0.0410265 loss)
I1022 07:33:09.080605 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0288488 (* 1 = 0.0288488 loss)
I1022 07:33:09.080619 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0207366 (* 1 = 0.0207366 loss)
I1022 07:33:09.080627 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000318517 (* 1 = 0.000318517 loss)
I1022 07:33:09.080636 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.7256e-06 (* 1 = 8.7256e-06 loss)
I1022 07:33:09.080643 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0276495 (* 1 = 0.0276495 loss)
I1022 07:33:09.080651 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00319358 (* 1 = 0.00319358 loss)
I1022 07:33:09.080659 25759 sgd_solver.cpp:106] Iteration 7100, lr = 0.002
I1022 07:34:33.863447 25759 solver.cpp:228] Iteration 7120, loss = 0.125143
I1022 07:34:33.863504 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:34:33.863510 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:34:33.863517 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:34:33.863524 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:34:33.863530 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00478667 (* 1 = 0.00478667 loss)
I1022 07:34:33.863535 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0044033 (* 1 = 0.0044033 loss)
I1022 07:34:33.863540 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.20236e-05 (* 1 = 4.20236e-05 loss)
I1022 07:34:33.863545 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.19235e-05 (* 1 = 1.19235e-05 loss)
I1022 07:34:33.863550 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00196393 (* 1 = 0.00196393 loss)
I1022 07:34:33.863555 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00209766 (* 1 = 0.00209766 loss)
I1022 07:34:33.863564 25759 sgd_solver.cpp:106] Iteration 7120, lr = 0.002
I1022 07:35:57.819821 25759 solver.cpp:228] Iteration 7140, loss = 0.0568849
I1022 07:35:57.819880 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:35:57.819896 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:35:57.819911 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:35:57.819921 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:35:57.819931 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00434567 (* 1 = 0.00434567 loss)
I1022 07:35:57.819942 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00452724 (* 1 = 0.00452724 loss)
I1022 07:35:57.819953 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000953991 (* 1 = 0.000953991 loss)
I1022 07:35:57.819967 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.04925e-06 (* 1 = 9.04925e-06 loss)
I1022 07:35:57.819979 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000655538 (* 1 = 0.000655538 loss)
I1022 07:35:57.819991 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00118065 (* 1 = 0.00118065 loss)
I1022 07:35:57.820003 25759 sgd_solver.cpp:106] Iteration 7140, lr = 0.002
I1022 07:37:24.696503 25759 solver.cpp:228] Iteration 7160, loss = 0.15369
I1022 07:37:24.696544 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99898
I1022 07:37:24.696550 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 07:37:24.696561 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00469389 (* 1 = 0.00469389 loss)
I1022 07:37:24.696568 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0171976 (* 1 = 0.0171976 loss)
I1022 07:37:24.696574 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00684191 (* 1 = 0.00684191 loss)
I1022 07:37:24.696580 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00953288 (* 1 = 0.00953288 loss)
I1022 07:37:24.696586 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000338116 (* 1 = 0.000338116 loss)
I1022 07:37:24.696593 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.98073e-05 (* 1 = 3.98073e-05 loss)
I1022 07:37:24.696599 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0226666 (* 1 = 0.0226666 loss)
I1022 07:37:24.696606 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0027616 (* 1 = 0.0027616 loss)
I1022 07:37:24.696622 25759 sgd_solver.cpp:106] Iteration 7160, lr = 0.002
I1022 07:38:50.596077 25759 solver.cpp:228] Iteration 7180, loss = 0.333614
I1022 07:38:50.596117 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 07:38:50.596129 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 07:38:50.596139 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00770279 (* 1 = 0.00770279 loss)
I1022 07:38:50.596145 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00583492 (* 1 = 0.00583492 loss)
I1022 07:38:50.596153 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00887906 (* 1 = 0.00887906 loss)
I1022 07:38:50.596158 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00800987 (* 1 = 0.00800987 loss)
I1022 07:38:50.596163 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.83588e-05 (* 1 = 1.83588e-05 loss)
I1022 07:38:50.596170 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.2285e-05 (* 1 = 1.2285e-05 loss)
I1022 07:38:50.596176 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00393963 (* 1 = 0.00393963 loss)
I1022 07:38:50.596182 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000129866 (* 1 = 0.000129866 loss)
I1022 07:38:50.596189 25759 sgd_solver.cpp:106] Iteration 7180, lr = 0.002
speed: 4.204s / iter
I1022 07:40:17.154106 25759 solver.cpp:228] Iteration 7200, loss = 0.0449532
I1022 07:40:17.154145 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 07:40:17.154161 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:40:17.154170 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00868636 (* 1 = 0.00868636 loss)
I1022 07:40:17.154176 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00243887 (* 1 = 0.00243887 loss)
I1022 07:40:17.154182 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00922724 (* 1 = 0.00922724 loss)
I1022 07:40:17.154187 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00493403 (* 1 = 0.00493403 loss)
I1022 07:40:17.154193 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000136001 (* 1 = 0.000136001 loss)
I1022 07:40:17.154199 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.02265e-05 (* 1 = 1.02265e-05 loss)
I1022 07:40:17.154206 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00488092 (* 1 = 0.00488092 loss)
I1022 07:40:17.154211 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00212357 (* 1 = 0.00212357 loss)
I1022 07:40:17.154217 25759 sgd_solver.cpp:106] Iteration 7200, lr = 0.002
I1022 07:41:40.768945 25759 solver.cpp:228] Iteration 7220, loss = 0.0379355
I1022 07:41:40.769009 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 07:41:40.769021 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:41:40.769039 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00922802 (* 1 = 0.00922802 loss)
I1022 07:41:40.769052 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000780491 (* 1 = 0.000780491 loss)
I1022 07:41:40.769064 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0121782 (* 1 = 0.0121782 loss)
I1022 07:41:40.769075 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0044875 (* 1 = 0.0044875 loss)
I1022 07:41:40.769090 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.68831e-05 (* 1 = 7.68831e-05 loss)
I1022 07:41:40.769104 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.39783e-05 (* 1 = 1.39783e-05 loss)
I1022 07:41:40.769119 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00463948 (* 1 = 0.00463948 loss)
I1022 07:41:40.769142 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00156754 (* 1 = 0.00156754 loss)
I1022 07:41:40.769155 25759 sgd_solver.cpp:106] Iteration 7220, lr = 0.002
I1022 07:43:06.429153 25759 solver.cpp:228] Iteration 7240, loss = 0.232865
I1022 07:43:06.429196 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995005
I1022 07:43:06.429203 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 07:43:06.429214 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0282945 (* 1 = 0.0282945 loss)
I1022 07:43:06.429220 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0101704 (* 1 = 0.0101704 loss)
I1022 07:43:06.429226 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0201692 (* 1 = 0.0201692 loss)
I1022 07:43:06.429232 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0120864 (* 1 = 0.0120864 loss)
I1022 07:43:06.429239 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000748902 (* 1 = 0.000748902 loss)
I1022 07:43:06.429246 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.87268e-05 (* 1 = 1.87268e-05 loss)
I1022 07:43:06.429252 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0195913 (* 1 = 0.0195913 loss)
I1022 07:43:06.429258 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000223174 (* 1 = 0.000223174 loss)
I1022 07:43:06.429270 25759 sgd_solver.cpp:106] Iteration 7240, lr = 0.002
I1022 07:44:33.163390 25759 solver.cpp:228] Iteration 7260, loss = 0.0631862
I1022 07:44:33.163444 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996004
I1022 07:44:33.163450 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 07:44:33.163460 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0248029 (* 1 = 0.0248029 loss)
I1022 07:44:33.163468 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0212555 (* 1 = 0.0212555 loss)
I1022 07:44:33.163475 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0207842 (* 1 = 0.0207842 loss)
I1022 07:44:33.163480 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0160898 (* 1 = 0.0160898 loss)
I1022 07:44:33.163486 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00302788 (* 1 = 0.00302788 loss)
I1022 07:44:33.163492 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.8936e-05 (* 1 = 1.8936e-05 loss)
I1022 07:44:33.163498 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0460596 (* 1 = 0.0460596 loss)
I1022 07:44:33.163506 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000358801 (* 1 = 0.000358801 loss)
I1022 07:44:33.163517 25759 sgd_solver.cpp:106] Iteration 7260, lr = 0.002
I1022 07:45:59.039512 25759 solver.cpp:228] Iteration 7280, loss = 0.128321
I1022 07:45:59.039551 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 07:45:59.039557 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:45:59.039566 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:45:59.039572 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:45:59.039578 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00816566 (* 1 = 0.00816566 loss)
I1022 07:45:59.039584 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00444098 (* 1 = 0.00444098 loss)
I1022 07:45:59.039590 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000190738 (* 1 = 0.000190738 loss)
I1022 07:45:59.039597 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.01714e-05 (* 1 = 3.01714e-05 loss)
I1022 07:45:59.039602 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00411085 (* 1 = 0.00411085 loss)
I1022 07:45:59.039608 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00502226 (* 1 = 0.00502226 loss)
I1022 07:45:59.039615 25759 sgd_solver.cpp:106] Iteration 7280, lr = 0.002
I1022 07:47:24.136457 25759 solver.cpp:228] Iteration 7300, loss = 0.0751813
I1022 07:47:24.136509 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:47:24.136514 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 07:47:24.136523 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0106425 (* 1 = 0.0106425 loss)
I1022 07:47:24.136530 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0139839 (* 1 = 0.0139839 loss)
I1022 07:47:24.136534 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00658589 (* 1 = 0.00658589 loss)
I1022 07:47:24.136538 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00679209 (* 1 = 0.00679209 loss)
I1022 07:47:24.136543 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.58143e-05 (* 1 = 4.58143e-05 loss)
I1022 07:47:24.136548 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.13213e-05 (* 1 = 2.13213e-05 loss)
I1022 07:47:24.136553 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00301092 (* 1 = 0.00301092 loss)
I1022 07:47:24.136556 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00178974 (* 1 = 0.00178974 loss)
I1022 07:47:24.136565 25759 sgd_solver.cpp:106] Iteration 7300, lr = 0.002
I1022 07:48:49.268586 25759 solver.cpp:228] Iteration 7320, loss = 0.0532265
I1022 07:48:49.268692 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:48:49.268703 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:48:49.268718 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:48:49.268730 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:48:49.268743 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00455775 (* 1 = 0.00455775 loss)
I1022 07:48:49.268756 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00438212 (* 1 = 0.00438212 loss)
I1022 07:48:49.268769 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000228475 (* 1 = 0.000228475 loss)
I1022 07:48:49.268784 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.09082e-05 (* 1 = 2.09082e-05 loss)
I1022 07:48:49.268797 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00749375 (* 1 = 0.00749375 loss)
I1022 07:48:49.268808 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00121038 (* 1 = 0.00121038 loss)
I1022 07:48:49.268821 25759 sgd_solver.cpp:106] Iteration 7320, lr = 0.002
I1022 07:50:13.541733 25759 solver.cpp:228] Iteration 7340, loss = 0.0911788
I1022 07:50:13.541764 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:50:13.541769 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:50:13.541774 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:50:13.541779 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:50:13.541784 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00422516 (* 1 = 0.00422516 loss)
I1022 07:50:13.541787 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00453848 (* 1 = 0.00453848 loss)
I1022 07:50:13.541791 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.8439e-05 (* 1 = 8.8439e-05 loss)
I1022 07:50:13.541798 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.28172e-05 (* 1 = 2.28172e-05 loss)
I1022 07:50:13.541802 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00616796 (* 1 = 0.00616796 loss)
I1022 07:50:13.541806 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00514675 (* 1 = 0.00514675 loss)
I1022 07:50:13.541815 25759 sgd_solver.cpp:106] Iteration 7340, lr = 0.002
I1022 07:51:37.478235 25759 solver.cpp:228] Iteration 7360, loss = 0.146891
I1022 07:51:37.478308 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 07:51:37.478319 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:51:37.478335 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:51:37.478348 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:51:37.478358 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00722348 (* 1 = 0.00722348 loss)
I1022 07:51:37.478370 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450955 (* 1 = 0.00450955 loss)
I1022 07:51:37.478384 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000161674 (* 1 = 0.000161674 loss)
I1022 07:51:37.478399 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.37609e-05 (* 1 = 2.37609e-05 loss)
I1022 07:51:37.478411 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00228017 (* 1 = 0.00228017 loss)
I1022 07:51:37.478425 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00108336 (* 1 = 0.00108336 loss)
I1022 07:51:37.478444 25759 sgd_solver.cpp:106] Iteration 7360, lr = 0.002
I1022 07:53:01.559761 25759 solver.cpp:228] Iteration 7380, loss = 0.182286
I1022 07:53:01.559806 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989516
I1022 07:53:01.559813 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994009
I1022 07:53:01.559823 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0481756 (* 1 = 0.0481756 loss)
I1022 07:53:01.559831 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0390163 (* 1 = 0.0390163 loss)
I1022 07:53:01.559839 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0332422 (* 1 = 0.0332422 loss)
I1022 07:53:01.559845 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0250272 (* 1 = 0.0250272 loss)
I1022 07:53:01.559852 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000567124 (* 1 = 0.000567124 loss)
I1022 07:53:01.559860 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.70583e-05 (* 1 = 1.70583e-05 loss)
I1022 07:53:01.559866 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0447449 (* 1 = 0.0447449 loss)
I1022 07:53:01.559875 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0060899 (* 1 = 0.0060899 loss)
I1022 07:53:01.559886 25759 sgd_solver.cpp:106] Iteration 7380, lr = 0.002
speed: 4.206s / iter
I1022 07:54:25.747479 25759 solver.cpp:228] Iteration 7400, loss = 0.162474
I1022 07:54:25.747517 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 07:54:25.747531 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 07:54:25.747540 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:54:25.747546 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:54:25.747553 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0132086 (* 1 = 0.0132086 loss)
I1022 07:54:25.747560 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00553347 (* 1 = 0.00553347 loss)
I1022 07:54:25.747565 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00162143 (* 1 = 0.00162143 loss)
I1022 07:54:25.747571 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.25303e-05 (* 1 = 1.25303e-05 loss)
I1022 07:54:25.747577 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00732875 (* 1 = 0.00732875 loss)
I1022 07:54:25.747583 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00142323 (* 1 = 0.00142323 loss)
I1022 07:54:25.747598 25759 sgd_solver.cpp:106] Iteration 7400, lr = 0.002
I1022 07:55:50.972168 25759 solver.cpp:228] Iteration 7420, loss = 0.100071
I1022 07:55:50.972232 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99301
I1022 07:55:50.972237 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996006
I1022 07:55:50.972244 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0707164 (* 1 = 0.0707164 loss)
I1022 07:55:50.972249 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0629227 (* 1 = 0.0629227 loss)
I1022 07:55:50.972254 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0244694 (* 1 = 0.0244694 loss)
I1022 07:55:50.972257 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0190012 (* 1 = 0.0190012 loss)
I1022 07:55:50.972262 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000270989 (* 1 = 0.000270989 loss)
I1022 07:55:50.972267 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.73659e-06 (* 1 = 9.73659e-06 loss)
I1022 07:55:50.972272 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0354407 (* 1 = 0.0354407 loss)
I1022 07:55:50.972276 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00778476 (* 1 = 0.00778476 loss)
I1022 07:55:50.972282 25759 sgd_solver.cpp:106] Iteration 7420, lr = 0.002
I1022 07:57:15.981281 25759 solver.cpp:228] Iteration 7440, loss = 0.136992
I1022 07:57:15.981340 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 07:57:15.981482 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:57:15.981492 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0176496 (* 1 = 0.0176496 loss)
I1022 07:57:15.981498 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00346589 (* 1 = 0.00346589 loss)
I1022 07:57:15.981501 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00703296 (* 1 = 0.00703296 loss)
I1022 07:57:15.981552 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00530462 (* 1 = 0.00530462 loss)
I1022 07:57:15.981557 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000111521 (* 1 = 0.000111521 loss)
I1022 07:57:15.981562 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.88671e-06 (* 1 = 4.88671e-06 loss)
I1022 07:57:15.981567 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0134816 (* 1 = 0.0134816 loss)
I1022 07:57:15.981572 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00408157 (* 1 = 0.00408157 loss)
I1022 07:57:15.981578 25759 sgd_solver.cpp:106] Iteration 7440, lr = 0.002
I1022 07:58:39.682947 25759 solver.cpp:228] Iteration 7460, loss = 0.121723
I1022 07:58:39.683029 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 07:58:39.683042 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 07:58:39.683058 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 07:58:39.683069 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 07:58:39.683081 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0047388 (* 1 = 0.0047388 loss)
I1022 07:58:39.683094 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00422745 (* 1 = 0.00422745 loss)
I1022 07:58:39.683111 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.57577e-05 (* 1 = 4.57577e-05 loss)
I1022 07:58:39.683126 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.13219e-06 (* 1 = 7.13219e-06 loss)
I1022 07:58:39.683140 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0016383 (* 1 = 0.0016383 loss)
I1022 07:58:39.683153 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000473796 (* 1 = 0.000473796 loss)
I1022 07:58:39.683179 25759 sgd_solver.cpp:106] Iteration 7460, lr = 0.002
I1022 08:00:04.344480 25759 solver.cpp:228] Iteration 7480, loss = 0.0521583
I1022 08:00:04.344532 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99051
I1022 08:00:04.344537 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996503
I1022 08:00:04.344545 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0202273 (* 1 = 0.0202273 loss)
I1022 08:00:04.344550 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00667256 (* 1 = 0.00667256 loss)
I1022 08:00:04.344554 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0242622 (* 1 = 0.0242622 loss)
I1022 08:00:04.344558 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.012828 (* 1 = 0.012828 loss)
I1022 08:00:04.344565 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.45798e-05 (* 1 = 6.45798e-05 loss)
I1022 08:00:04.344573 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.24948e-05 (* 1 = 1.24948e-05 loss)
I1022 08:00:04.344578 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00883149 (* 1 = 0.00883149 loss)
I1022 08:00:04.344583 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00672117 (* 1 = 0.00672117 loss)
I1022 08:00:04.344590 25759 sgd_solver.cpp:106] Iteration 7480, lr = 0.002
I1022 08:01:30.800385 25759 solver.cpp:228] Iteration 7500, loss = 0.273961
I1022 08:01:30.800443 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 08:01:30.800451 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 08:01:30.800459 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0187495 (* 1 = 0.0187495 loss)
I1022 08:01:30.800468 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0147507 (* 1 = 0.0147507 loss)
I1022 08:01:30.800474 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00893499 (* 1 = 0.00893499 loss)
I1022 08:01:30.800480 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00756122 (* 1 = 0.00756122 loss)
I1022 08:01:30.800487 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.08976e-05 (* 1 = 4.08976e-05 loss)
I1022 08:01:30.800493 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.7172e-05 (* 1 = 1.7172e-05 loss)
I1022 08:01:30.800499 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00987472 (* 1 = 0.00987472 loss)
I1022 08:01:30.800505 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000178803 (* 1 = 0.000178803 loss)
I1022 08:01:30.800513 25759 sgd_solver.cpp:106] Iteration 7500, lr = 0.002
I1022 08:02:55.511337 25759 solver.cpp:228] Iteration 7520, loss = 0.0336137
I1022 08:02:55.511384 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 08:02:55.511402 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 08:02:55.511412 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00983339 (* 1 = 0.00983339 loss)
I1022 08:02:55.511420 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00573163 (* 1 = 0.00573163 loss)
I1022 08:02:55.511425 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00991481 (* 1 = 0.00991481 loss)
I1022 08:02:55.511430 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00753179 (* 1 = 0.00753179 loss)
I1022 08:02:55.511436 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.22022e-05 (* 1 = 4.22022e-05 loss)
I1022 08:02:55.511443 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.46034e-06 (* 1 = 9.46034e-06 loss)
I1022 08:02:55.511449 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0046783 (* 1 = 0.0046783 loss)
I1022 08:02:55.511456 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00268751 (* 1 = 0.00268751 loss)
I1022 08:02:55.511464 25759 sgd_solver.cpp:106] Iteration 7520, lr = 0.002
I1022 08:04:20.015586 25759 solver.cpp:228] Iteration 7540, loss = 0.277177
I1022 08:04:20.015648 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986042
I1022 08:04:20.015658 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.984546
I1022 08:04:20.015673 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.137683 (* 1 = 0.137683 loss)
I1022 08:04:20.015684 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.138068 (* 1 = 0.138068 loss)
I1022 08:04:20.015696 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0550897 (* 1 = 0.0550897 loss)
I1022 08:04:20.015705 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0463207 (* 1 = 0.0463207 loss)
I1022 08:04:20.015722 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000175899 (* 1 = 0.000175899 loss)
I1022 08:04:20.015744 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.46797e-05 (* 1 = 1.46797e-05 loss)
I1022 08:04:20.015758 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.06159 (* 1 = 0.06159 loss)
I1022 08:04:20.015769 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000148369 (* 1 = 0.000148369 loss)
I1022 08:04:20.015786 25759 sgd_solver.cpp:106] Iteration 7540, lr = 0.002
I1022 08:05:41.603534 25759 solver.cpp:228] Iteration 7560, loss = 0.0372474
I1022 08:05:41.603581 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 08:05:41.603600 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 08:05:41.603610 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00872236 (* 1 = 0.00872236 loss)
I1022 08:05:41.603619 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0119236 (* 1 = 0.0119236 loss)
I1022 08:05:41.603626 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0107094 (* 1 = 0.0107094 loss)
I1022 08:05:41.603631 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00776619 (* 1 = 0.00776619 loss)
I1022 08:05:41.603638 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.14529e-05 (* 1 = 8.14529e-05 loss)
I1022 08:05:41.603646 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.22404e-06 (* 1 = 6.22404e-06 loss)
I1022 08:05:41.603652 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00343294 (* 1 = 0.00343294 loss)
I1022 08:05:41.603663 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00116566 (* 1 = 0.00116566 loss)
I1022 08:05:41.603670 25759 sgd_solver.cpp:106] Iteration 7560, lr = 0.002
I1022 08:07:02.720155 25759 solver.cpp:228] Iteration 7580, loss = 0.0486883
I1022 08:07:02.720204 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:07:02.720209 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:07:02.720216 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:07:02.720221 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:07:02.720226 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00384993 (* 1 = 0.00384993 loss)
I1022 08:07:02.720229 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00423003 (* 1 = 0.00423003 loss)
I1022 08:07:02.720234 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.41646e-05 (* 1 = 7.41646e-05 loss)
I1022 08:07:02.720239 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.83392e-06 (* 1 = 6.83392e-06 loss)
I1022 08:07:02.720244 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00337494 (* 1 = 0.00337494 loss)
I1022 08:07:02.720248 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00415344 (* 1 = 0.00415344 loss)
I1022 08:07:02.720253 25759 sgd_solver.cpp:106] Iteration 7580, lr = 0.002
speed: 4.205s / iter
I1022 08:08:24.740592 25759 solver.cpp:228] Iteration 7600, loss = 0.25269
I1022 08:08:24.740679 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988012
I1022 08:08:24.740685 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992008
I1022 08:08:24.740694 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0904242 (* 1 = 0.0904242 loss)
I1022 08:08:24.740700 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0519953 (* 1 = 0.0519953 loss)
I1022 08:08:24.740705 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0303683 (* 1 = 0.0303683 loss)
I1022 08:08:24.740710 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0226593 (* 1 = 0.0226593 loss)
I1022 08:08:24.740715 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00460812 (* 1 = 0.00460812 loss)
I1022 08:08:24.740720 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.30359e-05 (* 1 = 2.30359e-05 loss)
I1022 08:08:24.740725 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.151377 (* 1 = 0.151377 loss)
I1022 08:08:24.740731 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000166585 (* 1 = 0.000166585 loss)
I1022 08:08:24.740739 25759 sgd_solver.cpp:106] Iteration 7600, lr = 0.002
I1022 08:09:46.691843 25759 solver.cpp:228] Iteration 7620, loss = 0.119572
I1022 08:09:46.691890 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:09:46.691895 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:09:46.691902 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:09:46.691907 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:09:46.691911 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00424035 (* 1 = 0.00424035 loss)
I1022 08:09:46.691915 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00440981 (* 1 = 0.00440981 loss)
I1022 08:09:46.691920 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.74915e-05 (* 1 = 6.74915e-05 loss)
I1022 08:09:46.691926 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.90379e-06 (* 1 = 8.90379e-06 loss)
I1022 08:09:46.691929 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00500817 (* 1 = 0.00500817 loss)
I1022 08:09:46.691934 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00225532 (* 1 = 0.00225532 loss)
I1022 08:09:46.691943 25759 sgd_solver.cpp:106] Iteration 7620, lr = 0.002
I1022 08:11:08.133569 25759 solver.cpp:228] Iteration 7640, loss = 0.118244
I1022 08:11:08.133622 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:11:08.133630 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 08:11:08.133639 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0106073 (* 1 = 0.0106073 loss)
I1022 08:11:08.133647 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0143896 (* 1 = 0.0143896 loss)
I1022 08:11:08.133653 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00689295 (* 1 = 0.00689295 loss)
I1022 08:11:08.133659 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00670681 (* 1 = 0.00670681 loss)
I1022 08:11:08.133666 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.51009e-05 (* 1 = 3.51009e-05 loss)
I1022 08:11:08.133671 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.18063e-05 (* 1 = 2.18063e-05 loss)
I1022 08:11:08.133677 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0104206 (* 1 = 0.0104206 loss)
I1022 08:11:08.133684 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000278076 (* 1 = 0.000278076 loss)
I1022 08:11:08.133692 25759 sgd_solver.cpp:106] Iteration 7640, lr = 0.002
I1022 08:12:32.215613 25759 solver.cpp:228] Iteration 7660, loss = 0.165322
I1022 08:12:32.215665 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 08:12:32.215677 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 08:12:32.215692 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0119989 (* 1 = 0.0119989 loss)
I1022 08:12:32.215703 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0100171 (* 1 = 0.0100171 loss)
I1022 08:12:32.215713 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0124703 (* 1 = 0.0124703 loss)
I1022 08:12:32.215725 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00906102 (* 1 = 0.00906102 loss)
I1022 08:12:32.215737 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.47633e-05 (* 1 = 7.47633e-05 loss)
I1022 08:12:32.215749 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.16908e-05 (* 1 = 1.16908e-05 loss)
I1022 08:12:32.215761 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00495632 (* 1 = 0.00495632 loss)
I1022 08:12:32.215773 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00158678 (* 1 = 0.00158678 loss)
I1022 08:12:32.215785 25759 sgd_solver.cpp:106] Iteration 7660, lr = 0.002
I1022 08:13:57.798274 25759 solver.cpp:228] Iteration 7680, loss = 0.121168
I1022 08:13:57.798316 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 08:13:57.798322 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:13:57.798331 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:13:57.798346 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:13:57.798352 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000717633 (* 1 = 0.000717633 loss)
I1022 08:13:57.798359 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00470495 (* 1 = 0.00470495 loss)
I1022 08:13:57.798365 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.89813e-05 (* 1 = 8.89813e-05 loss)
I1022 08:13:57.798372 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.382e-05 (* 1 = 1.382e-05 loss)
I1022 08:13:57.798378 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00103805 (* 1 = 0.00103805 loss)
I1022 08:13:57.798384 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000592288 (* 1 = 0.000592288 loss)
I1022 08:13:57.798391 25759 sgd_solver.cpp:106] Iteration 7680, lr = 0.002
I1022 08:15:20.382805 25759 solver.cpp:228] Iteration 7700, loss = 0.147152
I1022 08:15:20.382860 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 08:15:20.382867 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 08:15:20.382877 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00716602 (* 1 = 0.00716602 loss)
I1022 08:15:20.382884 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0173181 (* 1 = 0.0173181 loss)
I1022 08:15:20.382890 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00985122 (* 1 = 0.00985122 loss)
I1022 08:15:20.382896 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0104119 (* 1 = 0.0104119 loss)
I1022 08:15:20.382903 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000528087 (* 1 = 0.000528087 loss)
I1022 08:15:20.382910 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.09053e-06 (* 1 = 8.09053e-06 loss)
I1022 08:15:20.382920 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0128462 (* 1 = 0.0128462 loss)
I1022 08:15:20.382926 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00117936 (* 1 = 0.00117936 loss)
I1022 08:15:20.382937 25759 sgd_solver.cpp:106] Iteration 7700, lr = 0.002
I1022 08:16:45.114240 25759 solver.cpp:228] Iteration 7720, loss = 0.0640479
I1022 08:16:45.114279 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 08:16:45.114285 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:16:45.114295 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0123571 (* 1 = 0.0123571 loss)
I1022 08:16:45.114300 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0112115 (* 1 = 0.0112115 loss)
I1022 08:16:45.114306 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0081953 (* 1 = 0.0081953 loss)
I1022 08:16:45.114312 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00598697 (* 1 = 0.00598697 loss)
I1022 08:16:45.114318 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000118531 (* 1 = 0.000118531 loss)
I1022 08:16:45.114325 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.78954e-05 (* 1 = 1.78954e-05 loss)
I1022 08:16:45.114331 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00765694 (* 1 = 0.00765694 loss)
I1022 08:16:45.114336 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00536339 (* 1 = 0.00536339 loss)
I1022 08:16:45.114346 25759 sgd_solver.cpp:106] Iteration 7720, lr = 0.002
I1022 08:18:11.285362 25759 solver.cpp:228] Iteration 7740, loss = 0.0888962
I1022 08:18:11.285394 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998492
I1022 08:18:11.285399 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 08:18:11.285406 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00680753 (* 1 = 0.00680753 loss)
I1022 08:18:11.285410 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0192313 (* 1 = 0.0192313 loss)
I1022 08:18:11.285415 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00630587 (* 1 = 0.00630587 loss)
I1022 08:18:11.285419 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00760795 (* 1 = 0.00760795 loss)
I1022 08:18:11.285423 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000543061 (* 1 = 0.000543061 loss)
I1022 08:18:11.285429 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.3727e-05 (* 1 = 2.3727e-05 loss)
I1022 08:18:11.285432 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0121869 (* 1 = 0.0121869 loss)
I1022 08:18:11.285436 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000817355 (* 1 = 0.000817355 loss)
I1022 08:18:11.285442 25759 sgd_solver.cpp:106] Iteration 7740, lr = 0.002
I1022 08:19:35.968358 25759 solver.cpp:228] Iteration 7760, loss = 0.209205
I1022 08:19:35.968410 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996004
I1022 08:19:35.968415 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 08:19:35.968422 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0196959 (* 1 = 0.0196959 loss)
I1022 08:19:35.968430 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000992664 (* 1 = 0.000992664 loss)
I1022 08:19:35.968435 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0147584 (* 1 = 0.0147584 loss)
I1022 08:19:35.968439 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00878806 (* 1 = 0.00878806 loss)
I1022 08:19:35.968443 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.1771e-05 (* 1 = 8.1771e-05 loss)
I1022 08:19:35.968448 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.07972e-06 (* 1 = 9.07972e-06 loss)
I1022 08:19:35.968453 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00535962 (* 1 = 0.00535962 loss)
I1022 08:19:35.968457 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.85196e-05 (* 1 = 4.85196e-05 loss)
I1022 08:19:35.968462 25759 sgd_solver.cpp:106] Iteration 7760, lr = 0.002
I1022 08:20:59.412065 25759 solver.cpp:228] Iteration 7780, loss = 0.0849659
I1022 08:20:59.412098 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995005
I1022 08:20:59.412103 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 08:20:59.412111 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0211314 (* 1 = 0.0211314 loss)
I1022 08:20:59.412117 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0146702 (* 1 = 0.0146702 loss)
I1022 08:20:59.412120 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0216685 (* 1 = 0.0216685 loss)
I1022 08:20:59.412125 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0133635 (* 1 = 0.0133635 loss)
I1022 08:20:59.412130 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000192079 (* 1 = 0.000192079 loss)
I1022 08:20:59.412135 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.43057e-05 (* 1 = 2.43057e-05 loss)
I1022 08:20:59.412140 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00890959 (* 1 = 0.00890959 loss)
I1022 08:20:59.412144 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000859604 (* 1 = 0.000859604 loss)
I1022 08:20:59.412150 25759 sgd_solver.cpp:106] Iteration 7780, lr = 0.002
speed: 4.205s / iter
I1022 08:22:24.362607 25759 solver.cpp:228] Iteration 7800, loss = 0.0920455
I1022 08:22:24.362658 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 08:22:24.362663 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 08:22:24.362673 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00674506 (* 1 = 0.00674506 loss)
I1022 08:22:24.362677 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0124973 (* 1 = 0.0124973 loss)
I1022 08:22:24.362681 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00831749 (* 1 = 0.00831749 loss)
I1022 08:22:24.362685 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00668986 (* 1 = 0.00668986 loss)
I1022 08:22:24.362690 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.58551e-05 (* 1 = 2.58551e-05 loss)
I1022 08:22:24.362694 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.05685e-05 (* 1 = 2.05685e-05 loss)
I1022 08:22:24.362700 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00661192 (* 1 = 0.00661192 loss)
I1022 08:22:24.362706 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000849475 (* 1 = 0.000849475 loss)
I1022 08:22:24.362711 25759 sgd_solver.cpp:106] Iteration 7800, lr = 0.002
I1022 08:23:49.224226 25759 solver.cpp:228] Iteration 7820, loss = 0.0995775
I1022 08:23:49.224269 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990481
I1022 08:23:49.224277 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994508
I1022 08:23:49.224288 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.071987 (* 1 = 0.071987 loss)
I1022 08:23:49.224297 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.102583 (* 1 = 0.102583 loss)
I1022 08:23:49.224305 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0197593 (* 1 = 0.0197593 loss)
I1022 08:23:49.224311 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0212859 (* 1 = 0.0212859 loss)
I1022 08:23:49.224319 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000187757 (* 1 = 0.000187757 loss)
I1022 08:23:49.224328 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.44529e-05 (* 1 = 1.44529e-05 loss)
I1022 08:23:49.224334 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0404892 (* 1 = 0.0404892 loss)
I1022 08:23:49.224341 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00350662 (* 1 = 0.00350662 loss)
I1022 08:23:49.224355 25759 sgd_solver.cpp:106] Iteration 7820, lr = 0.002
I1022 08:25:12.606631 25759 solver.cpp:228] Iteration 7840, loss = 0.125863
I1022 08:25:12.606690 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991013
I1022 08:25:12.606698 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997005
I1022 08:25:12.606709 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0222367 (* 1 = 0.0222367 loss)
I1022 08:25:12.606717 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0157505 (* 1 = 0.0157505 loss)
I1022 08:25:12.606724 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0287136 (* 1 = 0.0287136 loss)
I1022 08:25:12.606730 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0169909 (* 1 = 0.0169909 loss)
I1022 08:25:12.606737 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000945923 (* 1 = 0.000945923 loss)
I1022 08:25:12.606745 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.82736e-05 (* 1 = 3.82736e-05 loss)
I1022 08:25:12.606752 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0382647 (* 1 = 0.0382647 loss)
I1022 08:25:12.606760 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00118878 (* 1 = 0.00118878 loss)
I1022 08:25:12.606771 25759 sgd_solver.cpp:106] Iteration 7840, lr = 0.002
I1022 08:26:39.160640 25759 solver.cpp:228] Iteration 7860, loss = 0.0427185
I1022 08:26:39.160678 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995504
I1022 08:26:39.160686 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999001
I1022 08:26:39.160696 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0157243 (* 1 = 0.0157243 loss)
I1022 08:26:39.160703 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00338683 (* 1 = 0.00338683 loss)
I1022 08:26:39.160709 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0176506 (* 1 = 0.0176506 loss)
I1022 08:26:39.160714 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00924551 (* 1 = 0.00924551 loss)
I1022 08:26:39.160720 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000144308 (* 1 = 0.000144308 loss)
I1022 08:26:39.160727 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.03938e-05 (* 1 = 2.03938e-05 loss)
I1022 08:26:39.160733 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0160041 (* 1 = 0.0160041 loss)
I1022 08:26:39.160743 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000182023 (* 1 = 0.000182023 loss)
I1022 08:26:39.160750 25759 sgd_solver.cpp:106] Iteration 7860, lr = 0.002
I1022 08:28:03.843088 25759 solver.cpp:228] Iteration 7880, loss = 0.139497
I1022 08:28:03.843133 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 08:28:03.843138 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 08:28:03.843145 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0117533 (* 1 = 0.0117533 loss)
I1022 08:28:03.843153 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00535935 (* 1 = 0.00535935 loss)
I1022 08:28:03.843158 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0079047 (* 1 = 0.0079047 loss)
I1022 08:28:03.843163 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00531375 (* 1 = 0.00531375 loss)
I1022 08:28:03.843166 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000356462 (* 1 = 0.000356462 loss)
I1022 08:28:03.843171 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.85617e-06 (* 1 = 9.85617e-06 loss)
I1022 08:28:03.843176 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00852773 (* 1 = 0.00852773 loss)
I1022 08:28:03.843180 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00249683 (* 1 = 0.00249683 loss)
I1022 08:28:03.843189 25759 sgd_solver.cpp:106] Iteration 7880, lr = 0.002
I1022 08:29:29.939532 25759 solver.cpp:228] Iteration 7900, loss = 0.0808528
I1022 08:29:29.939574 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:29:29.939580 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:29:29.939589 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:29:29.939612 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:29:29.939618 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00488163 (* 1 = 0.00488163 loss)
I1022 08:29:29.939625 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0044111 (* 1 = 0.0044111 loss)
I1022 08:29:29.939630 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000107986 (* 1 = 0.000107986 loss)
I1022 08:29:29.939636 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.21314e-05 (* 1 = 1.21314e-05 loss)
I1022 08:29:29.939642 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00177933 (* 1 = 0.00177933 loss)
I1022 08:29:29.939649 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00319695 (* 1 = 0.00319695 loss)
I1022 08:29:29.939656 25759 sgd_solver.cpp:106] Iteration 7900, lr = 0.002
I1022 08:30:56.203104 25759 solver.cpp:228] Iteration 7920, loss = 0.104445
I1022 08:30:56.203171 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 08:30:56.203179 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 08:30:56.203192 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0193906 (* 1 = 0.0193906 loss)
I1022 08:30:56.203200 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0221422 (* 1 = 0.0221422 loss)
I1022 08:30:56.203207 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0207644 (* 1 = 0.0207644 loss)
I1022 08:30:56.203217 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.010401 (* 1 = 0.010401 loss)
I1022 08:30:56.203227 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000100065 (* 1 = 0.000100065 loss)
I1022 08:30:56.203235 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.13232e-05 (* 1 = 4.13232e-05 loss)
I1022 08:30:56.203244 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0176709 (* 1 = 0.0176709 loss)
I1022 08:30:56.203253 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0030124 (* 1 = 0.0030124 loss)
I1022 08:30:56.203267 25759 sgd_solver.cpp:106] Iteration 7920, lr = 0.002
I1022 08:32:20.812538 25759 solver.cpp:228] Iteration 7940, loss = 0.161802
I1022 08:32:20.812597 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 08:32:20.812605 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:32:20.812636 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:32:20.812644 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:32:20.812652 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0065759 (* 1 = 0.0065759 loss)
I1022 08:32:20.812659 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00438678 (* 1 = 0.00438678 loss)
I1022 08:32:20.812670 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.96402e-05 (* 1 = 6.96402e-05 loss)
I1022 08:32:20.812693 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.14725e-06 (* 1 = 9.14725e-06 loss)
I1022 08:32:20.812701 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00481467 (* 1 = 0.00481467 loss)
I1022 08:32:20.812737 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00164782 (* 1 = 0.00164782 loss)
I1022 08:32:20.812747 25759 sgd_solver.cpp:106] Iteration 7940, lr = 0.002
I1022 08:33:44.417572 25759 solver.cpp:228] Iteration 7960, loss = 0.0884269
I1022 08:33:44.417634 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:33:44.417642 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:33:44.417654 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:33:44.417662 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:33:44.417671 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00524865 (* 1 = 0.00524865 loss)
I1022 08:33:44.417682 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00449224 (* 1 = 0.00449224 loss)
I1022 08:33:44.417692 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.56413e-05 (* 1 = 6.56413e-05 loss)
I1022 08:33:44.417701 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.07163e-05 (* 1 = 1.07163e-05 loss)
I1022 08:33:44.417709 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00272924 (* 1 = 0.00272924 loss)
I1022 08:33:44.417719 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00869153 (* 1 = 0.00869153 loss)
I1022 08:33:44.417737 25759 sgd_solver.cpp:106] Iteration 7960, lr = 0.002
I1022 08:35:10.371719 25759 solver.cpp:228] Iteration 7980, loss = 0.0736254
I1022 08:35:10.371778 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:35:10.371783 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:35:10.371790 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:35:10.371796 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:35:10.371800 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00664689 (* 1 = 0.00664689 loss)
I1022 08:35:10.371805 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00457837 (* 1 = 0.00457837 loss)
I1022 08:35:10.371809 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000105116 (* 1 = 0.000105116 loss)
I1022 08:35:10.371814 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.82827e-05 (* 1 = 1.82827e-05 loss)
I1022 08:35:10.371820 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0052831 (* 1 = 0.0052831 loss)
I1022 08:35:10.371824 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00411833 (* 1 = 0.00411833 loss)
I1022 08:35:10.371834 25759 sgd_solver.cpp:106] Iteration 7980, lr = 0.002
speed: 4.206s / iter
bbbb
aaaa
Wrote snapshot to: /home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_8000.caffemodel
I1022 08:36:35.946115 25759 solver.cpp:228] Iteration 8000, loss = 0.153549
I1022 08:36:35.946154 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986035
I1022 08:36:35.946161 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993516
I1022 08:36:35.946171 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.122059 (* 1 = 0.122059 loss)
I1022 08:36:35.946177 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0874074 (* 1 = 0.0874074 loss)
I1022 08:36:35.946182 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0443373 (* 1 = 0.0443373 loss)
I1022 08:36:35.946188 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0285044 (* 1 = 0.0285044 loss)
I1022 08:36:35.946193 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000296794 (* 1 = 0.000296794 loss)
I1022 08:36:35.946200 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.00068e-05 (* 1 = 1.00068e-05 loss)
I1022 08:36:35.946207 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0408536 (* 1 = 0.0408536 loss)
I1022 08:36:35.946214 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00288964 (* 1 = 0.00288964 loss)
I1022 08:36:35.946223 25759 sgd_solver.cpp:106] Iteration 8000, lr = 0.002
I1022 08:38:01.799865 25759 solver.cpp:228] Iteration 8020, loss = 0.0466198
I1022 08:38:01.799908 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 08:38:01.799916 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:38:01.799927 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0042467 (* 1 = 0.0042467 loss)
I1022 08:38:01.799934 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00133747 (* 1 = 0.00133747 loss)
I1022 08:38:01.799947 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0119877 (* 1 = 0.0119877 loss)
I1022 08:38:01.799955 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00514718 (* 1 = 0.00514718 loss)
I1022 08:38:01.799962 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.73582e-05 (* 1 = 3.73582e-05 loss)
I1022 08:38:01.799968 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.12961e-05 (* 1 = 3.12961e-05 loss)
I1022 08:38:01.799974 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00535068 (* 1 = 0.00535068 loss)
I1022 08:38:01.799980 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00628602 (* 1 = 0.00628602 loss)
I1022 08:38:01.799988 25759 sgd_solver.cpp:106] Iteration 8020, lr = 0.002
I1022 08:39:25.927804 25759 solver.cpp:228] Iteration 8040, loss = 0.0885596
I1022 08:39:25.927860 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:39:25.927871 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:39:25.927884 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:39:25.927897 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:39:25.927908 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00452289 (* 1 = 0.00452289 loss)
I1022 08:39:25.927918 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00428677 (* 1 = 0.00428677 loss)
I1022 08:39:25.927928 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.09213e-05 (* 1 = 8.09213e-05 loss)
I1022 08:39:25.927958 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.49815e-06 (* 1 = 8.49815e-06 loss)
I1022 08:39:25.927969 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00554015 (* 1 = 0.00554015 loss)
I1022 08:39:25.927981 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00379421 (* 1 = 0.00379421 loss)
I1022 08:39:25.927994 25759 sgd_solver.cpp:106] Iteration 8040, lr = 0.002
I1022 08:40:51.650470 25759 solver.cpp:228] Iteration 8060, loss = 0.113056
I1022 08:40:51.650540 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 08:40:51.650552 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 08:40:51.650570 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00479529 (* 1 = 0.00479529 loss)
I1022 08:40:51.650583 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00824543 (* 1 = 0.00824543 loss)
I1022 08:40:51.650594 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00759596 (* 1 = 0.00759596 loss)
I1022 08:40:51.650605 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00699874 (* 1 = 0.00699874 loss)
I1022 08:40:51.650619 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.48505e-05 (* 1 = 2.48505e-05 loss)
I1022 08:40:51.650633 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.77208e-05 (* 1 = 1.77208e-05 loss)
I1022 08:40:51.650645 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00529966 (* 1 = 0.00529966 loss)
I1022 08:40:51.650657 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00103365 (* 1 = 0.00103365 loss)
I1022 08:40:51.650672 25759 sgd_solver.cpp:106] Iteration 8060, lr = 0.002
I1022 08:42:17.637127 25759 solver.cpp:228] Iteration 8080, loss = 0.0770681
I1022 08:42:17.637171 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:42:17.637189 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:42:17.637198 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:42:17.637207 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:42:17.637214 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00469583 (* 1 = 0.00469583 loss)
I1022 08:42:17.637219 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00433871 (* 1 = 0.00433871 loss)
I1022 08:42:17.637226 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.5799e-05 (* 1 = 7.5799e-05 loss)
I1022 08:42:17.637233 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.49463e-06 (* 1 = 6.49463e-06 loss)
I1022 08:42:17.637238 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0103366 (* 1 = 0.0103366 loss)
I1022 08:42:17.637245 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000858864 (* 1 = 0.000858864 loss)
I1022 08:42:17.637253 25759 sgd_solver.cpp:106] Iteration 8080, lr = 0.002
I1022 08:43:41.641580 25759 solver.cpp:228] Iteration 8100, loss = 0.0721943
I1022 08:43:41.641654 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 08:43:41.641666 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 08:43:41.641683 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00817548 (* 1 = 0.00817548 loss)
I1022 08:43:41.641697 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0126097 (* 1 = 0.0126097 loss)
I1022 08:43:41.641708 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0102099 (* 1 = 0.0102099 loss)
I1022 08:43:41.641721 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0105271 (* 1 = 0.0105271 loss)
I1022 08:43:41.641737 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000121699 (* 1 = 0.000121699 loss)
I1022 08:43:41.641752 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.26054e-05 (* 1 = 1.26054e-05 loss)
I1022 08:43:41.641764 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0213676 (* 1 = 0.0213676 loss)
I1022 08:43:41.641777 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0032414 (* 1 = 0.0032414 loss)
I1022 08:43:41.641791 25759 sgd_solver.cpp:106] Iteration 8100, lr = 0.002
I1022 08:45:06.496508 25759 solver.cpp:228] Iteration 8120, loss = 0.0736431
I1022 08:45:06.496551 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 08:45:06.496556 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 08:45:06.496565 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0264466 (* 1 = 0.0264466 loss)
I1022 08:45:06.496570 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00819742 (* 1 = 0.00819742 loss)
I1022 08:45:06.496574 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00823096 (* 1 = 0.00823096 loss)
I1022 08:45:06.496578 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00739776 (* 1 = 0.00739776 loss)
I1022 08:45:06.496587 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000141055 (* 1 = 0.000141055 loss)
I1022 08:45:06.496592 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.50984e-06 (* 1 = 7.50984e-06 loss)
I1022 08:45:06.496596 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00949991 (* 1 = 0.00949991 loss)
I1022 08:45:06.496600 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000474653 (* 1 = 0.000474653 loss)
I1022 08:45:06.496611 25759 sgd_solver.cpp:106] Iteration 8120, lr = 0.002
I1022 08:46:31.529916 25759 solver.cpp:228] Iteration 8140, loss = 0.0430983
I1022 08:46:31.529983 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 08:46:31.529994 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 08:46:31.530010 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0122393 (* 1 = 0.0122393 loss)
I1022 08:46:31.530022 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00500033 (* 1 = 0.00500033 loss)
I1022 08:46:31.530032 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00877971 (* 1 = 0.00877971 loss)
I1022 08:46:31.530042 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00530708 (* 1 = 0.00530708 loss)
I1022 08:46:31.530053 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.08704e-05 (* 1 = 6.08704e-05 loss)
I1022 08:46:31.530066 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.77501e-05 (* 1 = 1.77501e-05 loss)
I1022 08:46:31.530079 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00494411 (* 1 = 0.00494411 loss)
I1022 08:46:31.530092 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000880067 (* 1 = 0.000880067 loss)
I1022 08:46:31.530105 25759 sgd_solver.cpp:106] Iteration 8140, lr = 0.002
I1022 08:47:55.800694 25759 solver.cpp:228] Iteration 8160, loss = 0.0720608
I1022 08:47:55.800762 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994009
I1022 08:47:55.800772 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997005
I1022 08:47:55.800786 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0240596 (* 1 = 0.0240596 loss)
I1022 08:47:55.800797 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0107257 (* 1 = 0.0107257 loss)
I1022 08:47:55.800806 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0211429 (* 1 = 0.0211429 loss)
I1022 08:47:55.800814 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0143859 (* 1 = 0.0143859 loss)
I1022 08:47:55.800824 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000149813 (* 1 = 0.000149813 loss)
I1022 08:47:55.800851 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.67552e-05 (* 1 = 2.67552e-05 loss)
I1022 08:47:55.800874 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0106386 (* 1 = 0.0106386 loss)
I1022 08:47:55.800885 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000355755 (* 1 = 0.000355755 loss)
I1022 08:47:55.800897 25759 sgd_solver.cpp:106] Iteration 8160, lr = 0.002
I1022 08:49:16.986953 25759 solver.cpp:228] Iteration 8180, loss = 0.177124
I1022 08:49:16.987000 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997005
I1022 08:49:16.987005 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997005
I1022 08:49:16.987012 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0330414 (* 1 = 0.0330414 loss)
I1022 08:49:16.987017 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00904508 (* 1 = 0.00904508 loss)
I1022 08:49:16.987022 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0233118 (* 1 = 0.0233118 loss)
I1022 08:49:16.987026 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0149819 (* 1 = 0.0149819 loss)
I1022 08:49:16.987030 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000145497 (* 1 = 0.000145497 loss)
I1022 08:49:16.987035 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.4866e-06 (* 1 = 7.4866e-06 loss)
I1022 08:49:16.987040 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00975426 (* 1 = 0.00975426 loss)
I1022 08:49:16.987044 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000434668 (* 1 = 0.000434668 loss)
I1022 08:49:16.987051 25759 sgd_solver.cpp:106] Iteration 8180, lr = 0.002
speed: 4.207s / iter
I1022 08:50:41.837790 25759 solver.cpp:228] Iteration 8200, loss = 0.174231
I1022 08:50:41.837844 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995003
I1022 08:50:41.837855 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:50:41.837872 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00831077 (* 1 = 0.00831077 loss)
I1022 08:50:41.837884 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00243237 (* 1 = 0.00243237 loss)
I1022 08:50:41.837895 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0129389 (* 1 = 0.0129389 loss)
I1022 08:50:41.837906 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00595447 (* 1 = 0.00595447 loss)
I1022 08:50:41.837918 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.43394e-05 (* 1 = 4.43394e-05 loss)
I1022 08:50:41.837932 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.83737e-05 (* 1 = 1.83737e-05 loss)
I1022 08:50:41.837945 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00474812 (* 1 = 0.00474812 loss)
I1022 08:50:41.837958 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00494045 (* 1 = 0.00494045 loss)
I1022 08:50:41.837971 25759 sgd_solver.cpp:106] Iteration 8200, lr = 0.002
I1022 08:52:06.991529 25759 solver.cpp:228] Iteration 8220, loss = 0.0909941
I1022 08:52:06.991569 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991218
I1022 08:52:06.991575 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99301
I1022 08:52:06.991585 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0455346 (* 1 = 0.0455346 loss)
I1022 08:52:06.991590 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0303039 (* 1 = 0.0303039 loss)
I1022 08:52:06.991596 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0218877 (* 1 = 0.0218877 loss)
I1022 08:52:06.991602 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0236002 (* 1 = 0.0236002 loss)
I1022 08:52:06.991607 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00701263 (* 1 = 0.00701263 loss)
I1022 08:52:06.991614 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.29064e-05 (* 1 = 3.29064e-05 loss)
I1022 08:52:06.991619 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.272886 (* 1 = 0.272886 loss)
I1022 08:52:06.991626 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000369242 (* 1 = 0.000369242 loss)
I1022 08:52:06.991632 25759 sgd_solver.cpp:106] Iteration 8220, lr = 0.002
I1022 08:53:33.668316 25759 solver.cpp:228] Iteration 8240, loss = 0.109437
I1022 08:53:33.668366 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 08:53:33.668371 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 08:53:33.668380 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 08:53:33.668385 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 08:53:33.668388 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00559462 (* 1 = 0.00559462 loss)
I1022 08:53:33.668392 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00462615 (* 1 = 0.00462615 loss)
I1022 08:53:33.668397 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.91839e-05 (* 1 = 6.91839e-05 loss)
I1022 08:53:33.668402 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.66079e-06 (* 1 = 6.66079e-06 loss)
I1022 08:53:33.668406 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000278983 (* 1 = 0.000278983 loss)
I1022 08:53:33.668411 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00446865 (* 1 = 0.00446865 loss)
I1022 08:53:33.668421 25759 sgd_solver.cpp:106] Iteration 8240, lr = 0.002
I1022 08:54:58.124828 25759 solver.cpp:228] Iteration 8260, loss = 0.112926
I1022 08:54:58.124862 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 08:54:58.124883 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 08:54:58.124891 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00454682 (* 1 = 0.00454682 loss)
I1022 08:54:58.124897 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0047229 (* 1 = 0.0047229 loss)
I1022 08:54:58.124902 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00977788 (* 1 = 0.00977788 loss)
I1022 08:54:58.124905 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00916331 (* 1 = 0.00916331 loss)
I1022 08:54:58.124909 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000292318 (* 1 = 0.000292318 loss)
I1022 08:54:58.124915 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.14746e-05 (* 1 = 1.14746e-05 loss)
I1022 08:54:58.124920 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0211484 (* 1 = 0.0211484 loss)
I1022 08:54:58.124925 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00501033 (* 1 = 0.00501033 loss)
I1022 08:54:58.124931 25759 sgd_solver.cpp:106] Iteration 8260, lr = 0.002
I1022 08:56:24.453110 25759 solver.cpp:228] Iteration 8280, loss = 0.0599616
I1022 08:56:24.453150 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.987848
I1022 08:56:24.453156 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992012
I1022 08:56:24.453166 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0416416 (* 1 = 0.0416416 loss)
I1022 08:56:24.453172 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0501538 (* 1 = 0.0501538 loss)
I1022 08:56:24.453178 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0278541 (* 1 = 0.0278541 loss)
I1022 08:56:24.453186 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0237588 (* 1 = 0.0237588 loss)
I1022 08:56:24.453191 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.76361e-05 (* 1 = 9.76361e-05 loss)
I1022 08:56:24.453197 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.95867e-05 (* 1 = 1.95867e-05 loss)
I1022 08:56:24.453202 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0248624 (* 1 = 0.0248624 loss)
I1022 08:56:24.453208 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00047061 (* 1 = 0.00047061 loss)
I1022 08:56:24.453218 25759 sgd_solver.cpp:106] Iteration 8280, lr = 0.002
I1022 08:57:51.284649 25759 solver.cpp:228] Iteration 8300, loss = 0.11754
I1022 08:57:51.284703 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997003
I1022 08:57:51.284709 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 08:57:51.284719 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0260325 (* 1 = 0.0260325 loss)
I1022 08:57:51.284729 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00851072 (* 1 = 0.00851072 loss)
I1022 08:57:51.284734 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0158154 (* 1 = 0.0158154 loss)
I1022 08:57:51.284740 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0133237 (* 1 = 0.0133237 loss)
I1022 08:57:51.284746 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.62482e-05 (* 1 = 9.62482e-05 loss)
I1022 08:57:51.284754 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.84075e-05 (* 1 = 2.84075e-05 loss)
I1022 08:57:51.284759 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00547962 (* 1 = 0.00547962 loss)
I1022 08:57:51.284765 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000349788 (* 1 = 0.000349788 loss)
I1022 08:57:51.284772 25759 sgd_solver.cpp:106] Iteration 8300, lr = 0.002
I1022 08:59:17.310685 25759 solver.cpp:228] Iteration 8320, loss = 0.0691869
I1022 08:59:17.310726 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 08:59:17.310745 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 08:59:17.310755 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00528695 (* 1 = 0.00528695 loss)
I1022 08:59:17.310763 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00494688 (* 1 = 0.00494688 loss)
I1022 08:59:17.310770 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0111689 (* 1 = 0.0111689 loss)
I1022 08:59:17.310775 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00908052 (* 1 = 0.00908052 loss)
I1022 08:59:17.310781 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00105321 (* 1 = 0.00105321 loss)
I1022 08:59:17.310788 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.26892e-05 (* 1 = 2.26892e-05 loss)
I1022 08:59:17.310794 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0171825 (* 1 = 0.0171825 loss)
I1022 08:59:17.310801 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000943685 (* 1 = 0.000943685 loss)
I1022 08:59:17.310808 25759 sgd_solver.cpp:106] Iteration 8320, lr = 0.002
I1022 09:00:41.983531 25759 solver.cpp:228] Iteration 8340, loss = 0.121447
I1022 09:00:41.983572 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.977578
I1022 09:00:41.983579 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.989537
I1022 09:00:41.983589 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0881305 (* 1 = 0.0881305 loss)
I1022 09:00:41.983597 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0776028 (* 1 = 0.0776028 loss)
I1022 09:00:41.983603 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0640246 (* 1 = 0.0640246 loss)
I1022 09:00:41.983608 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0373107 (* 1 = 0.0373107 loss)
I1022 09:00:41.983614 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000644862 (* 1 = 0.000644862 loss)
I1022 09:00:41.983621 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00160579 (* 1 = 0.00160579 loss)
I1022 09:00:41.983628 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0731058 (* 1 = 0.0731058 loss)
I1022 09:00:41.983633 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00303356 (* 1 = 0.00303356 loss)
I1022 09:00:41.983640 25759 sgd_solver.cpp:106] Iteration 8340, lr = 0.002
I1022 09:02:05.568840 25759 solver.cpp:228] Iteration 8360, loss = 0.104048
I1022 09:02:05.568878 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 09:02:05.568894 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 09:02:05.568903 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0444781 (* 1 = 0.0444781 loss)
I1022 09:02:05.568910 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0145014 (* 1 = 0.0145014 loss)
I1022 09:02:05.568915 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0130964 (* 1 = 0.0130964 loss)
I1022 09:02:05.568922 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0112718 (* 1 = 0.0112718 loss)
I1022 09:02:05.568928 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000404112 (* 1 = 0.000404112 loss)
I1022 09:02:05.568934 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.49565e-05 (* 1 = 2.49565e-05 loss)
I1022 09:02:05.568940 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0151209 (* 1 = 0.0151209 loss)
I1022 09:02:05.568946 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000638443 (* 1 = 0.000638443 loss)
I1022 09:02:05.568953 25759 sgd_solver.cpp:106] Iteration 8360, lr = 0.002
I1022 09:03:30.362763 25759 solver.cpp:228] Iteration 8380, loss = 0.0441346
I1022 09:03:30.362803 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 09:03:30.362810 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:03:30.362819 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00680641 (* 1 = 0.00680641 loss)
I1022 09:03:30.362826 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000637869 (* 1 = 0.000637869 loss)
I1022 09:03:30.362833 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0101181 (* 1 = 0.0101181 loss)
I1022 09:03:30.362838 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00472197 (* 1 = 0.00472197 loss)
I1022 09:03:30.362843 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.47546e-05 (* 1 = 3.47546e-05 loss)
I1022 09:03:30.362849 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.11501e-06 (* 1 = 8.11501e-06 loss)
I1022 09:03:30.362855 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00203324 (* 1 = 0.00203324 loss)
I1022 09:03:30.362861 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000277962 (* 1 = 0.000277962 loss)
I1022 09:03:30.362867 25759 sgd_solver.cpp:106] Iteration 8380, lr = 0.002
speed: 4.208s / iter
I1022 09:04:56.447913 25759 solver.cpp:228] Iteration 8400, loss = 0.16478
I1022 09:04:56.447959 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 09:04:56.447968 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997503
I1022 09:04:56.447978 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0211661 (* 1 = 0.0211661 loss)
I1022 09:04:56.447986 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0198136 (* 1 = 0.0198136 loss)
I1022 09:04:56.447995 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0167728 (* 1 = 0.0167728 loss)
I1022 09:04:56.448002 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0137955 (* 1 = 0.0137955 loss)
I1022 09:04:56.448009 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.62756e-05 (* 1 = 7.62756e-05 loss)
I1022 09:04:56.448017 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.82641e-06 (* 1 = 8.82641e-06 loss)
I1022 09:04:56.448024 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0142171 (* 1 = 0.0142171 loss)
I1022 09:04:56.448031 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00426737 (* 1 = 0.00426737 loss)
I1022 09:04:56.448045 25759 sgd_solver.cpp:106] Iteration 8400, lr = 0.002
I1022 09:06:21.655283 25759 solver.cpp:228] Iteration 8420, loss = 0.133798
I1022 09:06:21.655323 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99496
I1022 09:06:21.655329 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 09:06:21.655339 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00846936 (* 1 = 0.00846936 loss)
I1022 09:06:21.655346 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00697084 (* 1 = 0.00697084 loss)
I1022 09:06:21.655354 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0116792 (* 1 = 0.0116792 loss)
I1022 09:06:21.655359 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00817297 (* 1 = 0.00817297 loss)
I1022 09:06:21.655365 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.24063e-05 (* 1 = 7.24063e-05 loss)
I1022 09:06:21.655372 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.22646e-05 (* 1 = 1.22646e-05 loss)
I1022 09:06:21.655378 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.004867 (* 1 = 0.004867 loss)
I1022 09:06:21.655385 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00409918 (* 1 = 0.00409918 loss)
I1022 09:06:21.655395 25759 sgd_solver.cpp:106] Iteration 8420, lr = 0.002
I1022 09:07:48.338662 25759 solver.cpp:228] Iteration 8440, loss = 0.185364
I1022 09:07:48.338701 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 09:07:48.338706 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:07:48.338716 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00962669 (* 1 = 0.00962669 loss)
I1022 09:07:48.338723 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00027614 (* 1 = 0.00027614 loss)
I1022 09:07:48.338729 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.011365 (* 1 = 0.011365 loss)
I1022 09:07:48.338734 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00493386 (* 1 = 0.00493386 loss)
I1022 09:07:48.338740 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.19543e-05 (* 1 = 3.19543e-05 loss)
I1022 09:07:48.338747 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.42771e-06 (* 1 = 5.42771e-06 loss)
I1022 09:07:48.338752 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0041207 (* 1 = 0.0041207 loss)
I1022 09:07:48.338758 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000906023 (* 1 = 0.000906023 loss)
I1022 09:07:48.338768 25759 sgd_solver.cpp:106] Iteration 8440, lr = 0.002
I1022 09:09:13.519503 25759 solver.cpp:228] Iteration 8460, loss = 0.075652
I1022 09:09:13.519554 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:09:13.519560 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:09:13.519567 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:09:13.519572 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:09:13.519577 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00470677 (* 1 = 0.00470677 loss)
I1022 09:09:13.519582 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00438937 (* 1 = 0.00438937 loss)
I1022 09:09:13.519587 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000108663 (* 1 = 0.000108663 loss)
I1022 09:09:13.519593 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.36598e-05 (* 1 = 1.36598e-05 loss)
I1022 09:09:13.519596 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00961778 (* 1 = 0.00961778 loss)
I1022 09:09:13.519601 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000395774 (* 1 = 0.000395774 loss)
I1022 09:09:13.519610 25759 sgd_solver.cpp:106] Iteration 8460, lr = 0.002
I1022 09:10:38.585245 25759 solver.cpp:228] Iteration 8480, loss = 0.108097
I1022 09:10:38.585304 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:10:38.585311 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:10:38.585324 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:10:38.585330 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:10:38.585337 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00437223 (* 1 = 0.00437223 loss)
I1022 09:10:38.585345 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00451685 (* 1 = 0.00451685 loss)
I1022 09:10:38.585351 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000112921 (* 1 = 0.000112921 loss)
I1022 09:10:38.585361 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.41049e-05 (* 1 = 1.41049e-05 loss)
I1022 09:10:38.585368 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00391174 (* 1 = 0.00391174 loss)
I1022 09:10:38.585376 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.002395 (* 1 = 0.002395 loss)
I1022 09:10:38.585397 25759 sgd_solver.cpp:106] Iteration 8480, lr = 0.002
I1022 09:12:03.713990 25759 solver.cpp:228] Iteration 8500, loss = 0.0430554
I1022 09:12:03.714041 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 09:12:03.714051 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 09:12:03.714064 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00683864 (* 1 = 0.00683864 loss)
I1022 09:12:03.714077 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00604362 (* 1 = 0.00604362 loss)
I1022 09:12:03.714087 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0103693 (* 1 = 0.0103693 loss)
I1022 09:12:03.714094 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00928658 (* 1 = 0.00928658 loss)
I1022 09:12:03.714103 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000364985 (* 1 = 0.000364985 loss)
I1022 09:12:03.714113 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.88392e-06 (* 1 = 8.88392e-06 loss)
I1022 09:12:03.714126 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0121754 (* 1 = 0.0121754 loss)
I1022 09:12:03.714138 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000167517 (* 1 = 0.000167517 loss)
I1022 09:12:03.714148 25759 sgd_solver.cpp:106] Iteration 8500, lr = 0.002
I1022 09:13:26.189795 25759 solver.cpp:228] Iteration 8520, loss = 0.0892864
I1022 09:13:26.189832 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:13:26.189839 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:13:26.189851 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:13:26.189857 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:13:26.189863 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00457205 (* 1 = 0.00457205 loss)
I1022 09:13:26.189870 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00432708 (* 1 = 0.00432708 loss)
I1022 09:13:26.189877 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.44316e-05 (* 1 = 8.44316e-05 loss)
I1022 09:13:26.189882 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.81766e-05 (* 1 = 1.81766e-05 loss)
I1022 09:13:26.189888 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00141474 (* 1 = 0.00141474 loss)
I1022 09:13:26.189894 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00189189 (* 1 = 0.00189189 loss)
I1022 09:13:26.189905 25759 sgd_solver.cpp:106] Iteration 8520, lr = 0.002
I1022 09:14:51.823166 25759 solver.cpp:228] Iteration 8540, loss = 0.0450487
I1022 09:14:51.823240 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 09:14:51.823246 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 09:14:51.823256 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00720001 (* 1 = 0.00720001 loss)
I1022 09:14:51.823262 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00539034 (* 1 = 0.00539034 loss)
I1022 09:14:51.823266 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00910784 (* 1 = 0.00910784 loss)
I1022 09:14:51.823271 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00721596 (* 1 = 0.00721596 loss)
I1022 09:14:51.823277 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.91989e-05 (* 1 = 9.91989e-05 loss)
I1022 09:14:51.823283 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.04608e-05 (* 1 = 2.04608e-05 loss)
I1022 09:14:51.823288 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00887719 (* 1 = 0.00887719 loss)
I1022 09:14:51.823292 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00336889 (* 1 = 0.00336889 loss)
I1022 09:14:51.823300 25759 sgd_solver.cpp:106] Iteration 8540, lr = 0.002
I1022 09:16:16.440661 25759 solver.cpp:228] Iteration 8560, loss = 0.0423873
I1022 09:16:16.440701 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:16:16.440717 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:16:16.440726 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:16:16.440732 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:16:16.440742 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00540624 (* 1 = 0.00540624 loss)
I1022 09:16:16.440747 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450706 (* 1 = 0.00450706 loss)
I1022 09:16:16.440754 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000140938 (* 1 = 0.000140938 loss)
I1022 09:16:16.440760 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.02126e-05 (* 1 = 2.02126e-05 loss)
I1022 09:16:16.440766 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00412958 (* 1 = 0.00412958 loss)
I1022 09:16:16.440773 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00146507 (* 1 = 0.00146507 loss)
I1022 09:16:16.440779 25759 sgd_solver.cpp:106] Iteration 8560, lr = 0.002
I1022 09:17:39.901159 25759 solver.cpp:228] Iteration 8580, loss = 0.141857
I1022 09:17:39.901207 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:17:39.901217 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:17:39.901232 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:17:39.901242 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:17:39.901252 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00429184 (* 1 = 0.00429184 loss)
I1022 09:17:39.901262 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00436736 (* 1 = 0.00436736 loss)
I1022 09:17:39.901271 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.45382e-05 (* 1 = 5.45382e-05 loss)
I1022 09:17:39.901283 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.8732e-06 (* 1 = 6.8732e-06 loss)
I1022 09:17:39.901293 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00246979 (* 1 = 0.00246979 loss)
I1022 09:17:39.901305 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000267725 (* 1 = 0.000267725 loss)
I1022 09:17:39.901320 25759 sgd_solver.cpp:106] Iteration 8580, lr = 0.002
speed: 4.209s / iter
I1022 09:19:01.003713 25759 solver.cpp:228] Iteration 8600, loss = 0.141151
I1022 09:19:01.003762 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99351
I1022 09:19:01.003767 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990514
I1022 09:19:01.003774 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0521257 (* 1 = 0.0521257 loss)
I1022 09:19:01.003779 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0267721 (* 1 = 0.0267721 loss)
I1022 09:19:01.003783 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.031891 (* 1 = 0.031891 loss)
I1022 09:19:01.003788 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0285106 (* 1 = 0.0285106 loss)
I1022 09:19:01.003793 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00417223 (* 1 = 0.00417223 loss)
I1022 09:19:01.003798 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.265e-05 (* 1 = 4.265e-05 loss)
I1022 09:19:01.003803 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.153699 (* 1 = 0.153699 loss)
I1022 09:19:01.003806 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000207447 (* 1 = 0.000207447 loss)
I1022 09:19:01.003828 25759 sgd_solver.cpp:106] Iteration 8600, lr = 0.002
I1022 09:20:26.233315 25759 solver.cpp:228] Iteration 8620, loss = 0.114877
I1022 09:20:26.233359 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989016
I1022 09:20:26.233376 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99351
I1022 09:20:26.233387 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0490297 (* 1 = 0.0490297 loss)
I1022 09:20:26.233395 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0302234 (* 1 = 0.0302234 loss)
I1022 09:20:26.233402 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0337053 (* 1 = 0.0337053 loss)
I1022 09:20:26.233408 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0274497 (* 1 = 0.0274497 loss)
I1022 09:20:26.233415 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00119149 (* 1 = 0.00119149 loss)
I1022 09:20:26.233423 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.21748e-05 (* 1 = 1.21748e-05 loss)
I1022 09:20:26.233430 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.170222 (* 1 = 0.170222 loss)
I1022 09:20:26.233438 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00209277 (* 1 = 0.00209277 loss)
I1022 09:20:26.233445 25759 sgd_solver.cpp:106] Iteration 8620, lr = 0.002
I1022 09:21:50.535120 25759 solver.cpp:228] Iteration 8640, loss = 0.0433056
I1022 09:21:50.535167 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:21:50.535174 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:21:50.535183 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:21:50.535190 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:21:50.535197 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00477598 (* 1 = 0.00477598 loss)
I1022 09:21:50.535205 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0045047 (* 1 = 0.0045047 loss)
I1022 09:21:50.535212 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.57988e-05 (* 1 = 3.57988e-05 loss)
I1022 09:21:50.535219 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.3799e-06 (* 1 = 7.3799e-06 loss)
I1022 09:21:50.535225 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0055157 (* 1 = 0.0055157 loss)
I1022 09:21:50.535231 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00494676 (* 1 = 0.00494676 loss)
I1022 09:21:50.535254 25759 sgd_solver.cpp:106] Iteration 8640, lr = 0.002
I1022 09:23:17.552965 25759 solver.cpp:228] Iteration 8660, loss = 0.163733
I1022 09:23:17.553045 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995005
I1022 09:23:17.553052 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999001
I1022 09:23:17.553064 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0249201 (* 1 = 0.0249201 loss)
I1022 09:23:17.553072 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00729046 (* 1 = 0.00729046 loss)
I1022 09:23:17.553079 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0144405 (* 1 = 0.0144405 loss)
I1022 09:23:17.553086 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00886518 (* 1 = 0.00886518 loss)
I1022 09:23:17.553092 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.53303e-05 (* 1 = 7.53303e-05 loss)
I1022 09:23:17.553099 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.38042e-05 (* 1 = 1.38042e-05 loss)
I1022 09:23:17.553107 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0138428 (* 1 = 0.0138428 loss)
I1022 09:23:17.553113 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00336564 (* 1 = 0.00336564 loss)
I1022 09:23:17.553122 25759 sgd_solver.cpp:106] Iteration 8660, lr = 0.002
I1022 09:24:41.559113 25759 solver.cpp:228] Iteration 8680, loss = 0.138417
I1022 09:24:41.559159 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 09:24:41.559165 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 09:24:41.559175 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.15648 (* 1 = 0.15648 loss)
I1022 09:24:41.559182 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0129721 (* 1 = 0.0129721 loss)
I1022 09:24:41.559187 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0122153 (* 1 = 0.0122153 loss)
I1022 09:24:41.559195 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00670668 (* 1 = 0.00670668 loss)
I1022 09:24:41.559201 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00170235 (* 1 = 0.00170235 loss)
I1022 09:24:41.559207 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.2156e-05 (* 1 = 1.2156e-05 loss)
I1022 09:24:41.559213 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.153291 (* 1 = 0.153291 loss)
I1022 09:24:41.559219 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00144169 (* 1 = 0.00144169 loss)
I1022 09:24:41.559226 25759 sgd_solver.cpp:106] Iteration 8680, lr = 0.002
I1022 09:26:06.197391 25759 solver.cpp:228] Iteration 8700, loss = 0.0696412
I1022 09:26:06.197443 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 09:26:06.197449 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 09:26:06.197456 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0252013 (* 1 = 0.0252013 loss)
I1022 09:26:06.197464 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.011598 (* 1 = 0.011598 loss)
I1022 09:26:06.197469 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0146818 (* 1 = 0.0146818 loss)
I1022 09:26:06.197474 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0114594 (* 1 = 0.0114594 loss)
I1022 09:26:06.197479 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000214863 (* 1 = 0.000214863 loss)
I1022 09:26:06.197484 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.92671e-06 (* 1 = 3.92671e-06 loss)
I1022 09:26:06.197489 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00669613 (* 1 = 0.00669613 loss)
I1022 09:26:06.197492 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00111766 (* 1 = 0.00111766 loss)
I1022 09:26:06.197502 25759 sgd_solver.cpp:106] Iteration 8700, lr = 0.002
I1022 09:27:31.090749 25759 solver.cpp:228] Iteration 8720, loss = 0.161163
I1022 09:27:31.090791 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.973123
I1022 09:27:31.090798 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.979156
I1022 09:27:31.090808 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.257051 (* 1 = 0.257051 loss)
I1022 09:27:31.090816 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.153608 (* 1 = 0.153608 loss)
I1022 09:27:31.090823 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0826891 (* 1 = 0.0826891 loss)
I1022 09:27:31.090831 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0807986 (* 1 = 0.0807986 loss)
I1022 09:27:31.090837 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00807688 (* 1 = 0.00807688 loss)
I1022 09:27:31.090844 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.20251e-05 (* 1 = 2.20251e-05 loss)
I1022 09:27:31.090852 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.158712 (* 1 = 0.158712 loss)
I1022 09:27:31.090858 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000833998 (* 1 = 0.000833998 loss)
I1022 09:27:31.090872 25759 sgd_solver.cpp:106] Iteration 8720, lr = 0.002
I1022 09:28:56.491679 25759 solver.cpp:228] Iteration 8740, loss = 0.161715
I1022 09:28:56.491729 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.981781
I1022 09:28:56.491735 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.989033
I1022 09:28:56.491744 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.106911 (* 1 = 0.106911 loss)
I1022 09:28:56.491749 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.079472 (* 1 = 0.079472 loss)
I1022 09:28:56.491753 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0405911 (* 1 = 0.0405911 loss)
I1022 09:28:56.491757 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0427143 (* 1 = 0.0427143 loss)
I1022 09:28:56.491762 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000687595 (* 1 = 0.000687595 loss)
I1022 09:28:56.491767 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.10979e-05 (* 1 = 5.10979e-05 loss)
I1022 09:28:56.491772 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0846443 (* 1 = 0.0846443 loss)
I1022 09:28:56.491777 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00236952 (* 1 = 0.00236952 loss)
I1022 09:28:56.491783 25759 sgd_solver.cpp:106] Iteration 8740, lr = 0.002
I1022 09:30:22.334681 25759 solver.cpp:228] Iteration 8760, loss = 0.125837
I1022 09:30:22.334719 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986028
I1022 09:30:22.334727 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991517
I1022 09:30:22.334735 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.232421 (* 1 = 0.232421 loss)
I1022 09:30:22.334743 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.123875 (* 1 = 0.123875 loss)
I1022 09:30:22.334748 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.060668 (* 1 = 0.060668 loss)
I1022 09:30:22.334753 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0308594 (* 1 = 0.0308594 loss)
I1022 09:30:22.334759 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00110076 (* 1 = 0.00110076 loss)
I1022 09:30:22.334765 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.88794e-05 (* 1 = 1.88794e-05 loss)
I1022 09:30:22.334771 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0470944 (* 1 = 0.0470944 loss)
I1022 09:30:22.334777 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00291021 (* 1 = 0.00291021 loss)
I1022 09:30:22.334784 25759 sgd_solver.cpp:106] Iteration 8760, lr = 0.002
I1022 09:31:47.002559 25759 solver.cpp:228] Iteration 8780, loss = 0.14456
I1022 09:31:47.002593 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991013
I1022 09:31:47.002598 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994508
I1022 09:31:47.002605 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0332565 (* 1 = 0.0332565 loss)
I1022 09:31:47.002609 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0316972 (* 1 = 0.0316972 loss)
I1022 09:31:47.002614 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0306258 (* 1 = 0.0306258 loss)
I1022 09:31:47.002617 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0207185 (* 1 = 0.0207185 loss)
I1022 09:31:47.002622 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000626847 (* 1 = 0.000626847 loss)
I1022 09:31:47.002627 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.61264e-05 (* 1 = 1.61264e-05 loss)
I1022 09:31:47.002631 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0406844 (* 1 = 0.0406844 loss)
I1022 09:31:47.002635 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0116751 (* 1 = 0.0116751 loss)
I1022 09:31:47.002643 25759 sgd_solver.cpp:106] Iteration 8780, lr = 0.002
speed: 4.210s / iter
I1022 09:33:12.602078 25759 solver.cpp:228] Iteration 8800, loss = 0.142136
I1022 09:33:12.602118 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 09:33:12.602124 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 09:33:12.602134 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0121337 (* 1 = 0.0121337 loss)
I1022 09:33:12.602140 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00472847 (* 1 = 0.00472847 loss)
I1022 09:33:12.602146 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0101834 (* 1 = 0.0101834 loss)
I1022 09:33:12.602152 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00820828 (* 1 = 0.00820828 loss)
I1022 09:33:12.602159 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000106222 (* 1 = 0.000106222 loss)
I1022 09:33:12.602164 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.90767e-05 (* 1 = 2.90767e-05 loss)
I1022 09:33:12.602169 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00942785 (* 1 = 0.00942785 loss)
I1022 09:33:12.602175 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00289031 (* 1 = 0.00289031 loss)
I1022 09:33:12.602182 25759 sgd_solver.cpp:106] Iteration 8800, lr = 0.002
I1022 09:34:35.663717 25759 solver.cpp:228] Iteration 8820, loss = 0.0673883
I1022 09:34:35.663750 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:34:35.663754 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:34:35.663761 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:34:35.663765 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:34:35.663769 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00369675 (* 1 = 0.00369675 loss)
I1022 09:34:35.663774 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0045527 (* 1 = 0.0045527 loss)
I1022 09:34:35.663779 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.89423e-05 (* 1 = 8.89423e-05 loss)
I1022 09:34:35.663784 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.57005e-05 (* 1 = 1.57005e-05 loss)
I1022 09:34:35.663787 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 9.68658e-05 (* 1 = 9.68658e-05 loss)
I1022 09:34:35.663791 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00396251 (* 1 = 0.00396251 loss)
I1022 09:34:35.663797 25759 sgd_solver.cpp:106] Iteration 8820, lr = 0.002
I1022 09:36:00.061172 25759 solver.cpp:228] Iteration 8840, loss = 0.0582446
I1022 09:36:00.061211 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:36:00.061218 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:36:00.061228 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:36:00.061234 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:36:00.061241 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00461527 (* 1 = 0.00461527 loss)
I1022 09:36:00.061247 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00446533 (* 1 = 0.00446533 loss)
I1022 09:36:00.061254 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.29257e-05 (* 1 = 8.29257e-05 loss)
I1022 09:36:00.061260 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.83624e-06 (* 1 = 8.83624e-06 loss)
I1022 09:36:00.061267 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00715796 (* 1 = 0.00715796 loss)
I1022 09:36:00.061273 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00471705 (* 1 = 0.00471705 loss)
I1022 09:36:00.061280 25759 sgd_solver.cpp:106] Iteration 8840, lr = 0.002
I1022 09:37:26.027638 25759 solver.cpp:228] Iteration 8860, loss = 0.259058
I1022 09:37:26.027680 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:37:26.027695 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:37:26.027705 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:37:26.027711 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:37:26.027719 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00456525 (* 1 = 0.00456525 loss)
I1022 09:37:26.027724 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00451705 (* 1 = 0.00451705 loss)
I1022 09:37:26.027731 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.0898e-05 (* 1 = 9.0898e-05 loss)
I1022 09:37:26.027739 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.03267e-05 (* 1 = 1.03267e-05 loss)
I1022 09:37:26.027745 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00353176 (* 1 = 0.00353176 loss)
I1022 09:37:26.027750 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00164001 (* 1 = 0.00164001 loss)
I1022 09:37:26.027757 25759 sgd_solver.cpp:106] Iteration 8860, lr = 0.002
I1022 09:38:50.646106 25759 solver.cpp:228] Iteration 8880, loss = 0.110453
I1022 09:38:50.646145 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998422
I1022 09:38:50.646152 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996502
I1022 09:38:50.646160 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0275092 (* 1 = 0.0275092 loss)
I1022 09:38:50.646167 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0184977 (* 1 = 0.0184977 loss)
I1022 09:38:50.646173 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00550938 (* 1 = 0.00550938 loss)
I1022 09:38:50.646179 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00959869 (* 1 = 0.00959869 loss)
I1022 09:38:50.646185 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.4594e-05 (* 1 = 3.4594e-05 loss)
I1022 09:38:50.646191 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.72336e-06 (* 1 = 8.72336e-06 loss)
I1022 09:38:50.646198 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00559263 (* 1 = 0.00559263 loss)
I1022 09:38:50.646203 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.91886e-05 (* 1 = 4.91886e-05 loss)
I1022 09:38:50.646209 25759 sgd_solver.cpp:106] Iteration 8880, lr = 0.002
I1022 09:40:15.100335 25759 solver.cpp:228] Iteration 8900, loss = 0.0614845
I1022 09:40:15.100375 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:40:15.100383 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:40:15.100391 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:40:15.100397 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:40:15.100404 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00457119 (* 1 = 0.00457119 loss)
I1022 09:40:15.100409 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00464141 (* 1 = 0.00464141 loss)
I1022 09:40:15.100415 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.24388e-05 (* 1 = 6.24388e-05 loss)
I1022 09:40:15.100421 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000185999 (* 1 = 0.000185999 loss)
I1022 09:40:15.100427 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000740422 (* 1 = 0.000740422 loss)
I1022 09:40:15.100433 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000374832 (* 1 = 0.000374832 loss)
I1022 09:40:15.100445 25759 sgd_solver.cpp:106] Iteration 8900, lr = 0.002
I1022 09:41:40.609485 25759 solver.cpp:228] Iteration 8920, loss = 0.050184
I1022 09:41:40.609547 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997003
I1022 09:41:40.609555 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 09:41:40.609565 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0238766 (* 1 = 0.0238766 loss)
I1022 09:41:40.609572 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0143227 (* 1 = 0.0143227 loss)
I1022 09:41:40.609578 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0159106 (* 1 = 0.0159106 loss)
I1022 09:41:40.609583 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0136195 (* 1 = 0.0136195 loss)
I1022 09:41:40.609591 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000133035 (* 1 = 0.000133035 loss)
I1022 09:41:40.609596 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.26998e-06 (* 1 = 7.26998e-06 loss)
I1022 09:41:40.609602 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0204015 (* 1 = 0.0204015 loss)
I1022 09:41:40.609609 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000334216 (* 1 = 0.000334216 loss)
I1022 09:41:40.609617 25759 sgd_solver.cpp:106] Iteration 8920, lr = 0.002
I1022 09:43:06.647254 25759 solver.cpp:228] Iteration 8940, loss = 0.0788679
I1022 09:43:06.647294 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997901
I1022 09:43:06.647310 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 09:43:06.647320 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00605959 (* 1 = 0.00605959 loss)
I1022 09:43:06.647326 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0055825 (* 1 = 0.0055825 loss)
I1022 09:43:06.647332 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00616766 (* 1 = 0.00616766 loss)
I1022 09:43:06.647338 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00727528 (* 1 = 0.00727528 loss)
I1022 09:43:06.647346 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.28167e-05 (* 1 = 8.28167e-05 loss)
I1022 09:43:06.647352 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.81877e-06 (* 1 = 8.81877e-06 loss)
I1022 09:43:06.647358 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00862814 (* 1 = 0.00862814 loss)
I1022 09:43:06.647364 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00043933 (* 1 = 0.00043933 loss)
I1022 09:43:06.647372 25759 sgd_solver.cpp:106] Iteration 8940, lr = 0.002
I1022 09:44:33.547607 25759 solver.cpp:228] Iteration 8960, loss = 0.138908
I1022 09:44:33.547658 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 09:44:33.547665 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:44:33.547674 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:44:33.547683 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:44:33.547689 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000350871 (* 1 = 0.000350871 loss)
I1022 09:44:33.547695 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00446449 (* 1 = 0.00446449 loss)
I1022 09:44:33.547701 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.87152e-05 (* 1 = 6.87152e-05 loss)
I1022 09:44:33.547708 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.77675e-06 (* 1 = 8.77675e-06 loss)
I1022 09:44:33.547714 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0010644 (* 1 = 0.0010644 loss)
I1022 09:44:33.547721 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00228212 (* 1 = 0.00228212 loss)
I1022 09:44:33.547729 25759 sgd_solver.cpp:106] Iteration 8960, lr = 0.002
I1022 09:45:58.268277 25759 solver.cpp:228] Iteration 8980, loss = 0.0698838
I1022 09:45:58.268316 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:45:58.268321 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:45:58.268329 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:45:58.268335 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:45:58.268342 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00448373 (* 1 = 0.00448373 loss)
I1022 09:45:58.268349 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450752 (* 1 = 0.00450752 loss)
I1022 09:45:58.268355 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000122923 (* 1 = 0.000122923 loss)
I1022 09:45:58.268362 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.81614e-06 (* 1 = 9.81614e-06 loss)
I1022 09:45:58.268368 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000145051 (* 1 = 0.000145051 loss)
I1022 09:45:58.268373 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000387712 (* 1 = 0.000387712 loss)
I1022 09:45:58.268379 25759 sgd_solver.cpp:106] Iteration 8980, lr = 0.002
speed: 4.210s / iter
I1022 09:47:19.448729 25759 solver.cpp:228] Iteration 9000, loss = 0.169431
I1022 09:47:19.448777 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:47:19.448782 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:47:19.448789 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:47:19.448794 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:47:19.448799 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00450315 (* 1 = 0.00450315 loss)
I1022 09:47:19.448803 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00384334 (* 1 = 0.00384334 loss)
I1022 09:47:19.448808 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.30199e-05 (* 1 = 8.30199e-05 loss)
I1022 09:47:19.448813 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.92009e-06 (* 1 = 9.92009e-06 loss)
I1022 09:47:19.448818 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00460703 (* 1 = 0.00460703 loss)
I1022 09:47:19.448822 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000785757 (* 1 = 0.000785757 loss)
I1022 09:47:19.448829 25759 sgd_solver.cpp:106] Iteration 9000, lr = 0.002
I1022 09:48:40.595470 25759 solver.cpp:228] Iteration 9020, loss = 0.117271
I1022 09:48:40.595540 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998428
I1022 09:48:40.595551 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 09:48:40.595566 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0147539 (* 1 = 0.0147539 loss)
I1022 09:48:40.595578 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00725228 (* 1 = 0.00725228 loss)
I1022 09:48:40.595588 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00447536 (* 1 = 0.00447536 loss)
I1022 09:48:40.595598 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00580568 (* 1 = 0.00580568 loss)
I1022 09:48:40.595609 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.90683e-05 (* 1 = 9.90683e-05 loss)
I1022 09:48:40.595623 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.28028e-06 (* 1 = 7.28028e-06 loss)
I1022 09:48:40.595636 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00849732 (* 1 = 0.00849732 loss)
I1022 09:48:40.595646 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00418196 (* 1 = 0.00418196 loss)
I1022 09:48:40.595659 25759 sgd_solver.cpp:106] Iteration 9020, lr = 0.002
I1022 09:50:02.258823 25759 solver.cpp:228] Iteration 9040, loss = 0.0734278
I1022 09:50:02.258863 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:50:02.258869 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:50:02.258878 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:50:02.258884 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:50:02.258890 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00428656 (* 1 = 0.00428656 loss)
I1022 09:50:02.258895 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00451098 (* 1 = 0.00451098 loss)
I1022 09:50:02.258901 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.84186e-05 (* 1 = 5.84186e-05 loss)
I1022 09:50:02.258908 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.781e-06 (* 1 = 8.781e-06 loss)
I1022 09:50:02.258913 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000672297 (* 1 = 0.000672297 loss)
I1022 09:50:02.258919 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00322119 (* 1 = 0.00322119 loss)
I1022 09:50:02.258926 25759 sgd_solver.cpp:106] Iteration 9040, lr = 0.002
I1022 09:51:24.513892 25759 solver.cpp:228] Iteration 9060, loss = 0.094842
I1022 09:51:24.513937 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 09:51:24.513945 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:51:24.513955 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:51:24.513963 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:51:24.513970 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000538144 (* 1 = 0.000538144 loss)
I1022 09:51:24.513978 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00447671 (* 1 = 0.00447671 loss)
I1022 09:51:24.513985 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.91824e-05 (* 1 = 7.91824e-05 loss)
I1022 09:51:24.513993 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.21187e-06 (* 1 = 9.21187e-06 loss)
I1022 09:51:24.514000 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000309681 (* 1 = 0.000309681 loss)
I1022 09:51:24.514008 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000343085 (* 1 = 0.000343085 loss)
I1022 09:51:24.514019 25759 sgd_solver.cpp:106] Iteration 9060, lr = 0.002
I1022 09:52:46.507477 25759 solver.cpp:228] Iteration 9080, loss = 0.13584
I1022 09:52:46.507510 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996577
I1022 09:52:46.507515 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 09:52:46.507522 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00462042 (* 1 = 0.00462042 loss)
I1022 09:52:46.507527 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00058617 (* 1 = 0.00058617 loss)
I1022 09:52:46.507531 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0048009 (* 1 = 0.0048009 loss)
I1022 09:52:46.507535 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00471185 (* 1 = 0.00471185 loss)
I1022 09:52:46.507539 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.90115e-05 (* 1 = 6.90115e-05 loss)
I1022 09:52:46.507544 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.28395e-06 (* 1 = 7.28395e-06 loss)
I1022 09:52:46.507549 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00416573 (* 1 = 0.00416573 loss)
I1022 09:52:46.507552 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00199946 (* 1 = 0.00199946 loss)
I1022 09:52:46.507563 25759 sgd_solver.cpp:106] Iteration 9080, lr = 0.002
I1022 09:54:09.942004 25759 solver.cpp:228] Iteration 9100, loss = 0.0210904
I1022 09:54:09.942060 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 09:54:09.942065 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:54:09.942072 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:54:09.942077 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:54:09.942081 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000236708 (* 1 = 0.000236708 loss)
I1022 09:54:09.942087 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0044805 (* 1 = 0.0044805 loss)
I1022 09:54:09.942091 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.86314e-05 (* 1 = 5.86314e-05 loss)
I1022 09:54:09.942096 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.96495e-06 (* 1 = 5.96495e-06 loss)
I1022 09:54:09.942101 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00320925 (* 1 = 0.00320925 loss)
I1022 09:54:09.942106 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00261267 (* 1 = 0.00261267 loss)
I1022 09:54:09.942116 25759 sgd_solver.cpp:106] Iteration 9100, lr = 0.002
I1022 09:55:34.084269 25759 solver.cpp:228] Iteration 9120, loss = 0.148883
I1022 09:55:34.084301 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996208
I1022 09:55:34.084306 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995008
I1022 09:55:34.084313 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0755502 (* 1 = 0.0755502 loss)
I1022 09:55:34.084317 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0420545 (* 1 = 0.0420545 loss)
I1022 09:55:34.084321 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0115807 (* 1 = 0.0115807 loss)
I1022 09:55:34.084326 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0191541 (* 1 = 0.0191541 loss)
I1022 09:55:34.084331 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000121128 (* 1 = 0.000121128 loss)
I1022 09:55:34.084334 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.51004e-05 (* 1 = 1.51004e-05 loss)
I1022 09:55:34.084338 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0352325 (* 1 = 0.0352325 loss)
I1022 09:55:34.084343 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00017786 (* 1 = 0.00017786 loss)
I1022 09:55:34.084364 25759 sgd_solver.cpp:106] Iteration 9120, lr = 0.002
I1022 09:57:00.212924 25759 solver.cpp:228] Iteration 9140, loss = 0.15288
I1022 09:57:00.212962 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 09:57:00.212968 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 09:57:00.212977 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 09:57:00.212983 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 09:57:00.212998 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00467151 (* 1 = 0.00467151 loss)
I1022 09:57:00.213007 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00459515 (* 1 = 0.00459515 loss)
I1022 09:57:00.213012 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.16388e-05 (* 1 = 9.16388e-05 loss)
I1022 09:57:00.213019 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.25568e-06 (* 1 = 9.25568e-06 loss)
I1022 09:57:00.213024 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00326348 (* 1 = 0.00326348 loss)
I1022 09:57:00.213030 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.002179 (* 1 = 0.002179 loss)
I1022 09:57:00.213037 25759 sgd_solver.cpp:106] Iteration 9140, lr = 0.002
I1022 09:58:24.727898 25759 solver.cpp:228] Iteration 9160, loss = 0.13476
I1022 09:58:24.727946 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994505
I1022 09:58:24.727952 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996503
I1022 09:58:24.727958 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0291759 (* 1 = 0.0291759 loss)
I1022 09:58:24.727963 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0190332 (* 1 = 0.0190332 loss)
I1022 09:58:24.727968 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0200684 (* 1 = 0.0200684 loss)
I1022 09:58:24.727972 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.014957 (* 1 = 0.014957 loss)
I1022 09:58:24.727977 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00052379 (* 1 = 0.00052379 loss)
I1022 09:58:24.727982 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.78821e-06 (* 1 = 6.78821e-06 loss)
I1022 09:58:24.727986 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0296411 (* 1 = 0.0296411 loss)
I1022 09:58:24.727990 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00302188 (* 1 = 0.00302188 loss)
I1022 09:58:24.727996 25759 sgd_solver.cpp:106] Iteration 9160, lr = 0.002
I1022 09:59:49.532557 25759 solver.cpp:228] Iteration 9180, loss = 0.115507
I1022 09:59:49.532634 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 09:59:49.532657 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 09:59:49.532673 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0139688 (* 1 = 0.0139688 loss)
I1022 09:59:49.532685 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00438383 (* 1 = 0.00438383 loss)
I1022 09:59:49.532706 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0110378 (* 1 = 0.0110378 loss)
I1022 09:59:49.532717 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00739101 (* 1 = 0.00739101 loss)
I1022 09:59:49.532733 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000121962 (* 1 = 0.000121962 loss)
I1022 09:59:49.532745 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.17545e-06 (* 1 = 6.17545e-06 loss)
I1022 09:59:49.532757 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0163921 (* 1 = 0.0163921 loss)
I1022 09:59:49.532768 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000881719 (* 1 = 0.000881719 loss)
I1022 09:59:49.532781 25759 sgd_solver.cpp:106] Iteration 9180, lr = 0.002
speed: 4.210s / iter
I1022 10:01:14.180306 25759 solver.cpp:228] Iteration 9200, loss = 0.088523
I1022 10:01:14.180338 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 10:01:14.180343 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 10:01:14.180351 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0170847 (* 1 = 0.0170847 loss)
I1022 10:01:14.180354 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00964828 (* 1 = 0.00964828 loss)
I1022 10:01:14.180359 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00955808 (* 1 = 0.00955808 loss)
I1022 10:01:14.180363 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0069916 (* 1 = 0.0069916 loss)
I1022 10:01:14.180367 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.56335e-05 (* 1 = 2.56335e-05 loss)
I1022 10:01:14.180372 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.80907e-06 (* 1 = 7.80907e-06 loss)
I1022 10:01:14.180377 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0155973 (* 1 = 0.0155973 loss)
I1022 10:01:14.180380 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00330842 (* 1 = 0.00330842 loss)
I1022 10:01:14.180385 25759 sgd_solver.cpp:106] Iteration 9200, lr = 0.002
I1022 10:02:38.697083 25759 solver.cpp:228] Iteration 9220, loss = 0.120747
I1022 10:02:38.697140 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993506
I1022 10:02:38.697147 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993007
I1022 10:02:38.697157 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0314851 (* 1 = 0.0314851 loss)
I1022 10:02:38.697166 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0279723 (* 1 = 0.0279723 loss)
I1022 10:02:38.697172 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0230549 (* 1 = 0.0230549 loss)
I1022 10:02:38.697177 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0206267 (* 1 = 0.0206267 loss)
I1022 10:02:38.697185 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000738026 (* 1 = 0.000738026 loss)
I1022 10:02:38.697191 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.85698e-05 (* 1 = 1.85698e-05 loss)
I1022 10:02:38.697198 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.06977 (* 1 = 0.06977 loss)
I1022 10:02:38.697204 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000196441 (* 1 = 0.000196441 loss)
I1022 10:02:38.697212 25759 sgd_solver.cpp:106] Iteration 9220, lr = 0.002
I1022 10:04:02.263876 25759 solver.cpp:228] Iteration 9240, loss = 0.0338499
I1022 10:04:02.263916 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994003
I1022 10:04:02.263923 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 10:04:02.263932 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00962418 (* 1 = 0.00962418 loss)
I1022 10:04:02.263938 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00405056 (* 1 = 0.00405056 loss)
I1022 10:04:02.263944 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0156386 (* 1 = 0.0156386 loss)
I1022 10:04:02.263950 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00769835 (* 1 = 0.00769835 loss)
I1022 10:04:02.263957 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.99283e-05 (* 1 = 2.99283e-05 loss)
I1022 10:04:02.263962 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.74874e-05 (* 1 = 2.74874e-05 loss)
I1022 10:04:02.263968 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00373639 (* 1 = 0.00373639 loss)
I1022 10:04:02.263973 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 8.42053e-05 (* 1 = 8.42053e-05 loss)
I1022 10:04:02.263980 25759 sgd_solver.cpp:106] Iteration 9240, lr = 0.002
I1022 10:05:24.447213 25759 solver.cpp:228] Iteration 9260, loss = 0.0672463
I1022 10:05:24.447260 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994503
I1022 10:05:24.447266 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 10:05:24.447274 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0116053 (* 1 = 0.0116053 loss)
I1022 10:05:24.447280 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00778809 (* 1 = 0.00778809 loss)
I1022 10:05:24.447284 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0136106 (* 1 = 0.0136106 loss)
I1022 10:05:24.447288 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00752846 (* 1 = 0.00752846 loss)
I1022 10:05:24.447293 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.40544e-05 (* 1 = 8.40544e-05 loss)
I1022 10:05:24.447299 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.22036e-05 (* 1 = 1.22036e-05 loss)
I1022 10:05:24.447302 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0102239 (* 1 = 0.0102239 loss)
I1022 10:05:24.447307 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00359429 (* 1 = 0.00359429 loss)
I1022 10:05:24.447316 25759 sgd_solver.cpp:106] Iteration 9260, lr = 0.002
I1022 10:06:45.947957 25759 solver.cpp:228] Iteration 9280, loss = 0.0970575
I1022 10:06:45.947999 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 10:06:45.948004 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 10:06:45.948011 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0165733 (* 1 = 0.0165733 loss)
I1022 10:06:45.948016 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00977013 (* 1 = 0.00977013 loss)
I1022 10:06:45.948021 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0185402 (* 1 = 0.0185402 loss)
I1022 10:06:45.948025 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0154878 (* 1 = 0.0154878 loss)
I1022 10:06:45.948030 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000200118 (* 1 = 0.000200118 loss)
I1022 10:06:45.948035 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.04503e-05 (* 1 = 1.04503e-05 loss)
I1022 10:06:45.948040 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0246166 (* 1 = 0.0246166 loss)
I1022 10:06:45.948043 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00391406 (* 1 = 0.00391406 loss)
I1022 10:06:45.948050 25759 sgd_solver.cpp:106] Iteration 9280, lr = 0.002
I1022 10:08:10.873121 25759 solver.cpp:228] Iteration 9300, loss = 0.0888172
I1022 10:08:10.873172 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 10:08:10.873188 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:08:10.873201 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:08:10.873211 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:08:10.873221 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00446488 (* 1 = 0.00446488 loss)
I1022 10:08:10.873230 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00420798 (* 1 = 0.00420798 loss)
I1022 10:08:10.873240 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.20243e-05 (* 1 = 5.20243e-05 loss)
I1022 10:08:10.873250 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.29964e-06 (* 1 = 4.29964e-06 loss)
I1022 10:08:10.873261 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000649592 (* 1 = 0.000649592 loss)
I1022 10:08:10.873288 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000898278 (* 1 = 0.000898278 loss)
I1022 10:08:10.873299 25759 sgd_solver.cpp:106] Iteration 9300, lr = 0.002
I1022 10:09:34.506095 25759 solver.cpp:228] Iteration 9320, loss = 0.0759024
I1022 10:09:34.506156 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 10:09:34.506165 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:09:34.506175 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0131149 (* 1 = 0.0131149 loss)
I1022 10:09:34.506183 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00037793 (* 1 = 0.00037793 loss)
I1022 10:09:34.506189 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00980231 (* 1 = 0.00980231 loss)
I1022 10:09:34.506196 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00504177 (* 1 = 0.00504177 loss)
I1022 10:09:34.506201 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.37043e-05 (* 1 = 5.37043e-05 loss)
I1022 10:09:34.506207 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.32597e-05 (* 1 = 1.32597e-05 loss)
I1022 10:09:34.506214 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0121588 (* 1 = 0.0121588 loss)
I1022 10:09:34.506220 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00137207 (* 1 = 0.00137207 loss)
I1022 10:09:34.506228 25759 sgd_solver.cpp:106] Iteration 9320, lr = 0.002
I1022 10:11:00.408125 25759 solver.cpp:228] Iteration 9340, loss = 0.0516992
I1022 10:11:00.408166 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 10:11:00.408182 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:11:00.408191 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:11:00.408198 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:11:00.408205 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000529472 (* 1 = 0.000529472 loss)
I1022 10:11:00.408212 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00433543 (* 1 = 0.00433543 loss)
I1022 10:11:00.408218 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.23071e-05 (* 1 = 2.23071e-05 loss)
I1022 10:11:00.408226 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.58611e-06 (* 1 = 2.58611e-06 loss)
I1022 10:11:00.408232 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0058002 (* 1 = 0.0058002 loss)
I1022 10:11:00.408239 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00222755 (* 1 = 0.00222755 loss)
I1022 10:11:00.408255 25759 sgd_solver.cpp:106] Iteration 9340, lr = 0.002
I1022 10:12:25.031597 25759 solver.cpp:228] Iteration 9360, loss = 0.0664274
I1022 10:12:25.031677 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997003
I1022 10:12:25.031689 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 10:12:25.031708 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0146849 (* 1 = 0.0146849 loss)
I1022 10:12:25.031723 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.023335 (* 1 = 0.023335 loss)
I1022 10:12:25.031734 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0188672 (* 1 = 0.0188672 loss)
I1022 10:12:25.031747 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0143083 (* 1 = 0.0143083 loss)
I1022 10:12:25.031759 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000432484 (* 1 = 0.000432484 loss)
I1022 10:12:25.031772 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.59889e-05 (* 1 = 1.59889e-05 loss)
I1022 10:12:25.031785 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0694 (* 1 = 0.0694 loss)
I1022 10:12:25.031800 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00104317 (* 1 = 0.00104317 loss)
I1022 10:12:25.031813 25759 sgd_solver.cpp:106] Iteration 9360, lr = 0.002
I1022 10:13:49.437491 25759 solver.cpp:228] Iteration 9380, loss = 0.120893
I1022 10:13:49.437528 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.987525
I1022 10:13:49.437535 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994012
I1022 10:13:49.437543 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0458314 (* 1 = 0.0458314 loss)
I1022 10:13:49.437551 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0182995 (* 1 = 0.0182995 loss)
I1022 10:13:49.437556 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0339101 (* 1 = 0.0339101 loss)
I1022 10:13:49.437561 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.023329 (* 1 = 0.023329 loss)
I1022 10:13:49.437567 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000897433 (* 1 = 0.000897433 loss)
I1022 10:13:49.437573 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.54605e-06 (* 1 = 9.54605e-06 loss)
I1022 10:13:49.437579 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0451373 (* 1 = 0.0451373 loss)
I1022 10:13:49.437584 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000768576 (* 1 = 0.000768576 loss)
I1022 10:13:49.437595 25759 sgd_solver.cpp:106] Iteration 9380, lr = 0.002
speed: 4.209s / iter
I1022 10:15:14.273707 25759 solver.cpp:228] Iteration 9400, loss = 0.0249152
I1022 10:15:14.273744 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 10:15:14.273751 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 10:15:14.273759 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00735137 (* 1 = 0.00735137 loss)
I1022 10:15:14.273766 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0059522 (* 1 = 0.0059522 loss)
I1022 10:15:14.273772 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0099162 (* 1 = 0.0099162 loss)
I1022 10:15:14.273780 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00759541 (* 1 = 0.00759541 loss)
I1022 10:15:14.273787 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00262265 (* 1 = 0.00262265 loss)
I1022 10:15:14.273792 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.16095e-05 (* 1 = 1.16095e-05 loss)
I1022 10:15:14.273798 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00364792 (* 1 = 0.00364792 loss)
I1022 10:15:14.273803 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000371027 (* 1 = 0.000371027 loss)
I1022 10:15:14.273811 25759 sgd_solver.cpp:106] Iteration 9400, lr = 0.002
I1022 10:16:39.235796 25759 solver.cpp:228] Iteration 9420, loss = 0.0815214
I1022 10:16:39.235843 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 10:16:39.235849 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:16:39.235857 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:16:39.235863 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:16:39.235868 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00415634 (* 1 = 0.00415634 loss)
I1022 10:16:39.235872 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00453986 (* 1 = 0.00453986 loss)
I1022 10:16:39.235877 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.31356e-05 (* 1 = 8.31356e-05 loss)
I1022 10:16:39.235882 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.37016e-06 (* 1 = 4.37016e-06 loss)
I1022 10:16:39.235886 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00198826 (* 1 = 0.00198826 loss)
I1022 10:16:39.235891 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00148013 (* 1 = 0.00148013 loss)
I1022 10:16:39.235896 25759 sgd_solver.cpp:106] Iteration 9420, lr = 0.002
I1022 10:18:04.077335 25759 solver.cpp:228] Iteration 9440, loss = 0.0931817
I1022 10:18:04.077368 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 10:18:04.077373 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996503
I1022 10:18:04.077380 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0161553 (* 1 = 0.0161553 loss)
I1022 10:18:04.077384 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0127162 (* 1 = 0.0127162 loss)
I1022 10:18:04.077389 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0167726 (* 1 = 0.0167726 loss)
I1022 10:18:04.077392 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0143208 (* 1 = 0.0143208 loss)
I1022 10:18:04.077397 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00111464 (* 1 = 0.00111464 loss)
I1022 10:18:04.077402 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.94495e-06 (* 1 = 9.94495e-06 loss)
I1022 10:18:04.077406 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0096338 (* 1 = 0.0096338 loss)
I1022 10:18:04.077410 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00275327 (* 1 = 0.00275327 loss)
I1022 10:18:04.077415 25759 sgd_solver.cpp:106] Iteration 9440, lr = 0.002
I1022 10:19:29.026031 25759 solver.cpp:228] Iteration 9460, loss = 0.0637303
I1022 10:19:29.026100 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994416
I1022 10:19:29.026113 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 10:19:29.026129 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0252799 (* 1 = 0.0252799 loss)
I1022 10:19:29.026142 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0260037 (* 1 = 0.0260037 loss)
I1022 10:19:29.026154 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0144468 (* 1 = 0.0144468 loss)
I1022 10:19:29.026165 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0147485 (* 1 = 0.0147485 loss)
I1022 10:19:29.026180 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000327792 (* 1 = 0.000327792 loss)
I1022 10:19:29.026195 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.56016e-06 (* 1 = 8.56016e-06 loss)
I1022 10:19:29.026208 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0501362 (* 1 = 0.0501362 loss)
I1022 10:19:29.026221 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00223187 (* 1 = 0.00223187 loss)
I1022 10:19:29.026237 25759 sgd_solver.cpp:106] Iteration 9460, lr = 0.002
I1022 10:20:52.355556 25759 solver.cpp:228] Iteration 9480, loss = 0.116639
I1022 10:20:52.355612 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994505
I1022 10:20:52.355618 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 10:20:52.355625 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0187931 (* 1 = 0.0187931 loss)
I1022 10:20:52.355630 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0176392 (* 1 = 0.0176392 loss)
I1022 10:20:52.355635 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0165741 (* 1 = 0.0165741 loss)
I1022 10:20:52.355639 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0126811 (* 1 = 0.0126811 loss)
I1022 10:20:52.355643 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000164587 (* 1 = 0.000164587 loss)
I1022 10:20:52.355649 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.23893e-06 (* 1 = 9.23893e-06 loss)
I1022 10:20:52.355654 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0298342 (* 1 = 0.0298342 loss)
I1022 10:20:52.355659 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00152989 (* 1 = 0.00152989 loss)
I1022 10:20:52.355666 25759 sgd_solver.cpp:106] Iteration 9480, lr = 0.002
I1022 10:22:17.101285 25759 solver.cpp:228] Iteration 9500, loss = 0.178112
I1022 10:22:17.101332 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.958678
I1022 10:22:17.101337 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.972181
I1022 10:22:17.101344 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.206952 (* 1 = 0.206952 loss)
I1022 10:22:17.101349 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.215588 (* 1 = 0.215588 loss)
I1022 10:22:17.101354 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0899018 (* 1 = 0.0899018 loss)
I1022 10:22:17.101358 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0937188 (* 1 = 0.0937188 loss)
I1022 10:22:17.101362 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00789242 (* 1 = 0.00789242 loss)
I1022 10:22:17.101367 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.01066e-05 (* 1 = 3.01066e-05 loss)
I1022 10:22:17.101372 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.207743 (* 1 = 0.207743 loss)
I1022 10:22:17.101377 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00159205 (* 1 = 0.00159205 loss)
I1022 10:22:17.101382 25759 sgd_solver.cpp:106] Iteration 9500, lr = 0.002
I1022 10:23:43.214891 25759 solver.cpp:228] Iteration 9520, loss = 0.0576903
I1022 10:23:43.214927 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 10:23:43.214939 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:23:43.214948 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:23:43.214954 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:23:43.214963 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00455802 (* 1 = 0.00455802 loss)
I1022 10:23:43.214969 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00448126 (* 1 = 0.00448126 loss)
I1022 10:23:43.214975 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.04623e-05 (* 1 = 8.04623e-05 loss)
I1022 10:23:43.214982 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.86515e-06 (* 1 = 7.86515e-06 loss)
I1022 10:23:43.214987 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00385077 (* 1 = 0.00385077 loss)
I1022 10:23:43.214993 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 9.8233e-05 (* 1 = 9.8233e-05 loss)
I1022 10:23:43.214999 25759 sgd_solver.cpp:106] Iteration 9520, lr = 0.002
I1022 10:25:09.668696 25759 solver.cpp:228] Iteration 9540, loss = 0.0447141
I1022 10:25:09.668750 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 10:25:09.668756 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:25:09.668766 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:25:09.668773 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:25:09.668779 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000368439 (* 1 = 0.000368439 loss)
I1022 10:25:09.668787 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00444144 (* 1 = 0.00444144 loss)
I1022 10:25:09.668792 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.21992e-05 (* 1 = 4.21992e-05 loss)
I1022 10:25:09.668799 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.36194e-06 (* 1 = 7.36194e-06 loss)
I1022 10:25:09.668805 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000474818 (* 1 = 0.000474818 loss)
I1022 10:25:09.668812 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000482117 (* 1 = 0.000482117 loss)
I1022 10:25:09.668836 25759 sgd_solver.cpp:106] Iteration 9540, lr = 0.002
I1022 10:26:35.293556 25759 solver.cpp:228] Iteration 9560, loss = 0.0590256
I1022 10:26:35.293624 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994382
I1022 10:26:35.293635 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994503
I1022 10:26:35.293653 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0529091 (* 1 = 0.0529091 loss)
I1022 10:26:35.293664 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0178653 (* 1 = 0.0178653 loss)
I1022 10:26:35.293674 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0107491 (* 1 = 0.0107491 loss)
I1022 10:26:35.293684 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0130248 (* 1 = 0.0130248 loss)
I1022 10:26:35.293695 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.82446e-05 (* 1 = 8.82446e-05 loss)
I1022 10:26:35.293709 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.1793e-06 (* 1 = 8.1793e-06 loss)
I1022 10:26:35.293730 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00377645 (* 1 = 0.00377645 loss)
I1022 10:26:35.293742 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00214637 (* 1 = 0.00214637 loss)
I1022 10:26:35.293756 25759 sgd_solver.cpp:106] Iteration 9560, lr = 0.002
I1022 10:28:00.968792 25759 solver.cpp:228] Iteration 9580, loss = 0.129812
I1022 10:28:00.968858 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 10:28:00.968869 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:28:00.968888 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0037965 (* 1 = 0.0037965 loss)
I1022 10:28:00.968915 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00197343 (* 1 = 0.00197343 loss)
I1022 10:28:00.968932 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00752615 (* 1 = 0.00752615 loss)
I1022 10:28:00.968951 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00443974 (* 1 = 0.00443974 loss)
I1022 10:28:00.968969 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.67232e-05 (* 1 = 3.67232e-05 loss)
I1022 10:28:00.968986 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.17854e-05 (* 1 = 4.17854e-05 loss)
I1022 10:28:00.968999 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0017283 (* 1 = 0.0017283 loss)
I1022 10:28:00.969013 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00408118 (* 1 = 0.00408118 loss)
I1022 10:28:00.969027 25759 sgd_solver.cpp:106] Iteration 9580, lr = 0.002
speed: 4.211s / iter
I1022 10:29:27.182188 25759 solver.cpp:228] Iteration 9600, loss = 0.0218716
I1022 10:29:27.182241 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999487
I1022 10:29:27.182248 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 10:29:27.182260 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00357954 (* 1 = 0.00357954 loss)
I1022 10:29:27.182267 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00604702 (* 1 = 0.00604702 loss)
I1022 10:29:27.182273 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00216016 (* 1 = 0.00216016 loss)
I1022 10:29:27.182279 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00581436 (* 1 = 0.00581436 loss)
I1022 10:29:27.182287 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.33819e-05 (* 1 = 4.33819e-05 loss)
I1022 10:29:27.182294 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.18664e-05 (* 1 = 1.18664e-05 loss)
I1022 10:29:27.182301 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00438137 (* 1 = 0.00438137 loss)
I1022 10:29:27.182312 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000117763 (* 1 = 0.000117763 loss)
I1022 10:29:27.182324 25759 sgd_solver.cpp:106] Iteration 9600, lr = 0.002
I1022 10:30:53.717387 25759 solver.cpp:228] Iteration 9620, loss = 0.125402
I1022 10:30:53.717442 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99898
I1022 10:30:53.717448 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 10:30:53.717458 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00878531 (* 1 = 0.00878531 loss)
I1022 10:30:53.717468 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00906645 (* 1 = 0.00906645 loss)
I1022 10:30:53.717473 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00313269 (* 1 = 0.00313269 loss)
I1022 10:30:53.717478 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00615093 (* 1 = 0.00615093 loss)
I1022 10:30:53.717484 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.67054e-05 (* 1 = 1.67054e-05 loss)
I1022 10:30:53.717491 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.9532e-06 (* 1 = 9.9532e-06 loss)
I1022 10:30:53.717496 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00218749 (* 1 = 0.00218749 loss)
I1022 10:30:53.717502 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00106182 (* 1 = 0.00106182 loss)
I1022 10:30:53.717510 25759 sgd_solver.cpp:106] Iteration 9620, lr = 0.002
I1022 10:32:16.979311 25759 solver.cpp:228] Iteration 9640, loss = 0.0795255
I1022 10:32:16.979383 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997367
I1022 10:32:16.979388 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 10:32:16.979398 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0113428 (* 1 = 0.0113428 loss)
I1022 10:32:16.979403 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00446057 (* 1 = 0.00446057 loss)
I1022 10:32:16.979406 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00607662 (* 1 = 0.00607662 loss)
I1022 10:32:16.979410 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00702637 (* 1 = 0.00702637 loss)
I1022 10:32:16.979414 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000274112 (* 1 = 0.000274112 loss)
I1022 10:32:16.979420 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.62204e-06 (* 1 = 7.62204e-06 loss)
I1022 10:32:16.979424 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00293302 (* 1 = 0.00293302 loss)
I1022 10:32:16.979429 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00278454 (* 1 = 0.00278454 loss)
I1022 10:32:16.979435 25759 sgd_solver.cpp:106] Iteration 9640, lr = 0.002
I1022 10:33:43.167826 25759 solver.cpp:228] Iteration 9660, loss = 0.193424
I1022 10:33:43.167876 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998385
I1022 10:33:43.167896 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 10:33:43.167910 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0115135 (* 1 = 0.0115135 loss)
I1022 10:33:43.167923 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00639067 (* 1 = 0.00639067 loss)
I1022 10:33:43.167933 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00658057 (* 1 = 0.00658057 loss)
I1022 10:33:43.167943 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00826316 (* 1 = 0.00826316 loss)
I1022 10:33:43.167958 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.95511e-05 (* 1 = 6.95511e-05 loss)
I1022 10:33:43.167970 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.62827e-05 (* 1 = 1.62827e-05 loss)
I1022 10:33:43.167981 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0144867 (* 1 = 0.0144867 loss)
I1022 10:33:43.167994 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00109835 (* 1 = 0.00109835 loss)
I1022 10:33:43.168006 25759 sgd_solver.cpp:106] Iteration 9660, lr = 0.002
I1022 10:35:08.887629 25759 solver.cpp:228] Iteration 9680, loss = 0.151929
I1022 10:35:08.887668 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 10:35:08.887676 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:35:08.887684 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:35:08.887691 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:35:08.887697 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00461006 (* 1 = 0.00461006 loss)
I1022 10:35:08.887704 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00460058 (* 1 = 0.00460058 loss)
I1022 10:35:08.887711 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.54872e-05 (* 1 = 3.54872e-05 loss)
I1022 10:35:08.887717 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.81717e-06 (* 1 = 7.81717e-06 loss)
I1022 10:35:08.887723 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00440144 (* 1 = 0.00440144 loss)
I1022 10:35:08.887730 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000590067 (* 1 = 0.000590067 loss)
I1022 10:35:08.887742 25759 sgd_solver.cpp:106] Iteration 9680, lr = 0.002
I1022 10:36:32.366461 25759 solver.cpp:228] Iteration 9700, loss = 0.0754763
I1022 10:36:32.366531 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995855
I1022 10:36:32.366539 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 10:36:32.366552 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0363174 (* 1 = 0.0363174 loss)
I1022 10:36:32.366561 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0116663 (* 1 = 0.0116663 loss)
I1022 10:36:32.366570 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00683786 (* 1 = 0.00683786 loss)
I1022 10:36:32.366578 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00973007 (* 1 = 0.00973007 loss)
I1022 10:36:32.366586 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.80315e-05 (* 1 = 7.80315e-05 loss)
I1022 10:36:32.366595 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.12712e-05 (* 1 = 1.12712e-05 loss)
I1022 10:36:32.366607 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.012269 (* 1 = 0.012269 loss)
I1022 10:36:32.366619 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000710348 (* 1 = 0.000710348 loss)
I1022 10:36:32.366628 25759 sgd_solver.cpp:106] Iteration 9700, lr = 0.002
I1022 10:37:54.119650 25759 solver.cpp:228] Iteration 9720, loss = 0.176785
I1022 10:37:54.119684 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 10:37:54.119688 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:37:54.119695 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:37:54.119699 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:37:54.119704 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000227367 (* 1 = 0.000227367 loss)
I1022 10:37:54.119709 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00407299 (* 1 = 0.00407299 loss)
I1022 10:37:54.119712 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.08117e-05 (* 1 = 5.08117e-05 loss)
I1022 10:37:54.119719 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.68669e-06 (* 1 = 8.68669e-06 loss)
I1022 10:37:54.119722 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000374766 (* 1 = 0.000374766 loss)
I1022 10:37:54.119726 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00162804 (* 1 = 0.00162804 loss)
I1022 10:37:54.119731 25759 sgd_solver.cpp:106] Iteration 9720, lr = 0.002
I1022 10:39:18.448710 25759 solver.cpp:228] Iteration 9740, loss = 0.0844902
I1022 10:39:18.448757 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994108
I1022 10:39:18.448763 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995511
I1022 10:39:18.448770 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0986428 (* 1 = 0.0986428 loss)
I1022 10:39:18.448776 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0754444 (* 1 = 0.0754444 loss)
I1022 10:39:18.448781 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0151115 (* 1 = 0.0151115 loss)
I1022 10:39:18.448784 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0227337 (* 1 = 0.0227337 loss)
I1022 10:39:18.448789 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000692635 (* 1 = 0.000692635 loss)
I1022 10:39:18.448794 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.03702e-06 (* 1 = 6.03702e-06 loss)
I1022 10:39:18.448799 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0489236 (* 1 = 0.0489236 loss)
I1022 10:39:18.448803 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000454747 (* 1 = 0.000454747 loss)
I1022 10:39:18.448809 25759 sgd_solver.cpp:106] Iteration 9740, lr = 0.002
I1022 10:40:43.215492 25759 solver.cpp:228] Iteration 9760, loss = 0.0274565
I1022 10:40:43.215530 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998957
I1022 10:40:43.215538 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:40:43.215546 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.025201 (* 1 = 0.025201 loss)
I1022 10:40:43.215553 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0034402 (* 1 = 0.0034402 loss)
I1022 10:40:43.215559 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00393766 (* 1 = 0.00393766 loss)
I1022 10:40:43.215567 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00456974 (* 1 = 0.00456974 loss)
I1022 10:40:43.215572 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000203314 (* 1 = 0.000203314 loss)
I1022 10:40:43.215579 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.23797e-05 (* 1 = 1.23797e-05 loss)
I1022 10:40:43.215584 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0159323 (* 1 = 0.0159323 loss)
I1022 10:40:43.215590 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000225357 (* 1 = 0.000225357 loss)
I1022 10:40:43.215597 25759 sgd_solver.cpp:106] Iteration 9760, lr = 0.002
I1022 10:42:06.847767 25759 solver.cpp:228] Iteration 9780, loss = 0.0469307
I1022 10:42:06.847805 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99834
I1022 10:42:06.847812 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 10:42:06.847821 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00388831 (* 1 = 0.00388831 loss)
I1022 10:42:06.847827 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00594271 (* 1 = 0.00594271 loss)
I1022 10:42:06.847833 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00565804 (* 1 = 0.00565804 loss)
I1022 10:42:06.847841 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00576007 (* 1 = 0.00576007 loss)
I1022 10:42:06.847846 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000393414 (* 1 = 0.000393414 loss)
I1022 10:42:06.847852 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.62763e-06 (* 1 = 8.62763e-06 loss)
I1022 10:42:06.847857 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00167839 (* 1 = 0.00167839 loss)
I1022 10:42:06.847863 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0060814 (* 1 = 0.0060814 loss)
I1022 10:42:06.847872 25759 sgd_solver.cpp:106] Iteration 9780, lr = 0.002
speed: 4.211s / iter
I1022 10:43:30.860265 25759 solver.cpp:228] Iteration 9800, loss = 0.146208
I1022 10:43:30.860311 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994217
I1022 10:43:30.860316 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1022 10:43:30.860327 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0552861 (* 1 = 0.0552861 loss)
I1022 10:43:30.860333 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0240436 (* 1 = 0.0240436 loss)
I1022 10:43:30.860339 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0168086 (* 1 = 0.0168086 loss)
I1022 10:43:30.860345 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0185648 (* 1 = 0.0185648 loss)
I1022 10:43:30.860352 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00408873 (* 1 = 0.00408873 loss)
I1022 10:43:30.860358 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.14374e-05 (* 1 = 1.14374e-05 loss)
I1022 10:43:30.860364 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0223398 (* 1 = 0.0223398 loss)
I1022 10:43:30.860370 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000255884 (* 1 = 0.000255884 loss)
I1022 10:43:30.860378 25759 sgd_solver.cpp:106] Iteration 9800, lr = 0.002
I1022 10:44:55.577381 25759 solver.cpp:228] Iteration 9820, loss = 0.0524162
I1022 10:44:55.577417 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 10:44:55.577421 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:44:55.577428 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:44:55.577432 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:44:55.577437 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00631119 (* 1 = 0.00631119 loss)
I1022 10:44:55.577441 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00592805 (* 1 = 0.00592805 loss)
I1022 10:44:55.577447 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.51074e-05 (* 1 = 8.51074e-05 loss)
I1022 10:44:55.577452 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.39984e-05 (* 1 = 1.39984e-05 loss)
I1022 10:44:55.577456 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00659874 (* 1 = 0.00659874 loss)
I1022 10:44:55.577461 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000171894 (* 1 = 0.000171894 loss)
I1022 10:44:55.577466 25759 sgd_solver.cpp:106] Iteration 9820, lr = 0.002
I1022 10:46:21.389659 25759 solver.cpp:228] Iteration 9840, loss = 0.134674
I1022 10:46:21.389698 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995507
I1022 10:46:21.389705 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997005
I1022 10:46:21.389715 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0312868 (* 1 = 0.0312868 loss)
I1022 10:46:21.389722 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0170555 (* 1 = 0.0170555 loss)
I1022 10:46:21.389729 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0226364 (* 1 = 0.0226364 loss)
I1022 10:46:21.389734 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0145966 (* 1 = 0.0145966 loss)
I1022 10:46:21.389740 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000128208 (* 1 = 0.000128208 loss)
I1022 10:46:21.389747 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.33787e-05 (* 1 = 1.33787e-05 loss)
I1022 10:46:21.389753 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0258538 (* 1 = 0.0258538 loss)
I1022 10:46:21.389760 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000499484 (* 1 = 0.000499484 loss)
I1022 10:46:21.389765 25759 sgd_solver.cpp:106] Iteration 9840, lr = 0.002
I1022 10:47:46.040141 25759 solver.cpp:228] Iteration 9860, loss = 0.16842
I1022 10:47:46.040180 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 10:47:46.040187 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:47:46.040196 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:47:46.040202 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:47:46.040210 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00412213 (* 1 = 0.00412213 loss)
I1022 10:47:46.040216 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00446791 (* 1 = 0.00446791 loss)
I1022 10:47:46.040223 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.78823e-05 (* 1 = 6.78823e-05 loss)
I1022 10:47:46.040230 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.06241e-05 (* 1 = 1.06241e-05 loss)
I1022 10:47:46.040236 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000553761 (* 1 = 0.000553761 loss)
I1022 10:47:46.040242 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0039287 (* 1 = 0.0039287 loss)
I1022 10:47:46.040249 25759 sgd_solver.cpp:106] Iteration 9860, lr = 0.002
I1022 10:49:11.084733 25759 solver.cpp:228] Iteration 9880, loss = 0.0528045
I1022 10:49:11.084781 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992817
I1022 10:49:11.084787 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 10:49:11.084798 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.023399 (* 1 = 0.023399 loss)
I1022 10:49:11.084805 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00896435 (* 1 = 0.00896435 loss)
I1022 10:49:11.084811 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0148105 (* 1 = 0.0148105 loss)
I1022 10:49:11.084817 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0159454 (* 1 = 0.0159454 loss)
I1022 10:49:11.084823 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000421307 (* 1 = 0.000421307 loss)
I1022 10:49:11.084830 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.9402e-06 (* 1 = 6.9402e-06 loss)
I1022 10:49:11.084836 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0158859 (* 1 = 0.0158859 loss)
I1022 10:49:11.084842 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000114147 (* 1 = 0.000114147 loss)
I1022 10:49:11.084854 25759 sgd_solver.cpp:106] Iteration 9880, lr = 0.002
I1022 10:50:35.961585 25759 solver.cpp:228] Iteration 9900, loss = 0.12736
I1022 10:50:35.961652 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996436
I1022 10:50:35.961658 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 10:50:35.961669 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00612004 (* 1 = 0.00612004 loss)
I1022 10:50:35.961676 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00195689 (* 1 = 0.00195689 loss)
I1022 10:50:35.961683 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00545889 (* 1 = 0.00545889 loss)
I1022 10:50:35.961688 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00452568 (* 1 = 0.00452568 loss)
I1022 10:50:35.961695 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000422371 (* 1 = 0.000422371 loss)
I1022 10:50:35.961702 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.42836e-06 (* 1 = 8.42836e-06 loss)
I1022 10:50:35.961709 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00572228 (* 1 = 0.00572228 loss)
I1022 10:50:35.961715 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00491185 (* 1 = 0.00491185 loss)
I1022 10:50:35.961730 25759 sgd_solver.cpp:106] Iteration 9900, lr = 0.002
I1022 10:52:02.318680 25759 solver.cpp:228] Iteration 9920, loss = 0.031433
I1022 10:52:02.318718 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 10:52:02.318732 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 10:52:02.318742 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 10:52:02.318747 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 10:52:02.318756 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000327831 (* 1 = 0.000327831 loss)
I1022 10:52:02.318763 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00458733 (* 1 = 0.00458733 loss)
I1022 10:52:02.318768 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.22897e-05 (* 1 = 7.22897e-05 loss)
I1022 10:52:02.318774 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.56052e-05 (* 1 = 1.56052e-05 loss)
I1022 10:52:02.318779 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00937639 (* 1 = 0.00937639 loss)
I1022 10:52:02.318785 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00326898 (* 1 = 0.00326898 loss)
I1022 10:52:02.318796 25759 sgd_solver.cpp:106] Iteration 9920, lr = 0.002
I1022 10:53:27.461680 25759 solver.cpp:228] Iteration 9940, loss = 0.0817151
I1022 10:53:27.461712 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999455
I1022 10:53:27.461717 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 10:53:27.461724 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0162319 (* 1 = 0.0162319 loss)
I1022 10:53:27.461730 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00693222 (* 1 = 0.00693222 loss)
I1022 10:53:27.461733 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00426378 (* 1 = 0.00426378 loss)
I1022 10:53:27.461737 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00677401 (* 1 = 0.00677401 loss)
I1022 10:53:27.461741 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000145823 (* 1 = 0.000145823 loss)
I1022 10:53:27.461746 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.69952e-05 (* 1 = 1.69952e-05 loss)
I1022 10:53:27.461750 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00643233 (* 1 = 0.00643233 loss)
I1022 10:53:27.461755 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00102667 (* 1 = 0.00102667 loss)
I1022 10:53:27.461760 25759 sgd_solver.cpp:106] Iteration 9940, lr = 0.002
I1022 10:54:50.709146 25759 solver.cpp:228] Iteration 9960, loss = 0.0825233
I1022 10:54:50.709180 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992997
I1022 10:54:50.709185 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996505
I1022 10:54:50.709192 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0740594 (* 1 = 0.0740594 loss)
I1022 10:54:50.709197 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0227983 (* 1 = 0.0227983 loss)
I1022 10:54:50.709216 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0149473 (* 1 = 0.0149473 loss)
I1022 10:54:50.709220 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0162583 (* 1 = 0.0162583 loss)
I1022 10:54:50.709225 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000388428 (* 1 = 0.000388428 loss)
I1022 10:54:50.709230 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.37641e-06 (* 1 = 9.37641e-06 loss)
I1022 10:54:50.709234 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0328019 (* 1 = 0.0328019 loss)
I1022 10:54:50.709239 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0050798 (* 1 = 0.0050798 loss)
I1022 10:54:50.709244 25759 sgd_solver.cpp:106] Iteration 9960, lr = 0.002
I1022 10:56:12.370105 25759 solver.cpp:228] Iteration 9980, loss = 0.101814
I1022 10:56:12.370167 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.979042
I1022 10:56:12.370172 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992526
I1022 10:56:12.370182 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.104646 (* 1 = 0.104646 loss)
I1022 10:56:12.370187 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0554286 (* 1 = 0.0554286 loss)
I1022 10:56:12.370191 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0571477 (* 1 = 0.0571477 loss)
I1022 10:56:12.370195 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0379841 (* 1 = 0.0379841 loss)
I1022 10:56:12.370200 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00935207 (* 1 = 0.00935207 loss)
I1022 10:56:12.370206 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.15838e-05 (* 1 = 1.15838e-05 loss)
I1022 10:56:12.370211 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.068925 (* 1 = 0.068925 loss)
I1022 10:56:12.370216 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000622886 (* 1 = 0.000622886 loss)
I1022 10:56:12.370223 25759 sgd_solver.cpp:106] Iteration 9980, lr = 0.002
speed: 4.211s / iter
bbbb
aaaa
Wrote snapshot to: /home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_10000.caffemodel
I1022 10:57:35.855315 25759 solver.cpp:228] Iteration 10000, loss = 0.0522308
I1022 10:57:35.855355 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 10:57:35.855360 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 10:57:35.855370 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0143407 (* 1 = 0.0143407 loss)
I1022 10:57:35.855376 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00472857 (* 1 = 0.00472857 loss)
I1022 10:57:35.855382 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0105919 (* 1 = 0.0105919 loss)
I1022 10:57:35.855387 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00933272 (* 1 = 0.00933272 loss)
I1022 10:57:35.855393 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000291578 (* 1 = 0.000291578 loss)
I1022 10:57:35.855399 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.56899e-06 (* 1 = 8.56899e-06 loss)
I1022 10:57:35.855406 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00865714 (* 1 = 0.00865714 loss)
I1022 10:57:35.855410 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00165266 (* 1 = 0.00165266 loss)
I1022 10:57:35.855417 25759 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 1
I1022 10:57:35.855420 25759 sgd_solver.cpp:106] Iteration 10000, lr = 0.0002
I1022 10:58:59.347280 25759 solver.cpp:228] Iteration 10020, loss = 0.0751032
I1022 10:58:59.347319 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998976
I1022 10:58:59.347326 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 10:58:59.347335 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00586632 (* 1 = 0.00586632 loss)
I1022 10:58:59.347342 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0129014 (* 1 = 0.0129014 loss)
I1022 10:58:59.347347 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00440888 (* 1 = 0.00440888 loss)
I1022 10:58:59.347353 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00754034 (* 1 = 0.00754034 loss)
I1022 10:58:59.347359 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000151682 (* 1 = 0.000151682 loss)
I1022 10:58:59.347365 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.51545e-05 (* 1 = 1.51545e-05 loss)
I1022 10:58:59.347371 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0113307 (* 1 = 0.0113307 loss)
I1022 10:58:59.347378 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000470219 (* 1 = 0.000470219 loss)
I1022 10:58:59.347388 25759 sgd_solver.cpp:106] Iteration 10020, lr = 0.0002
I1022 11:00:25.634053 25759 solver.cpp:228] Iteration 10040, loss = 0.0809402
I1022 11:00:25.634136 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997937
I1022 11:00:25.634146 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 11:00:25.634163 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00767428 (* 1 = 0.00767428 loss)
I1022 11:00:25.634176 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0105369 (* 1 = 0.0105369 loss)
I1022 11:00:25.634186 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00689404 (* 1 = 0.00689404 loss)
I1022 11:00:25.634198 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00728782 (* 1 = 0.00728782 loss)
I1022 11:00:25.634212 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.90674e-05 (* 1 = 3.90674e-05 loss)
I1022 11:00:25.634224 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.49802e-05 (* 1 = 1.49802e-05 loss)
I1022 11:00:25.634241 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00438717 (* 1 = 0.00438717 loss)
I1022 11:00:25.634253 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000244449 (* 1 = 0.000244449 loss)
I1022 11:00:25.634268 25759 sgd_solver.cpp:106] Iteration 10040, lr = 0.0002
I1022 11:01:51.300962 25759 solver.cpp:228] Iteration 10060, loss = 0.0578719
I1022 11:01:51.301000 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998373
I1022 11:01:51.301007 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 11:01:51.301017 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00739275 (* 1 = 0.00739275 loss)
I1022 11:01:51.301023 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00292257 (* 1 = 0.00292257 loss)
I1022 11:01:51.301028 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00451298 (* 1 = 0.00451298 loss)
I1022 11:01:51.301035 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00505439 (* 1 = 0.00505439 loss)
I1022 11:01:51.301041 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.83296e-05 (* 1 = 6.83296e-05 loss)
I1022 11:01:51.301046 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.66543e-06 (* 1 = 8.66543e-06 loss)
I1022 11:01:51.301053 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00646271 (* 1 = 0.00646271 loss)
I1022 11:01:51.301059 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000776131 (* 1 = 0.000776131 loss)
I1022 11:01:51.301065 25759 sgd_solver.cpp:106] Iteration 10060, lr = 0.0002
I1022 11:03:15.676292 25759 solver.cpp:228] Iteration 10080, loss = 0.102356
I1022 11:03:15.676329 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9952
I1022 11:03:15.676335 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999001
I1022 11:03:15.676345 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0141314 (* 1 = 0.0141314 loss)
I1022 11:03:15.676352 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00410223 (* 1 = 0.00410223 loss)
I1022 11:03:15.676357 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00906347 (* 1 = 0.00906347 loss)
I1022 11:03:15.676364 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00886881 (* 1 = 0.00886881 loss)
I1022 11:03:15.676370 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000103126 (* 1 = 0.000103126 loss)
I1022 11:03:15.676376 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.47128e-05 (* 1 = 1.47128e-05 loss)
I1022 11:03:15.676381 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00326856 (* 1 = 0.00326856 loss)
I1022 11:03:15.676388 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000115192 (* 1 = 0.000115192 loss)
I1022 11:03:15.676394 25759 sgd_solver.cpp:106] Iteration 10080, lr = 0.0002
I1022 11:04:40.041321 25759 solver.cpp:228] Iteration 10100, loss = 0.0683816
I1022 11:04:40.041375 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:04:40.041383 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:04:40.041391 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:04:40.041399 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:04:40.041404 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000338012 (* 1 = 0.000338012 loss)
I1022 11:04:40.041411 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00418922 (* 1 = 0.00418922 loss)
I1022 11:04:40.041419 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.18451e-05 (* 1 = 4.18451e-05 loss)
I1022 11:04:40.041424 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.30441e-06 (* 1 = 8.30441e-06 loss)
I1022 11:04:40.041431 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00135278 (* 1 = 0.00135278 loss)
I1022 11:04:40.041438 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.27119e-05 (* 1 = 2.27119e-05 loss)
I1022 11:04:40.041450 25759 sgd_solver.cpp:106] Iteration 10100, lr = 0.0002
I1022 11:06:05.458416 25759 solver.cpp:228] Iteration 10120, loss = 0.0339155
I1022 11:06:05.458482 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 11:06:05.458490 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:06:05.458503 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00597236 (* 1 = 0.00597236 loss)
I1022 11:06:05.458509 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000320497 (* 1 = 0.000320497 loss)
I1022 11:06:05.458516 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0071916 (* 1 = 0.0071916 loss)
I1022 11:06:05.458523 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00449196 (* 1 = 0.00449196 loss)
I1022 11:06:05.458531 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.50962e-05 (* 1 = 5.50962e-05 loss)
I1022 11:06:05.458539 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.09157e-06 (* 1 = 6.09157e-06 loss)
I1022 11:06:05.458545 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00229667 (* 1 = 0.00229667 loss)
I1022 11:06:05.458552 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000224253 (* 1 = 0.000224253 loss)
I1022 11:06:05.458562 25759 sgd_solver.cpp:106] Iteration 10120, lr = 0.0002
I1022 11:07:29.697621 25759 solver.cpp:228] Iteration 10140, loss = 0.0352085
I1022 11:07:29.697679 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999492
I1022 11:07:29.697685 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 11:07:29.697692 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0148013 (* 1 = 0.0148013 loss)
I1022 11:07:29.697697 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00704816 (* 1 = 0.00704816 loss)
I1022 11:07:29.697702 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00271066 (* 1 = 0.00271066 loss)
I1022 11:07:29.697707 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00631523 (* 1 = 0.00631523 loss)
I1022 11:07:29.697712 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.47881e-05 (* 1 = 8.47881e-05 loss)
I1022 11:07:29.697717 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.12117e-06 (* 1 = 6.12117e-06 loss)
I1022 11:07:29.697722 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00484482 (* 1 = 0.00484482 loss)
I1022 11:07:29.697727 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0011285 (* 1 = 0.0011285 loss)
I1022 11:07:29.697739 25759 sgd_solver.cpp:106] Iteration 10140, lr = 0.0002
I1022 11:08:54.182840 25759 solver.cpp:228] Iteration 10160, loss = 0.0604036
I1022 11:08:54.182878 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 11:08:54.182884 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:08:54.182893 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:08:54.182899 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:08:54.182905 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00435579 (* 1 = 0.00435579 loss)
I1022 11:08:54.182914 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00426745 (* 1 = 0.00426745 loss)
I1022 11:08:54.182922 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.5301e-05 (* 1 = 4.5301e-05 loss)
I1022 11:08:54.182930 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.63465e-06 (* 1 = 6.63465e-06 loss)
I1022 11:08:54.182937 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 6.40649e-05 (* 1 = 6.40649e-05 loss)
I1022 11:08:54.182945 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 3.98557e-05 (* 1 = 3.98557e-05 loss)
I1022 11:08:54.182958 25759 sgd_solver.cpp:106] Iteration 10160, lr = 0.0002
I1022 11:10:16.128159 25759 solver.cpp:228] Iteration 10180, loss = 0.0659673
I1022 11:10:16.128231 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991901
I1022 11:10:16.128235 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 11:10:16.128244 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0185698 (* 1 = 0.0185698 loss)
I1022 11:10:16.128250 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0173293 (* 1 = 0.0173293 loss)
I1022 11:10:16.128255 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0152216 (* 1 = 0.0152216 loss)
I1022 11:10:16.128259 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0130445 (* 1 = 0.0130445 loss)
I1022 11:10:16.128265 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000210848 (* 1 = 0.000210848 loss)
I1022 11:10:16.128270 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.67969e-06 (* 1 = 7.67969e-06 loss)
I1022 11:10:16.128275 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0102804 (* 1 = 0.0102804 loss)
I1022 11:10:16.128280 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000781557 (* 1 = 0.000781557 loss)
I1022 11:10:16.128293 25759 sgd_solver.cpp:106] Iteration 10180, lr = 0.0002
speed: 4.211s / iter
I1022 11:11:38.586508 25759 solver.cpp:228] Iteration 10200, loss = 0.19102
I1022 11:11:38.586545 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.969409
I1022 11:11:38.586551 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.976155
I1022 11:11:38.586560 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.160934 (* 1 = 0.160934 loss)
I1022 11:11:38.586566 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.18013 (* 1 = 0.18013 loss)
I1022 11:11:38.586572 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0787395 (* 1 = 0.0787395 loss)
I1022 11:11:38.586580 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0819269 (* 1 = 0.0819269 loss)
I1022 11:11:38.586586 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00303151 (* 1 = 0.00303151 loss)
I1022 11:11:38.586592 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.07599e-05 (* 1 = 2.07599e-05 loss)
I1022 11:11:38.586598 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.089367 (* 1 = 0.089367 loss)
I1022 11:11:38.586604 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000187489 (* 1 = 0.000187489 loss)
I1022 11:11:38.586616 25759 sgd_solver.cpp:106] Iteration 10200, lr = 0.0002
I1022 11:13:01.409624 25759 solver.cpp:228] Iteration 10220, loss = 0.0450579
I1022 11:13:01.409670 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996466
I1022 11:13:01.409677 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 11:13:01.409687 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0125183 (* 1 = 0.0125183 loss)
I1022 11:13:01.409693 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0110824 (* 1 = 0.0110824 loss)
I1022 11:13:01.409698 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0101783 (* 1 = 0.0101783 loss)
I1022 11:13:01.409704 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0127314 (* 1 = 0.0127314 loss)
I1022 11:13:01.409711 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000280052 (* 1 = 0.000280052 loss)
I1022 11:13:01.409718 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.40444e-05 (* 1 = 1.40444e-05 loss)
I1022 11:13:01.409723 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0181834 (* 1 = 0.0181834 loss)
I1022 11:13:01.409729 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000133761 (* 1 = 0.000133761 loss)
I1022 11:13:01.409741 25759 sgd_solver.cpp:106] Iteration 10220, lr = 0.0002
I1022 11:14:26.372242 25759 solver.cpp:228] Iteration 10240, loss = 0.037219
I1022 11:14:26.372275 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:14:26.372280 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:14:26.372287 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:14:26.372292 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:14:26.372297 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000307329 (* 1 = 0.000307329 loss)
I1022 11:14:26.372301 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00431831 (* 1 = 0.00431831 loss)
I1022 11:14:26.372305 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.20435e-05 (* 1 = 2.20435e-05 loss)
I1022 11:14:26.372310 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.43344e-06 (* 1 = 6.43344e-06 loss)
I1022 11:14:26.372313 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 9.93523e-05 (* 1 = 9.93523e-05 loss)
I1022 11:14:26.372318 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000105484 (* 1 = 0.000105484 loss)
I1022 11:14:26.372323 25759 sgd_solver.cpp:106] Iteration 10240, lr = 0.0002
I1022 11:15:52.304024 25759 solver.cpp:228] Iteration 10260, loss = 0.181421
I1022 11:15:52.304072 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:15:52.304082 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:15:52.304095 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:15:52.304105 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:15:52.304113 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000187543 (* 1 = 0.000187543 loss)
I1022 11:15:52.304122 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00399598 (* 1 = 0.00399598 loss)
I1022 11:15:52.304132 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.56295e-05 (* 1 = 5.56295e-05 loss)
I1022 11:15:52.304153 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.74954e-05 (* 1 = 1.74954e-05 loss)
I1022 11:15:52.304164 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000463177 (* 1 = 0.000463177 loss)
I1022 11:15:52.304173 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 3.49653e-05 (* 1 = 3.49653e-05 loss)
I1022 11:15:52.304185 25759 sgd_solver.cpp:106] Iteration 10260, lr = 0.0002
I1022 11:17:14.970378 25759 solver.cpp:228] Iteration 10280, loss = 0.0625178
I1022 11:17:14.970429 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995385
I1022 11:17:14.970434 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 11:17:14.970443 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0139845 (* 1 = 0.0139845 loss)
I1022 11:17:14.970450 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0141653 (* 1 = 0.0141653 loss)
I1022 11:17:14.970454 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0110423 (* 1 = 0.0110423 loss)
I1022 11:17:14.970458 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0146029 (* 1 = 0.0146029 loss)
I1022 11:17:14.970463 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000522643 (* 1 = 0.000522643 loss)
I1022 11:17:14.970468 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.66158e-05 (* 1 = 1.66158e-05 loss)
I1022 11:17:14.970474 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0136836 (* 1 = 0.0136836 loss)
I1022 11:17:14.970479 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.03279e-05 (* 1 = 4.03279e-05 loss)
I1022 11:17:14.970484 25759 sgd_solver.cpp:106] Iteration 10280, lr = 0.0002
I1022 11:18:37.973139 25759 solver.cpp:228] Iteration 10300, loss = 0.0835368
I1022 11:18:37.973170 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994947
I1022 11:18:37.973176 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99301
I1022 11:18:37.973183 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0454632 (* 1 = 0.0454632 loss)
I1022 11:18:37.973187 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0466023 (* 1 = 0.0466023 loss)
I1022 11:18:37.973191 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0149441 (* 1 = 0.0149441 loss)
I1022 11:18:37.973196 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0242918 (* 1 = 0.0242918 loss)
I1022 11:18:37.973201 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000927894 (* 1 = 0.000927894 loss)
I1022 11:18:37.973204 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.40552e-06 (* 1 = 8.40552e-06 loss)
I1022 11:18:37.973208 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0314226 (* 1 = 0.0314226 loss)
I1022 11:18:37.973212 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000550287 (* 1 = 0.000550287 loss)
I1022 11:18:37.973217 25759 sgd_solver.cpp:106] Iteration 10300, lr = 0.0002
I1022 11:20:00.886798 25759 solver.cpp:228] Iteration 10320, loss = 0.0590333
I1022 11:20:00.886831 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994742
I1022 11:20:00.886835 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994505
I1022 11:20:00.886843 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00786141 (* 1 = 0.00786141 loss)
I1022 11:20:00.886847 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0171241 (* 1 = 0.0171241 loss)
I1022 11:20:00.886852 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0129345 (* 1 = 0.0129345 loss)
I1022 11:20:00.886855 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0188834 (* 1 = 0.0188834 loss)
I1022 11:20:00.886859 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000228005 (* 1 = 0.000228005 loss)
I1022 11:20:00.886864 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.24817e-05 (* 1 = 1.24817e-05 loss)
I1022 11:20:00.886868 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0112743 (* 1 = 0.0112743 loss)
I1022 11:20:00.886873 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000110842 (* 1 = 0.000110842 loss)
I1022 11:20:00.886881 25759 sgd_solver.cpp:106] Iteration 10320, lr = 0.0002
I1022 11:21:22.009434 25759 solver.cpp:228] Iteration 10340, loss = 0.0617581
I1022 11:21:22.009474 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993225
I1022 11:21:22.009480 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993506
I1022 11:21:22.009490 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.02973 (* 1 = 0.02973 loss)
I1022 11:21:22.009496 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0322635 (* 1 = 0.0322635 loss)
I1022 11:21:22.009501 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0194899 (* 1 = 0.0194899 loss)
I1022 11:21:22.009507 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.024072 (* 1 = 0.024072 loss)
I1022 11:21:22.009513 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00370307 (* 1 = 0.00370307 loss)
I1022 11:21:22.009519 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.96175e-05 (* 1 = 2.96175e-05 loss)
I1022 11:21:22.009526 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0911346 (* 1 = 0.0911346 loss)
I1022 11:21:22.009531 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000197602 (* 1 = 0.000197602 loss)
I1022 11:21:22.009539 25759 sgd_solver.cpp:106] Iteration 10340, lr = 0.0002
I1022 11:22:41.821606 25759 solver.cpp:228] Iteration 10360, loss = 0.0507598
I1022 11:22:41.821653 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995313
I1022 11:22:41.821660 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 11:22:41.821666 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00607551 (* 1 = 0.00607551 loss)
I1022 11:22:41.821671 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00527641 (* 1 = 0.00527641 loss)
I1022 11:22:41.821676 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00759619 (* 1 = 0.00759619 loss)
I1022 11:22:41.821679 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00989992 (* 1 = 0.00989992 loss)
I1022 11:22:41.821684 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000277065 (* 1 = 0.000277065 loss)
I1022 11:22:41.821689 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.12426e-05 (* 1 = 1.12426e-05 loss)
I1022 11:22:41.821693 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0089806 (* 1 = 0.0089806 loss)
I1022 11:22:41.821698 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000301169 (* 1 = 0.000301169 loss)
I1022 11:22:41.821705 25759 sgd_solver.cpp:106] Iteration 10360, lr = 0.0002
I1022 11:24:03.950844 25759 solver.cpp:228] Iteration 10380, loss = 0.0465956
I1022 11:24:03.950893 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993007
I1022 11:24:03.950904 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 11:24:03.950919 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0143151 (* 1 = 0.0143151 loss)
I1022 11:24:03.950932 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00745407 (* 1 = 0.00745407 loss)
I1022 11:24:03.950942 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0238984 (* 1 = 0.0238984 loss)
I1022 11:24:03.950950 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0119619 (* 1 = 0.0119619 loss)
I1022 11:24:03.950961 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000542996 (* 1 = 0.000542996 loss)
I1022 11:24:03.950970 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.78521e-05 (* 1 = 1.78521e-05 loss)
I1022 11:24:03.950980 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0159172 (* 1 = 0.0159172 loss)
I1022 11:24:03.950994 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.26463e-05 (* 1 = 2.26463e-05 loss)
I1022 11:24:03.951005 25759 sgd_solver.cpp:106] Iteration 10380, lr = 0.0002
speed: 4.210s / iter
I1022 11:25:28.629593 25759 solver.cpp:228] Iteration 10400, loss = 0.0557825
I1022 11:25:28.629632 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996967
I1022 11:25:28.629638 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 11:25:28.629648 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0206448 (* 1 = 0.0206448 loss)
I1022 11:25:28.629654 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0149854 (* 1 = 0.0149854 loss)
I1022 11:25:28.629659 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00840208 (* 1 = 0.00840208 loss)
I1022 11:25:28.629667 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0123194 (* 1 = 0.0123194 loss)
I1022 11:25:28.629673 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.27546e-05 (* 1 = 5.27546e-05 loss)
I1022 11:25:28.629678 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.20333e-05 (* 1 = 1.20333e-05 loss)
I1022 11:25:28.629683 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00746219 (* 1 = 0.00746219 loss)
I1022 11:25:28.629689 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 9.1016e-06 (* 1 = 9.1016e-06 loss)
I1022 11:25:28.629698 25759 sgd_solver.cpp:106] Iteration 10400, lr = 0.0002
I1022 11:26:54.961236 25759 solver.cpp:228] Iteration 10420, loss = 0.0250662
I1022 11:26:54.961304 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:26:54.961316 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:26:54.961333 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:26:54.961341 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:26:54.961352 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000267223 (* 1 = 0.000267223 loss)
I1022 11:26:54.961364 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00458607 (* 1 = 0.00458607 loss)
I1022 11:26:54.961385 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000147268 (* 1 = 0.000147268 loss)
I1022 11:26:54.961397 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.56088e-05 (* 1 = 1.56088e-05 loss)
I1022 11:26:54.961410 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00176599 (* 1 = 0.00176599 loss)
I1022 11:26:54.961421 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.52773e-05 (* 1 = 4.52773e-05 loss)
I1022 11:26:54.961436 25759 sgd_solver.cpp:106] Iteration 10420, lr = 0.0002
I1022 11:28:17.787660 25759 solver.cpp:228] Iteration 10440, loss = 0.0504284
I1022 11:28:17.787719 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996352
I1022 11:28:17.787724 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 11:28:17.787732 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00994425 (* 1 = 0.00994425 loss)
I1022 11:28:17.787739 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00145244 (* 1 = 0.00145244 loss)
I1022 11:28:17.787744 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00875455 (* 1 = 0.00875455 loss)
I1022 11:28:17.787748 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0050557 (* 1 = 0.0050557 loss)
I1022 11:28:17.787755 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.9256e-05 (* 1 = 8.9256e-05 loss)
I1022 11:28:17.787758 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.69324e-06 (* 1 = 8.69324e-06 loss)
I1022 11:28:17.787763 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00570755 (* 1 = 0.00570755 loss)
I1022 11:28:17.787768 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000118962 (* 1 = 0.000118962 loss)
I1022 11:28:17.787775 25759 sgd_solver.cpp:106] Iteration 10440, lr = 0.0002
I1022 11:29:42.958864 25759 solver.cpp:228] Iteration 10460, loss = 0.0589044
I1022 11:29:42.958902 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99203
I1022 11:29:42.958919 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996006
I1022 11:29:42.958928 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.025495 (* 1 = 0.025495 loss)
I1022 11:29:42.958935 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0153551 (* 1 = 0.0153551 loss)
I1022 11:29:42.958941 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0182017 (* 1 = 0.0182017 loss)
I1022 11:29:42.958946 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0174468 (* 1 = 0.0174468 loss)
I1022 11:29:42.958953 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000165993 (* 1 = 0.000165993 loss)
I1022 11:29:42.958959 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.37519e-05 (* 1 = 1.37519e-05 loss)
I1022 11:29:42.958966 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0136685 (* 1 = 0.0136685 loss)
I1022 11:29:42.958972 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000433353 (* 1 = 0.000433353 loss)
I1022 11:29:42.958983 25759 sgd_solver.cpp:106] Iteration 10460, lr = 0.0002
I1022 11:31:08.684872 25759 solver.cpp:228] Iteration 10480, loss = 0.0412991
I1022 11:31:08.684911 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995377
I1022 11:31:08.684918 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993506
I1022 11:31:08.684927 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0364651 (* 1 = 0.0364651 loss)
I1022 11:31:08.684934 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0169999 (* 1 = 0.0169999 loss)
I1022 11:31:08.684939 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.012425 (* 1 = 0.012425 loss)
I1022 11:31:08.684945 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0184639 (* 1 = 0.0184639 loss)
I1022 11:31:08.684952 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000807299 (* 1 = 0.000807299 loss)
I1022 11:31:08.684957 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.5917e-05 (* 1 = 1.5917e-05 loss)
I1022 11:31:08.684962 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0263995 (* 1 = 0.0263995 loss)
I1022 11:31:08.684968 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000124781 (* 1 = 0.000124781 loss)
I1022 11:31:08.684976 25759 sgd_solver.cpp:106] Iteration 10480, lr = 0.0002
I1022 11:32:32.044113 25759 solver.cpp:228] Iteration 10500, loss = 0.161461
I1022 11:32:32.044152 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:32:32.044159 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:32:32.044168 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:32:32.044174 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:32:32.044180 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000230415 (* 1 = 0.000230415 loss)
I1022 11:32:32.044186 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00436425 (* 1 = 0.00436425 loss)
I1022 11:32:32.044193 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000431208 (* 1 = 0.000431208 loss)
I1022 11:32:32.044199 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.58154e-05 (* 1 = 1.58154e-05 loss)
I1022 11:32:32.044205 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00165523 (* 1 = 0.00165523 loss)
I1022 11:32:32.044211 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 8.01099e-05 (* 1 = 8.01099e-05 loss)
I1022 11:32:32.044219 25759 sgd_solver.cpp:106] Iteration 10500, lr = 0.0002
I1022 11:33:57.154343 25759 solver.cpp:228] Iteration 10520, loss = 0.0535476
I1022 11:33:57.154419 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.987554
I1022 11:33:57.154430 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994003
I1022 11:33:57.154446 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0118104 (* 1 = 0.0118104 loss)
I1022 11:33:57.154459 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0045271 (* 1 = 0.0045271 loss)
I1022 11:33:57.154477 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0301941 (* 1 = 0.0301941 loss)
I1022 11:33:57.154489 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0117622 (* 1 = 0.0117622 loss)
I1022 11:33:57.154503 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.87957e-05 (* 1 = 2.87957e-05 loss)
I1022 11:33:57.154516 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.42381e-05 (* 1 = 2.42381e-05 loss)
I1022 11:33:57.154528 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000660905 (* 1 = 0.000660905 loss)
I1022 11:33:57.154541 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000467511 (* 1 = 0.000467511 loss)
I1022 11:33:57.154554 25759 sgd_solver.cpp:106] Iteration 10520, lr = 0.0002
I1022 11:35:19.852428 25759 solver.cpp:228] Iteration 10540, loss = 0.0548263
I1022 11:35:19.852480 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:35:19.852485 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:35:19.852493 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:35:19.852497 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:35:19.852502 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000247349 (* 1 = 0.000247349 loss)
I1022 11:35:19.852507 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0045475 (* 1 = 0.0045475 loss)
I1022 11:35:19.852511 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.63446e-05 (* 1 = 9.63446e-05 loss)
I1022 11:35:19.852516 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.3893e-05 (* 1 = 1.3893e-05 loss)
I1022 11:35:19.852520 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000108958 (* 1 = 0.000108958 loss)
I1022 11:35:19.852525 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00049342 (* 1 = 0.00049342 loss)
I1022 11:35:19.852531 25759 sgd_solver.cpp:106] Iteration 10540, lr = 0.0002
I1022 11:36:46.210273 25759 solver.cpp:228] Iteration 10560, loss = 0.0546754
I1022 11:36:46.210336 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998387
I1022 11:36:46.210346 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 11:36:46.210361 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00523269 (* 1 = 0.00523269 loss)
I1022 11:36:46.210371 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00458052 (* 1 = 0.00458052 loss)
I1022 11:36:46.210379 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00559163 (* 1 = 0.00559163 loss)
I1022 11:36:46.210388 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00876338 (* 1 = 0.00876338 loss)
I1022 11:36:46.210398 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000397446 (* 1 = 0.000397446 loss)
I1022 11:36:46.210408 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.99043e-05 (* 1 = 1.99043e-05 loss)
I1022 11:36:46.210417 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0118648 (* 1 = 0.0118648 loss)
I1022 11:36:46.210433 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000230032 (* 1 = 0.000230032 loss)
I1022 11:36:46.210444 25759 sgd_solver.cpp:106] Iteration 10560, lr = 0.0002
I1022 11:38:10.978653 25759 solver.cpp:228] Iteration 10580, loss = 0.0931132
I1022 11:38:10.978687 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995005
I1022 11:38:10.978691 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995504
I1022 11:38:10.978698 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00853103 (* 1 = 0.00853103 loss)
I1022 11:38:10.978703 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0141875 (* 1 = 0.0141875 loss)
I1022 11:38:10.978706 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.020356 (* 1 = 0.020356 loss)
I1022 11:38:10.978710 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0188437 (* 1 = 0.0188437 loss)
I1022 11:38:10.978715 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000386261 (* 1 = 0.000386261 loss)
I1022 11:38:10.978719 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.61232e-05 (* 1 = 1.61232e-05 loss)
I1022 11:38:10.978724 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0156151 (* 1 = 0.0156151 loss)
I1022 11:38:10.978727 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 8.62695e-05 (* 1 = 8.62695e-05 loss)
I1022 11:38:10.978734 25759 sgd_solver.cpp:106] Iteration 10580, lr = 0.0002
speed: 4.210s / iter
I1022 11:39:36.046607 25759 solver.cpp:228] Iteration 10600, loss = 0.0819287
I1022 11:39:36.046679 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.987026
I1022 11:39:36.046691 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996008
I1022 11:39:36.046708 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0281438 (* 1 = 0.0281438 loss)
I1022 11:39:36.046720 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.015431 (* 1 = 0.015431 loss)
I1022 11:39:36.046733 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0364246 (* 1 = 0.0364246 loss)
I1022 11:39:36.046746 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0245436 (* 1 = 0.0245436 loss)
I1022 11:39:36.046761 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00058903 (* 1 = 0.00058903 loss)
I1022 11:39:36.046773 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.42508e-05 (* 1 = 3.42508e-05 loss)
I1022 11:39:36.046787 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0251078 (* 1 = 0.0251078 loss)
I1022 11:39:36.046799 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000348596 (* 1 = 0.000348596 loss)
I1022 11:39:36.046813 25759 sgd_solver.cpp:106] Iteration 10600, lr = 0.0002
I1022 11:41:01.190799 25759 solver.cpp:228] Iteration 10620, loss = 0.0393068
I1022 11:41:01.190865 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99406
I1022 11:41:01.190871 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 11:41:01.190899 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.031603 (* 1 = 0.031603 loss)
I1022 11:41:01.190904 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.019349 (* 1 = 0.019349 loss)
I1022 11:41:01.190909 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0114676 (* 1 = 0.0114676 loss)
I1022 11:41:01.190913 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0126852 (* 1 = 0.0126852 loss)
I1022 11:41:01.190919 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0001066 (* 1 = 0.0001066 loss)
I1022 11:41:01.190924 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.13041e-05 (* 1 = 1.13041e-05 loss)
I1022 11:41:01.190929 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0094886 (* 1 = 0.0094886 loss)
I1022 11:41:01.190934 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000740059 (* 1 = 0.000740059 loss)
I1022 11:41:01.190942 25759 sgd_solver.cpp:106] Iteration 10620, lr = 0.0002
I1022 11:42:26.763890 25759 solver.cpp:228] Iteration 10640, loss = 0.0988032
I1022 11:42:26.763939 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99531
I1022 11:42:26.763945 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 11:42:26.763953 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0183798 (* 1 = 0.0183798 loss)
I1022 11:42:26.763957 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0117351 (* 1 = 0.0117351 loss)
I1022 11:42:26.763962 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.010612 (* 1 = 0.010612 loss)
I1022 11:42:26.763965 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0108398 (* 1 = 0.0108398 loss)
I1022 11:42:26.763970 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.6094e-05 (* 1 = 6.6094e-05 loss)
I1022 11:42:26.763975 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.74997e-05 (* 1 = 1.74997e-05 loss)
I1022 11:42:26.763980 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0130543 (* 1 = 0.0130543 loss)
I1022 11:42:26.763984 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00021976 (* 1 = 0.00021976 loss)
I1022 11:42:26.763991 25759 sgd_solver.cpp:106] Iteration 10640, lr = 0.0002
I1022 11:43:52.178222 25759 solver.cpp:228] Iteration 10660, loss = 0.0927162
I1022 11:43:52.178294 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.986584
I1022 11:43:52.178304 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992515
I1022 11:43:52.178321 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.109478 (* 1 = 0.109478 loss)
I1022 11:43:52.178333 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.114292 (* 1 = 0.114292 loss)
I1022 11:43:52.178342 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0312904 (* 1 = 0.0312904 loss)
I1022 11:43:52.178352 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0279176 (* 1 = 0.0279176 loss)
I1022 11:43:52.178369 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000684057 (* 1 = 0.000684057 loss)
I1022 11:43:52.178380 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.95661e-05 (* 1 = 2.95661e-05 loss)
I1022 11:43:52.178393 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.026915 (* 1 = 0.026915 loss)
I1022 11:43:52.178406 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.28079e-05 (* 1 = 6.28079e-05 loss)
I1022 11:43:52.178419 25759 sgd_solver.cpp:106] Iteration 10660, lr = 0.0002
I1022 11:45:15.107908 25759 solver.cpp:228] Iteration 10680, loss = 0.0294389
I1022 11:45:15.107941 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:45:15.107946 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:45:15.107954 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:45:15.107959 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:45:15.107962 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000593899 (* 1 = 0.000593899 loss)
I1022 11:45:15.107967 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00439 (* 1 = 0.00439 loss)
I1022 11:45:15.107972 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.18973e-05 (* 1 = 6.18973e-05 loss)
I1022 11:45:15.107977 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.35503e-06 (* 1 = 6.35503e-06 loss)
I1022 11:45:15.107981 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000107223 (* 1 = 0.000107223 loss)
I1022 11:45:15.107986 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 9.39775e-05 (* 1 = 9.39775e-05 loss)
I1022 11:45:15.107995 25759 sgd_solver.cpp:106] Iteration 10680, lr = 0.0002
I1022 11:46:41.224489 25759 solver.cpp:228] Iteration 10700, loss = 0.0835602
I1022 11:46:41.224529 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.990176
I1022 11:46:41.224536 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998502
I1022 11:46:41.224546 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0224812 (* 1 = 0.0224812 loss)
I1022 11:46:41.224553 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.008328 (* 1 = 0.008328 loss)
I1022 11:46:41.224560 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0182505 (* 1 = 0.0182505 loss)
I1022 11:46:41.224565 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0138266 (* 1 = 0.0138266 loss)
I1022 11:46:41.224572 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000157052 (* 1 = 0.000157052 loss)
I1022 11:46:41.224578 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.34495e-05 (* 1 = 1.34495e-05 loss)
I1022 11:46:41.224584 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0118344 (* 1 = 0.0118344 loss)
I1022 11:46:41.224591 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000650394 (* 1 = 0.000650394 loss)
I1022 11:46:41.224614 25759 sgd_solver.cpp:106] Iteration 10700, lr = 0.0002
I1022 11:48:06.733912 25759 solver.cpp:228] Iteration 10720, loss = 0.0272653
I1022 11:48:06.733956 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996247
I1022 11:48:06.733964 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997503
I1022 11:48:06.733975 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.027881 (* 1 = 0.027881 loss)
I1022 11:48:06.733983 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0121963 (* 1 = 0.0121963 loss)
I1022 11:48:06.733989 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0105183 (* 1 = 0.0105183 loss)
I1022 11:48:06.733995 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0109381 (* 1 = 0.0109381 loss)
I1022 11:48:06.734002 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.52914e-05 (* 1 = 7.52914e-05 loss)
I1022 11:48:06.734010 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.69562e-06 (* 1 = 9.69562e-06 loss)
I1022 11:48:06.734017 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00762338 (* 1 = 0.00762338 loss)
I1022 11:48:06.734028 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 5.27273e-05 (* 1 = 5.27273e-05 loss)
I1022 11:48:06.734041 25759 sgd_solver.cpp:106] Iteration 10720, lr = 0.0002
I1022 11:49:31.533540 25759 solver.cpp:228] Iteration 10740, loss = 0.0234108
I1022 11:49:31.533586 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:49:31.533591 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:49:31.533598 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:49:31.533604 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:49:31.533608 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000253983 (* 1 = 0.000253983 loss)
I1022 11:49:31.533613 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0044171 (* 1 = 0.0044171 loss)
I1022 11:49:31.533618 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.11481e-05 (* 1 = 5.11481e-05 loss)
I1022 11:49:31.533623 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.08597e-06 (* 1 = 7.08597e-06 loss)
I1022 11:49:31.533627 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000574093 (* 1 = 0.000574093 loss)
I1022 11:49:31.533648 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0009616 (* 1 = 0.0009616 loss)
I1022 11:49:31.533654 25759 sgd_solver.cpp:106] Iteration 10740, lr = 0.0002
I1022 11:50:56.510890 25759 solver.cpp:228] Iteration 10760, loss = 0.0283185
I1022 11:50:56.510949 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996825
I1022 11:50:56.510962 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:50:56.510980 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.004796 (* 1 = 0.004796 loss)
I1022 11:50:56.510993 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000364432 (* 1 = 0.000364432 loss)
I1022 11:50:56.511005 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0049916 (* 1 = 0.0049916 loss)
I1022 11:50:56.511018 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0046426 (* 1 = 0.0046426 loss)
I1022 11:50:56.511034 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000869883 (* 1 = 0.000869883 loss)
I1022 11:50:56.511046 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.54722e-05 (* 1 = 4.54722e-05 loss)
I1022 11:50:56.511059 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00213525 (* 1 = 0.00213525 loss)
I1022 11:50:56.511072 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000465862 (* 1 = 0.000465862 loss)
I1022 11:50:56.511093 25759 sgd_solver.cpp:106] Iteration 10760, lr = 0.0002
I1022 11:52:19.957446 25759 solver.cpp:228] Iteration 10780, loss = 0.113308
I1022 11:52:19.957527 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997003
I1022 11:52:19.957538 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 11:52:19.957554 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0313221 (* 1 = 0.0313221 loss)
I1022 11:52:19.957566 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00647346 (* 1 = 0.00647346 loss)
I1022 11:52:19.957576 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.013931 (* 1 = 0.013931 loss)
I1022 11:52:19.957587 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00987417 (* 1 = 0.00987417 loss)
I1022 11:52:19.957602 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.51941e-05 (* 1 = 7.51941e-05 loss)
I1022 11:52:19.957613 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.8626e-05 (* 1 = 1.8626e-05 loss)
I1022 11:52:19.957625 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00907071 (* 1 = 0.00907071 loss)
I1022 11:52:19.957636 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.21698e-05 (* 1 = 1.21698e-05 loss)
I1022 11:52:19.957648 25759 sgd_solver.cpp:106] Iteration 10780, lr = 0.0002
speed: 4.211s / iter
I1022 11:53:45.191922 25759 solver.cpp:228] Iteration 10800, loss = 0.0401446
I1022 11:53:45.191972 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:53:45.191979 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:53:45.191988 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:53:45.191995 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:53:45.192001 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00021565 (* 1 = 0.00021565 loss)
I1022 11:53:45.192008 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00435985 (* 1 = 0.00435985 loss)
I1022 11:53:45.192013 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.69735e-05 (* 1 = 4.69735e-05 loss)
I1022 11:53:45.192019 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.16011e-05 (* 1 = 1.16011e-05 loss)
I1022 11:53:45.192025 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 7.07434e-05 (* 1 = 7.07434e-05 loss)
I1022 11:53:45.192030 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.87297e-05 (* 1 = 2.87297e-05 loss)
I1022 11:53:45.192040 25759 sgd_solver.cpp:106] Iteration 10800, lr = 0.0002
I1022 11:55:10.720057 25759 solver.cpp:228] Iteration 10820, loss = 0.053453
I1022 11:55:10.720094 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:55:10.720108 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:55:10.720116 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:55:10.720121 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:55:10.720129 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000230898 (* 1 = 0.000230898 loss)
I1022 11:55:10.720135 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00449519 (* 1 = 0.00449519 loss)
I1022 11:55:10.720141 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.71055e-05 (* 1 = 5.71055e-05 loss)
I1022 11:55:10.720147 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.77824e-06 (* 1 = 3.77824e-06 loss)
I1022 11:55:10.720154 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000426728 (* 1 = 0.000426728 loss)
I1022 11:55:10.720160 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000320725 (* 1 = 0.000320725 loss)
I1022 11:55:10.720166 25759 sgd_solver.cpp:106] Iteration 10820, lr = 0.0002
I1022 11:56:37.300750 25759 solver.cpp:228] Iteration 10840, loss = 0.232595
I1022 11:56:37.300789 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997393
I1022 11:56:37.300796 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 11:56:37.300807 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00897749 (* 1 = 0.00897749 loss)
I1022 11:56:37.300813 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00936535 (* 1 = 0.00936535 loss)
I1022 11:56:37.300819 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00647729 (* 1 = 0.00647729 loss)
I1022 11:56:37.300824 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00804091 (* 1 = 0.00804091 loss)
I1022 11:56:37.300830 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.21046e-05 (* 1 = 6.21046e-05 loss)
I1022 11:56:37.300837 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.23713e-05 (* 1 = 2.23713e-05 loss)
I1022 11:56:37.300843 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00180307 (* 1 = 0.00180307 loss)
I1022 11:56:37.300848 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.74208e-05 (* 1 = 1.74208e-05 loss)
I1022 11:56:37.300855 25759 sgd_solver.cpp:106] Iteration 10840, lr = 0.0002
I1022 11:58:01.458050 25759 solver.cpp:228] Iteration 10860, loss = 0.0644791
I1022 11:58:01.458108 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988126
I1022 11:58:01.458118 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993028
I1022 11:58:01.458133 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.119666 (* 1 = 0.119666 loss)
I1022 11:58:01.458143 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0502076 (* 1 = 0.0502076 loss)
I1022 11:58:01.458153 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0343296 (* 1 = 0.0343296 loss)
I1022 11:58:01.458163 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0388013 (* 1 = 0.0388013 loss)
I1022 11:58:01.458173 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000608418 (* 1 = 0.000608418 loss)
I1022 11:58:01.458191 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.27747e-05 (* 1 = 1.27747e-05 loss)
I1022 11:58:01.458202 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.032034 (* 1 = 0.032034 loss)
I1022 11:58:01.458214 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.23988e-05 (* 1 = 7.23988e-05 loss)
I1022 11:58:01.458225 25759 sgd_solver.cpp:106] Iteration 10860, lr = 0.0002
I1022 11:59:24.430122 25759 solver.cpp:228] Iteration 10880, loss = 0.0223998
I1022 11:59:24.430181 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 11:59:24.430187 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 11:59:24.430196 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 11:59:24.430202 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 11:59:24.430207 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00021897 (* 1 = 0.00021897 loss)
I1022 11:59:24.430212 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00454477 (* 1 = 0.00454477 loss)
I1022 11:59:24.430217 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.91679e-05 (* 1 = 9.91679e-05 loss)
I1022 11:59:24.430222 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.42554e-05 (* 1 = 1.42554e-05 loss)
I1022 11:59:24.430227 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 7.48034e-05 (* 1 = 7.48034e-05 loss)
I1022 11:59:24.430232 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000309142 (* 1 = 0.000309142 loss)
I1022 11:59:24.430238 25759 sgd_solver.cpp:106] Iteration 10880, lr = 0.0002
I1022 12:00:46.327802 25759 solver.cpp:228] Iteration 10900, loss = 0.0598225
I1022 12:00:46.327842 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997994
I1022 12:00:46.327852 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 12:00:46.327864 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0119933 (* 1 = 0.0119933 loss)
I1022 12:00:46.327873 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0089936 (* 1 = 0.0089936 loss)
I1022 12:00:46.327883 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00379325 (* 1 = 0.00379325 loss)
I1022 12:00:46.327894 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00691351 (* 1 = 0.00691351 loss)
I1022 12:00:46.327906 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.52691e-05 (* 1 = 8.52691e-05 loss)
I1022 12:00:46.327917 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.67013e-05 (* 1 = 1.67013e-05 loss)
I1022 12:00:46.327929 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00251687 (* 1 = 0.00251687 loss)
I1022 12:00:46.327939 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.85338e-05 (* 1 = 2.85338e-05 loss)
I1022 12:00:46.327952 25759 sgd_solver.cpp:106] Iteration 10900, lr = 0.0002
I1022 12:02:11.063077 25759 solver.cpp:228] Iteration 10920, loss = 0.0408099
I1022 12:02:11.063122 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 12:02:11.063128 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:02:11.063139 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:02:11.063145 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:02:11.063153 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00506183 (* 1 = 0.00506183 loss)
I1022 12:02:11.063159 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450238 (* 1 = 0.00450238 loss)
I1022 12:02:11.063168 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.48075e-05 (* 1 = 8.48075e-05 loss)
I1022 12:02:11.063174 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.80236e-06 (* 1 = 8.80236e-06 loss)
I1022 12:02:11.063181 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 5.76873e-05 (* 1 = 5.76873e-05 loss)
I1022 12:02:11.063189 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000111782 (* 1 = 0.000111782 loss)
I1022 12:02:11.063195 25759 sgd_solver.cpp:106] Iteration 10920, lr = 0.0002
I1022 12:03:36.763586 25759 solver.cpp:228] Iteration 10940, loss = 0.0629687
I1022 12:03:36.763626 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 12:03:36.763633 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 12:03:36.763643 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00656231 (* 1 = 0.00656231 loss)
I1022 12:03:36.763649 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0057826 (* 1 = 0.0057826 loss)
I1022 12:03:36.763655 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00778561 (* 1 = 0.00778561 loss)
I1022 12:03:36.763661 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00954184 (* 1 = 0.00954184 loss)
I1022 12:03:36.763669 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000196826 (* 1 = 0.000196826 loss)
I1022 12:03:36.763677 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.4481e-06 (* 1 = 8.4481e-06 loss)
I1022 12:03:36.763684 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00349872 (* 1 = 0.00349872 loss)
I1022 12:03:36.763689 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000153192 (* 1 = 0.000153192 loss)
I1022 12:03:36.763697 25759 sgd_solver.cpp:106] Iteration 10940, lr = 0.0002
I1022 12:05:01.442384 25759 solver.cpp:228] Iteration 10960, loss = 0.105227
I1022 12:05:01.442441 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993193
I1022 12:05:01.442448 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991013
I1022 12:05:01.442458 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.037408 (* 1 = 0.037408 loss)
I1022 12:05:01.442464 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0347763 (* 1 = 0.0347763 loss)
I1022 12:05:01.442471 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0202495 (* 1 = 0.0202495 loss)
I1022 12:05:01.442476 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0297557 (* 1 = 0.0297557 loss)
I1022 12:05:01.442482 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00388875 (* 1 = 0.00388875 loss)
I1022 12:05:01.442488 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.62244e-05 (* 1 = 2.62244e-05 loss)
I1022 12:05:01.442494 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0779949 (* 1 = 0.0779949 loss)
I1022 12:05:01.442500 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000939955 (* 1 = 0.000939955 loss)
I1022 12:05:01.442512 25759 sgd_solver.cpp:106] Iteration 10960, lr = 0.0002
I1022 12:06:27.107508 25759 solver.cpp:228] Iteration 10980, loss = 0.0431753
I1022 12:06:27.107569 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 12:06:27.107579 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:06:27.107592 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:06:27.107604 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:06:27.107614 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00463453 (* 1 = 0.00463453 loss)
I1022 12:06:27.107622 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00452541 (* 1 = 0.00452541 loss)
I1022 12:06:27.107633 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.05519e-05 (* 1 = 7.05519e-05 loss)
I1022 12:06:27.107643 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.68058e-06 (* 1 = 6.68058e-06 loss)
I1022 12:06:27.107655 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000435324 (* 1 = 0.000435324 loss)
I1022 12:06:27.107664 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000448741 (* 1 = 0.000448741 loss)
I1022 12:06:27.107677 25759 sgd_solver.cpp:106] Iteration 10980, lr = 0.0002
speed: 4.211s / iter
I1022 12:07:50.569149 25759 solver.cpp:228] Iteration 11000, loss = 0.148813
I1022 12:07:50.569247 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 12:07:50.569258 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:07:50.569277 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:07:50.569288 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:07:50.569299 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000191104 (* 1 = 0.000191104 loss)
I1022 12:07:50.569314 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00406637 (* 1 = 0.00406637 loss)
I1022 12:07:50.569329 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.48379e-05 (* 1 = 4.48379e-05 loss)
I1022 12:07:50.569344 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.03307e-05 (* 1 = 1.03307e-05 loss)
I1022 12:07:50.569356 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 4.14719e-05 (* 1 = 4.14719e-05 loss)
I1022 12:07:50.569370 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.44369e-05 (* 1 = 4.44369e-05 loss)
I1022 12:07:50.569382 25759 sgd_solver.cpp:106] Iteration 11000, lr = 0.0002
I1022 12:09:16.008677 25759 solver.cpp:228] Iteration 11020, loss = 0.0810164
I1022 12:09:16.008738 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997472
I1022 12:09:16.008744 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 12:09:16.008756 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0123892 (* 1 = 0.0123892 loss)
I1022 12:09:16.008764 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00995519 (* 1 = 0.00995519 loss)
I1022 12:09:16.008769 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00571156 (* 1 = 0.00571156 loss)
I1022 12:09:16.008774 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00689904 (* 1 = 0.00689904 loss)
I1022 12:09:16.008780 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.0164e-05 (* 1 = 6.0164e-05 loss)
I1022 12:09:16.008787 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.0617e-05 (* 1 = 1.0617e-05 loss)
I1022 12:09:16.008795 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00233803 (* 1 = 0.00233803 loss)
I1022 12:09:16.008802 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000512415 (* 1 = 0.000512415 loss)
I1022 12:09:16.008810 25759 sgd_solver.cpp:106] Iteration 11020, lr = 0.0002
I1022 12:10:41.862237 25759 solver.cpp:228] Iteration 11040, loss = 0.0842977
I1022 12:10:41.862288 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988464
I1022 12:10:41.862293 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.991036
I1022 12:10:41.862301 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.10347 (* 1 = 0.10347 loss)
I1022 12:10:41.862306 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0392166 (* 1 = 0.0392166 loss)
I1022 12:10:41.862310 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0342077 (* 1 = 0.0342077 loss)
I1022 12:10:41.862314 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0387185 (* 1 = 0.0387185 loss)
I1022 12:10:41.862319 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000741321 (* 1 = 0.000741321 loss)
I1022 12:10:41.862324 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.10426e-05 (* 1 = 2.10426e-05 loss)
I1022 12:10:41.862329 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0274151 (* 1 = 0.0274151 loss)
I1022 12:10:41.862334 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000732749 (* 1 = 0.000732749 loss)
I1022 12:10:41.862340 25759 sgd_solver.cpp:106] Iteration 11040, lr = 0.0002
I1022 12:12:06.506328 25759 solver.cpp:228] Iteration 11060, loss = 0.0653988
I1022 12:12:06.506400 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997823
I1022 12:12:06.506407 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 12:12:06.506418 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.009045 (* 1 = 0.009045 loss)
I1022 12:12:06.506425 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00192599 (* 1 = 0.00192599 loss)
I1022 12:12:06.506431 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00551585 (* 1 = 0.00551585 loss)
I1022 12:12:06.506438 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00655552 (* 1 = 0.00655552 loss)
I1022 12:12:06.506444 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.87503e-05 (* 1 = 2.87503e-05 loss)
I1022 12:12:06.506451 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.9576e-06 (* 1 = 7.9576e-06 loss)
I1022 12:12:06.506458 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00169057 (* 1 = 0.00169057 loss)
I1022 12:12:06.506464 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.16284e-05 (* 1 = 1.16284e-05 loss)
I1022 12:12:06.506477 25759 sgd_solver.cpp:106] Iteration 11060, lr = 0.0002
I1022 12:13:30.454372 25759 solver.cpp:228] Iteration 11080, loss = 0.0524095
I1022 12:13:30.454432 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 12:13:30.454437 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 12:13:30.454445 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00608692 (* 1 = 0.00608692 loss)
I1022 12:13:30.454452 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00282075 (* 1 = 0.00282075 loss)
I1022 12:13:30.454457 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00706922 (* 1 = 0.00706922 loss)
I1022 12:13:30.454460 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00603975 (* 1 = 0.00603975 loss)
I1022 12:13:30.454465 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.49228e-05 (* 1 = 1.49228e-05 loss)
I1022 12:13:30.454470 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.89016e-06 (* 1 = 6.89016e-06 loss)
I1022 12:13:30.454475 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000766654 (* 1 = 0.000766654 loss)
I1022 12:13:30.454495 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.39976e-05 (* 1 = 1.39976e-05 loss)
I1022 12:13:30.454502 25759 sgd_solver.cpp:106] Iteration 11080, lr = 0.0002
I1022 12:14:53.803660 25759 solver.cpp:228] Iteration 11100, loss = 0.0405713
I1022 12:14:53.803721 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 12:14:53.803732 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:14:53.803747 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:14:53.803757 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:14:53.803767 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00463791 (* 1 = 0.00463791 loss)
I1022 12:14:53.803777 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450132 (* 1 = 0.00450132 loss)
I1022 12:14:53.803791 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.73715e-05 (* 1 = 8.73715e-05 loss)
I1022 12:14:53.803804 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.044e-05 (* 1 = 1.044e-05 loss)
I1022 12:14:53.803817 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000288802 (* 1 = 0.000288802 loss)
I1022 12:14:53.803828 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.54517e-05 (* 1 = 1.54517e-05 loss)
I1022 12:14:53.803848 25759 sgd_solver.cpp:106] Iteration 11100, lr = 0.0002
I1022 12:16:17.717543 25759 solver.cpp:228] Iteration 11120, loss = 0.0168917
I1022 12:16:17.717595 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 12:16:17.717602 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:16:17.717609 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:16:17.717613 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:16:17.717618 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00442793 (* 1 = 0.00442793 loss)
I1022 12:16:17.717622 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00456142 (* 1 = 0.00456142 loss)
I1022 12:16:17.717628 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.95553e-05 (* 1 = 5.95553e-05 loss)
I1022 12:16:17.717633 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.2115e-06 (* 1 = 8.2115e-06 loss)
I1022 12:16:17.717638 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00034641 (* 1 = 0.00034641 loss)
I1022 12:16:17.717643 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.35709e-06 (* 1 = 6.35709e-06 loss)
I1022 12:16:17.717649 25759 sgd_solver.cpp:106] Iteration 11120, lr = 0.0002
I1022 12:17:42.062952 25759 solver.cpp:228] Iteration 11140, loss = 0.0317904
I1022 12:17:42.063014 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 12:17:42.063021 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:17:42.063031 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:17:42.063037 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:17:42.063043 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00493623 (* 1 = 0.00493623 loss)
I1022 12:17:42.063050 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00430381 (* 1 = 0.00430381 loss)
I1022 12:17:42.063056 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000271481 (* 1 = 0.000271481 loss)
I1022 12:17:42.063063 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.97526e-06 (* 1 = 8.97526e-06 loss)
I1022 12:17:42.063069 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000119731 (* 1 = 0.000119731 loss)
I1022 12:17:42.063076 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.48618e-05 (* 1 = 4.48618e-05 loss)
I1022 12:17:42.063091 25759 sgd_solver.cpp:106] Iteration 11140, lr = 0.0002
I1022 12:19:05.025460 25759 solver.cpp:228] Iteration 11160, loss = 0.0468353
I1022 12:19:05.025511 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 12:19:05.025532 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:19:05.025539 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:19:05.025543 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:19:05.025548 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000401695 (* 1 = 0.000401695 loss)
I1022 12:19:05.025553 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00453188 (* 1 = 0.00453188 loss)
I1022 12:19:05.025558 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000107388 (* 1 = 0.000107388 loss)
I1022 12:19:05.025563 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.64484e-05 (* 1 = 1.64484e-05 loss)
I1022 12:19:05.025568 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000187826 (* 1 = 0.000187826 loss)
I1022 12:19:05.025573 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000567051 (* 1 = 0.000567051 loss)
I1022 12:19:05.025578 25759 sgd_solver.cpp:106] Iteration 11160, lr = 0.0002
I1022 12:20:29.693383 25759 solver.cpp:228] Iteration 11180, loss = 0.0984244
I1022 12:20:29.693440 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999431
I1022 12:20:29.693447 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:20:29.693455 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0105991 (* 1 = 0.0105991 loss)
I1022 12:20:29.693461 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000918127 (* 1 = 0.000918127 loss)
I1022 12:20:29.693465 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00321617 (* 1 = 0.00321617 loss)
I1022 12:20:29.693470 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00453809 (* 1 = 0.00453809 loss)
I1022 12:20:29.693475 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.86235e-05 (* 1 = 3.86235e-05 loss)
I1022 12:20:29.693480 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.95339e-06 (* 1 = 6.95339e-06 loss)
I1022 12:20:29.693485 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00103413 (* 1 = 0.00103413 loss)
I1022 12:20:29.693490 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000202895 (* 1 = 0.000202895 loss)
I1022 12:20:29.693497 25759 sgd_solver.cpp:106] Iteration 11180, lr = 0.0002
speed: 4.211s / iter
I1022 12:21:52.455255 25759 solver.cpp:228] Iteration 11200, loss = 0.0748362
I1022 12:21:52.455307 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996006
I1022 12:21:52.455324 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998003
I1022 12:21:52.455334 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0238446 (* 1 = 0.0238446 loss)
I1022 12:21:52.455341 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00703927 (* 1 = 0.00703927 loss)
I1022 12:21:52.455348 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0179941 (* 1 = 0.0179941 loss)
I1022 12:21:52.455353 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0138835 (* 1 = 0.0138835 loss)
I1022 12:21:52.455360 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000379575 (* 1 = 0.000379575 loss)
I1022 12:21:52.455368 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.01521e-06 (* 1 = 8.01521e-06 loss)
I1022 12:21:52.455374 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0102529 (* 1 = 0.0102529 loss)
I1022 12:21:52.455379 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.58657e-05 (* 1 = 2.58657e-05 loss)
I1022 12:21:52.455387 25759 sgd_solver.cpp:106] Iteration 11200, lr = 0.0002
I1022 12:23:16.524552 25759 solver.cpp:228] Iteration 11220, loss = 0.162368
I1022 12:23:16.524590 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 12:23:16.524597 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:23:16.524606 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:23:16.524617 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:23:16.524623 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000595598 (* 1 = 0.000595598 loss)
I1022 12:23:16.524629 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00443807 (* 1 = 0.00443807 loss)
I1022 12:23:16.524636 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.56202e-05 (* 1 = 6.56202e-05 loss)
I1022 12:23:16.524641 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.96973e-06 (* 1 = 9.96973e-06 loss)
I1022 12:23:16.524647 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00130119 (* 1 = 0.00130119 loss)
I1022 12:23:16.524653 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000189026 (* 1 = 0.000189026 loss)
I1022 12:23:16.524664 25759 sgd_solver.cpp:106] Iteration 11220, lr = 0.0002
I1022 12:24:39.828310 25759 solver.cpp:228] Iteration 11240, loss = 0.0313094
I1022 12:24:39.828389 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996991
I1022 12:24:39.828399 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997503
I1022 12:24:39.828415 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0190121 (* 1 = 0.0190121 loss)
I1022 12:24:39.828426 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00500783 (* 1 = 0.00500783 loss)
I1022 12:24:39.828436 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00619802 (* 1 = 0.00619802 loss)
I1022 12:24:39.828446 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0108806 (* 1 = 0.0108806 loss)
I1022 12:24:39.828461 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0001371 (* 1 = 0.0001371 loss)
I1022 12:24:39.828474 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.51799e-05 (* 1 = 1.51799e-05 loss)
I1022 12:24:39.828485 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0083338 (* 1 = 0.0083338 loss)
I1022 12:24:39.828495 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000128579 (* 1 = 0.000128579 loss)
I1022 12:24:39.828510 25759 sgd_solver.cpp:106] Iteration 11240, lr = 0.0002
I1022 12:26:03.719444 25759 solver.cpp:228] Iteration 11260, loss = 0.0699233
I1022 12:26:03.719483 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985264
I1022 12:26:03.719491 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996006
I1022 12:26:03.719501 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0459226 (* 1 = 0.0459226 loss)
I1022 12:26:03.719506 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.028052 (* 1 = 0.028052 loss)
I1022 12:26:03.719512 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0309522 (* 1 = 0.0309522 loss)
I1022 12:26:03.719521 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0209014 (* 1 = 0.0209014 loss)
I1022 12:26:03.719527 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00242452 (* 1 = 0.00242452 loss)
I1022 12:26:03.719533 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.48558e-05 (* 1 = 1.48558e-05 loss)
I1022 12:26:03.719539 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0204489 (* 1 = 0.0204489 loss)
I1022 12:26:03.719545 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000568748 (* 1 = 0.000568748 loss)
I1022 12:26:03.719553 25759 sgd_solver.cpp:106] Iteration 11260, lr = 0.0002
I1022 12:27:28.697434 25759 solver.cpp:228] Iteration 11280, loss = 0.110186
I1022 12:27:28.697476 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 12:27:28.697494 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 12:27:28.697504 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00612242 (* 1 = 0.00612242 loss)
I1022 12:27:28.697510 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0102478 (* 1 = 0.0102478 loss)
I1022 12:27:28.697516 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00949005 (* 1 = 0.00949005 loss)
I1022 12:27:28.697522 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00647643 (* 1 = 0.00647643 loss)
I1022 12:27:28.697530 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000211502 (* 1 = 0.000211502 loss)
I1022 12:27:28.697535 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.24207e-05 (* 1 = 2.24207e-05 loss)
I1022 12:27:28.697542 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0191312 (* 1 = 0.0191312 loss)
I1022 12:27:28.697549 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000205619 (* 1 = 0.000205619 loss)
I1022 12:27:28.697561 25759 sgd_solver.cpp:106] Iteration 11280, lr = 0.0002
I1022 12:28:52.458849 25759 solver.cpp:228] Iteration 11300, loss = 0.0615722
I1022 12:28:52.458904 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999487
I1022 12:28:52.458910 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:28:52.458917 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00806722 (* 1 = 0.00806722 loss)
I1022 12:28:52.458923 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00182415 (* 1 = 0.00182415 loss)
I1022 12:28:52.458927 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00258236 (* 1 = 0.00258236 loss)
I1022 12:28:52.458932 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00444929 (* 1 = 0.00444929 loss)
I1022 12:28:52.458937 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.99891e-05 (* 1 = 1.99891e-05 loss)
I1022 12:28:52.458941 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.34414e-05 (* 1 = 1.34414e-05 loss)
I1022 12:28:52.458946 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0023741 (* 1 = 0.0023741 loss)
I1022 12:28:52.458951 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 5.44003e-06 (* 1 = 5.44003e-06 loss)
I1022 12:28:52.458957 25759 sgd_solver.cpp:106] Iteration 11300, lr = 0.0002
I1022 12:30:13.925819 25759 solver.cpp:228] Iteration 11320, loss = 0.0376325
I1022 12:30:13.925878 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 12:30:13.925884 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997501
I1022 12:30:13.925891 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00933417 (* 1 = 0.00933417 loss)
I1022 12:30:13.925896 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00954468 (* 1 = 0.00954468 loss)
I1022 12:30:13.925901 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.010473 (* 1 = 0.010473 loss)
I1022 12:30:13.925906 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00731056 (* 1 = 0.00731056 loss)
I1022 12:30:13.925911 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.57451e-05 (* 1 = 3.57451e-05 loss)
I1022 12:30:13.925916 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.03187e-05 (* 1 = 2.03187e-05 loss)
I1022 12:30:13.925921 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00130962 (* 1 = 0.00130962 loss)
I1022 12:30:13.925925 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.627e-05 (* 1 = 7.627e-05 loss)
I1022 12:30:13.925932 25759 sgd_solver.cpp:106] Iteration 11320, lr = 0.0002
I1022 12:31:35.567119 25759 solver.cpp:228] Iteration 11340, loss = 0.0691435
I1022 12:31:35.567157 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994885
I1022 12:31:35.567163 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 12:31:35.567173 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00759246 (* 1 = 0.00759246 loss)
I1022 12:31:35.567178 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00155829 (* 1 = 0.00155829 loss)
I1022 12:31:35.567184 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.011506 (* 1 = 0.011506 loss)
I1022 12:31:35.567190 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00794076 (* 1 = 0.00794076 loss)
I1022 12:31:35.567196 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.0227857 (* 1 = 0.0227857 loss)
I1022 12:31:35.567203 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.66122e-06 (* 1 = 9.66122e-06 loss)
I1022 12:31:35.567207 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00334456 (* 1 = 0.00334456 loss)
I1022 12:31:35.567214 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0002558 (* 1 = 0.0002558 loss)
I1022 12:31:35.567221 25759 sgd_solver.cpp:106] Iteration 11340, lr = 0.0002
I1022 12:32:59.556864 25759 solver.cpp:228] Iteration 11360, loss = 0.0557157
I1022 12:32:59.556915 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 12:32:59.556919 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:32:59.556926 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:32:59.556931 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:32:59.556951 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000275209 (* 1 = 0.000275209 loss)
I1022 12:32:59.556957 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00430843 (* 1 = 0.00430843 loss)
I1022 12:32:59.556960 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.61087e-05 (* 1 = 8.61087e-05 loss)
I1022 12:32:59.556965 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.57337e-06 (* 1 = 6.57337e-06 loss)
I1022 12:32:59.556969 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000360916 (* 1 = 0.000360916 loss)
I1022 12:32:59.556974 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.44758e-05 (* 1 = 7.44758e-05 loss)
I1022 12:32:59.556983 25759 sgd_solver.cpp:106] Iteration 11360, lr = 0.0002
I1022 12:34:24.618813 25759 solver.cpp:228] Iteration 11380, loss = 0.105775
I1022 12:34:24.618851 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992854
I1022 12:34:24.618857 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994511
I1022 12:34:24.618866 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0295238 (* 1 = 0.0295238 loss)
I1022 12:34:24.618872 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0254727 (* 1 = 0.0254727 loss)
I1022 12:34:24.618878 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0169026 (* 1 = 0.0169026 loss)
I1022 12:34:24.618883 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0230872 (* 1 = 0.0230872 loss)
I1022 12:34:24.618891 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000135195 (* 1 = 0.000135195 loss)
I1022 12:34:24.618896 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.57567e-05 (* 1 = 1.57567e-05 loss)
I1022 12:34:24.618901 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00750749 (* 1 = 0.00750749 loss)
I1022 12:34:24.618907 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000124087 (* 1 = 0.000124087 loss)
I1022 12:34:24.618919 25759 sgd_solver.cpp:106] Iteration 11380, lr = 0.0002
speed: 4.211s / iter
I1022 12:35:49.771092 25759 solver.cpp:228] Iteration 11400, loss = 0.0317136
I1022 12:35:49.771131 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998993
I1022 12:35:49.771137 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 12:35:49.771147 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.015346 (* 1 = 0.015346 loss)
I1022 12:35:49.771153 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00369004 (* 1 = 0.00369004 loss)
I1022 12:35:49.771159 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00593176 (* 1 = 0.00593176 loss)
I1022 12:35:49.771167 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00847301 (* 1 = 0.00847301 loss)
I1022 12:35:49.771174 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.87433e-05 (* 1 = 6.87433e-05 loss)
I1022 12:35:49.771180 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.18854e-05 (* 1 = 6.18854e-05 loss)
I1022 12:35:49.771186 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00173832 (* 1 = 0.00173832 loss)
I1022 12:35:49.771193 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000305469 (* 1 = 0.000305469 loss)
I1022 12:35:49.771200 25759 sgd_solver.cpp:106] Iteration 11400, lr = 0.0002
I1022 12:37:15.174583 25759 solver.cpp:228] Iteration 11420, loss = 0.0337574
I1022 12:37:15.174645 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 12:37:15.174654 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:37:15.174664 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:37:15.174671 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:37:15.174679 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00807615 (* 1 = 0.00807615 loss)
I1022 12:37:15.174685 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00447252 (* 1 = 0.00447252 loss)
I1022 12:37:15.174693 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000110884 (* 1 = 0.000110884 loss)
I1022 12:37:15.174700 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.44135e-05 (* 1 = 1.44135e-05 loss)
I1022 12:37:15.174715 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000400554 (* 1 = 0.000400554 loss)
I1022 12:37:15.174724 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.02144e-05 (* 1 = 1.02144e-05 loss)
I1022 12:37:15.174734 25759 sgd_solver.cpp:106] Iteration 11420, lr = 0.0002
I1022 12:38:39.970486 25759 solver.cpp:228] Iteration 11440, loss = 0.0727717
I1022 12:38:39.970530 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 12:38:39.970536 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 12:38:39.970546 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00382469 (* 1 = 0.00382469 loss)
I1022 12:38:39.970553 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00799821 (* 1 = 0.00799821 loss)
I1022 12:38:39.970562 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00923556 (* 1 = 0.00923556 loss)
I1022 12:38:39.970568 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00850291 (* 1 = 0.00850291 loss)
I1022 12:38:39.970576 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.98422e-05 (* 1 = 9.98422e-05 loss)
I1022 12:38:39.970582 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.43362e-05 (* 1 = 1.43362e-05 loss)
I1022 12:38:39.970588 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00569593 (* 1 = 0.00569593 loss)
I1022 12:38:39.970595 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00100906 (* 1 = 0.00100906 loss)
I1022 12:38:39.970608 25759 sgd_solver.cpp:106] Iteration 11440, lr = 0.0002
I1022 12:40:03.367233 25759 solver.cpp:228] Iteration 11460, loss = 0.161409
I1022 12:40:03.367316 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989033
I1022 12:40:03.367327 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99003
I1022 12:40:03.367346 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.143287 (* 1 = 0.143287 loss)
I1022 12:40:03.367358 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0670867 (* 1 = 0.0670867 loss)
I1022 12:40:03.367369 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0507979 (* 1 = 0.0507979 loss)
I1022 12:40:03.367383 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0403779 (* 1 = 0.0403779 loss)
I1022 12:40:03.367399 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00169059 (* 1 = 0.00169059 loss)
I1022 12:40:03.367413 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.99856e-05 (* 1 = 1.99856e-05 loss)
I1022 12:40:03.367426 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0533407 (* 1 = 0.0533407 loss)
I1022 12:40:03.367439 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00102179 (* 1 = 0.00102179 loss)
I1022 12:40:03.367455 25759 sgd_solver.cpp:106] Iteration 11460, lr = 0.0002
I1022 12:41:28.564988 25759 solver.cpp:228] Iteration 11480, loss = 0.0644616
I1022 12:41:28.565027 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998461
I1022 12:41:28.565034 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:41:28.565044 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00548671 (* 1 = 0.00548671 loss)
I1022 12:41:28.565052 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00201585 (* 1 = 0.00201585 loss)
I1022 12:41:28.565057 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0028593 (* 1 = 0.0028593 loss)
I1022 12:41:28.565064 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00475388 (* 1 = 0.00475388 loss)
I1022 12:41:28.565070 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.21777e-05 (* 1 = 5.21777e-05 loss)
I1022 12:41:28.565078 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.12322e-06 (* 1 = 6.12322e-06 loss)
I1022 12:41:28.565083 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00152527 (* 1 = 0.00152527 loss)
I1022 12:41:28.565089 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.61986e-05 (* 1 = 1.61986e-05 loss)
I1022 12:41:28.565098 25759 sgd_solver.cpp:106] Iteration 11480, lr = 0.0002
I1022 12:42:52.939031 25759 solver.cpp:228] Iteration 11500, loss = 0.0394208
I1022 12:42:52.939079 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 12:42:52.939085 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 12:42:52.939092 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00381115 (* 1 = 0.00381115 loss)
I1022 12:42:52.939097 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00600598 (* 1 = 0.00600598 loss)
I1022 12:42:52.939105 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0110527 (* 1 = 0.0110527 loss)
I1022 12:42:52.939108 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00920665 (* 1 = 0.00920665 loss)
I1022 12:42:52.939112 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00105565 (* 1 = 0.00105565 loss)
I1022 12:42:52.939117 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.25244e-05 (* 1 = 2.25244e-05 loss)
I1022 12:42:52.939121 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00540167 (* 1 = 0.00540167 loss)
I1022 12:42:52.939126 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.53513e-05 (* 1 = 7.53513e-05 loss)
I1022 12:42:52.939134 25759 sgd_solver.cpp:106] Iteration 11500, lr = 0.0002
I1022 12:44:17.258293 25759 solver.cpp:228] Iteration 11520, loss = 0.0569293
I1022 12:44:17.258352 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 12:44:17.258359 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:44:17.258370 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:44:17.258376 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:44:17.258383 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000218325 (* 1 = 0.000218325 loss)
I1022 12:44:17.258390 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00412031 (* 1 = 0.00412031 loss)
I1022 12:44:17.258397 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.84299e-05 (* 1 = 3.84299e-05 loss)
I1022 12:44:17.258404 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.39223e-06 (* 1 = 4.39223e-06 loss)
I1022 12:44:17.258410 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000205021 (* 1 = 0.000205021 loss)
I1022 12:44:17.258417 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000152072 (* 1 = 0.000152072 loss)
I1022 12:44:17.258425 25759 sgd_solver.cpp:106] Iteration 11520, lr = 0.0002
I1022 12:45:40.826134 25759 solver.cpp:228] Iteration 11540, loss = 0.125744
I1022 12:45:40.826184 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 12:45:40.826189 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995502
I1022 12:45:40.826197 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.006281 (* 1 = 0.006281 loss)
I1022 12:45:40.826202 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0106166 (* 1 = 0.0106166 loss)
I1022 12:45:40.826207 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0112544 (* 1 = 0.0112544 loss)
I1022 12:45:40.826211 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.014226 (* 1 = 0.014226 loss)
I1022 12:45:40.826215 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00209335 (* 1 = 0.00209335 loss)
I1022 12:45:40.826220 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.39213e-05 (* 1 = 1.39213e-05 loss)
I1022 12:45:40.826225 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.066504 (* 1 = 0.066504 loss)
I1022 12:45:40.826231 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000612928 (* 1 = 0.000612928 loss)
I1022 12:45:40.826236 25759 sgd_solver.cpp:106] Iteration 11540, lr = 0.0002
I1022 12:47:05.443594 25759 solver.cpp:228] Iteration 11560, loss = 0.075194
I1022 12:47:05.443647 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996505
I1022 12:47:05.443655 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997504
I1022 12:47:05.443675 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0305584 (* 1 = 0.0305584 loss)
I1022 12:47:05.443683 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00848176 (* 1 = 0.00848176 loss)
I1022 12:47:05.443689 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0180048 (* 1 = 0.0180048 loss)
I1022 12:47:05.443696 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0132835 (* 1 = 0.0132835 loss)
I1022 12:47:05.443702 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000174361 (* 1 = 0.000174361 loss)
I1022 12:47:05.443709 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.61568e-05 (* 1 = 2.61568e-05 loss)
I1022 12:47:05.443716 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00528822 (* 1 = 0.00528822 loss)
I1022 12:47:05.443722 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000179217 (* 1 = 0.000179217 loss)
I1022 12:47:05.443730 25759 sgd_solver.cpp:106] Iteration 11560, lr = 0.0002
I1022 12:48:31.793687 25759 solver.cpp:228] Iteration 11580, loss = 0.0356537
I1022 12:48:31.793736 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 12:48:31.793742 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:48:31.793750 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:48:31.793753 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:48:31.793758 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000213891 (* 1 = 0.000213891 loss)
I1022 12:48:31.793762 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00432948 (* 1 = 0.00432948 loss)
I1022 12:48:31.793767 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.39967e-05 (* 1 = 4.39967e-05 loss)
I1022 12:48:31.793771 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.81976e-06 (* 1 = 7.81976e-06 loss)
I1022 12:48:31.793776 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000258528 (* 1 = 0.000258528 loss)
I1022 12:48:31.793781 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.32717e-05 (* 1 = 4.32717e-05 loss)
I1022 12:48:31.793790 25759 sgd_solver.cpp:106] Iteration 11580, lr = 0.0002
speed: 4.211s / iter
I1022 12:49:58.071950 25759 solver.cpp:228] Iteration 11600, loss = 0.073271
I1022 12:49:58.072021 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 12:49:58.072032 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:49:58.072049 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 12:49:58.072060 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 12:49:58.072072 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000266499 (* 1 = 0.000266499 loss)
I1022 12:49:58.072088 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00435959 (* 1 = 0.00435959 loss)
I1022 12:49:58.072101 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.26812e-05 (* 1 = 3.26812e-05 loss)
I1022 12:49:58.072115 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.823e-06 (* 1 = 3.823e-06 loss)
I1022 12:49:58.072129 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000568443 (* 1 = 0.000568443 loss)
I1022 12:49:58.072142 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.66545e-05 (* 1 = 2.66545e-05 loss)
I1022 12:49:58.072163 25759 sgd_solver.cpp:106] Iteration 11600, lr = 0.0002
I1022 12:51:24.298902 25759 solver.cpp:228] Iteration 11620, loss = 0.0509089
I1022 12:51:24.298964 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996006
I1022 12:51:24.298971 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997504
I1022 12:51:24.298983 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0257639 (* 1 = 0.0257639 loss)
I1022 12:51:24.298990 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00577522 (* 1 = 0.00577522 loss)
I1022 12:51:24.299000 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0185212 (* 1 = 0.0185212 loss)
I1022 12:51:24.299006 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0146346 (* 1 = 0.0146346 loss)
I1022 12:51:24.299013 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000177653 (* 1 = 0.000177653 loss)
I1022 12:51:24.299021 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.84332e-05 (* 1 = 1.84332e-05 loss)
I1022 12:51:24.299027 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00592378 (* 1 = 0.00592378 loss)
I1022 12:51:24.299033 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000239015 (* 1 = 0.000239015 loss)
I1022 12:51:24.299048 25759 sgd_solver.cpp:106] Iteration 11620, lr = 0.0002
I1022 12:52:48.262100 25759 solver.cpp:228] Iteration 11640, loss = 0.0559097
I1022 12:52:48.262157 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992677
I1022 12:52:48.262166 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 12:52:48.262179 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0177657 (* 1 = 0.0177657 loss)
I1022 12:52:48.262188 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00831795 (* 1 = 0.00831795 loss)
I1022 12:52:48.262197 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0213824 (* 1 = 0.0213824 loss)
I1022 12:52:48.262204 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0188473 (* 1 = 0.0188473 loss)
I1022 12:52:48.262213 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00852216 (* 1 = 0.00852216 loss)
I1022 12:52:48.262221 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.64896e-05 (* 1 = 2.64896e-05 loss)
I1022 12:52:48.262229 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0429821 (* 1 = 0.0429821 loss)
I1022 12:52:48.262238 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00010501 (* 1 = 0.00010501 loss)
I1022 12:52:48.262249 25759 sgd_solver.cpp:106] Iteration 11640, lr = 0.0002
I1022 12:54:14.496135 25759 solver.cpp:228] Iteration 11660, loss = 0.0633864
I1022 12:54:14.496192 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994508
I1022 12:54:14.496198 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994009
I1022 12:54:14.496206 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0173119 (* 1 = 0.0173119 loss)
I1022 12:54:14.496212 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0402328 (* 1 = 0.0402328 loss)
I1022 12:54:14.496217 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0285744 (* 1 = 0.0285744 loss)
I1022 12:54:14.496220 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0267224 (* 1 = 0.0267224 loss)
I1022 12:54:14.496225 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000370734 (* 1 = 0.000370734 loss)
I1022 12:54:14.496230 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.56195e-05 (* 1 = 2.56195e-05 loss)
I1022 12:54:14.496235 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0226305 (* 1 = 0.0226305 loss)
I1022 12:54:14.496240 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 9.3673e-05 (* 1 = 9.3673e-05 loss)
I1022 12:54:14.496246 25759 sgd_solver.cpp:106] Iteration 11660, lr = 0.0002
I1022 12:55:37.837148 25759 solver.cpp:228] Iteration 11680, loss = 0.0366173
I1022 12:55:37.837196 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 12:55:37.837201 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 12:55:37.837209 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0118948 (* 1 = 0.0118948 loss)
I1022 12:55:37.837214 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00102993 (* 1 = 0.00102993 loss)
I1022 12:55:37.837218 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0085598 (* 1 = 0.0085598 loss)
I1022 12:55:37.837222 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00460592 (* 1 = 0.00460592 loss)
I1022 12:55:37.837227 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.8893e-06 (* 1 = 4.8893e-06 loss)
I1022 12:55:37.837231 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.44942e-06 (* 1 = 5.44942e-06 loss)
I1022 12:55:37.837236 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00150599 (* 1 = 0.00150599 loss)
I1022 12:55:37.837241 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.59727e-05 (* 1 = 2.59727e-05 loss)
I1022 12:55:37.837246 25759 sgd_solver.cpp:106] Iteration 11680, lr = 0.0002
I1022 12:57:02.244343 25759 solver.cpp:228] Iteration 11700, loss = 0.0812612
I1022 12:57:02.244412 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.984546
I1022 12:57:02.244424 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.990528
I1022 12:57:02.244442 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0624 (* 1 = 0.0624 loss)
I1022 12:57:02.244453 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0713568 (* 1 = 0.0713568 loss)
I1022 12:57:02.244463 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0519611 (* 1 = 0.0519611 loss)
I1022 12:57:02.244474 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0415607 (* 1 = 0.0415607 loss)
I1022 12:57:02.244503 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00122275 (* 1 = 0.00122275 loss)
I1022 12:57:02.244516 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.08005e-05 (* 1 = 2.08005e-05 loss)
I1022 12:57:02.244527 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0418511 (* 1 = 0.0418511 loss)
I1022 12:57:02.244537 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00125754 (* 1 = 0.00125754 loss)
I1022 12:57:02.244552 25759 sgd_solver.cpp:106] Iteration 11700, lr = 0.0002
I1022 12:58:26.145627 25759 solver.cpp:228] Iteration 11720, loss = 0.0516313
I1022 12:58:26.145676 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 12:58:26.145681 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 12:58:26.145690 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00881496 (* 1 = 0.00881496 loss)
I1022 12:58:26.145695 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00481842 (* 1 = 0.00481842 loss)
I1022 12:58:26.145699 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0142992 (* 1 = 0.0142992 loss)
I1022 12:58:26.145704 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00905052 (* 1 = 0.00905052 loss)
I1022 12:58:26.145709 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.60752e-05 (* 1 = 1.60752e-05 loss)
I1022 12:58:26.145714 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.04834e-05 (* 1 = 1.04834e-05 loss)
I1022 12:58:26.145718 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00167854 (* 1 = 0.00167854 loss)
I1022 12:58:26.145722 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000168278 (* 1 = 0.000168278 loss)
I1022 12:58:26.145731 25759 sgd_solver.cpp:106] Iteration 11720, lr = 0.0002
I1022 12:59:51.929635 25759 solver.cpp:228] Iteration 11740, loss = 0.0926609
I1022 12:59:51.929674 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994009
I1022 12:59:51.929682 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997504
I1022 12:59:51.929690 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0146836 (* 1 = 0.0146836 loss)
I1022 12:59:51.929697 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0220024 (* 1 = 0.0220024 loss)
I1022 12:59:51.929702 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0211299 (* 1 = 0.0211299 loss)
I1022 12:59:51.929708 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0144271 (* 1 = 0.0144271 loss)
I1022 12:59:51.929714 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.57135e-05 (* 1 = 7.57135e-05 loss)
I1022 12:59:51.929719 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.24739e-05 (* 1 = 1.24739e-05 loss)
I1022 12:59:51.929725 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00354156 (* 1 = 0.00354156 loss)
I1022 12:59:51.929731 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.44555e-05 (* 1 = 1.44555e-05 loss)
I1022 12:59:51.929738 25759 sgd_solver.cpp:106] Iteration 11740, lr = 0.0002
I1022 13:01:14.333731 25759 solver.cpp:228] Iteration 11760, loss = 0.0637377
I1022 13:01:14.333781 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 13:01:14.333793 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:01:14.333809 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0179814 (* 1 = 0.0179814 loss)
I1022 13:01:14.333822 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00080671 (* 1 = 0.00080671 loss)
I1022 13:01:14.333832 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00861131 (* 1 = 0.00861131 loss)
I1022 13:01:14.333842 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0041539 (* 1 = 0.0041539 loss)
I1022 13:01:14.333853 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.47226e-05 (* 1 = 1.47226e-05 loss)
I1022 13:01:14.333868 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.53916e-06 (* 1 = 3.53916e-06 loss)
I1022 13:01:14.333879 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00262175 (* 1 = 0.00262175 loss)
I1022 13:01:14.333891 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00011651 (* 1 = 0.00011651 loss)
I1022 13:01:14.333902 25759 sgd_solver.cpp:106] Iteration 11760, lr = 0.0002
I1022 13:02:38.216748 25759 solver.cpp:228] Iteration 11780, loss = 0.0568132
I1022 13:02:38.216800 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 13:02:38.216810 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:02:38.216825 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00659653 (* 1 = 0.00659653 loss)
I1022 13:02:38.216835 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00155325 (* 1 = 0.00155325 loss)
I1022 13:02:38.216843 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00670818 (* 1 = 0.00670818 loss)
I1022 13:02:38.216852 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00449088 (* 1 = 0.00449088 loss)
I1022 13:02:38.216862 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.46771e-05 (* 1 = 1.46771e-05 loss)
I1022 13:02:38.216872 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.20361e-06 (* 1 = 8.20361e-06 loss)
I1022 13:02:38.216884 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00190642 (* 1 = 0.00190642 loss)
I1022 13:02:38.216897 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.0002785 (* 1 = 0.0002785 loss)
I1022 13:02:38.216908 25759 sgd_solver.cpp:106] Iteration 11780, lr = 0.0002
speed: 4.211s / iter
I1022 13:04:00.966926 25759 solver.cpp:228] Iteration 11800, loss = 0.0625872
I1022 13:04:00.966987 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 13:04:00.966994 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:04:00.967003 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 13:04:00.967007 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 13:04:00.967013 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000321563 (* 1 = 0.000321563 loss)
I1022 13:04:00.967018 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00460893 (* 1 = 0.00460893 loss)
I1022 13:04:00.967023 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.12524e-05 (* 1 = 6.12524e-05 loss)
I1022 13:04:00.967041 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.88345e-06 (* 1 = 4.88345e-06 loss)
I1022 13:04:00.967046 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00023392 (* 1 = 0.00023392 loss)
I1022 13:04:00.967051 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.82953e-05 (* 1 = 1.82953e-05 loss)
I1022 13:04:00.967059 25759 sgd_solver.cpp:106] Iteration 11800, lr = 0.0002
I1022 13:05:21.906051 25759 solver.cpp:228] Iteration 11820, loss = 0.0276246
I1022 13:05:21.906085 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 13:05:21.906090 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:05:21.906096 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 13:05:21.906100 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 13:05:21.906105 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00341398 (* 1 = 0.00341398 loss)
I1022 13:05:21.906110 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00434895 (* 1 = 0.00434895 loss)
I1022 13:05:21.906113 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.2188e-05 (* 1 = 7.2188e-05 loss)
I1022 13:05:21.906121 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.44147e-06 (* 1 = 8.44147e-06 loss)
I1022 13:05:21.906124 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000866067 (* 1 = 0.000866067 loss)
I1022 13:05:21.906128 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000158957 (* 1 = 0.000158957 loss)
I1022 13:05:21.906134 25759 sgd_solver.cpp:106] Iteration 11820, lr = 0.0002
I1022 13:06:43.400064 25759 solver.cpp:228] Iteration 11840, loss = 0.0448005
I1022 13:06:43.400131 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.98895
I1022 13:06:43.400137 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 13:06:43.400146 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0132876 (* 1 = 0.0132876 loss)
I1022 13:06:43.400152 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00039817 (* 1 = 0.00039817 loss)
I1022 13:06:43.400156 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0198184 (* 1 = 0.0198184 loss)
I1022 13:06:43.400161 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00873756 (* 1 = 0.00873756 loss)
I1022 13:06:43.400167 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.89953e-05 (* 1 = 4.89953e-05 loss)
I1022 13:06:43.400172 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.05581e-05 (* 1 = 1.05581e-05 loss)
I1022 13:06:43.400177 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00380758 (* 1 = 0.00380758 loss)
I1022 13:06:43.400182 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000163384 (* 1 = 0.000163384 loss)
I1022 13:06:43.400189 25759 sgd_solver.cpp:106] Iteration 11840, lr = 0.0002
I1022 13:08:06.758369 25759 solver.cpp:228] Iteration 11860, loss = 0.0302885
I1022 13:08:06.758419 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997492
I1022 13:08:06.758424 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997504
I1022 13:08:06.758431 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0278388 (* 1 = 0.0278388 loss)
I1022 13:08:06.758435 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0119463 (* 1 = 0.0119463 loss)
I1022 13:08:06.758440 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00797778 (* 1 = 0.00797778 loss)
I1022 13:08:06.758460 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0138211 (* 1 = 0.0138211 loss)
I1022 13:08:06.758464 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.62483e-05 (* 1 = 8.62483e-05 loss)
I1022 13:08:06.758469 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.12434e-05 (* 1 = 1.12434e-05 loss)
I1022 13:08:06.758473 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00551119 (* 1 = 0.00551119 loss)
I1022 13:08:06.758478 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.34607e-05 (* 1 = 4.34607e-05 loss)
I1022 13:08:06.758484 25759 sgd_solver.cpp:106] Iteration 11860, lr = 0.0002
I1022 13:09:31.117626 25759 solver.cpp:228] Iteration 11880, loss = 0.151953
I1022 13:09:31.117676 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997503
I1022 13:09:31.117681 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997503
I1022 13:09:31.117689 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0130103 (* 1 = 0.0130103 loss)
I1022 13:09:31.117693 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0132186 (* 1 = 0.0132186 loss)
I1022 13:09:31.117697 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0160502 (* 1 = 0.0160502 loss)
I1022 13:09:31.117702 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0122998 (* 1 = 0.0122998 loss)
I1022 13:09:31.117707 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.28127e-05 (* 1 = 2.28127e-05 loss)
I1022 13:09:31.117712 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.18053e-06 (* 1 = 9.18053e-06 loss)
I1022 13:09:31.117717 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00243357 (* 1 = 0.00243357 loss)
I1022 13:09:31.117723 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.1728e-05 (* 1 = 1.1728e-05 loss)
I1022 13:09:31.117734 25759 sgd_solver.cpp:106] Iteration 11880, lr = 0.0002
I1022 13:10:54.680564 25759 solver.cpp:228] Iteration 11900, loss = 0.0212222
I1022 13:10:54.680629 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 13:10:54.680641 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:10:54.680661 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 13:10:54.680671 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 13:10:54.680682 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000370777 (* 1 = 0.000370777 loss)
I1022 13:10:54.680694 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00435 (* 1 = 0.00435 loss)
I1022 13:10:54.680706 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.09703e-05 (* 1 = 6.09703e-05 loss)
I1022 13:10:54.680719 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.1172e-05 (* 1 = 1.1172e-05 loss)
I1022 13:10:54.680732 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000195647 (* 1 = 0.000195647 loss)
I1022 13:10:54.680744 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00082693 (* 1 = 0.00082693 loss)
I1022 13:10:54.680757 25759 sgd_solver.cpp:106] Iteration 11900, lr = 0.0002
I1022 13:12:16.795933 25759 solver.cpp:228] Iteration 11920, loss = 0.0200218
I1022 13:12:16.796020 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999478
I1022 13:12:16.796031 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:12:16.796049 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 13:12:16.796059 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 13:12:16.796072 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00146465 (* 1 = 0.00146465 loss)
I1022 13:12:16.796088 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00418648 (* 1 = 0.00418648 loss)
I1022 13:12:16.796103 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.86294e-05 (* 1 = 5.86294e-05 loss)
I1022 13:12:16.796116 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.00311832 (* 1 = 0.00311832 loss)
I1022 13:12:16.796129 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000412276 (* 1 = 0.000412276 loss)
I1022 13:12:16.796142 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.51903e-05 (* 1 = 7.51903e-05 loss)
I1022 13:12:16.796157 25759 sgd_solver.cpp:106] Iteration 11920, lr = 0.0002
I1022 13:13:40.792049 25759 solver.cpp:228] Iteration 11940, loss = 0.132843
I1022 13:13:40.792086 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999493
I1022 13:13:40.792093 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:13:40.792104 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00511153 (* 1 = 0.00511153 loss)
I1022 13:13:40.792109 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00166325 (* 1 = 0.00166325 loss)
I1022 13:13:40.792115 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00280697 (* 1 = 0.00280697 loss)
I1022 13:13:40.792120 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00476538 (* 1 = 0.00476538 loss)
I1022 13:13:40.792126 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.37658e-05 (* 1 = 3.37658e-05 loss)
I1022 13:13:40.792132 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.32152e-06 (* 1 = 7.32152e-06 loss)
I1022 13:13:40.792138 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000976564 (* 1 = 0.000976564 loss)
I1022 13:13:40.792146 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000179587 (* 1 = 0.000179587 loss)
I1022 13:13:40.792155 25759 sgd_solver.cpp:106] Iteration 11940, lr = 0.0002
I1022 13:15:06.665139 25759 solver.cpp:228] Iteration 11960, loss = 0.0307198
I1022 13:15:06.665186 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 13:15:06.665192 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 13:15:06.665202 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00702925 (* 1 = 0.00702925 loss)
I1022 13:15:06.665210 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00561493 (* 1 = 0.00561493 loss)
I1022 13:15:06.665216 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00763213 (* 1 = 0.00763213 loss)
I1022 13:15:06.665222 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0064788 (* 1 = 0.0064788 loss)
I1022 13:15:06.665230 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.65052e-05 (* 1 = 2.65052e-05 loss)
I1022 13:15:06.665236 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.11308e-06 (* 1 = 6.11308e-06 loss)
I1022 13:15:06.665241 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00215018 (* 1 = 0.00215018 loss)
I1022 13:15:06.665247 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00011242 (* 1 = 0.00011242 loss)
I1022 13:15:06.665256 25759 sgd_solver.cpp:106] Iteration 11960, lr = 0.0002
I1022 13:16:31.575691 25759 solver.cpp:228] Iteration 11980, loss = 0.0327097
I1022 13:16:31.575728 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 13:16:31.575736 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996002
I1022 13:16:31.575745 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0306029 (* 1 = 0.0306029 loss)
I1022 13:16:31.575752 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0106233 (* 1 = 0.0106233 loss)
I1022 13:16:31.575757 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0114758 (* 1 = 0.0114758 loss)
I1022 13:16:31.575762 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0114104 (* 1 = 0.0114104 loss)
I1022 13:16:31.575768 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.35126e-05 (* 1 = 6.35126e-05 loss)
I1022 13:16:31.575774 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.55826e-05 (* 1 = 3.55826e-05 loss)
I1022 13:16:31.575779 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0081832 (* 1 = 0.0081832 loss)
I1022 13:16:31.575785 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000503142 (* 1 = 0.000503142 loss)
I1022 13:16:31.575793 25759 sgd_solver.cpp:106] Iteration 11980, lr = 0.0002
speed: 4.211s / iter
bbbb
aaaa
Wrote snapshot to: /home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_12000.caffemodel
I1022 13:17:56.271852 25759 solver.cpp:228] Iteration 12000, loss = 0.0513321
I1022 13:17:56.271901 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995349
I1022 13:17:56.271908 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 13:17:56.271919 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00968898 (* 1 = 0.00968898 loss)
I1022 13:17:56.271926 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00194243 (* 1 = 0.00194243 loss)
I1022 13:17:56.271935 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0099528 (* 1 = 0.0099528 loss)
I1022 13:17:56.271941 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00580659 (* 1 = 0.00580659 loss)
I1022 13:17:56.271948 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.53359e-05 (* 1 = 4.53359e-05 loss)
I1022 13:17:56.271955 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.16283e-06 (* 1 = 4.16283e-06 loss)
I1022 13:17:56.271961 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00323171 (* 1 = 0.00323171 loss)
I1022 13:17:56.271967 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00050557 (* 1 = 0.00050557 loss)
I1022 13:17:56.271975 25759 sgd_solver.cpp:46] MultiStep Status: Iteration 12000, step = 2
I1022 13:17:56.271980 25759 sgd_solver.cpp:106] Iteration 12000, lr = 2e-05
I1022 13:19:17.655119 25759 solver.cpp:228] Iteration 12020, loss = 0.0543895
I1022 13:19:17.655179 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997994
I1022 13:19:17.655185 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 13:19:17.655194 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0062418 (* 1 = 0.0062418 loss)
I1022 13:19:17.655200 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00640797 (* 1 = 0.00640797 loss)
I1022 13:19:17.655205 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00455268 (* 1 = 0.00455268 loss)
I1022 13:19:17.655210 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00607719 (* 1 = 0.00607719 loss)
I1022 13:19:17.655215 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.52387e-05 (* 1 = 1.52387e-05 loss)
I1022 13:19:17.655220 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.47388e-06 (* 1 = 7.47388e-06 loss)
I1022 13:19:17.655225 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000885539 (* 1 = 0.000885539 loss)
I1022 13:19:17.655230 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.68241e-05 (* 1 = 6.68241e-05 loss)
I1022 13:19:17.655236 25759 sgd_solver.cpp:106] Iteration 12020, lr = 2e-05
I1022 13:20:39.620862 25759 solver.cpp:228] Iteration 12040, loss = 0.148036
I1022 13:20:39.620913 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998462
I1022 13:20:39.620918 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997503
I1022 13:20:39.620926 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0330401 (* 1 = 0.0330401 loss)
I1022 13:20:39.620930 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0130224 (* 1 = 0.0130224 loss)
I1022 13:20:39.620935 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00525446 (* 1 = 0.00525446 loss)
I1022 13:20:39.620939 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0076938 (* 1 = 0.0076938 loss)
I1022 13:20:39.620944 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.23439e-05 (* 1 = 3.23439e-05 loss)
I1022 13:20:39.620949 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.93913e-06 (* 1 = 8.93913e-06 loss)
I1022 13:20:39.620954 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00178999 (* 1 = 0.00178999 loss)
I1022 13:20:39.620959 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000112569 (* 1 = 0.000112569 loss)
I1022 13:20:39.620965 25759 sgd_solver.cpp:106] Iteration 12040, lr = 2e-05
I1022 13:22:02.006516 25759 solver.cpp:228] Iteration 12060, loss = 0.0435171
I1022 13:22:02.006554 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998976
I1022 13:22:02.006570 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:22:02.006579 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00411456 (* 1 = 0.00411456 loss)
I1022 13:22:02.006585 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000333437 (* 1 = 0.000333437 loss)
I1022 13:22:02.006590 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00298619 (* 1 = 0.00298619 loss)
I1022 13:22:02.006597 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00471286 (* 1 = 0.00471286 loss)
I1022 13:22:02.006603 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.70713e-05 (* 1 = 3.70713e-05 loss)
I1022 13:22:02.006608 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.75943e-06 (* 1 = 7.75943e-06 loss)
I1022 13:22:02.006614 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0011453 (* 1 = 0.0011453 loss)
I1022 13:22:02.006621 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000134006 (* 1 = 0.000134006 loss)
I1022 13:22:02.006629 25759 sgd_solver.cpp:106] Iteration 12060, lr = 2e-05
I1022 13:23:27.576038 25759 solver.cpp:228] Iteration 12080, loss = 0.121727
I1022 13:23:27.576086 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 13:23:27.576092 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:23:27.576099 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 13:23:27.576103 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 13:23:27.576108 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00478233 (* 1 = 0.00478233 loss)
I1022 13:23:27.576113 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00426821 (* 1 = 0.00426821 loss)
I1022 13:23:27.576117 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.77126e-05 (* 1 = 9.77126e-05 loss)
I1022 13:23:27.576122 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.83343e-06 (* 1 = 7.83343e-06 loss)
I1022 13:23:27.576126 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 7.22784e-05 (* 1 = 7.22784e-05 loss)
I1022 13:23:27.576131 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000940145 (* 1 = 0.000940145 loss)
I1022 13:23:27.576136 25759 sgd_solver.cpp:106] Iteration 12080, lr = 2e-05
I1022 13:24:53.420001 25759 solver.cpp:228] Iteration 12100, loss = 0.0641501
I1022 13:24:53.420039 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998942
I1022 13:24:53.420047 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:24:53.420055 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0125971 (* 1 = 0.0125971 loss)
I1022 13:24:53.420061 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0012157 (* 1 = 0.0012157 loss)
I1022 13:24:53.420068 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00414421 (* 1 = 0.00414421 loss)
I1022 13:24:53.420073 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00416994 (* 1 = 0.00416994 loss)
I1022 13:24:53.420079 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000720902 (* 1 = 0.000720902 loss)
I1022 13:24:53.420085 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.03183e-06 (* 1 = 9.03183e-06 loss)
I1022 13:24:53.420090 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00150654 (* 1 = 0.00150654 loss)
I1022 13:24:53.420097 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.34335e-05 (* 1 = 6.34335e-05 loss)
I1022 13:24:53.420104 25759 sgd_solver.cpp:106] Iteration 12100, lr = 2e-05
I1022 13:26:17.479009 25759 solver.cpp:228] Iteration 12120, loss = 0.0809293
I1022 13:26:17.479066 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 13:26:17.479074 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:26:17.479080 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.011278 (* 1 = 0.011278 loss)
I1022 13:26:17.479089 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00826017 (* 1 = 0.00826017 loss)
I1022 13:26:17.479092 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00792366 (* 1 = 0.00792366 loss)
I1022 13:26:17.479097 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00556557 (* 1 = 0.00556557 loss)
I1022 13:26:17.479102 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.27836e-05 (* 1 = 3.27836e-05 loss)
I1022 13:26:17.479107 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.67945e-06 (* 1 = 7.67945e-06 loss)
I1022 13:26:17.479112 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00184631 (* 1 = 0.00184631 loss)
I1022 13:26:17.479116 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000242669 (* 1 = 0.000242669 loss)
I1022 13:26:17.479122 25759 sgd_solver.cpp:106] Iteration 12120, lr = 2e-05
I1022 13:27:40.788440 25759 solver.cpp:228] Iteration 12140, loss = 0.024047
I1022 13:27:40.788471 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994947
I1022 13:27:40.788476 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995507
I1022 13:27:40.788484 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0300092 (* 1 = 0.0300092 loss)
I1022 13:27:40.788488 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0146149 (* 1 = 0.0146149 loss)
I1022 13:27:40.788492 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0122621 (* 1 = 0.0122621 loss)
I1022 13:27:40.788496 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0177315 (* 1 = 0.0177315 loss)
I1022 13:27:40.788501 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.9542e-05 (* 1 = 5.9542e-05 loss)
I1022 13:27:40.788506 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.81523e-06 (* 1 = 5.81523e-06 loss)
I1022 13:27:40.788509 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00660693 (* 1 = 0.00660693 loss)
I1022 13:27:40.788513 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000135913 (* 1 = 0.000135913 loss)
I1022 13:27:40.788518 25759 sgd_solver.cpp:106] Iteration 12140, lr = 2e-05
I1022 13:29:02.964690 25759 solver.cpp:228] Iteration 12160, loss = 0.0483535
I1022 13:29:02.964727 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9975
I1022 13:29:02.964743 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999001
I1022 13:29:02.964752 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.01395 (* 1 = 0.01395 loss)
I1022 13:29:02.964758 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00160247 (* 1 = 0.00160247 loss)
I1022 13:29:02.964764 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00708411 (* 1 = 0.00708411 loss)
I1022 13:29:02.964769 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00833798 (* 1 = 0.00833798 loss)
I1022 13:29:02.964776 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.12501e-05 (* 1 = 6.12501e-05 loss)
I1022 13:29:02.964781 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.58031e-06 (* 1 = 5.58031e-06 loss)
I1022 13:29:02.964787 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00286868 (* 1 = 0.00286868 loss)
I1022 13:29:02.964794 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.18991e-05 (* 1 = 1.18991e-05 loss)
I1022 13:29:02.964802 25759 sgd_solver.cpp:106] Iteration 12160, lr = 2e-05
I1022 13:30:25.921838 25759 solver.cpp:228] Iteration 12180, loss = 0.0259444
I1022 13:30:25.921895 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999494
I1022 13:30:25.921903 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 13:30:25.921913 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00559536 (* 1 = 0.00559536 loss)
I1022 13:30:25.921921 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00404013 (* 1 = 0.00404013 loss)
I1022 13:30:25.921926 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0035781 (* 1 = 0.0035781 loss)
I1022 13:30:25.921932 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00665114 (* 1 = 0.00665114 loss)
I1022 13:30:25.921938 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.21098e-05 (* 1 = 2.21098e-05 loss)
I1022 13:30:25.921944 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.62253e-05 (* 1 = 1.62253e-05 loss)
I1022 13:30:25.921950 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00155522 (* 1 = 0.00155522 loss)
I1022 13:30:25.921957 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000309596 (* 1 = 0.000309596 loss)
I1022 13:30:25.921963 25759 sgd_solver.cpp:106] Iteration 12180, lr = 2e-05
speed: 4.210s / iter
I1022 13:31:50.353587 25759 solver.cpp:228] Iteration 12200, loss = 0.0615169
I1022 13:31:50.353652 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999467
I1022 13:31:50.353664 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 13:31:50.353682 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00722156 (* 1 = 0.00722156 loss)
I1022 13:31:50.353693 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00862114 (* 1 = 0.00862114 loss)
I1022 13:31:50.353703 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00307429 (* 1 = 0.00307429 loss)
I1022 13:31:50.353713 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00561069 (* 1 = 0.00561069 loss)
I1022 13:31:50.353727 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.25348e-05 (* 1 = 6.25348e-05 loss)
I1022 13:31:50.353739 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.74902e-06 (* 1 = 9.74902e-06 loss)
I1022 13:31:50.353752 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0078637 (* 1 = 0.0078637 loss)
I1022 13:31:50.353765 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000124275 (* 1 = 0.000124275 loss)
I1022 13:31:50.353780 25759 sgd_solver.cpp:106] Iteration 12200, lr = 2e-05
I1022 13:33:16.714319 25759 solver.cpp:228] Iteration 12220, loss = 0.0724361
I1022 13:33:16.714359 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993513
I1022 13:33:16.714366 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992515
I1022 13:33:16.714376 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.035835 (* 1 = 0.035835 loss)
I1022 13:33:16.714382 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0412209 (* 1 = 0.0412209 loss)
I1022 13:33:16.714387 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0327032 (* 1 = 0.0327032 loss)
I1022 13:33:16.714393 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0287071 (* 1 = 0.0287071 loss)
I1022 13:33:16.714399 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000801617 (* 1 = 0.000801617 loss)
I1022 13:33:16.714406 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.2467e-06 (* 1 = 9.2467e-06 loss)
I1022 13:33:16.714412 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0258066 (* 1 = 0.0258066 loss)
I1022 13:33:16.714418 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.85253e-05 (* 1 = 2.85253e-05 loss)
I1022 13:33:16.714426 25759 sgd_solver.cpp:106] Iteration 12220, lr = 2e-05
I1022 13:34:42.699817 25759 solver.cpp:228] Iteration 12240, loss = 0.0429891
I1022 13:34:42.699854 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993108
I1022 13:34:42.699860 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.989016
I1022 13:34:42.699868 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0323872 (* 1 = 0.0323872 loss)
I1022 13:34:42.699872 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0351799 (* 1 = 0.0351799 loss)
I1022 13:34:42.699877 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0181614 (* 1 = 0.0181614 loss)
I1022 13:34:42.699882 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0336982 (* 1 = 0.0336982 loss)
I1022 13:34:42.699887 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00883986 (* 1 = 0.00883986 loss)
I1022 13:34:42.699892 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.07946e-05 (* 1 = 1.07946e-05 loss)
I1022 13:34:42.699896 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0555784 (* 1 = 0.0555784 loss)
I1022 13:34:42.699901 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000993234 (* 1 = 0.000993234 loss)
I1022 13:34:42.699908 25759 sgd_solver.cpp:106] Iteration 12240, lr = 2e-05
I1022 13:36:08.469863 25759 solver.cpp:228] Iteration 12260, loss = 0.163632
I1022 13:36:08.469905 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994006
I1022 13:36:08.469913 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 13:36:08.469923 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00830138 (* 1 = 0.00830138 loss)
I1022 13:36:08.469928 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0100353 (* 1 = 0.0100353 loss)
I1022 13:36:08.469935 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0174074 (* 1 = 0.0174074 loss)
I1022 13:36:08.469941 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0174332 (* 1 = 0.0174332 loss)
I1022 13:36:08.469947 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00122817 (* 1 = 0.00122817 loss)
I1022 13:36:08.469954 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.90112e-05 (* 1 = 1.90112e-05 loss)
I1022 13:36:08.469960 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0157547 (* 1 = 0.0157547 loss)
I1022 13:36:08.469966 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.95779e-05 (* 1 = 6.95779e-05 loss)
I1022 13:36:08.469974 25759 sgd_solver.cpp:106] Iteration 12260, lr = 2e-05
I1022 13:37:29.486076 25759 solver.cpp:228] Iteration 12280, loss = 0.0840639
I1022 13:37:29.486124 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998972
I1022 13:37:29.486129 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 13:37:29.486137 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00922703 (* 1 = 0.00922703 loss)
I1022 13:37:29.486141 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00701902 (* 1 = 0.00701902 loss)
I1022 13:37:29.486145 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00542335 (* 1 = 0.00542335 loss)
I1022 13:37:29.486150 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00632628 (* 1 = 0.00632628 loss)
I1022 13:37:29.486155 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.5066e-05 (* 1 = 4.5066e-05 loss)
I1022 13:37:29.486158 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.64119e-06 (* 1 = 9.64119e-06 loss)
I1022 13:37:29.486163 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00344572 (* 1 = 0.00344572 loss)
I1022 13:37:29.486168 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000826691 (* 1 = 0.000826691 loss)
I1022 13:37:29.486173 25759 sgd_solver.cpp:106] Iteration 12280, lr = 2e-05
I1022 13:38:50.426847 25759 solver.cpp:228] Iteration 12300, loss = 0.0664311
I1022 13:38:50.426887 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 13:38:50.426893 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 13:38:50.426903 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0134744 (* 1 = 0.0134744 loss)
I1022 13:38:50.426908 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00280143 (* 1 = 0.00280143 loss)
I1022 13:38:50.426913 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0153651 (* 1 = 0.0153651 loss)
I1022 13:38:50.426920 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00987744 (* 1 = 0.00987744 loss)
I1022 13:38:50.426926 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.76769e-05 (* 1 = 3.76769e-05 loss)
I1022 13:38:50.426932 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.03347e-05 (* 1 = 1.03347e-05 loss)
I1022 13:38:50.426939 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00192318 (* 1 = 0.00192318 loss)
I1022 13:38:50.426944 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 3.65806e-05 (* 1 = 3.65806e-05 loss)
I1022 13:38:50.426951 25759 sgd_solver.cpp:106] Iteration 12300, lr = 2e-05
I1022 13:40:15.911491 25759 solver.cpp:228] Iteration 12320, loss = 0.0455955
I1022 13:40:15.911538 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995504
I1022 13:40:15.911543 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996503
I1022 13:40:15.911551 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0126488 (* 1 = 0.0126488 loss)
I1022 13:40:15.911556 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0124279 (* 1 = 0.0124279 loss)
I1022 13:40:15.911561 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0196834 (* 1 = 0.0196834 loss)
I1022 13:40:15.911566 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0166252 (* 1 = 0.0166252 loss)
I1022 13:40:15.911583 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000100283 (* 1 = 0.000100283 loss)
I1022 13:40:15.911588 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.6214e-06 (* 1 = 6.6214e-06 loss)
I1022 13:40:15.911592 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0088735 (* 1 = 0.0088735 loss)
I1022 13:40:15.911597 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.12453e-05 (* 1 = 7.12453e-05 loss)
I1022 13:40:15.911602 25759 sgd_solver.cpp:106] Iteration 12320, lr = 2e-05
I1022 13:41:40.205757 25759 solver.cpp:228] Iteration 12340, loss = 0.068073
I1022 13:41:40.205809 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.988018
I1022 13:41:40.205821 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994009
I1022 13:41:40.205834 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0445984 (* 1 = 0.0445984 loss)
I1022 13:41:40.205843 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0448167 (* 1 = 0.0448167 loss)
I1022 13:41:40.205852 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0343028 (* 1 = 0.0343028 loss)
I1022 13:41:40.205862 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0215458 (* 1 = 0.0215458 loss)
I1022 13:41:40.205871 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00317531 (* 1 = 0.00317531 loss)
I1022 13:41:40.205880 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000111331 (* 1 = 0.000111331 loss)
I1022 13:41:40.205889 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00761128 (* 1 = 0.00761128 loss)
I1022 13:41:40.205899 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000310498 (* 1 = 0.000310498 loss)
I1022 13:41:40.205916 25759 sgd_solver.cpp:106] Iteration 12340, lr = 2e-05
I1022 13:43:02.979715 25759 solver.cpp:228] Iteration 12360, loss = 0.0279121
I1022 13:43:02.979763 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998474
I1022 13:43:02.979768 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:43:02.979776 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00809736 (* 1 = 0.00809736 loss)
I1022 13:43:02.979780 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00109484 (* 1 = 0.00109484 loss)
I1022 13:43:02.979785 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00325967 (* 1 = 0.00325967 loss)
I1022 13:43:02.979789 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00457297 (* 1 = 0.00457297 loss)
I1022 13:43:02.979794 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.99813e-05 (* 1 = 1.99813e-05 loss)
I1022 13:43:02.979799 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.39502e-06 (* 1 = 8.39502e-06 loss)
I1022 13:43:02.979804 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00162417 (* 1 = 0.00162417 loss)
I1022 13:43:02.979807 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000193589 (* 1 = 0.000193589 loss)
I1022 13:43:02.979816 25759 sgd_solver.cpp:106] Iteration 12360, lr = 2e-05
I1022 13:44:26.496883 25759 solver.cpp:228] Iteration 12380, loss = 0.0380639
I1022 13:44:26.496922 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 13:44:26.496929 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 13:44:26.496938 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00604243 (* 1 = 0.00604243 loss)
I1022 13:44:26.496945 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00110276 (* 1 = 0.00110276 loss)
I1022 13:44:26.496950 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00633815 (* 1 = 0.00633815 loss)
I1022 13:44:26.496956 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00486886 (* 1 = 0.00486886 loss)
I1022 13:44:26.496963 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.791e-06 (* 1 = 6.791e-06 loss)
I1022 13:44:26.496968 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.87719e-06 (* 1 = 5.87719e-06 loss)
I1022 13:44:26.496974 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00101519 (* 1 = 0.00101519 loss)
I1022 13:44:26.496980 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.8213e-05 (* 1 = 2.8213e-05 loss)
I1022 13:44:26.496987 25759 sgd_solver.cpp:106] Iteration 12380, lr = 2e-05
speed: 4.210s / iter
I1022 13:45:50.430114 25759 solver.cpp:228] Iteration 12400, loss = 0.0348887
I1022 13:45:50.430186 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 13:45:50.430198 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:45:50.430213 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 13:45:50.430223 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 13:45:50.430235 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00463743 (* 1 = 0.00463743 loss)
I1022 13:45:50.430248 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00447528 (* 1 = 0.00447528 loss)
I1022 13:45:50.430258 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.4019e-05 (* 1 = 5.4019e-05 loss)
I1022 13:45:50.430271 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000175289 (* 1 = 0.000175289 loss)
I1022 13:45:50.430284 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000387477 (* 1 = 0.000387477 loss)
I1022 13:45:50.430296 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000284657 (* 1 = 0.000284657 loss)
I1022 13:45:50.430312 25759 sgd_solver.cpp:106] Iteration 12400, lr = 2e-05
I1022 13:47:16.465850 25759 solver.cpp:228] Iteration 12420, loss = 0.060925
I1022 13:47:16.465889 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.992508
I1022 13:47:16.465896 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 13:47:16.465905 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0132091 (* 1 = 0.0132091 loss)
I1022 13:47:16.465911 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0120071 (* 1 = 0.0120071 loss)
I1022 13:47:16.465916 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.023409 (* 1 = 0.023409 loss)
I1022 13:47:16.465922 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0180579 (* 1 = 0.0180579 loss)
I1022 13:47:16.465929 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000260065 (* 1 = 0.000260065 loss)
I1022 13:47:16.465934 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.88698e-06 (* 1 = 7.88698e-06 loss)
I1022 13:47:16.465939 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0133131 (* 1 = 0.0133131 loss)
I1022 13:47:16.465945 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000172029 (* 1 = 0.000172029 loss)
I1022 13:47:16.465955 25759 sgd_solver.cpp:106] Iteration 12420, lr = 2e-05
I1022 13:48:41.361915 25759 solver.cpp:228] Iteration 12440, loss = 0.0314785
I1022 13:48:41.361974 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996503
I1022 13:48:41.361981 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 13:48:41.361991 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0276731 (* 1 = 0.0276731 loss)
I1022 13:48:41.362000 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00756556 (* 1 = 0.00756556 loss)
I1022 13:48:41.362006 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0180559 (* 1 = 0.0180559 loss)
I1022 13:48:41.362012 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0127183 (* 1 = 0.0127183 loss)
I1022 13:48:41.362018 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.4342e-05 (* 1 = 2.4342e-05 loss)
I1022 13:48:41.362025 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.45966e-05 (* 1 = 1.45966e-05 loss)
I1022 13:48:41.362030 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00670349 (* 1 = 0.00670349 loss)
I1022 13:48:41.362036 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000357342 (* 1 = 0.000357342 loss)
I1022 13:48:41.362044 25759 sgd_solver.cpp:106] Iteration 12440, lr = 2e-05
I1022 13:50:04.571239 25759 solver.cpp:228] Iteration 12460, loss = 0.0637744
I1022 13:50:04.571277 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 13:50:04.571285 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:50:04.571293 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 13:50:04.571298 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 13:50:04.571305 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000668525 (* 1 = 0.000668525 loss)
I1022 13:50:04.571313 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00430717 (* 1 = 0.00430717 loss)
I1022 13:50:04.571319 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.21947e-05 (* 1 = 4.21947e-05 loss)
I1022 13:50:04.571326 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.53451e-06 (* 1 = 5.53451e-06 loss)
I1022 13:50:04.571331 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 4.23976e-05 (* 1 = 4.23976e-05 loss)
I1022 13:50:04.571337 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.02773e-05 (* 1 = 7.02773e-05 loss)
I1022 13:50:04.571344 25759 sgd_solver.cpp:106] Iteration 12460, lr = 2e-05
I1022 13:51:29.150537 25759 solver.cpp:228] Iteration 12480, loss = 0.0577639
I1022 13:51:29.150576 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 13:51:29.150583 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 13:51:29.150593 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00654428 (* 1 = 0.00654428 loss)
I1022 13:51:29.150599 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000269702 (* 1 = 0.000269702 loss)
I1022 13:51:29.150605 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00967367 (* 1 = 0.00967367 loss)
I1022 13:51:29.150614 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0049045 (* 1 = 0.0049045 loss)
I1022 13:51:29.150619 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000191721 (* 1 = 0.000191721 loss)
I1022 13:51:29.150626 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.7465e-06 (* 1 = 6.7465e-06 loss)
I1022 13:51:29.150632 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00101691 (* 1 = 0.00101691 loss)
I1022 13:51:29.150640 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00011154 (* 1 = 0.00011154 loss)
I1022 13:51:29.150646 25759 sgd_solver.cpp:106] Iteration 12480, lr = 2e-05
I1022 13:52:55.057937 25759 solver.cpp:228] Iteration 12500, loss = 0.115998
I1022 13:52:55.057976 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 13:52:55.057991 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:52:55.058001 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00868874 (* 1 = 0.00868874 loss)
I1022 13:52:55.058008 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000196108 (* 1 = 0.000196108 loss)
I1022 13:52:55.058013 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00764404 (* 1 = 0.00764404 loss)
I1022 13:52:55.058019 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00479369 (* 1 = 0.00479369 loss)
I1022 13:52:55.058025 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.0386e-05 (* 1 = 2.0386e-05 loss)
I1022 13:52:55.058032 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.80976e-06 (* 1 = 8.80976e-06 loss)
I1022 13:52:55.058037 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00311347 (* 1 = 0.00311347 loss)
I1022 13:52:55.058044 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000122903 (* 1 = 0.000122903 loss)
I1022 13:52:55.058054 25759 sgd_solver.cpp:106] Iteration 12500, lr = 2e-05
I1022 13:54:21.457584 25759 solver.cpp:228] Iteration 12520, loss = 0.0361357
I1022 13:54:21.457631 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993147
I1022 13:54:21.457638 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99501
I1022 13:54:21.457645 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.035703 (* 1 = 0.035703 loss)
I1022 13:54:21.457653 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.019353 (* 1 = 0.019353 loss)
I1022 13:54:21.457657 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0214531 (* 1 = 0.0214531 loss)
I1022 13:54:21.457661 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0225072 (* 1 = 0.0225072 loss)
I1022 13:54:21.457665 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000118327 (* 1 = 0.000118327 loss)
I1022 13:54:21.457670 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.72279e-05 (* 1 = 2.72279e-05 loss)
I1022 13:54:21.457675 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00512721 (* 1 = 0.00512721 loss)
I1022 13:54:21.457679 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000666574 (* 1 = 0.000666574 loss)
I1022 13:54:21.457689 25759 sgd_solver.cpp:106] Iteration 12520, lr = 2e-05
I1022 13:55:44.453860 25759 solver.cpp:228] Iteration 12540, loss = 0.0374534
I1022 13:55:44.453922 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998498
I1022 13:55:44.453930 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 13:55:44.453943 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00977738 (* 1 = 0.00977738 loss)
I1022 13:55:44.453953 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00322163 (* 1 = 0.00322163 loss)
I1022 13:55:44.453960 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00574918 (* 1 = 0.00574918 loss)
I1022 13:55:44.453969 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00711878 (* 1 = 0.00711878 loss)
I1022 13:55:44.453977 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.36884e-05 (* 1 = 3.36884e-05 loss)
I1022 13:55:44.453985 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.12352e-05 (* 1 = 1.12352e-05 loss)
I1022 13:55:44.453994 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00814355 (* 1 = 0.00814355 loss)
I1022 13:55:44.454016 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.58775e-05 (* 1 = 4.58775e-05 loss)
I1022 13:55:44.454026 25759 sgd_solver.cpp:106] Iteration 12540, lr = 2e-05
I1022 13:57:05.916376 25759 solver.cpp:228] Iteration 12560, loss = 0.0320363
I1022 13:57:05.916425 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998999
I1022 13:57:05.916431 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 13:57:05.916438 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00553752 (* 1 = 0.00553752 loss)
I1022 13:57:05.916443 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000708278 (* 1 = 0.000708278 loss)
I1022 13:57:05.916448 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00380824 (* 1 = 0.00380824 loss)
I1022 13:57:05.916452 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00457715 (* 1 = 0.00457715 loss)
I1022 13:57:05.916457 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.38194e-05 (* 1 = 1.38194e-05 loss)
I1022 13:57:05.916461 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.02124e-06 (* 1 = 8.02124e-06 loss)
I1022 13:57:05.916466 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00112795 (* 1 = 0.00112795 loss)
I1022 13:57:05.916471 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.05952e-05 (* 1 = 1.05952e-05 loss)
I1022 13:57:05.916478 25759 sgd_solver.cpp:106] Iteration 12560, lr = 2e-05
I1022 13:58:28.965613 25759 solver.cpp:228] Iteration 12580, loss = 0.0373425
I1022 13:58:28.965644 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 13:58:28.965651 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 13:58:28.965657 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0110356 (* 1 = 0.0110356 loss)
I1022 13:58:28.965662 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00931217 (* 1 = 0.00931217 loss)
I1022 13:58:28.965667 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00778758 (* 1 = 0.00778758 loss)
I1022 13:58:28.965670 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00602113 (* 1 = 0.00602113 loss)
I1022 13:58:28.965675 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.40053e-05 (* 1 = 1.40053e-05 loss)
I1022 13:58:28.965679 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.84602e-05 (* 1 = 1.84602e-05 loss)
I1022 13:58:28.965683 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00216935 (* 1 = 0.00216935 loss)
I1022 13:58:28.965687 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.02259e-05 (* 1 = 2.02259e-05 loss)
I1022 13:58:28.965695 25759 sgd_solver.cpp:106] Iteration 12580, lr = 2e-05
speed: 4.210s / iter
I1022 13:59:53.738338 25759 solver.cpp:228] Iteration 12600, loss = 0.0772748
I1022 13:59:53.738415 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994464
I1022 13:59:53.738426 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.993007
I1022 13:59:53.738443 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0473514 (* 1 = 0.0473514 loss)
I1022 13:59:53.738454 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0255711 (* 1 = 0.0255711 loss)
I1022 13:59:53.738464 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0146459 (* 1 = 0.0146459 loss)
I1022 13:59:53.738485 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0196602 (* 1 = 0.0196602 loss)
I1022 13:59:53.738499 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00141538 (* 1 = 0.00141538 loss)
I1022 13:59:53.738510 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.3636e-05 (* 1 = 1.3636e-05 loss)
I1022 13:59:53.738523 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0184505 (* 1 = 0.0184505 loss)
I1022 13:59:53.738536 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.04933e-05 (* 1 = 2.04933e-05 loss)
I1022 13:59:53.738553 25759 sgd_solver.cpp:106] Iteration 12600, lr = 2e-05
I1022 14:01:17.532972 25759 solver.cpp:228] Iteration 12620, loss = 0.0620526
I1022 14:01:17.533012 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994006
I1022 14:01:17.533020 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997003
I1022 14:01:17.533028 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0108067 (* 1 = 0.0108067 loss)
I1022 14:01:17.533035 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0118334 (* 1 = 0.0118334 loss)
I1022 14:01:17.533041 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0196543 (* 1 = 0.0196543 loss)
I1022 14:01:17.533046 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0126964 (* 1 = 0.0126964 loss)
I1022 14:01:17.533052 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000338692 (* 1 = 0.000338692 loss)
I1022 14:01:17.533057 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.67032e-05 (* 1 = 1.67032e-05 loss)
I1022 14:01:17.533063 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00821857 (* 1 = 0.00821857 loss)
I1022 14:01:17.533069 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00011065 (* 1 = 0.00011065 loss)
I1022 14:01:17.533077 25759 sgd_solver.cpp:106] Iteration 12620, lr = 2e-05
I1022 14:02:43.304908 25759 solver.cpp:228] Iteration 12640, loss = 0.0797107
I1022 14:02:43.304949 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995507
I1022 14:02:43.304955 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997504
I1022 14:02:43.304965 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0201284 (* 1 = 0.0201284 loss)
I1022 14:02:43.304971 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0146506 (* 1 = 0.0146506 loss)
I1022 14:02:43.304976 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0212189 (* 1 = 0.0212189 loss)
I1022 14:02:43.304982 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0129289 (* 1 = 0.0129289 loss)
I1022 14:02:43.304988 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.07237e-05 (* 1 = 4.07237e-05 loss)
I1022 14:02:43.304994 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.32922e-05 (* 1 = 1.32922e-05 loss)
I1022 14:02:43.305001 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00487953 (* 1 = 0.00487953 loss)
I1022 14:02:43.305006 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 3.43323e-05 (* 1 = 3.43323e-05 loss)
I1022 14:02:43.305017 25759 sgd_solver.cpp:106] Iteration 12640, lr = 2e-05
I1022 14:04:07.766535 25759 solver.cpp:228] Iteration 12660, loss = 0.0253766
I1022 14:04:07.766620 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997003
I1022 14:04:07.766633 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 14:04:07.766649 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0229295 (* 1 = 0.0229295 loss)
I1022 14:04:07.766661 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0348916 (* 1 = 0.0348916 loss)
I1022 14:04:07.766672 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0155529 (* 1 = 0.0155529 loss)
I1022 14:04:07.766686 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0133138 (* 1 = 0.0133138 loss)
I1022 14:04:07.766700 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.06354e-05 (* 1 = 7.06354e-05 loss)
I1022 14:04:07.766713 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.48941e-05 (* 1 = 1.48941e-05 loss)
I1022 14:04:07.766727 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00401047 (* 1 = 0.00401047 loss)
I1022 14:04:07.766741 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 3.40997e-05 (* 1 = 3.40997e-05 loss)
I1022 14:04:07.766755 25759 sgd_solver.cpp:106] Iteration 12660, lr = 2e-05
I1022 14:05:32.140791 25759 solver.cpp:228] Iteration 12680, loss = 0.119304
I1022 14:05:32.140841 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996921
I1022 14:05:32.140846 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996004
I1022 14:05:32.140853 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0160698 (* 1 = 0.0160698 loss)
I1022 14:05:32.140858 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0151537 (* 1 = 0.0151537 loss)
I1022 14:05:32.140863 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00920447 (* 1 = 0.00920447 loss)
I1022 14:05:32.140868 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0122366 (* 1 = 0.0122366 loss)
I1022 14:05:32.140872 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000302087 (* 1 = 0.000302087 loss)
I1022 14:05:32.140877 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.94881e-06 (* 1 = 6.94881e-06 loss)
I1022 14:05:32.140882 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0103064 (* 1 = 0.0103064 loss)
I1022 14:05:32.140887 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 8.18814e-05 (* 1 = 8.18814e-05 loss)
I1022 14:05:32.140895 25759 sgd_solver.cpp:106] Iteration 12680, lr = 2e-05
I1022 14:06:57.599716 25759 solver.cpp:228] Iteration 12700, loss = 0.0259573
I1022 14:06:57.599802 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 14:06:57.599814 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:06:57.599831 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:06:57.599841 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:06:57.599853 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00437719 (* 1 = 0.00437719 loss)
I1022 14:06:57.599866 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00450301 (* 1 = 0.00450301 loss)
I1022 14:06:57.599880 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 9.58274e-05 (* 1 = 9.58274e-05 loss)
I1022 14:06:57.599894 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.84762e-05 (* 1 = 1.84762e-05 loss)
I1022 14:06:57.599905 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000429066 (* 1 = 0.000429066 loss)
I1022 14:06:57.599918 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 3.10371e-05 (* 1 = 3.10371e-05 loss)
I1022 14:06:57.599938 25759 sgd_solver.cpp:106] Iteration 12700, lr = 2e-05
I1022 14:08:21.662179 25759 solver.cpp:228] Iteration 12720, loss = 0.043813
I1022 14:08:21.662227 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997003
I1022 14:08:21.662236 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 14:08:21.662248 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00631875 (* 1 = 0.00631875 loss)
I1022 14:08:21.662256 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00639714 (* 1 = 0.00639714 loss)
I1022 14:08:21.662264 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0140071 (* 1 = 0.0140071 loss)
I1022 14:08:21.662272 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00968837 (* 1 = 0.00968837 loss)
I1022 14:08:21.662281 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.63758e-05 (* 1 = 3.63758e-05 loss)
I1022 14:08:21.662287 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.11988e-06 (* 1 = 6.11988e-06 loss)
I1022 14:08:21.662295 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00215015 (* 1 = 0.00215015 loss)
I1022 14:08:21.662303 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.18204e-05 (* 1 = 1.18204e-05 loss)
I1022 14:08:21.662320 25759 sgd_solver.cpp:106] Iteration 12720, lr = 2e-05
I1022 14:09:45.920251 25759 solver.cpp:228] Iteration 12740, loss = 0.0362846
I1022 14:09:45.920289 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996988
I1022 14:09:45.920295 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 14:09:45.920305 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0123833 (* 1 = 0.0123833 loss)
I1022 14:09:45.920310 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00679514 (* 1 = 0.00679514 loss)
I1022 14:09:45.920315 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00856392 (* 1 = 0.00856392 loss)
I1022 14:09:45.920321 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00691705 (* 1 = 0.00691705 loss)
I1022 14:09:45.920327 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.37423e-05 (* 1 = 3.37423e-05 loss)
I1022 14:09:45.920333 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.10373e-06 (* 1 = 8.10373e-06 loss)
I1022 14:09:45.920339 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00296446 (* 1 = 0.00296446 loss)
I1022 14:09:45.920346 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000115767 (* 1 = 0.000115767 loss)
I1022 14:09:45.920353 25759 sgd_solver.cpp:106] Iteration 12740, lr = 2e-05
I1022 14:11:10.000710 25759 solver.cpp:228] Iteration 12760, loss = 0.0332061
I1022 14:11:10.000758 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 14:11:10.000764 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:11:10.000771 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:11:10.000775 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:11:10.000780 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000238562 (* 1 = 0.000238562 loss)
I1022 14:11:10.000784 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00422398 (* 1 = 0.00422398 loss)
I1022 14:11:10.000789 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.74862e-05 (* 1 = 4.74862e-05 loss)
I1022 14:11:10.000793 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.29713e-06 (* 1 = 7.29713e-06 loss)
I1022 14:11:10.000798 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000712463 (* 1 = 0.000712463 loss)
I1022 14:11:10.000803 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000611609 (* 1 = 0.000611609 loss)
I1022 14:11:10.000808 25759 sgd_solver.cpp:106] Iteration 12760, lr = 2e-05
I1022 14:12:33.124286 25759 solver.cpp:228] Iteration 12780, loss = 0.074758
I1022 14:12:33.124349 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.993795
I1022 14:12:33.124356 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.996509
I1022 14:12:33.124364 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0516199 (* 1 = 0.0516199 loss)
I1022 14:12:33.124369 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0175027 (* 1 = 0.0175027 loss)
I1022 14:12:33.124374 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0168874 (* 1 = 0.0168874 loss)
I1022 14:12:33.124378 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.022475 (* 1 = 0.022475 loss)
I1022 14:12:33.124383 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.49256e-05 (* 1 = 7.49256e-05 loss)
I1022 14:12:33.124388 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.08276e-05 (* 1 = 1.08276e-05 loss)
I1022 14:12:33.124393 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0114139 (* 1 = 0.0114139 loss)
I1022 14:12:33.124398 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000386812 (* 1 = 0.000386812 loss)
I1022 14:12:33.124404 25759 sgd_solver.cpp:106] Iteration 12780, lr = 2e-05
speed: 4.210s / iter
I1022 14:13:59.144032 25759 solver.cpp:228] Iteration 12800, loss = 0.046585
I1022 14:13:59.144070 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996929
I1022 14:13:59.144078 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 14:13:59.144086 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00433944 (* 1 = 0.00433944 loss)
I1022 14:13:59.144093 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00638738 (* 1 = 0.00638738 loss)
I1022 14:13:59.144098 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00679752 (* 1 = 0.00679752 loss)
I1022 14:13:59.144106 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00857225 (* 1 = 0.00857225 loss)
I1022 14:13:59.144112 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00017419 (* 1 = 0.00017419 loss)
I1022 14:13:59.144119 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.18473e-06 (* 1 = 6.18473e-06 loss)
I1022 14:13:59.144124 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00575275 (* 1 = 0.00575275 loss)
I1022 14:13:59.144130 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.89523e-05 (* 1 = 2.89523e-05 loss)
I1022 14:13:59.144137 25759 sgd_solver.cpp:106] Iteration 12800, lr = 2e-05
I1022 14:15:23.717844 25759 solver.cpp:228] Iteration 12820, loss = 0.0800704
I1022 14:15:23.717903 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.991474
I1022 14:15:23.717909 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995507
I1022 14:15:23.717917 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0202371 (* 1 = 0.0202371 loss)
I1022 14:15:23.717926 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0211995 (* 1 = 0.0211995 loss)
I1022 14:15:23.717929 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0239573 (* 1 = 0.0239573 loss)
I1022 14:15:23.717933 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0178231 (* 1 = 0.0178231 loss)
I1022 14:15:23.717939 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00111569 (* 1 = 0.00111569 loss)
I1022 14:15:23.717944 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.84418e-05 (* 1 = 2.84418e-05 loss)
I1022 14:15:23.717948 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00929769 (* 1 = 0.00929769 loss)
I1022 14:15:23.717969 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000350042 (* 1 = 0.000350042 loss)
I1022 14:15:23.717977 25759 sgd_solver.cpp:106] Iteration 12820, lr = 2e-05
I1022 14:16:47.749591 25759 solver.cpp:228] Iteration 12840, loss = 0.0387936
I1022 14:16:47.749645 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 14:16:47.749652 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:16:47.749662 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:16:47.749670 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:16:47.749677 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00452381 (* 1 = 0.00452381 loss)
I1022 14:16:47.749686 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00438373 (* 1 = 0.00438373 loss)
I1022 14:16:47.749693 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.7553e-05 (* 1 = 6.7553e-05 loss)
I1022 14:16:47.749701 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.39205e-06 (* 1 = 6.39205e-06 loss)
I1022 14:16:47.749708 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000125714 (* 1 = 0.000125714 loss)
I1022 14:16:47.749716 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000197106 (* 1 = 0.000197106 loss)
I1022 14:16:47.749722 25759 sgd_solver.cpp:106] Iteration 12840, lr = 2e-05
I1022 14:18:12.076727 25759 solver.cpp:228] Iteration 12860, loss = 0.0330754
I1022 14:18:12.076792 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 14:18:12.076803 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 14:18:12.076817 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00363915 (* 1 = 0.00363915 loss)
I1022 14:18:12.076828 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00812715 (* 1 = 0.00812715 loss)
I1022 14:18:12.076836 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0108717 (* 1 = 0.0108717 loss)
I1022 14:18:12.076846 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00914133 (* 1 = 0.00914133 loss)
I1022 14:18:12.076855 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00215098 (* 1 = 0.00215098 loss)
I1022 14:18:12.076869 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.8684e-05 (* 1 = 3.8684e-05 loss)
I1022 14:18:12.076879 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00893801 (* 1 = 0.00893801 loss)
I1022 14:18:12.076892 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000120318 (* 1 = 0.000120318 loss)
I1022 14:18:12.076905 25759 sgd_solver.cpp:106] Iteration 12860, lr = 2e-05
I1022 14:19:35.535995 25759 solver.cpp:228] Iteration 12880, loss = 0.0709065
I1022 14:19:35.536028 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.995502
I1022 14:19:35.536033 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 14:19:35.536041 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0263396 (* 1 = 0.0263396 loss)
I1022 14:19:35.536044 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0237394 (* 1 = 0.0237394 loss)
I1022 14:19:35.536048 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0122934 (* 1 = 0.0122934 loss)
I1022 14:19:35.536052 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0138947 (* 1 = 0.0138947 loss)
I1022 14:19:35.536057 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00423851 (* 1 = 0.00423851 loss)
I1022 14:19:35.536062 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.01263e-05 (* 1 = 1.01263e-05 loss)
I1022 14:19:35.536067 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0225539 (* 1 = 0.0225539 loss)
I1022 14:19:35.536072 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000118088 (* 1 = 0.000118088 loss)
I1022 14:19:35.536077 25759 sgd_solver.cpp:106] Iteration 12880, lr = 2e-05
I1022 14:20:58.626446 25759 solver.cpp:228] Iteration 12900, loss = 0.0884389
I1022 14:20:58.626513 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 14:20:58.626524 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:20:58.626543 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:20:58.626552 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:20:58.626564 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000299607 (* 1 = 0.000299607 loss)
I1022 14:20:58.626576 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00448988 (* 1 = 0.00448988 loss)
I1022 14:20:58.626588 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.61318e-05 (* 1 = 6.61318e-05 loss)
I1022 14:20:58.626600 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.26646e-06 (* 1 = 8.26646e-06 loss)
I1022 14:20:58.626612 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 3.63428e-05 (* 1 = 3.63428e-05 loss)
I1022 14:20:58.626626 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 3.25307e-05 (* 1 = 3.25307e-05 loss)
I1022 14:20:58.626639 25759 sgd_solver.cpp:106] Iteration 12900, lr = 2e-05
I1022 14:22:21.205508 25759 solver.cpp:228] Iteration 12920, loss = 0.0634008
I1022 14:22:21.205562 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998002
I1022 14:22:21.205569 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999001
I1022 14:22:21.205575 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0126562 (* 1 = 0.0126562 loss)
I1022 14:22:21.205584 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00232693 (* 1 = 0.00232693 loss)
I1022 14:22:21.205587 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0134443 (* 1 = 0.0134443 loss)
I1022 14:22:21.205592 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00844847 (* 1 = 0.00844847 loss)
I1022 14:22:21.205597 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.99584e-05 (* 1 = 2.99584e-05 loss)
I1022 14:22:21.205602 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.23322e-05 (* 1 = 1.23322e-05 loss)
I1022 14:22:21.205606 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00268047 (* 1 = 0.00268047 loss)
I1022 14:22:21.205612 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000106221 (* 1 = 0.000106221 loss)
I1022 14:22:21.205618 25759 sgd_solver.cpp:106] Iteration 12920, lr = 2e-05
I1022 14:23:42.928484 25759 solver.cpp:228] Iteration 12940, loss = 0.0580773
I1022 14:23:42.928539 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 14:23:42.928545 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:23:42.928552 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:23:42.928560 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:23:42.928565 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00481822 (* 1 = 0.00481822 loss)
I1022 14:23:42.928570 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00445236 (* 1 = 0.00445236 loss)
I1022 14:23:42.928573 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000133075 (* 1 = 0.000133075 loss)
I1022 14:23:42.928578 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.16857e-05 (* 1 = 1.16857e-05 loss)
I1022 14:23:42.928583 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000434323 (* 1 = 0.000434323 loss)
I1022 14:23:42.928588 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 5.43811e-05 (* 1 = 5.43811e-05 loss)
I1022 14:23:42.928594 25759 sgd_solver.cpp:106] Iteration 12940, lr = 2e-05
I1022 14:25:06.386106 25759 solver.cpp:228] Iteration 12960, loss = 0.0565723
I1022 14:25:06.386155 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994009
I1022 14:25:06.386160 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998003
I1022 14:25:06.386168 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0268692 (* 1 = 0.0268692 loss)
I1022 14:25:06.386173 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.010216 (* 1 = 0.010216 loss)
I1022 14:25:06.386178 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0229524 (* 1 = 0.0229524 loss)
I1022 14:25:06.386181 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0128158 (* 1 = 0.0128158 loss)
I1022 14:25:06.386186 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.06104e-05 (* 1 = 7.06104e-05 loss)
I1022 14:25:06.386190 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.7467e-05 (* 1 = 1.7467e-05 loss)
I1022 14:25:06.386195 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00597063 (* 1 = 0.00597063 loss)
I1022 14:25:06.386200 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000161032 (* 1 = 0.000161032 loss)
I1022 14:25:06.386209 25759 sgd_solver.cpp:106] Iteration 12960, lr = 2e-05
I1022 14:26:31.036231 25759 solver.cpp:228] Iteration 12980, loss = 0.116853
I1022 14:26:31.036303 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.985356
I1022 14:26:31.036314 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.989055
I1022 14:26:31.036329 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.241777 (* 1 = 0.241777 loss)
I1022 14:26:31.036340 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0941503 (* 1 = 0.0941503 loss)
I1022 14:26:31.036350 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.03957 (* 1 = 0.03957 loss)
I1022 14:26:31.036372 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0509935 (* 1 = 0.0509935 loss)
I1022 14:26:31.036384 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000194399 (* 1 = 0.000194399 loss)
I1022 14:26:31.036396 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.38368e-05 (* 1 = 1.38368e-05 loss)
I1022 14:26:31.036408 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0446115 (* 1 = 0.0446115 loss)
I1022 14:26:31.036420 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000323827 (* 1 = 0.000323827 loss)
I1022 14:26:31.036433 25759 sgd_solver.cpp:106] Iteration 12980, lr = 2e-05
speed: 4.210s / iter
I1022 14:27:55.152323 25759 solver.cpp:228] Iteration 13000, loss = 0.144686
I1022 14:27:55.152365 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.965649
I1022 14:27:55.152372 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.979643
I1022 14:27:55.152382 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.26086 (* 1 = 0.26086 loss)
I1022 14:27:55.152390 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.122069 (* 1 = 0.122069 loss)
I1022 14:27:55.152395 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0937845 (* 1 = 0.0937845 loss)
I1022 14:27:55.152401 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0822172 (* 1 = 0.0822172 loss)
I1022 14:27:55.152408 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00988674 (* 1 = 0.00988674 loss)
I1022 14:27:55.152416 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.43606e-05 (* 1 = 2.43606e-05 loss)
I1022 14:27:55.152424 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0746497 (* 1 = 0.0746497 loss)
I1022 14:27:55.152432 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000450947 (* 1 = 0.000450947 loss)
I1022 14:27:55.152441 25759 sgd_solver.cpp:106] Iteration 13000, lr = 2e-05
I1022 14:29:19.179291 25759 solver.cpp:228] Iteration 13020, loss = 0.169897
I1022 14:29:19.179332 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 14:29:19.179340 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:29:19.179350 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:29:19.179358 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:29:19.179365 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000225838 (* 1 = 0.000225838 loss)
I1022 14:29:19.179374 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00409505 (* 1 = 0.00409505 loss)
I1022 14:29:19.179381 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.36532e-05 (* 1 = 3.36532e-05 loss)
I1022 14:29:19.179389 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.8796e-06 (* 1 = 9.8796e-06 loss)
I1022 14:29:19.179396 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000144729 (* 1 = 0.000144729 loss)
I1022 14:29:19.179404 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000346602 (* 1 = 0.000346602 loss)
I1022 14:29:19.179414 25759 sgd_solver.cpp:106] Iteration 13020, lr = 2e-05
I1022 14:30:44.544392 25759 solver.cpp:228] Iteration 13040, loss = 0.0254632
I1022 14:30:44.544478 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 14:30:44.544493 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:30:44.544509 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:30:44.544522 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:30:44.544533 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00457711 (* 1 = 0.00457711 loss)
I1022 14:30:44.544548 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00445422 (* 1 = 0.00445422 loss)
I1022 14:30:44.544560 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.98408e-05 (* 1 = 4.98408e-05 loss)
I1022 14:30:44.544574 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.43499e-06 (* 1 = 9.43499e-06 loss)
I1022 14:30:44.544586 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000233367 (* 1 = 0.000233367 loss)
I1022 14:30:44.544600 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000495914 (* 1 = 0.000495914 loss)
I1022 14:30:44.544636 25759 sgd_solver.cpp:106] Iteration 13040, lr = 2e-05
I1022 14:32:09.511605 25759 solver.cpp:228] Iteration 13060, loss = 0.0856434
I1022 14:32:09.511651 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.98715
I1022 14:32:09.511669 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.986534
I1022 14:32:09.511682 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0642799 (* 1 = 0.0642799 loss)
I1022 14:32:09.511688 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0605318 (* 1 = 0.0605318 loss)
I1022 14:32:09.511694 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0336432 (* 1 = 0.0336432 loss)
I1022 14:32:09.511703 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0433899 (* 1 = 0.0433899 loss)
I1022 14:32:09.511710 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00661891 (* 1 = 0.00661891 loss)
I1022 14:32:09.511718 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.17352e-05 (* 1 = 2.17352e-05 loss)
I1022 14:32:09.511725 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0722575 (* 1 = 0.0722575 loss)
I1022 14:32:09.511739 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000101601 (* 1 = 0.000101601 loss)
I1022 14:32:09.511746 25759 sgd_solver.cpp:106] Iteration 13060, lr = 2e-05
I1022 14:33:36.639427 25759 solver.cpp:228] Iteration 13080, loss = 0.0859678
I1022 14:33:36.639482 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994006
I1022 14:33:36.639489 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997503
I1022 14:33:36.639499 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0164042 (* 1 = 0.0164042 loss)
I1022 14:33:36.639506 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0119299 (* 1 = 0.0119299 loss)
I1022 14:33:36.639511 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0197937 (* 1 = 0.0197937 loss)
I1022 14:33:36.639518 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.01399 (* 1 = 0.01399 loss)
I1022 14:33:36.639524 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000175116 (* 1 = 0.000175116 loss)
I1022 14:33:36.639530 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.19525e-05 (* 1 = 1.19525e-05 loss)
I1022 14:33:36.639536 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00445291 (* 1 = 0.00445291 loss)
I1022 14:33:36.639542 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000106108 (* 1 = 0.000106108 loss)
I1022 14:33:36.639549 25759 sgd_solver.cpp:106] Iteration 13080, lr = 2e-05
I1022 14:35:01.539923 25759 solver.cpp:228] Iteration 13100, loss = 0.0153424
I1022 14:35:01.539957 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996994
I1022 14:35:01.539961 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997002
I1022 14:35:01.539968 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00320232 (* 1 = 0.00320232 loss)
I1022 14:35:01.539973 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00931513 (* 1 = 0.00931513 loss)
I1022 14:35:01.539978 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00632602 (* 1 = 0.00632602 loss)
I1022 14:35:01.539981 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0106292 (* 1 = 0.0106292 loss)
I1022 14:35:01.539985 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.30912e-05 (* 1 = 7.30912e-05 loss)
I1022 14:35:01.539990 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.05799e-05 (* 1 = 1.05799e-05 loss)
I1022 14:35:01.539994 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00357281 (* 1 = 0.00357281 loss)
I1022 14:35:01.539999 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000145615 (* 1 = 0.000145615 loss)
I1022 14:35:01.540004 25759 sgd_solver.cpp:106] Iteration 13100, lr = 2e-05
I1022 14:36:26.923772 25759 solver.cpp:228] Iteration 13120, loss = 0.0536802
I1022 14:36:26.923825 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997495
I1022 14:36:26.923835 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 14:36:26.923848 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00477224 (* 1 = 0.00477224 loss)
I1022 14:36:26.923859 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0108167 (* 1 = 0.0108167 loss)
I1022 14:36:26.923867 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00683148 (* 1 = 0.00683148 loss)
I1022 14:36:26.923877 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0102206 (* 1 = 0.0102206 loss)
I1022 14:36:26.923887 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000506704 (* 1 = 0.000506704 loss)
I1022 14:36:26.923897 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.51674e-06 (* 1 = 8.51674e-06 loss)
I1022 14:36:26.923908 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00452916 (* 1 = 0.00452916 loss)
I1022 14:36:26.923919 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.35694e-05 (* 1 = 2.35694e-05 loss)
I1022 14:36:26.923929 25759 sgd_solver.cpp:106] Iteration 13120, lr = 2e-05
I1022 14:37:52.557293 25759 solver.cpp:228] Iteration 13140, loss = 0.031642
I1022 14:37:52.557343 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 14:37:52.557348 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:37:52.557354 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:37:52.557360 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:37:52.557365 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00034052 (* 1 = 0.00034052 loss)
I1022 14:37:52.557370 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00460984 (* 1 = 0.00460984 loss)
I1022 14:37:52.557374 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.52309e-05 (* 1 = 5.52309e-05 loss)
I1022 14:37:52.557379 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.93116e-06 (* 1 = 3.93116e-06 loss)
I1022 14:37:52.557384 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 6.77494e-05 (* 1 = 6.77494e-05 loss)
I1022 14:37:52.557389 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.2524e-05 (* 1 = 2.2524e-05 loss)
I1022 14:37:52.557394 25759 sgd_solver.cpp:106] Iteration 13140, lr = 2e-05
I1022 14:39:17.254679 25759 solver.cpp:228] Iteration 13160, loss = 0.0200634
I1022 14:39:17.254719 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 14:39:17.254726 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:39:17.254734 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:39:17.254740 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:39:17.254748 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00948177 (* 1 = 0.00948177 loss)
I1022 14:39:17.254755 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00449651 (* 1 = 0.00449651 loss)
I1022 14:39:17.254760 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.6405e-05 (* 1 = 4.6405e-05 loss)
I1022 14:39:17.254766 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.0089e-06 (* 1 = 6.0089e-06 loss)
I1022 14:39:17.254772 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000229518 (* 1 = 0.000229518 loss)
I1022 14:39:17.254778 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 8.6064e-05 (* 1 = 8.6064e-05 loss)
I1022 14:39:17.254784 25759 sgd_solver.cpp:106] Iteration 13160, lr = 2e-05
I1022 14:40:43.354120 25759 solver.cpp:228] Iteration 13180, loss = 0.0540048
I1022 14:40:43.354168 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996004
I1022 14:40:43.354174 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999001
I1022 14:40:43.354182 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0238369 (* 1 = 0.0238369 loss)
I1022 14:40:43.354185 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00633601 (* 1 = 0.00633601 loss)
I1022 14:40:43.354190 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0156435 (* 1 = 0.0156435 loss)
I1022 14:40:43.354194 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00862465 (* 1 = 0.00862465 loss)
I1022 14:40:43.354199 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000301649 (* 1 = 0.000301649 loss)
I1022 14:40:43.354203 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.44564e-06 (* 1 = 8.44564e-06 loss)
I1022 14:40:43.354208 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00565165 (* 1 = 0.00565165 loss)
I1022 14:40:43.354213 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000580235 (* 1 = 0.000580235 loss)
I1022 14:40:43.354219 25759 sgd_solver.cpp:106] Iteration 13180, lr = 2e-05
speed: 4.211s / iter
I1022 14:42:08.203271 25759 solver.cpp:228] Iteration 13200, loss = 0.159443
I1022 14:42:08.203325 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997972
I1022 14:42:08.203333 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.997503
I1022 14:42:08.203343 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0135226 (* 1 = 0.0135226 loss)
I1022 14:42:08.203349 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0157836 (* 1 = 0.0157836 loss)
I1022 14:42:08.203356 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00655418 (* 1 = 0.00655418 loss)
I1022 14:42:08.203361 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0135829 (* 1 = 0.0135829 loss)
I1022 14:42:08.203369 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.961e-05 (* 1 = 2.961e-05 loss)
I1022 14:42:08.203377 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.39991e-06 (* 1 = 9.39991e-06 loss)
I1022 14:42:08.203384 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00280641 (* 1 = 0.00280641 loss)
I1022 14:42:08.203392 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000217894 (* 1 = 0.000217894 loss)
I1022 14:42:08.203403 25759 sgd_solver.cpp:106] Iteration 13200, lr = 2e-05
I1022 14:43:32.203316 25759 solver.cpp:228] Iteration 13220, loss = 0.0218686
I1022 14:43:32.203372 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 14:43:32.203378 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:43:32.203385 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:43:32.203389 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:43:32.203394 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00445078 (* 1 = 0.00445078 loss)
I1022 14:43:32.203399 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00441737 (* 1 = 0.00441737 loss)
I1022 14:43:32.203404 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.83335e-05 (* 1 = 4.83335e-05 loss)
I1022 14:43:32.203408 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.76432e-06 (* 1 = 8.76432e-06 loss)
I1022 14:43:32.203413 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000791674 (* 1 = 0.000791674 loss)
I1022 14:43:32.203418 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 8.748e-05 (* 1 = 8.748e-05 loss)
I1022 14:43:32.203428 25759 sgd_solver.cpp:106] Iteration 13220, lr = 2e-05
I1022 14:44:56.144784 25759 solver.cpp:228] Iteration 13240, loss = 0.0451199
I1022 14:44:56.144830 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996362
I1022 14:44:56.144848 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998002
I1022 14:44:56.144857 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0128876 (* 1 = 0.0128876 loss)
I1022 14:44:56.144867 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0157169 (* 1 = 0.0157169 loss)
I1022 14:44:56.144873 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0113231 (* 1 = 0.0113231 loss)
I1022 14:44:56.144879 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0115137 (* 1 = 0.0115137 loss)
I1022 14:44:56.144886 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.62069e-05 (* 1 = 5.62069e-05 loss)
I1022 14:44:56.144891 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.27554e-05 (* 1 = 1.27554e-05 loss)
I1022 14:44:56.144897 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00512995 (* 1 = 0.00512995 loss)
I1022 14:44:56.144904 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.56024e-05 (* 1 = 1.56024e-05 loss)
I1022 14:44:56.144912 25759 sgd_solver.cpp:106] Iteration 13240, lr = 2e-05
I1022 14:46:20.411116 25759 solver.cpp:228] Iteration 13260, loss = 0.0446913
I1022 14:46:20.411180 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998001
I1022 14:46:20.411185 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 14:46:20.411195 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00439156 (* 1 = 0.00439156 loss)
I1022 14:46:20.411201 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00313302 (* 1 = 0.00313302 loss)
I1022 14:46:20.411206 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00737168 (* 1 = 0.00737168 loss)
I1022 14:46:20.411211 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00590034 (* 1 = 0.00590034 loss)
I1022 14:46:20.411214 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.5752e-05 (* 1 = 1.5752e-05 loss)
I1022 14:46:20.411219 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.65036e-06 (* 1 = 8.65036e-06 loss)
I1022 14:46:20.411224 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000660978 (* 1 = 0.000660978 loss)
I1022 14:46:20.411229 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 3.55642e-05 (* 1 = 3.55642e-05 loss)
I1022 14:46:20.411237 25759 sgd_solver.cpp:106] Iteration 13260, lr = 2e-05
I1022 14:47:47.199913 25759 solver.cpp:228] Iteration 13280, loss = 0.0380971
I1022 14:47:47.199970 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 14:47:47.199978 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 14:47:47.199988 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00558399 (* 1 = 0.00558399 loss)
I1022 14:47:47.199995 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00511274 (* 1 = 0.00511274 loss)
I1022 14:47:47.200001 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.01167 (* 1 = 0.01167 loss)
I1022 14:47:47.200007 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00809593 (* 1 = 0.00809593 loss)
I1022 14:47:47.200013 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000285736 (* 1 = 0.000285736 loss)
I1022 14:47:47.200021 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.13642e-05 (* 1 = 1.13642e-05 loss)
I1022 14:47:47.200026 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00568958 (* 1 = 0.00568958 loss)
I1022 14:47:47.200032 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000579012 (* 1 = 0.000579012 loss)
I1022 14:47:47.200039 25759 sgd_solver.cpp:106] Iteration 13280, lr = 2e-05
I1022 14:49:12.418272 25759 solver.cpp:228] Iteration 13300, loss = 0.063833
I1022 14:49:12.418323 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 14:49:12.418329 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 14:49:12.418335 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00525931 (* 1 = 0.00525931 loss)
I1022 14:49:12.418340 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000400086 (* 1 = 0.000400086 loss)
I1022 14:49:12.418345 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00658025 (* 1 = 0.00658025 loss)
I1022 14:49:12.418349 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00571328 (* 1 = 0.00571328 loss)
I1022 14:49:12.418354 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 1.83879e-05 (* 1 = 1.83879e-05 loss)
I1022 14:49:12.418359 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.048e-05 (* 1 = 1.048e-05 loss)
I1022 14:49:12.418364 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000638365 (* 1 = 0.000638365 loss)
I1022 14:49:12.418368 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000162001 (* 1 = 0.000162001 loss)
I1022 14:49:12.418375 25759 sgd_solver.cpp:106] Iteration 13300, lr = 2e-05
I1022 14:50:37.796012 25759 solver.cpp:228] Iteration 13320, loss = 0.053858
I1022 14:50:37.796097 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 14:50:37.796109 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:50:37.796124 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:50:37.796134 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:50:37.796145 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00447034 (* 1 = 0.00447034 loss)
I1022 14:50:37.796157 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00412766 (* 1 = 0.00412766 loss)
I1022 14:50:37.796170 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.32479e-05 (* 1 = 7.32479e-05 loss)
I1022 14:50:37.796183 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.50267e-06 (* 1 = 6.50267e-06 loss)
I1022 14:50:37.796195 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000526488 (* 1 = 0.000526488 loss)
I1022 14:50:37.796207 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000103871 (* 1 = 0.000103871 loss)
I1022 14:50:37.796219 25759 sgd_solver.cpp:106] Iteration 13320, lr = 2e-05
I1022 14:52:04.814985 25759 solver.cpp:228] Iteration 13340, loss = 0.0430575
I1022 14:52:04.815018 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 14:52:04.815023 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 14:52:04.815030 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00424004 (* 1 = 0.00424004 loss)
I1022 14:52:04.815035 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00529192 (* 1 = 0.00529192 loss)
I1022 14:52:04.815039 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00789243 (* 1 = 0.00789243 loss)
I1022 14:52:04.815043 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00496803 (* 1 = 0.00496803 loss)
I1022 14:52:04.815047 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.38439e-05 (* 1 = 4.38439e-05 loss)
I1022 14:52:04.815052 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.80584e-05 (* 1 = 1.80584e-05 loss)
I1022 14:52:04.815055 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00114079 (* 1 = 0.00114079 loss)
I1022 14:52:04.815060 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.76722e-05 (* 1 = 6.76722e-05 loss)
I1022 14:52:04.815065 25759 sgd_solver.cpp:106] Iteration 13340, lr = 2e-05
I1022 14:53:29.250417 25759 solver.cpp:228] Iteration 13360, loss = 0.114665
I1022 14:53:29.250478 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.969303
I1022 14:53:29.250486 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.982604
I1022 14:53:29.250505 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.12304 (* 1 = 0.12304 loss)
I1022 14:53:29.250512 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0924712 (* 1 = 0.0924712 loss)
I1022 14:53:29.250519 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0716115 (* 1 = 0.0716115 loss)
I1022 14:53:29.250527 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0661258 (* 1 = 0.0661258 loss)
I1022 14:53:29.250535 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.014753 (* 1 = 0.014753 loss)
I1022 14:53:29.250542 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.7194e-05 (* 1 = 1.7194e-05 loss)
I1022 14:53:29.250555 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.091024 (* 1 = 0.091024 loss)
I1022 14:53:29.250563 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.95181e-05 (* 1 = 6.95181e-05 loss)
I1022 14:53:29.250573 25759 sgd_solver.cpp:106] Iteration 13360, lr = 2e-05
I1022 14:54:53.271924 25759 solver.cpp:228] Iteration 13380, loss = 0.052005
I1022 14:54:53.271975 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.989516
I1022 14:54:53.271984 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.994508
I1022 14:54:53.271997 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0471358 (* 1 = 0.0471358 loss)
I1022 14:54:53.272006 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0454041 (* 1 = 0.0454041 loss)
I1022 14:54:53.272014 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0338653 (* 1 = 0.0338653 loss)
I1022 14:54:53.272023 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0215127 (* 1 = 0.0215127 loss)
I1022 14:54:53.272032 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000143613 (* 1 = 0.000143613 loss)
I1022 14:54:53.272040 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.53167e-05 (* 1 = 1.53167e-05 loss)
I1022 14:54:53.272049 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00785472 (* 1 = 0.00785472 loss)
I1022 14:54:53.272075 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000224651 (* 1 = 0.000224651 loss)
I1022 14:54:53.272085 25759 sgd_solver.cpp:106] Iteration 13380, lr = 2e-05
speed: 4.211s / iter
I1022 14:56:18.620738 25759 solver.cpp:228] Iteration 13400, loss = 0.0241071
I1022 14:56:18.620785 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 14:56:18.620790 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:56:18.620797 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:56:18.620802 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:56:18.620806 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00027782 (* 1 = 0.00027782 loss)
I1022 14:56:18.620811 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00437844 (* 1 = 0.00437844 loss)
I1022 14:56:18.620815 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.27612e-05 (* 1 = 5.27612e-05 loss)
I1022 14:56:18.620820 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.2049e-06 (* 1 = 6.2049e-06 loss)
I1022 14:56:18.620824 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000263837 (* 1 = 0.000263837 loss)
I1022 14:56:18.620829 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000137563 (* 1 = 0.000137563 loss)
I1022 14:56:18.620836 25759 sgd_solver.cpp:106] Iteration 13400, lr = 2e-05
I1022 14:57:44.871769 25759 solver.cpp:228] Iteration 13420, loss = 0.105164
I1022 14:57:44.871809 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 14:57:44.871815 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 14:57:44.871825 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0121349 (* 1 = 0.0121349 loss)
I1022 14:57:44.871831 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0028924 (* 1 = 0.0028924 loss)
I1022 14:57:44.871836 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00926793 (* 1 = 0.00926793 loss)
I1022 14:57:44.871842 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00658943 (* 1 = 0.00658943 loss)
I1022 14:57:44.871848 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.08649e-05 (* 1 = 2.08649e-05 loss)
I1022 14:57:44.871855 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.08187e-05 (* 1 = 2.08187e-05 loss)
I1022 14:57:44.871860 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0021379 (* 1 = 0.0021379 loss)
I1022 14:57:44.871865 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000228747 (* 1 = 0.000228747 loss)
I1022 14:57:44.871876 25759 sgd_solver.cpp:106] Iteration 13420, lr = 2e-05
I1022 14:59:09.705864 25759 solver.cpp:228] Iteration 13440, loss = 0.0696311
I1022 14:59:09.705904 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 14:59:09.705921 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 14:59:09.705931 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 14:59:09.705937 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 14:59:09.705943 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00490912 (* 1 = 0.00490912 loss)
I1022 14:59:09.705950 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00446404 (* 1 = 0.00446404 loss)
I1022 14:59:09.705957 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.74148e-05 (* 1 = 8.74148e-05 loss)
I1022 14:59:09.705963 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.90123e-06 (* 1 = 7.90123e-06 loss)
I1022 14:59:09.705970 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 8.03627e-05 (* 1 = 8.03627e-05 loss)
I1022 14:59:09.705976 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.9446e-05 (* 1 = 6.9446e-05 loss)
I1022 14:59:09.705992 25759 sgd_solver.cpp:106] Iteration 13440, lr = 2e-05
I1022 15:00:35.195924 25759 solver.cpp:228] Iteration 13460, loss = 0.067733
I1022 15:00:35.195962 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 15:00:35.195969 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:00:35.195978 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00997858 (* 1 = 0.00997858 loss)
I1022 15:00:35.195986 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00101016 (* 1 = 0.00101016 loss)
I1022 15:00:35.195991 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00707826 (* 1 = 0.00707826 loss)
I1022 15:00:35.195996 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00453047 (* 1 = 0.00453047 loss)
I1022 15:00:35.196002 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.72361e-05 (* 1 = 3.72361e-05 loss)
I1022 15:00:35.196008 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.73165e-06 (* 1 = 3.73165e-06 loss)
I1022 15:00:35.196017 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00152245 (* 1 = 0.00152245 loss)
I1022 15:00:35.196022 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 1.48638e-05 (* 1 = 1.48638e-05 loss)
I1022 15:00:35.196030 25759 sgd_solver.cpp:106] Iteration 13460, lr = 2e-05
I1022 15:01:58.195953 25759 solver.cpp:228] Iteration 13480, loss = 0.0473779
I1022 15:01:58.196009 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997503
I1022 15:01:58.196017 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 15:01:58.196028 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0110856 (* 1 = 0.0110856 loss)
I1022 15:01:58.196035 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0108959 (* 1 = 0.0108959 loss)
I1022 15:01:58.196041 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0146383 (* 1 = 0.0146383 loss)
I1022 15:01:58.196048 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00974386 (* 1 = 0.00974386 loss)
I1022 15:01:58.196055 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000173783 (* 1 = 0.000173783 loss)
I1022 15:01:58.196063 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.02111e-05 (* 1 = 1.02111e-05 loss)
I1022 15:01:58.196070 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00380507 (* 1 = 0.00380507 loss)
I1022 15:01:58.196077 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.52712e-05 (* 1 = 6.52712e-05 loss)
I1022 15:01:58.196085 25759 sgd_solver.cpp:106] Iteration 13480, lr = 2e-05
I1022 15:03:23.177273 25759 solver.cpp:228] Iteration 13500, loss = 0.0377343
I1022 15:03:23.177325 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.999
I1022 15:03:23.177345 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 15:03:23.177361 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00263218 (* 1 = 0.00263218 loss)
I1022 15:03:23.177372 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00840137 (* 1 = 0.00840137 loss)
I1022 15:03:23.177382 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00557502 (* 1 = 0.00557502 loss)
I1022 15:03:23.177392 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00851428 (* 1 = 0.00851428 loss)
I1022 15:03:23.177415 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000209582 (* 1 = 0.000209582 loss)
I1022 15:03:23.177428 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.66781e-06 (* 1 = 7.66781e-06 loss)
I1022 15:03:23.177438 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00517707 (* 1 = 0.00517707 loss)
I1022 15:03:23.177449 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000115083 (* 1 = 0.000115083 loss)
I1022 15:03:23.177464 25759 sgd_solver.cpp:106] Iteration 13500, lr = 2e-05
I1022 15:04:47.647135 25759 solver.cpp:228] Iteration 13520, loss = 0.0700008
I1022 15:04:47.647210 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998995
I1022 15:04:47.647225 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 15:04:47.647243 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0116726 (* 1 = 0.0116726 loss)
I1022 15:04:47.647256 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00111423 (* 1 = 0.00111423 loss)
I1022 15:04:47.647272 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00393914 (* 1 = 0.00393914 loss)
I1022 15:04:47.647287 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0051565 (* 1 = 0.0051565 loss)
I1022 15:04:47.647301 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.12265e-05 (* 1 = 7.12265e-05 loss)
I1022 15:04:47.647315 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 7.67668e-06 (* 1 = 7.67668e-06 loss)
I1022 15:04:47.647327 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00144637 (* 1 = 0.00144637 loss)
I1022 15:04:47.647341 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000270896 (* 1 = 0.000270896 loss)
I1022 15:04:47.647354 25759 sgd_solver.cpp:106] Iteration 13520, lr = 2e-05
I1022 15:06:12.465306 25759 solver.cpp:228] Iteration 13540, loss = 0.215827
I1022 15:06:12.465360 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997002
I1022 15:06:12.465368 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 15:06:12.465378 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00592418 (* 1 = 0.00592418 loss)
I1022 15:06:12.465384 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.000868861 (* 1 = 0.000868861 loss)
I1022 15:06:12.465390 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0104528 (* 1 = 0.0104528 loss)
I1022 15:06:12.465396 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00579619 (* 1 = 0.00579619 loss)
I1022 15:06:12.465402 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 5.95501e-05 (* 1 = 5.95501e-05 loss)
I1022 15:06:12.465409 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.08406e-05 (* 1 = 2.08406e-05 loss)
I1022 15:06:12.465415 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00140268 (* 1 = 0.00140268 loss)
I1022 15:06:12.465423 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.25317e-05 (* 1 = 6.25317e-05 loss)
I1022 15:06:12.465431 25759 sgd_solver.cpp:106] Iteration 13540, lr = 2e-05
I1022 15:07:36.971634 25759 solver.cpp:228] Iteration 13560, loss = 0.0776579
I1022 15:07:36.971679 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.994797
I1022 15:07:36.971688 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.992012
I1022 15:07:36.971698 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0125935 (* 1 = 0.0125935 loss)
I1022 15:07:36.971704 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0189381 (* 1 = 0.0189381 loss)
I1022 15:07:36.971712 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0182123 (* 1 = 0.0182123 loss)
I1022 15:07:36.971719 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0250843 (* 1 = 0.0250843 loss)
I1022 15:07:36.971725 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000607159 (* 1 = 0.000607159 loss)
I1022 15:07:36.971734 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 2.73399e-05 (* 1 = 2.73399e-05 loss)
I1022 15:07:36.971740 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0149784 (* 1 = 0.0149784 loss)
I1022 15:07:36.971748 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000345093 (* 1 = 0.000345093 loss)
I1022 15:07:36.971758 25759 sgd_solver.cpp:106] Iteration 13560, lr = 2e-05
I1022 15:09:02.013170 25759 solver.cpp:228] Iteration 13580, loss = 0.0325172
I1022 15:09:02.013226 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.99639
I1022 15:09:02.013236 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 15:09:02.013247 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0094433 (* 1 = 0.0094433 loss)
I1022 15:09:02.013254 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00891477 (* 1 = 0.00891477 loss)
I1022 15:09:02.013262 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00760427 (* 1 = 0.00760427 loss)
I1022 15:09:02.013269 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00680621 (* 1 = 0.00680621 loss)
I1022 15:09:02.013276 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 4.36878e-05 (* 1 = 4.36878e-05 loss)
I1022 15:09:02.013283 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.6654e-06 (* 1 = 9.6654e-06 loss)
I1022 15:09:02.013290 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00195282 (* 1 = 0.00195282 loss)
I1022 15:09:02.013299 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000682254 (* 1 = 0.000682254 loss)
I1022 15:09:02.013311 25759 sgd_solver.cpp:106] Iteration 13580, lr = 2e-05
speed: 4.212s / iter
I1022 15:10:27.307911 25759 solver.cpp:228] Iteration 13600, loss = 0.0855547
I1022 15:10:27.307965 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 15:10:27.307971 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:10:27.307977 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:10:27.307981 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:10:27.307986 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00471925 (* 1 = 0.00471925 loss)
I1022 15:10:27.307991 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00444393 (* 1 = 0.00444393 loss)
I1022 15:10:27.307996 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.8528e-05 (* 1 = 3.8528e-05 loss)
I1022 15:10:27.308001 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.69163e-06 (* 1 = 5.69163e-06 loss)
I1022 15:10:27.308004 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 8.68749e-05 (* 1 = 8.68749e-05 loss)
I1022 15:10:27.308009 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.23971e-05 (* 1 = 2.23971e-05 loss)
I1022 15:10:27.308015 25759 sgd_solver.cpp:106] Iteration 13600, lr = 2e-05
I1022 15:11:52.073529 25759 solver.cpp:228] Iteration 13620, loss = 0.046177
I1022 15:11:52.073587 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 15:11:52.073596 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.999
I1022 15:11:52.073606 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00886862 (* 1 = 0.00886862 loss)
I1022 15:11:52.073614 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00366445 (* 1 = 0.00366445 loss)
I1022 15:11:52.073619 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00860675 (* 1 = 0.00860675 loss)
I1022 15:11:52.073626 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00583975 (* 1 = 0.00583975 loss)
I1022 15:11:52.073632 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000121375 (* 1 = 0.000121375 loss)
I1022 15:11:52.073638 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.80377e-05 (* 1 = 1.80377e-05 loss)
I1022 15:11:52.073644 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00373664 (* 1 = 0.00373664 loss)
I1022 15:11:52.073650 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000344816 (* 1 = 0.000344816 loss)
I1022 15:11:52.073658 25759 sgd_solver.cpp:106] Iteration 13620, lr = 2e-05
I1022 15:13:16.973961 25759 solver.cpp:228] Iteration 13640, loss = 0.052084
I1022 15:13:16.974014 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997425
I1022 15:13:16.974025 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.99351
I1022 15:13:16.974040 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0280318 (* 1 = 0.0280318 loss)
I1022 15:13:16.974051 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0174925 (* 1 = 0.0174925 loss)
I1022 15:13:16.974071 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0169671 (* 1 = 0.0169671 loss)
I1022 15:13:16.974084 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0260669 (* 1 = 0.0260669 loss)
I1022 15:13:16.974094 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00326132 (* 1 = 0.00326132 loss)
I1022 15:13:16.974107 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.83036e-05 (* 1 = 3.83036e-05 loss)
I1022 15:13:16.974117 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0330758 (* 1 = 0.0330758 loss)
I1022 15:13:16.974129 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000190674 (* 1 = 0.000190674 loss)
I1022 15:13:16.974140 25759 sgd_solver.cpp:106] Iteration 13640, lr = 2e-05
I1022 15:14:43.161142 25759 solver.cpp:228] Iteration 13660, loss = 0.0244487
I1022 15:14:43.161180 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 15:14:43.161187 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:14:43.161196 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:14:43.161201 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:14:43.161207 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000295302 (* 1 = 0.000295302 loss)
I1022 15:14:43.161216 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00451549 (* 1 = 0.00451549 loss)
I1022 15:14:43.161221 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.26614e-05 (* 1 = 7.26614e-05 loss)
I1022 15:14:43.161227 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.77788e-06 (* 1 = 8.77788e-06 loss)
I1022 15:14:43.161233 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 8.74257e-05 (* 1 = 8.74257e-05 loss)
I1022 15:14:43.161239 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.10705e-05 (* 1 = 7.10705e-05 loss)
I1022 15:14:43.161248 25759 sgd_solver.cpp:106] Iteration 13660, lr = 2e-05
I1022 15:16:09.253326 25759 solver.cpp:228] Iteration 13680, loss = 0.0385897
I1022 15:16:09.253376 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 15:16:09.253381 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:16:09.253387 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:16:09.253391 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:16:09.253398 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00499919 (* 1 = 0.00499919 loss)
I1022 15:16:09.253403 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00445959 (* 1 = 0.00445959 loss)
I1022 15:16:09.253407 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000106003 (* 1 = 0.000106003 loss)
I1022 15:16:09.253412 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.90634e-05 (* 1 = 1.90634e-05 loss)
I1022 15:16:09.253417 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000150315 (* 1 = 0.000150315 loss)
I1022 15:16:09.253422 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 5.53932e-05 (* 1 = 5.53932e-05 loss)
I1022 15:16:09.253430 25759 sgd_solver.cpp:106] Iteration 13680, lr = 2e-05
I1022 15:17:34.049953 25759 solver.cpp:228] Iteration 13700, loss = 0.0937126
I1022 15:17:34.050001 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 15:17:34.050009 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:17:34.050019 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:17:34.050024 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:17:34.050030 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00450509 (* 1 = 0.00450509 loss)
I1022 15:17:34.050036 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00443458 (* 1 = 0.00443458 loss)
I1022 15:17:34.050042 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00011085 (* 1 = 0.00011085 loss)
I1022 15:17:34.050048 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.11543e-05 (* 1 = 1.11543e-05 loss)
I1022 15:17:34.050055 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000136332 (* 1 = 0.000136332 loss)
I1022 15:17:34.050060 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.00015807 (* 1 = 0.00015807 loss)
I1022 15:17:34.050072 25759 sgd_solver.cpp:106] Iteration 13700, lr = 2e-05
I1022 15:18:59.728363 25759 solver.cpp:228] Iteration 13720, loss = 0.039473
I1022 15:18:59.728404 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 15:18:59.728411 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:18:59.728420 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:18:59.728426 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:18:59.728432 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000251063 (* 1 = 0.000251063 loss)
I1022 15:18:59.728440 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0043606 (* 1 = 0.0043606 loss)
I1022 15:18:59.728446 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 7.24824e-05 (* 1 = 7.24824e-05 loss)
I1022 15:18:59.728452 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.14142e-05 (* 1 = 1.14142e-05 loss)
I1022 15:18:59.728458 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000318942 (* 1 = 0.000318942 loss)
I1022 15:18:59.728464 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000483776 (* 1 = 0.000483776 loss)
I1022 15:18:59.728476 25759 sgd_solver.cpp:106] Iteration 13720, lr = 2e-05
I1022 15:20:23.711060 25759 solver.cpp:228] Iteration 13740, loss = 0.0203298
I1022 15:20:23.711102 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996002
I1022 15:20:23.711107 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 15:20:23.711119 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00453894 (* 1 = 0.00453894 loss)
I1022 15:20:23.711123 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00497819 (* 1 = 0.00497819 loss)
I1022 15:20:23.711127 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0115537 (* 1 = 0.0115537 loss)
I1022 15:20:23.711133 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00762475 (* 1 = 0.00762475 loss)
I1022 15:20:23.711136 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000430068 (* 1 = 0.000430068 loss)
I1022 15:20:23.711143 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.94173e-06 (* 1 = 8.94173e-06 loss)
I1022 15:20:23.711148 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00302089 (* 1 = 0.00302089 loss)
I1022 15:20:23.711153 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000138149 (* 1 = 0.000138149 loss)
I1022 15:20:23.711163 25759 sgd_solver.cpp:106] Iteration 13740, lr = 2e-05
I1022 15:21:48.841696 25759 solver.cpp:228] Iteration 13760, loss = 0.10091
I1022 15:21:48.841753 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 15:21:48.841760 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:21:48.841770 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:21:48.841776 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:21:48.841784 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00514772 (* 1 = 0.00514772 loss)
I1022 15:21:48.841790 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00452958 (* 1 = 0.00452958 loss)
I1022 15:21:48.841797 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000215406 (* 1 = 0.000215406 loss)
I1022 15:21:48.841804 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 0.000301038 (* 1 = 0.000301038 loss)
I1022 15:21:48.841811 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00123355 (* 1 = 0.00123355 loss)
I1022 15:21:48.841822 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 6.66243e-05 (* 1 = 6.66243e-05 loss)
I1022 15:21:48.841830 25759 sgd_solver.cpp:106] Iteration 13760, lr = 2e-05
I1022 15:23:15.940309 25759 solver.cpp:228] Iteration 13780, loss = 0.120264
I1022 15:23:15.940347 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.997501
I1022 15:23:15.940354 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:23:15.940363 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00497224 (* 1 = 0.00497224 loss)
I1022 15:23:15.940369 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 4.35968e-05 (* 1 = 4.35968e-05 loss)
I1022 15:23:15.940376 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00796082 (* 1 = 0.00796082 loss)
I1022 15:23:15.940382 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00445668 (* 1 = 0.00445668 loss)
I1022 15:23:15.940388 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.8179e-05 (* 1 = 6.8179e-05 loss)
I1022 15:23:15.940393 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.49353e-06 (* 1 = 6.49353e-06 loss)
I1022 15:23:15.940399 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00105493 (* 1 = 0.00105493 loss)
I1022 15:23:15.940405 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 7.49446e-05 (* 1 = 7.49446e-05 loss)
I1022 15:23:15.940412 25759 sgd_solver.cpp:106] Iteration 13780, lr = 2e-05
speed: 4.213s / iter
I1022 15:24:41.711309 25759 solver.cpp:228] Iteration 13800, loss = 0.122247
I1022 15:24:41.711346 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 15:24:41.711354 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:24:41.711361 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:24:41.711367 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:24:41.711374 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00468775 (* 1 = 0.00468775 loss)
I1022 15:24:41.711380 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00408364 (* 1 = 0.00408364 loss)
I1022 15:24:41.711385 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.77029e-05 (* 1 = 6.77029e-05 loss)
I1022 15:24:41.711390 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.8932e-06 (* 1 = 8.8932e-06 loss)
I1022 15:24:41.711396 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 7.34876e-05 (* 1 = 7.34876e-05 loss)
I1022 15:24:41.711402 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000313801 (* 1 = 0.000313801 loss)
I1022 15:24:41.711412 25759 sgd_solver.cpp:106] Iteration 13800, lr = 2e-05
I1022 15:26:08.183589 25759 solver.cpp:228] Iteration 13820, loss = 0.0506097
I1022 15:26:08.183655 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 15:26:08.183667 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:26:08.183683 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:26:08.183694 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:26:08.183707 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000241196 (* 1 = 0.000241196 loss)
I1022 15:26:08.183720 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00449446 (* 1 = 0.00449446 loss)
I1022 15:26:08.183735 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.5383e-05 (* 1 = 3.5383e-05 loss)
I1022 15:26:08.183749 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 6.00652e-06 (* 1 = 6.00652e-06 loss)
I1022 15:26:08.183763 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 7.92235e-05 (* 1 = 7.92235e-05 loss)
I1022 15:26:08.183776 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000125647 (* 1 = 0.000125647 loss)
I1022 15:26:08.183790 25759 sgd_solver.cpp:106] Iteration 13820, lr = 2e-05
I1022 15:27:33.766602 25759 solver.cpp:228] Iteration 13840, loss = 0.0786313
I1022 15:27:33.766665 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 15:27:33.766672 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:27:33.766680 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:27:33.766685 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:27:33.766690 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00408898 (* 1 = 0.00408898 loss)
I1022 15:27:33.766695 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00438766 (* 1 = 0.00438766 loss)
I1022 15:27:33.766700 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 8.28152e-05 (* 1 = 8.28152e-05 loss)
I1022 15:27:33.766705 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.30186e-06 (* 1 = 8.30186e-06 loss)
I1022 15:27:33.766710 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000376033 (* 1 = 0.000376033 loss)
I1022 15:27:33.766716 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.55398e-05 (* 1 = 4.55398e-05 loss)
I1022 15:27:33.766722 25759 sgd_solver.cpp:106] Iteration 13840, lr = 2e-05
I1022 15:28:58.610602 25759 solver.cpp:228] Iteration 13860, loss = 0.028787
I1022 15:28:58.610642 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 15:28:58.610649 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:28:58.610657 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:28:58.610663 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:28:58.610669 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00465966 (* 1 = 0.00465966 loss)
I1022 15:28:58.610675 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00431853 (* 1 = 0.00431853 loss)
I1022 15:28:58.610682 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.73431e-05 (* 1 = 3.73431e-05 loss)
I1022 15:28:58.610687 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 3.58773e-06 (* 1 = 3.58773e-06 loss)
I1022 15:28:58.610693 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000315574 (* 1 = 0.000315574 loss)
I1022 15:28:58.610699 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.74963e-05 (* 1 = 2.74963e-05 loss)
I1022 15:28:58.610707 25759 sgd_solver.cpp:106] Iteration 13860, lr = 2e-05
I1022 15:30:24.901877 25759 solver.cpp:228] Iteration 13880, loss = 0.0414961
I1022 15:30:24.901916 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996004
I1022 15:30:24.901922 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.995005
I1022 15:30:24.901932 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.012586 (* 1 = 0.012586 loss)
I1022 15:30:24.901937 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0134091 (* 1 = 0.0134091 loss)
I1022 15:30:24.901943 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.017994 (* 1 = 0.017994 loss)
I1022 15:30:24.901950 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0164004 (* 1 = 0.0164004 loss)
I1022 15:30:24.901957 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.000495483 (* 1 = 0.000495483 loss)
I1022 15:30:24.901962 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 5.26124e-06 (* 1 = 5.26124e-06 loss)
I1022 15:30:24.901968 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0085847 (* 1 = 0.0085847 loss)
I1022 15:30:24.901974 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 5.06992e-05 (* 1 = 5.06992e-05 loss)
I1022 15:30:24.901983 25759 sgd_solver.cpp:106] Iteration 13880, lr = 2e-05
I1022 15:31:51.350639 25759 solver.cpp:228] Iteration 13900, loss = 0.0633002
I1022 15:31:51.350679 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 15:31:51.350695 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:31:51.350705 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00479896 (* 1 = 0.00479896 loss)
I1022 15:31:51.350711 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.00102416 (* 1 = 0.00102416 loss)
I1022 15:31:51.350716 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00730068 (* 1 = 0.00730068 loss)
I1022 15:31:51.350723 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00578536 (* 1 = 0.00578536 loss)
I1022 15:31:51.350728 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 2.23833e-05 (* 1 = 2.23833e-05 loss)
I1022 15:31:51.350733 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 1.48971e-05 (* 1 = 1.48971e-05 loss)
I1022 15:31:51.350739 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00367624 (* 1 = 0.00367624 loss)
I1022 15:31:51.350745 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000179132 (* 1 = 0.000179132 loss)
I1022 15:31:51.350754 25759 sgd_solver.cpp:106] Iteration 13900, lr = 2e-05
I1022 15:33:18.579195 25759 solver.cpp:228] Iteration 13920, loss = 0.0272929
I1022 15:33:18.579243 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.9995
I1022 15:33:18.579250 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:33:18.579260 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:33:18.579267 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:33:18.579273 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00356783 (* 1 = 0.00356783 loss)
I1022 15:33:18.579280 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00453116 (* 1 = 0.00453116 loss)
I1022 15:33:18.579288 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 6.71321e-05 (* 1 = 6.71321e-05 loss)
I1022 15:33:18.579293 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.04593e-06 (* 1 = 9.04593e-06 loss)
I1022 15:33:18.579299 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 3.03893e-05 (* 1 = 3.03893e-05 loss)
I1022 15:33:18.579305 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 2.84343e-05 (* 1 = 2.84343e-05 loss)
I1022 15:33:18.579313 25759 sgd_solver.cpp:106] Iteration 13920, lr = 2e-05
I1022 15:34:44.765727 25759 solver.cpp:228] Iteration 13940, loss = 0.0316308
I1022 15:34:44.765765 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.996502
I1022 15:34:44.765780 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998001
I1022 15:34:44.765789 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.00962466 (* 1 = 0.00962466 loss)
I1022 15:34:44.765795 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0134308 (* 1 = 0.0134308 loss)
I1022 15:34:44.765800 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.0112591 (* 1 = 0.0112591 loss)
I1022 15:34:44.765806 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00862024 (* 1 = 0.00862024 loss)
I1022 15:34:44.765812 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00062658 (* 1 = 0.00062658 loss)
I1022 15:34:44.765818 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 8.4122e-06 (* 1 = 8.4122e-06 loss)
I1022 15:34:44.765825 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.0177544 (* 1 = 0.0177544 loss)
I1022 15:34:44.765830 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 4.69659e-06 (* 1 = 4.69659e-06 loss)
I1022 15:34:44.765836 25759 sgd_solver.cpp:106] Iteration 13940, lr = 2e-05
I1022 15:36:09.375233 25759 solver.cpp:228] Iteration 13960, loss = 0.0560071
I1022 15:36:09.375275 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 0.998501
I1022 15:36:09.375289 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.998501
I1022 15:36:09.375299 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0.0041248 (* 1 = 0.0041248 loss)
I1022 15:36:09.375305 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0.0106729 (* 1 = 0.0106729 loss)
I1022 15:36:09.375311 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.00509763 (* 1 = 0.00509763 loss)
I1022 15:36:09.375319 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.00899994 (* 1 = 0.00899994 loss)
I1022 15:36:09.375324 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 0.00432996 (* 1 = 0.00432996 loss)
I1022 15:36:09.375330 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 9.6676e-06 (* 1 = 9.6676e-06 loss)
I1022 15:36:09.375337 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.00233674 (* 1 = 0.00233674 loss)
I1022 15:36:09.375344 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000137195 (* 1 = 0.000137195 loss)
I1022 15:36:09.375360 25759 sgd_solver.cpp:106] Iteration 13960, lr = 2e-05
I1022 15:37:33.375095 25759 solver.cpp:228] Iteration 13980, loss = 0.0318851
I1022 15:37:33.375150 25759 solver.cpp:244]     Train net output #0: accuarcy_p2 = 1
I1022 15:37:33.375156 25759 solver.cpp:244]     Train net output #1: accuarcy_p3 = 0.9995
I1022 15:37:33.375164 25759 solver.cpp:244]     Train net output #2: loss_bbox_p2 = 0 (* 1 = 0 loss)
I1022 15:37:33.375169 25759 solver.cpp:244]     Train net output #3: loss_bbox_p3 = 0 (* 1 = 0 loss)
I1022 15:37:33.375174 25759 solver.cpp:244]     Train net output #4: loss_cls_p2 = 0.000241382 (* 1 = 0.000241382 loss)
I1022 15:37:33.375178 25759 solver.cpp:244]     Train net output #5: loss_cls_p3 = 0.0043994 (* 1 = 0.0043994 loss)
I1022 15:37:33.375183 25759 solver.cpp:244]     Train net output #6: rpn_cls_loss_p2 = 3.9041e-05 (* 1 = 3.9041e-05 loss)
I1022 15:37:33.375188 25759 solver.cpp:244]     Train net output #7: rpn_cls_loss_p3 = 4.96697e-06 (* 1 = 4.96697e-06 loss)
I1022 15:37:33.375192 25759 solver.cpp:244]     Train net output #8: rpn_loss_bbox_p2 = 0.000820817 (* 1 = 0.000820817 loss)
I1022 15:37:33.375197 25759 solver.cpp:244]     Train net output #9: rpn_loss_bbox_p3 = 0.000520834 (* 1 = 0.000520834 loss)
I1022 15:37:33.375207 25759 sgd_solver.cpp:106] Iteration 13980, lr = 2e-05
speed: 4.214s / iter
bbbb
aaaa
Wrote snapshot to: /home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_14000.caffemodel
done solving

real	983m22.383s
user	894m55.432s
sys	108m38.696s
+ set +x
+ ./tools/test_net.py --gpu 3 --def experiments/10_22/model_ohem/multi_test.prototxt --net /home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_14000.caffemodel --imdb voc_0712_test --cfg experiments/10_22/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='/home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_14000.caffemodel', cfg_file='experiments/10_22/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=3, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/10_22/model_ohem/multi_test.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'DATA_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '10_22/model',
 'GPU_ID': 3,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/models/pascal_voc',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/neuiva1/sol/10_12/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.55,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 20,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 20,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 2000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W1022 15:38:59.400336 27315 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W1022 15:38:59.400373 27315 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W1022 15:38:59.400377 27315 _caffe.cpp:125] Net('experiments/10_22/model_ohem/multi_test.prototxt', 1, weights='/home/neuiva1/sol/10_12/py-R-FCN/output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_14000.caffemodel')
I1022 15:38:59.404040 27315 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/10_22/model_ohem/multi_test.prototxt
I1022 15:38:59.404090 27315 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W1022 15:38:59.404095 27315 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I1022 15:38:59.406266 27315 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b
I1022 15:38:59.407383 27315 layer_factory.hpp:77] Creating layer input
I1022 15:38:59.407397 27315 net.cpp:100] Creating Layer input
I1022 15:38:59.407402 27315 net.cpp:418] input -> data
I1022 15:38:59.407420 27315 net.cpp:418] input -> im_info
I1022 15:38:59.859017 27315 net.cpp:150] Setting up input
I1022 15:38:59.859066 27315 net.cpp:157] Top shape: 1 3 224 224 (150528)
I1022 15:38:59.859069 27315 net.cpp:157] Top shape: 1 3 (3)
I1022 15:38:59.859071 27315 net.cpp:165] Memory required for data: 602124
I1022 15:38:59.859078 27315 layer_factory.hpp:77] Creating layer conv1
I1022 15:38:59.859100 27315 net.cpp:100] Creating Layer conv1
I1022 15:38:59.859103 27315 net.cpp:444] conv1 <- data
I1022 15:38:59.859113 27315 net.cpp:418] conv1 -> conv1
I1022 15:39:00.550104 27315 net.cpp:150] Setting up conv1
I1022 15:39:00.550173 27315 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 15:39:00.550177 27315 net.cpp:165] Memory required for data: 3813388
I1022 15:39:00.550197 27315 layer_factory.hpp:77] Creating layer bn_conv1
I1022 15:39:00.550240 27315 net.cpp:100] Creating Layer bn_conv1
I1022 15:39:00.550246 27315 net.cpp:444] bn_conv1 <- conv1
I1022 15:39:00.550253 27315 net.cpp:405] bn_conv1 -> conv1 (in-place)
I1022 15:39:00.550629 27315 net.cpp:150] Setting up bn_conv1
I1022 15:39:00.550637 27315 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 15:39:00.550640 27315 net.cpp:165] Memory required for data: 7024652
I1022 15:39:00.550662 27315 layer_factory.hpp:77] Creating layer scale_conv1
I1022 15:39:00.550683 27315 net.cpp:100] Creating Layer scale_conv1
I1022 15:39:00.550691 27315 net.cpp:444] scale_conv1 <- conv1
I1022 15:39:00.550696 27315 net.cpp:405] scale_conv1 -> conv1 (in-place)
I1022 15:39:00.550765 27315 layer_factory.hpp:77] Creating layer scale_conv1
I1022 15:39:00.550979 27315 net.cpp:150] Setting up scale_conv1
I1022 15:39:00.550987 27315 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 15:39:00.550990 27315 net.cpp:165] Memory required for data: 10235916
I1022 15:39:00.550997 27315 layer_factory.hpp:77] Creating layer conv1_relu
I1022 15:39:00.551014 27315 net.cpp:100] Creating Layer conv1_relu
I1022 15:39:00.551019 27315 net.cpp:444] conv1_relu <- conv1
I1022 15:39:00.551023 27315 net.cpp:405] conv1_relu -> conv1 (in-place)
I1022 15:39:00.551251 27315 net.cpp:150] Setting up conv1_relu
I1022 15:39:00.551261 27315 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 15:39:00.551265 27315 net.cpp:165] Memory required for data: 13447180
I1022 15:39:00.551268 27315 layer_factory.hpp:77] Creating layer pool1
I1022 15:39:00.551275 27315 net.cpp:100] Creating Layer pool1
I1022 15:39:00.551280 27315 net.cpp:444] pool1 <- conv1
I1022 15:39:00.551285 27315 net.cpp:418] pool1 -> pool1
I1022 15:39:00.551353 27315 net.cpp:150] Setting up pool1
I1022 15:39:00.551360 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.551363 27315 net.cpp:165] Memory required for data: 14249996
I1022 15:39:00.551367 27315 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I1022 15:39:00.551379 27315 net.cpp:100] Creating Layer pool1_pool1_0_split
I1022 15:39:00.551384 27315 net.cpp:444] pool1_pool1_0_split <- pool1
I1022 15:39:00.551388 27315 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1022 15:39:00.551395 27315 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1022 15:39:00.551452 27315 net.cpp:150] Setting up pool1_pool1_0_split
I1022 15:39:00.551460 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.551463 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.551466 27315 net.cpp:165] Memory required for data: 15855628
I1022 15:39:00.551470 27315 layer_factory.hpp:77] Creating layer res2a_branch1
I1022 15:39:00.551486 27315 net.cpp:100] Creating Layer res2a_branch1
I1022 15:39:00.551491 27315 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I1022 15:39:00.551496 27315 net.cpp:418] res2a_branch1 -> res2a_branch1
I1022 15:39:00.553266 27315 net.cpp:150] Setting up res2a_branch1
I1022 15:39:00.553279 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.553283 27315 net.cpp:165] Memory required for data: 19066892
I1022 15:39:00.553289 27315 layer_factory.hpp:77] Creating layer bn2a_branch1
I1022 15:39:00.553297 27315 net.cpp:100] Creating Layer bn2a_branch1
I1022 15:39:00.553303 27315 net.cpp:444] bn2a_branch1 <- res2a_branch1
I1022 15:39:00.553308 27315 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I1022 15:39:00.557325 27315 net.cpp:150] Setting up bn2a_branch1
I1022 15:39:00.557340 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.557344 27315 net.cpp:165] Memory required for data: 22278156
I1022 15:39:00.557358 27315 layer_factory.hpp:77] Creating layer scale2a_branch1
I1022 15:39:00.557368 27315 net.cpp:100] Creating Layer scale2a_branch1
I1022 15:39:00.557370 27315 net.cpp:444] scale2a_branch1 <- res2a_branch1
I1022 15:39:00.557377 27315 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I1022 15:39:00.557443 27315 layer_factory.hpp:77] Creating layer scale2a_branch1
I1022 15:39:00.557628 27315 net.cpp:150] Setting up scale2a_branch1
I1022 15:39:00.557636 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.557639 27315 net.cpp:165] Memory required for data: 25489420
I1022 15:39:00.557646 27315 layer_factory.hpp:77] Creating layer res2a_branch2a
I1022 15:39:00.557654 27315 net.cpp:100] Creating Layer res2a_branch2a
I1022 15:39:00.557658 27315 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I1022 15:39:00.557665 27315 net.cpp:418] res2a_branch2a -> res2a_branch2a
I1022 15:39:00.559347 27315 net.cpp:150] Setting up res2a_branch2a
I1022 15:39:00.559361 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.559366 27315 net.cpp:165] Memory required for data: 26292236
I1022 15:39:00.559373 27315 layer_factory.hpp:77] Creating layer bn2a_branch2a
I1022 15:39:00.559381 27315 net.cpp:100] Creating Layer bn2a_branch2a
I1022 15:39:00.559386 27315 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I1022 15:39:00.559392 27315 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I1022 15:39:00.559726 27315 net.cpp:150] Setting up bn2a_branch2a
I1022 15:39:00.559734 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.559737 27315 net.cpp:165] Memory required for data: 27095052
I1022 15:39:00.559747 27315 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1022 15:39:00.559754 27315 net.cpp:100] Creating Layer scale2a_branch2a
I1022 15:39:00.559759 27315 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I1022 15:39:00.559764 27315 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I1022 15:39:00.559823 27315 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1022 15:39:00.560019 27315 net.cpp:150] Setting up scale2a_branch2a
I1022 15:39:00.560026 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.560029 27315 net.cpp:165] Memory required for data: 27897868
I1022 15:39:00.560035 27315 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I1022 15:39:00.560042 27315 net.cpp:100] Creating Layer res2a_branch2a_relu
I1022 15:39:00.560045 27315 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I1022 15:39:00.560050 27315 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I1022 15:39:00.560273 27315 net.cpp:150] Setting up res2a_branch2a_relu
I1022 15:39:00.560283 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.560286 27315 net.cpp:165] Memory required for data: 28700684
I1022 15:39:00.560292 27315 layer_factory.hpp:77] Creating layer res2a_branch2b
I1022 15:39:00.560300 27315 net.cpp:100] Creating Layer res2a_branch2b
I1022 15:39:00.560305 27315 net.cpp:444] res2a_branch2b <- res2a_branch2a
I1022 15:39:00.560310 27315 net.cpp:418] res2a_branch2b -> res2a_branch2b
I1022 15:39:00.564422 27315 net.cpp:150] Setting up res2a_branch2b
I1022 15:39:00.564437 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.564440 27315 net.cpp:165] Memory required for data: 29503500
I1022 15:39:00.564455 27315 layer_factory.hpp:77] Creating layer bn2a_branch2b
I1022 15:39:00.564462 27315 net.cpp:100] Creating Layer bn2a_branch2b
I1022 15:39:00.564466 27315 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I1022 15:39:00.564473 27315 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I1022 15:39:00.564843 27315 net.cpp:150] Setting up bn2a_branch2b
I1022 15:39:00.564851 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.564854 27315 net.cpp:165] Memory required for data: 30306316
I1022 15:39:00.564873 27315 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1022 15:39:00.564880 27315 net.cpp:100] Creating Layer scale2a_branch2b
I1022 15:39:00.564883 27315 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I1022 15:39:00.564888 27315 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I1022 15:39:00.564947 27315 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1022 15:39:00.565146 27315 net.cpp:150] Setting up scale2a_branch2b
I1022 15:39:00.565153 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.565156 27315 net.cpp:165] Memory required for data: 31109132
I1022 15:39:00.565162 27315 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I1022 15:39:00.565169 27315 net.cpp:100] Creating Layer res2a_branch2b_relu
I1022 15:39:00.565172 27315 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I1022 15:39:00.565176 27315 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I1022 15:39:00.566046 27315 net.cpp:150] Setting up res2a_branch2b_relu
I1022 15:39:00.566058 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.566061 27315 net.cpp:165] Memory required for data: 31911948
I1022 15:39:00.566074 27315 layer_factory.hpp:77] Creating layer res2a_branch2c
I1022 15:39:00.566083 27315 net.cpp:100] Creating Layer res2a_branch2c
I1022 15:39:00.566087 27315 net.cpp:444] res2a_branch2c <- res2a_branch2b
I1022 15:39:00.566092 27315 net.cpp:418] res2a_branch2c -> res2a_branch2c
I1022 15:39:00.568944 27315 net.cpp:150] Setting up res2a_branch2c
I1022 15:39:00.568959 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.568962 27315 net.cpp:165] Memory required for data: 35123212
I1022 15:39:00.568975 27315 layer_factory.hpp:77] Creating layer bn2a_branch2c
I1022 15:39:00.568984 27315 net.cpp:100] Creating Layer bn2a_branch2c
I1022 15:39:00.568989 27315 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I1022 15:39:00.568995 27315 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I1022 15:39:00.569355 27315 net.cpp:150] Setting up bn2a_branch2c
I1022 15:39:00.569365 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.569368 27315 net.cpp:165] Memory required for data: 38334476
I1022 15:39:00.569386 27315 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1022 15:39:00.569392 27315 net.cpp:100] Creating Layer scale2a_branch2c
I1022 15:39:00.569396 27315 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I1022 15:39:00.569403 27315 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I1022 15:39:00.569466 27315 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1022 15:39:00.569656 27315 net.cpp:150] Setting up scale2a_branch2c
I1022 15:39:00.569664 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.569667 27315 net.cpp:165] Memory required for data: 41545740
I1022 15:39:00.569674 27315 layer_factory.hpp:77] Creating layer res2a
I1022 15:39:00.569680 27315 net.cpp:100] Creating Layer res2a
I1022 15:39:00.569684 27315 net.cpp:444] res2a <- res2a_branch1
I1022 15:39:00.569687 27315 net.cpp:444] res2a <- res2a_branch2c
I1022 15:39:00.569694 27315 net.cpp:418] res2a -> res2a
I1022 15:39:00.569741 27315 net.cpp:150] Setting up res2a
I1022 15:39:00.569748 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.569751 27315 net.cpp:165] Memory required for data: 44757004
I1022 15:39:00.569754 27315 layer_factory.hpp:77] Creating layer res2a_relu
I1022 15:39:00.569759 27315 net.cpp:100] Creating Layer res2a_relu
I1022 15:39:00.569762 27315 net.cpp:444] res2a_relu <- res2a
I1022 15:39:00.569768 27315 net.cpp:405] res2a_relu -> res2a (in-place)
I1022 15:39:00.570003 27315 net.cpp:150] Setting up res2a_relu
I1022 15:39:00.570011 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.570014 27315 net.cpp:165] Memory required for data: 47968268
I1022 15:39:00.570019 27315 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I1022 15:39:00.570025 27315 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I1022 15:39:00.570030 27315 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I1022 15:39:00.570036 27315 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I1022 15:39:00.570045 27315 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I1022 15:39:00.570113 27315 net.cpp:150] Setting up res2a_res2a_relu_0_split
I1022 15:39:00.570120 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.570124 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.570127 27315 net.cpp:165] Memory required for data: 54390796
I1022 15:39:00.570130 27315 layer_factory.hpp:77] Creating layer res2b_branch2a
I1022 15:39:00.570140 27315 net.cpp:100] Creating Layer res2b_branch2a
I1022 15:39:00.570144 27315 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I1022 15:39:00.570150 27315 net.cpp:418] res2b_branch2a -> res2b_branch2a
I1022 15:39:00.573360 27315 net.cpp:150] Setting up res2b_branch2a
I1022 15:39:00.573375 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.573379 27315 net.cpp:165] Memory required for data: 55193612
I1022 15:39:00.573385 27315 layer_factory.hpp:77] Creating layer bn2b_branch2a
I1022 15:39:00.573396 27315 net.cpp:100] Creating Layer bn2b_branch2a
I1022 15:39:00.573401 27315 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I1022 15:39:00.573408 27315 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I1022 15:39:00.573783 27315 net.cpp:150] Setting up bn2b_branch2a
I1022 15:39:00.573791 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.573793 27315 net.cpp:165] Memory required for data: 55996428
I1022 15:39:00.573815 27315 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1022 15:39:00.573822 27315 net.cpp:100] Creating Layer scale2b_branch2a
I1022 15:39:00.573825 27315 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I1022 15:39:00.573832 27315 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I1022 15:39:00.573899 27315 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1022 15:39:00.574101 27315 net.cpp:150] Setting up scale2b_branch2a
I1022 15:39:00.574108 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.574111 27315 net.cpp:165] Memory required for data: 56799244
I1022 15:39:00.574116 27315 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I1022 15:39:00.574124 27315 net.cpp:100] Creating Layer res2b_branch2a_relu
I1022 15:39:00.574127 27315 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I1022 15:39:00.574131 27315 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I1022 15:39:00.574369 27315 net.cpp:150] Setting up res2b_branch2a_relu
I1022 15:39:00.574381 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.574383 27315 net.cpp:165] Memory required for data: 57602060
I1022 15:39:00.574388 27315 layer_factory.hpp:77] Creating layer res2b_branch2b
I1022 15:39:00.574394 27315 net.cpp:100] Creating Layer res2b_branch2b
I1022 15:39:00.574399 27315 net.cpp:444] res2b_branch2b <- res2b_branch2a
I1022 15:39:00.574406 27315 net.cpp:418] res2b_branch2b -> res2b_branch2b
I1022 15:39:00.577479 27315 net.cpp:150] Setting up res2b_branch2b
I1022 15:39:00.577494 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.577498 27315 net.cpp:165] Memory required for data: 58404876
I1022 15:39:00.577508 27315 layer_factory.hpp:77] Creating layer bn2b_branch2b
I1022 15:39:00.577517 27315 net.cpp:100] Creating Layer bn2b_branch2b
I1022 15:39:00.577522 27315 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I1022 15:39:00.577527 27315 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I1022 15:39:00.577898 27315 net.cpp:150] Setting up bn2b_branch2b
I1022 15:39:00.577905 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.577908 27315 net.cpp:165] Memory required for data: 59207692
I1022 15:39:00.577925 27315 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1022 15:39:00.577934 27315 net.cpp:100] Creating Layer scale2b_branch2b
I1022 15:39:00.577936 27315 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I1022 15:39:00.577942 27315 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I1022 15:39:00.578004 27315 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1022 15:39:00.578214 27315 net.cpp:150] Setting up scale2b_branch2b
I1022 15:39:00.578222 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.578224 27315 net.cpp:165] Memory required for data: 60010508
I1022 15:39:00.578230 27315 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I1022 15:39:00.578238 27315 net.cpp:100] Creating Layer res2b_branch2b_relu
I1022 15:39:00.578240 27315 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I1022 15:39:00.578246 27315 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I1022 15:39:00.579152 27315 net.cpp:150] Setting up res2b_branch2b_relu
I1022 15:39:00.579164 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.579167 27315 net.cpp:165] Memory required for data: 60813324
I1022 15:39:00.579180 27315 layer_factory.hpp:77] Creating layer res2b_branch2c
I1022 15:39:00.579195 27315 net.cpp:100] Creating Layer res2b_branch2c
I1022 15:39:00.579198 27315 net.cpp:444] res2b_branch2c <- res2b_branch2b
I1022 15:39:00.579205 27315 net.cpp:418] res2b_branch2c -> res2b_branch2c
I1022 15:39:00.580998 27315 net.cpp:150] Setting up res2b_branch2c
I1022 15:39:00.581012 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.581014 27315 net.cpp:165] Memory required for data: 64024588
I1022 15:39:00.581029 27315 layer_factory.hpp:77] Creating layer bn2b_branch2c
I1022 15:39:00.581037 27315 net.cpp:100] Creating Layer bn2b_branch2c
I1022 15:39:00.581040 27315 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I1022 15:39:00.581048 27315 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I1022 15:39:00.581409 27315 net.cpp:150] Setting up bn2b_branch2c
I1022 15:39:00.581418 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.581420 27315 net.cpp:165] Memory required for data: 67235852
I1022 15:39:00.581439 27315 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1022 15:39:00.581447 27315 net.cpp:100] Creating Layer scale2b_branch2c
I1022 15:39:00.581450 27315 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I1022 15:39:00.581455 27315 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I1022 15:39:00.581517 27315 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1022 15:39:00.581710 27315 net.cpp:150] Setting up scale2b_branch2c
I1022 15:39:00.581717 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.581720 27315 net.cpp:165] Memory required for data: 70447116
I1022 15:39:00.581727 27315 layer_factory.hpp:77] Creating layer res2b
I1022 15:39:00.581732 27315 net.cpp:100] Creating Layer res2b
I1022 15:39:00.581737 27315 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I1022 15:39:00.581746 27315 net.cpp:444] res2b <- res2b_branch2c
I1022 15:39:00.581751 27315 net.cpp:418] res2b -> res2b
I1022 15:39:00.581790 27315 net.cpp:150] Setting up res2b
I1022 15:39:00.581797 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.581800 27315 net.cpp:165] Memory required for data: 73658380
I1022 15:39:00.581804 27315 layer_factory.hpp:77] Creating layer res2b_relu
I1022 15:39:00.581809 27315 net.cpp:100] Creating Layer res2b_relu
I1022 15:39:00.581811 27315 net.cpp:444] res2b_relu <- res2b
I1022 15:39:00.581817 27315 net.cpp:405] res2b_relu -> res2b (in-place)
I1022 15:39:00.582049 27315 net.cpp:150] Setting up res2b_relu
I1022 15:39:00.582058 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.582062 27315 net.cpp:165] Memory required for data: 76869644
I1022 15:39:00.582065 27315 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I1022 15:39:00.582073 27315 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I1022 15:39:00.582077 27315 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I1022 15:39:00.582082 27315 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I1022 15:39:00.582092 27315 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I1022 15:39:00.582157 27315 net.cpp:150] Setting up res2b_res2b_relu_0_split
I1022 15:39:00.582164 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.582167 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.582170 27315 net.cpp:165] Memory required for data: 83292172
I1022 15:39:00.582173 27315 layer_factory.hpp:77] Creating layer res2c_branch2a
I1022 15:39:00.582185 27315 net.cpp:100] Creating Layer res2c_branch2a
I1022 15:39:00.582190 27315 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I1022 15:39:00.582195 27315 net.cpp:418] res2c_branch2a -> res2c_branch2a
I1022 15:39:00.583910 27315 net.cpp:150] Setting up res2c_branch2a
I1022 15:39:00.583923 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.583926 27315 net.cpp:165] Memory required for data: 84094988
I1022 15:39:00.583932 27315 layer_factory.hpp:77] Creating layer bn2c_branch2a
I1022 15:39:00.583942 27315 net.cpp:100] Creating Layer bn2c_branch2a
I1022 15:39:00.583946 27315 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I1022 15:39:00.583953 27315 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I1022 15:39:00.584321 27315 net.cpp:150] Setting up bn2c_branch2a
I1022 15:39:00.584328 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.584331 27315 net.cpp:165] Memory required for data: 84897804
I1022 15:39:00.584338 27315 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1022 15:39:00.584348 27315 net.cpp:100] Creating Layer scale2c_branch2a
I1022 15:39:00.584352 27315 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I1022 15:39:00.584359 27315 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I1022 15:39:00.584421 27315 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1022 15:39:00.584647 27315 net.cpp:150] Setting up scale2c_branch2a
I1022 15:39:00.584657 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.584661 27315 net.cpp:165] Memory required for data: 85700620
I1022 15:39:00.584666 27315 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I1022 15:39:00.584673 27315 net.cpp:100] Creating Layer res2c_branch2a_relu
I1022 15:39:00.584676 27315 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I1022 15:39:00.584681 27315 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I1022 15:39:00.584918 27315 net.cpp:150] Setting up res2c_branch2a_relu
I1022 15:39:00.584928 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.584930 27315 net.cpp:165] Memory required for data: 86503436
I1022 15:39:00.584933 27315 layer_factory.hpp:77] Creating layer res2c_branch2b
I1022 15:39:00.584942 27315 net.cpp:100] Creating Layer res2c_branch2b
I1022 15:39:00.584947 27315 net.cpp:444] res2c_branch2b <- res2c_branch2a
I1022 15:39:00.584952 27315 net.cpp:418] res2c_branch2b -> res2c_branch2b
I1022 15:39:00.587330 27315 net.cpp:150] Setting up res2c_branch2b
I1022 15:39:00.587345 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.587349 27315 net.cpp:165] Memory required for data: 87306252
I1022 15:39:00.587357 27315 layer_factory.hpp:77] Creating layer bn2c_branch2b
I1022 15:39:00.587364 27315 net.cpp:100] Creating Layer bn2c_branch2b
I1022 15:39:00.587368 27315 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I1022 15:39:00.587375 27315 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I1022 15:39:00.587762 27315 net.cpp:150] Setting up bn2c_branch2b
I1022 15:39:00.587769 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.587772 27315 net.cpp:165] Memory required for data: 88109068
I1022 15:39:00.587791 27315 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1022 15:39:00.587800 27315 net.cpp:100] Creating Layer scale2c_branch2b
I1022 15:39:00.587802 27315 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I1022 15:39:00.587808 27315 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I1022 15:39:00.587873 27315 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1022 15:39:00.588081 27315 net.cpp:150] Setting up scale2c_branch2b
I1022 15:39:00.588089 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.588091 27315 net.cpp:165] Memory required for data: 88911884
I1022 15:39:00.588099 27315 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I1022 15:39:00.588104 27315 net.cpp:100] Creating Layer res2c_branch2b_relu
I1022 15:39:00.588107 27315 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I1022 15:39:00.588114 27315 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I1022 15:39:00.588353 27315 net.cpp:150] Setting up res2c_branch2b_relu
I1022 15:39:00.588363 27315 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:39:00.588366 27315 net.cpp:165] Memory required for data: 89714700
I1022 15:39:00.588369 27315 layer_factory.hpp:77] Creating layer res2c_branch2c
I1022 15:39:00.588378 27315 net.cpp:100] Creating Layer res2c_branch2c
I1022 15:39:00.588383 27315 net.cpp:444] res2c_branch2c <- res2c_branch2b
I1022 15:39:00.588390 27315 net.cpp:418] res2c_branch2c -> res2c_branch2c
I1022 15:39:00.590160 27315 net.cpp:150] Setting up res2c_branch2c
I1022 15:39:00.590175 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.590185 27315 net.cpp:165] Memory required for data: 92925964
I1022 15:39:00.590191 27315 layer_factory.hpp:77] Creating layer bn2c_branch2c
I1022 15:39:00.590199 27315 net.cpp:100] Creating Layer bn2c_branch2c
I1022 15:39:00.590203 27315 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I1022 15:39:00.590210 27315 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I1022 15:39:00.590575 27315 net.cpp:150] Setting up bn2c_branch2c
I1022 15:39:00.590582 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.590585 27315 net.cpp:165] Memory required for data: 96137228
I1022 15:39:00.590611 27315 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1022 15:39:00.590617 27315 net.cpp:100] Creating Layer scale2c_branch2c
I1022 15:39:00.590620 27315 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I1022 15:39:00.590626 27315 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I1022 15:39:00.590688 27315 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1022 15:39:00.590883 27315 net.cpp:150] Setting up scale2c_branch2c
I1022 15:39:00.590890 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.590894 27315 net.cpp:165] Memory required for data: 99348492
I1022 15:39:00.590899 27315 layer_factory.hpp:77] Creating layer res2c
I1022 15:39:00.590906 27315 net.cpp:100] Creating Layer res2c
I1022 15:39:00.590911 27315 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I1022 15:39:00.590915 27315 net.cpp:444] res2c <- res2c_branch2c
I1022 15:39:00.590920 27315 net.cpp:418] res2c -> res2c
I1022 15:39:00.590956 27315 net.cpp:150] Setting up res2c
I1022 15:39:00.590963 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.590966 27315 net.cpp:165] Memory required for data: 102559756
I1022 15:39:00.590970 27315 layer_factory.hpp:77] Creating layer res2c_relu
I1022 15:39:00.590973 27315 net.cpp:100] Creating Layer res2c_relu
I1022 15:39:00.590976 27315 net.cpp:444] res2c_relu <- res2c
I1022 15:39:00.590981 27315 net.cpp:405] res2c_relu -> res2c (in-place)
I1022 15:39:00.593071 27315 net.cpp:150] Setting up res2c_relu
I1022 15:39:00.593086 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.593097 27315 net.cpp:165] Memory required for data: 105771020
I1022 15:39:00.593101 27315 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I1022 15:39:00.593109 27315 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I1022 15:39:00.593113 27315 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I1022 15:39:00.593119 27315 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I1022 15:39:00.593129 27315 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I1022 15:39:00.593205 27315 net.cpp:150] Setting up res2c_res2c_relu_0_split
I1022 15:39:00.593214 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.593216 27315 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:39:00.593220 27315 net.cpp:165] Memory required for data: 112193548
I1022 15:39:00.593224 27315 layer_factory.hpp:77] Creating layer res3a_branch1
I1022 15:39:00.593232 27315 net.cpp:100] Creating Layer res3a_branch1
I1022 15:39:00.593237 27315 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I1022 15:39:00.593245 27315 net.cpp:418] res3a_branch1 -> res3a_branch1
I1022 15:39:00.599651 27315 net.cpp:150] Setting up res3a_branch1
I1022 15:39:00.599666 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.599670 27315 net.cpp:165] Memory required for data: 113799180
I1022 15:39:00.599685 27315 layer_factory.hpp:77] Creating layer bn3a_branch1
I1022 15:39:00.599694 27315 net.cpp:100] Creating Layer bn3a_branch1
I1022 15:39:00.599699 27315 net.cpp:444] bn3a_branch1 <- res3a_branch1
I1022 15:39:00.599705 27315 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I1022 15:39:00.601902 27315 net.cpp:150] Setting up bn3a_branch1
I1022 15:39:00.601915 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.601918 27315 net.cpp:165] Memory required for data: 115404812
I1022 15:39:00.601936 27315 layer_factory.hpp:77] Creating layer scale3a_branch1
I1022 15:39:00.601945 27315 net.cpp:100] Creating Layer scale3a_branch1
I1022 15:39:00.601948 27315 net.cpp:444] scale3a_branch1 <- res3a_branch1
I1022 15:39:00.601955 27315 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I1022 15:39:00.602028 27315 layer_factory.hpp:77] Creating layer scale3a_branch1
I1022 15:39:00.602223 27315 net.cpp:150] Setting up scale3a_branch1
I1022 15:39:00.602231 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.602233 27315 net.cpp:165] Memory required for data: 117010444
I1022 15:39:00.602239 27315 layer_factory.hpp:77] Creating layer res3a_branch2a
I1022 15:39:00.602249 27315 net.cpp:100] Creating Layer res3a_branch2a
I1022 15:39:00.602255 27315 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I1022 15:39:00.602263 27315 net.cpp:418] res3a_branch2a -> res3a_branch2a
I1022 15:39:00.604084 27315 net.cpp:150] Setting up res3a_branch2a
I1022 15:39:00.604099 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.604101 27315 net.cpp:165] Memory required for data: 117411852
I1022 15:39:00.604116 27315 layer_factory.hpp:77] Creating layer bn3a_branch2a
I1022 15:39:00.604125 27315 net.cpp:100] Creating Layer bn3a_branch2a
I1022 15:39:00.604130 27315 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I1022 15:39:00.604136 27315 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I1022 15:39:00.604501 27315 net.cpp:150] Setting up bn3a_branch2a
I1022 15:39:00.604508 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.604511 27315 net.cpp:165] Memory required for data: 117813260
I1022 15:39:00.604529 27315 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1022 15:39:00.604537 27315 net.cpp:100] Creating Layer scale3a_branch2a
I1022 15:39:00.604540 27315 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I1022 15:39:00.604547 27315 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I1022 15:39:00.604617 27315 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1022 15:39:00.604825 27315 net.cpp:150] Setting up scale3a_branch2a
I1022 15:39:00.604833 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.604836 27315 net.cpp:165] Memory required for data: 118214668
I1022 15:39:00.604842 27315 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I1022 15:39:00.604851 27315 net.cpp:100] Creating Layer res3a_branch2a_relu
I1022 15:39:00.604856 27315 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I1022 15:39:00.604861 27315 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I1022 15:39:00.605768 27315 net.cpp:150] Setting up res3a_branch2a_relu
I1022 15:39:00.605780 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.605783 27315 net.cpp:165] Memory required for data: 118616076
I1022 15:39:00.605795 27315 layer_factory.hpp:77] Creating layer res3a_branch2b
I1022 15:39:00.605806 27315 net.cpp:100] Creating Layer res3a_branch2b
I1022 15:39:00.605810 27315 net.cpp:444] res3a_branch2b <- res3a_branch2a
I1022 15:39:00.605819 27315 net.cpp:418] res3a_branch2b -> res3a_branch2b
I1022 15:39:00.608366 27315 net.cpp:150] Setting up res3a_branch2b
I1022 15:39:00.608378 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.608381 27315 net.cpp:165] Memory required for data: 119017484
I1022 15:39:00.608397 27315 layer_factory.hpp:77] Creating layer bn3a_branch2b
I1022 15:39:00.608405 27315 net.cpp:100] Creating Layer bn3a_branch2b
I1022 15:39:00.608409 27315 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I1022 15:39:00.608414 27315 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I1022 15:39:00.608824 27315 net.cpp:150] Setting up bn3a_branch2b
I1022 15:39:00.608832 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.608835 27315 net.cpp:165] Memory required for data: 119418892
I1022 15:39:00.608851 27315 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1022 15:39:00.608857 27315 net.cpp:100] Creating Layer scale3a_branch2b
I1022 15:39:00.608861 27315 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I1022 15:39:00.608867 27315 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I1022 15:39:00.608933 27315 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1022 15:39:00.609156 27315 net.cpp:150] Setting up scale3a_branch2b
I1022 15:39:00.609165 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.609169 27315 net.cpp:165] Memory required for data: 119820300
I1022 15:39:00.609174 27315 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I1022 15:39:00.609181 27315 net.cpp:100] Creating Layer res3a_branch2b_relu
I1022 15:39:00.609185 27315 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I1022 15:39:00.609189 27315 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I1022 15:39:00.609426 27315 net.cpp:150] Setting up res3a_branch2b_relu
I1022 15:39:00.609434 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.609437 27315 net.cpp:165] Memory required for data: 120221708
I1022 15:39:00.609441 27315 layer_factory.hpp:77] Creating layer res3a_branch2c
I1022 15:39:00.609450 27315 net.cpp:100] Creating Layer res3a_branch2c
I1022 15:39:00.609455 27315 net.cpp:444] res3a_branch2c <- res3a_branch2b
I1022 15:39:00.609463 27315 net.cpp:418] res3a_branch2c -> res3a_branch2c
I1022 15:39:00.613658 27315 net.cpp:150] Setting up res3a_branch2c
I1022 15:39:00.613673 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.613677 27315 net.cpp:165] Memory required for data: 121827340
I1022 15:39:00.613687 27315 layer_factory.hpp:77] Creating layer bn3a_branch2c
I1022 15:39:00.613701 27315 net.cpp:100] Creating Layer bn3a_branch2c
I1022 15:39:00.613708 27315 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I1022 15:39:00.613713 27315 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I1022 15:39:00.614085 27315 net.cpp:150] Setting up bn3a_branch2c
I1022 15:39:00.614094 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.614096 27315 net.cpp:165] Memory required for data: 123432972
I1022 15:39:00.614114 27315 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1022 15:39:00.614122 27315 net.cpp:100] Creating Layer scale3a_branch2c
I1022 15:39:00.614125 27315 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I1022 15:39:00.614132 27315 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I1022 15:39:00.614202 27315 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1022 15:39:00.614399 27315 net.cpp:150] Setting up scale3a_branch2c
I1022 15:39:00.614408 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.614410 27315 net.cpp:165] Memory required for data: 125038604
I1022 15:39:00.614415 27315 layer_factory.hpp:77] Creating layer res3a
I1022 15:39:00.614425 27315 net.cpp:100] Creating Layer res3a
I1022 15:39:00.614429 27315 net.cpp:444] res3a <- res3a_branch1
I1022 15:39:00.614434 27315 net.cpp:444] res3a <- res3a_branch2c
I1022 15:39:00.614439 27315 net.cpp:418] res3a -> res3a
I1022 15:39:00.614476 27315 net.cpp:150] Setting up res3a
I1022 15:39:00.614483 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.614486 27315 net.cpp:165] Memory required for data: 126644236
I1022 15:39:00.614490 27315 layer_factory.hpp:77] Creating layer res3a_relu
I1022 15:39:00.614495 27315 net.cpp:100] Creating Layer res3a_relu
I1022 15:39:00.614497 27315 net.cpp:444] res3a_relu <- res3a
I1022 15:39:00.614501 27315 net.cpp:405] res3a_relu -> res3a (in-place)
I1022 15:39:00.617475 27315 net.cpp:150] Setting up res3a_relu
I1022 15:39:00.617489 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.617493 27315 net.cpp:165] Memory required for data: 128249868
I1022 15:39:00.617504 27315 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I1022 15:39:00.617514 27315 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I1022 15:39:00.617518 27315 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I1022 15:39:00.617527 27315 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I1022 15:39:00.617534 27315 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I1022 15:39:00.617612 27315 net.cpp:150] Setting up res3a_res3a_relu_0_split
I1022 15:39:00.617620 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.617624 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.617627 27315 net.cpp:165] Memory required for data: 131461132
I1022 15:39:00.617630 27315 layer_factory.hpp:77] Creating layer res3b_branch2a
I1022 15:39:00.617641 27315 net.cpp:100] Creating Layer res3b_branch2a
I1022 15:39:00.617646 27315 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I1022 15:39:00.617651 27315 net.cpp:418] res3b_branch2a -> res3b_branch2a
I1022 15:39:00.619459 27315 net.cpp:150] Setting up res3b_branch2a
I1022 15:39:00.619472 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.619475 27315 net.cpp:165] Memory required for data: 131862540
I1022 15:39:00.619490 27315 layer_factory.hpp:77] Creating layer bn3b_branch2a
I1022 15:39:00.619499 27315 net.cpp:100] Creating Layer bn3b_branch2a
I1022 15:39:00.619503 27315 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I1022 15:39:00.619510 27315 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I1022 15:39:00.619884 27315 net.cpp:150] Setting up bn3b_branch2a
I1022 15:39:00.619891 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.619894 27315 net.cpp:165] Memory required for data: 132263948
I1022 15:39:00.619912 27315 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1022 15:39:00.619920 27315 net.cpp:100] Creating Layer scale3b_branch2a
I1022 15:39:00.619925 27315 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I1022 15:39:00.619932 27315 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I1022 15:39:00.619997 27315 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1022 15:39:00.620205 27315 net.cpp:150] Setting up scale3b_branch2a
I1022 15:39:00.620213 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.620215 27315 net.cpp:165] Memory required for data: 132665356
I1022 15:39:00.620221 27315 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I1022 15:39:00.620229 27315 net.cpp:100] Creating Layer res3b_branch2a_relu
I1022 15:39:00.620235 27315 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I1022 15:39:00.620240 27315 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I1022 15:39:00.620477 27315 net.cpp:150] Setting up res3b_branch2a_relu
I1022 15:39:00.620486 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.620489 27315 net.cpp:165] Memory required for data: 133066764
I1022 15:39:00.620492 27315 layer_factory.hpp:77] Creating layer res3b_branch2b
I1022 15:39:00.620502 27315 net.cpp:100] Creating Layer res3b_branch2b
I1022 15:39:00.620507 27315 net.cpp:444] res3b_branch2b <- res3b_branch2a
I1022 15:39:00.620512 27315 net.cpp:418] res3b_branch2b -> res3b_branch2b
I1022 15:39:00.623064 27315 net.cpp:150] Setting up res3b_branch2b
I1022 15:39:00.623081 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.623085 27315 net.cpp:165] Memory required for data: 133468172
I1022 15:39:00.623095 27315 layer_factory.hpp:77] Creating layer bn3b_branch2b
I1022 15:39:00.623102 27315 net.cpp:100] Creating Layer bn3b_branch2b
I1022 15:39:00.623106 27315 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I1022 15:39:00.623114 27315 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I1022 15:39:00.623502 27315 net.cpp:150] Setting up bn3b_branch2b
I1022 15:39:00.623509 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.623512 27315 net.cpp:165] Memory required for data: 133869580
I1022 15:39:00.623531 27315 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1022 15:39:00.623539 27315 net.cpp:100] Creating Layer scale3b_branch2b
I1022 15:39:00.623543 27315 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I1022 15:39:00.623549 27315 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I1022 15:39:00.623615 27315 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1022 15:39:00.623817 27315 net.cpp:150] Setting up scale3b_branch2b
I1022 15:39:00.623824 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.623827 27315 net.cpp:165] Memory required for data: 134270988
I1022 15:39:00.623833 27315 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I1022 15:39:00.623841 27315 net.cpp:100] Creating Layer res3b_branch2b_relu
I1022 15:39:00.623843 27315 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I1022 15:39:00.623849 27315 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I1022 15:39:00.624088 27315 net.cpp:150] Setting up res3b_branch2b_relu
I1022 15:39:00.624096 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.624099 27315 net.cpp:165] Memory required for data: 134672396
I1022 15:39:00.624104 27315 layer_factory.hpp:77] Creating layer res3b_branch2c
I1022 15:39:00.624112 27315 net.cpp:100] Creating Layer res3b_branch2c
I1022 15:39:00.624117 27315 net.cpp:444] res3b_branch2c <- res3b_branch2b
I1022 15:39:00.624125 27315 net.cpp:418] res3b_branch2c -> res3b_branch2c
I1022 15:39:00.625994 27315 net.cpp:150] Setting up res3b_branch2c
I1022 15:39:00.626008 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.626010 27315 net.cpp:165] Memory required for data: 136278028
I1022 15:39:00.626024 27315 layer_factory.hpp:77] Creating layer bn3b_branch2c
I1022 15:39:00.626034 27315 net.cpp:100] Creating Layer bn3b_branch2c
I1022 15:39:00.626037 27315 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I1022 15:39:00.626042 27315 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I1022 15:39:00.626418 27315 net.cpp:150] Setting up bn3b_branch2c
I1022 15:39:00.626425 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.626428 27315 net.cpp:165] Memory required for data: 137883660
I1022 15:39:00.626441 27315 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1022 15:39:00.626447 27315 net.cpp:100] Creating Layer scale3b_branch2c
I1022 15:39:00.626451 27315 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I1022 15:39:00.626457 27315 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I1022 15:39:00.626528 27315 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1022 15:39:00.626727 27315 net.cpp:150] Setting up scale3b_branch2c
I1022 15:39:00.626734 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.626737 27315 net.cpp:165] Memory required for data: 139489292
I1022 15:39:00.626742 27315 layer_factory.hpp:77] Creating layer res3b
I1022 15:39:00.626749 27315 net.cpp:100] Creating Layer res3b
I1022 15:39:00.626754 27315 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I1022 15:39:00.626757 27315 net.cpp:444] res3b <- res3b_branch2c
I1022 15:39:00.626763 27315 net.cpp:418] res3b -> res3b
I1022 15:39:00.626802 27315 net.cpp:150] Setting up res3b
I1022 15:39:00.626809 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.626811 27315 net.cpp:165] Memory required for data: 141094924
I1022 15:39:00.626814 27315 layer_factory.hpp:77] Creating layer res3b_relu
I1022 15:39:00.626821 27315 net.cpp:100] Creating Layer res3b_relu
I1022 15:39:00.626827 27315 net.cpp:444] res3b_relu <- res3b
I1022 15:39:00.626830 27315 net.cpp:405] res3b_relu -> res3b (in-place)
I1022 15:39:00.627737 27315 net.cpp:150] Setting up res3b_relu
I1022 15:39:00.627758 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.627760 27315 net.cpp:165] Memory required for data: 142700556
I1022 15:39:00.627763 27315 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I1022 15:39:00.627769 27315 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I1022 15:39:00.627774 27315 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I1022 15:39:00.627781 27315 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I1022 15:39:00.627789 27315 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I1022 15:39:00.627864 27315 net.cpp:150] Setting up res3b_res3b_relu_0_split
I1022 15:39:00.627871 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.627873 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.627876 27315 net.cpp:165] Memory required for data: 145911820
I1022 15:39:00.627879 27315 layer_factory.hpp:77] Creating layer res3c_branch2a
I1022 15:39:00.627889 27315 net.cpp:100] Creating Layer res3c_branch2a
I1022 15:39:00.627892 27315 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I1022 15:39:00.627899 27315 net.cpp:418] res3c_branch2a -> res3c_branch2a
I1022 15:39:00.634507 27315 net.cpp:150] Setting up res3c_branch2a
I1022 15:39:00.634524 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.634527 27315 net.cpp:165] Memory required for data: 146313228
I1022 15:39:00.634533 27315 layer_factory.hpp:77] Creating layer bn3c_branch2a
I1022 15:39:00.634541 27315 net.cpp:100] Creating Layer bn3c_branch2a
I1022 15:39:00.634546 27315 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I1022 15:39:00.634552 27315 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I1022 15:39:00.634917 27315 net.cpp:150] Setting up bn3c_branch2a
I1022 15:39:00.634925 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.634928 27315 net.cpp:165] Memory required for data: 146714636
I1022 15:39:00.634935 27315 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1022 15:39:00.634943 27315 net.cpp:100] Creating Layer scale3c_branch2a
I1022 15:39:00.634948 27315 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I1022 15:39:00.634953 27315 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I1022 15:39:00.635020 27315 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1022 15:39:00.635222 27315 net.cpp:150] Setting up scale3c_branch2a
I1022 15:39:00.635231 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.635233 27315 net.cpp:165] Memory required for data: 147116044
I1022 15:39:00.635239 27315 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I1022 15:39:00.635246 27315 net.cpp:100] Creating Layer res3c_branch2a_relu
I1022 15:39:00.635251 27315 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I1022 15:39:00.635257 27315 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I1022 15:39:00.635494 27315 net.cpp:150] Setting up res3c_branch2a_relu
I1022 15:39:00.635504 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.635507 27315 net.cpp:165] Memory required for data: 147517452
I1022 15:39:00.635511 27315 layer_factory.hpp:77] Creating layer res3c_branch2b
I1022 15:39:00.635521 27315 net.cpp:100] Creating Layer res3c_branch2b
I1022 15:39:00.635527 27315 net.cpp:444] res3c_branch2b <- res3c_branch2a
I1022 15:39:00.635535 27315 net.cpp:418] res3c_branch2b -> res3c_branch2b
I1022 15:39:00.639889 27315 net.cpp:150] Setting up res3c_branch2b
I1022 15:39:00.639901 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.639905 27315 net.cpp:165] Memory required for data: 147918860
I1022 15:39:00.639911 27315 layer_factory.hpp:77] Creating layer bn3c_branch2b
I1022 15:39:00.639920 27315 net.cpp:100] Creating Layer bn3c_branch2b
I1022 15:39:00.639925 27315 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I1022 15:39:00.639931 27315 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I1022 15:39:00.640306 27315 net.cpp:150] Setting up bn3c_branch2b
I1022 15:39:00.640318 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.640321 27315 net.cpp:165] Memory required for data: 148320268
I1022 15:39:00.640336 27315 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1022 15:39:00.640342 27315 net.cpp:100] Creating Layer scale3c_branch2b
I1022 15:39:00.640347 27315 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I1022 15:39:00.640354 27315 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I1022 15:39:00.640421 27315 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1022 15:39:00.640651 27315 net.cpp:150] Setting up scale3c_branch2b
I1022 15:39:00.640661 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.640664 27315 net.cpp:165] Memory required for data: 148721676
I1022 15:39:00.640671 27315 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I1022 15:39:00.640676 27315 net.cpp:100] Creating Layer res3c_branch2b_relu
I1022 15:39:00.640679 27315 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I1022 15:39:00.640683 27315 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I1022 15:39:00.640944 27315 net.cpp:150] Setting up res3c_branch2b_relu
I1022 15:39:00.640952 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.640955 27315 net.cpp:165] Memory required for data: 149123084
I1022 15:39:00.640967 27315 layer_factory.hpp:77] Creating layer res3c_branch2c
I1022 15:39:00.640976 27315 net.cpp:100] Creating Layer res3c_branch2c
I1022 15:39:00.640983 27315 net.cpp:444] res3c_branch2c <- res3c_branch2b
I1022 15:39:00.640988 27315 net.cpp:418] res3c_branch2c -> res3c_branch2c
I1022 15:39:00.642848 27315 net.cpp:150] Setting up res3c_branch2c
I1022 15:39:00.642861 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.642864 27315 net.cpp:165] Memory required for data: 150728716
I1022 15:39:00.642870 27315 layer_factory.hpp:77] Creating layer bn3c_branch2c
I1022 15:39:00.642877 27315 net.cpp:100] Creating Layer bn3c_branch2c
I1022 15:39:00.642880 27315 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I1022 15:39:00.642896 27315 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I1022 15:39:00.643283 27315 net.cpp:150] Setting up bn3c_branch2c
I1022 15:39:00.643291 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.643294 27315 net.cpp:165] Memory required for data: 152334348
I1022 15:39:00.643301 27315 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1022 15:39:00.643309 27315 net.cpp:100] Creating Layer scale3c_branch2c
I1022 15:39:00.643313 27315 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I1022 15:39:00.643319 27315 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I1022 15:39:00.643389 27315 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1022 15:39:00.643592 27315 net.cpp:150] Setting up scale3c_branch2c
I1022 15:39:00.643600 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.643604 27315 net.cpp:165] Memory required for data: 153939980
I1022 15:39:00.643610 27315 layer_factory.hpp:77] Creating layer res3c
I1022 15:39:00.643615 27315 net.cpp:100] Creating Layer res3c
I1022 15:39:00.643620 27315 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I1022 15:39:00.643623 27315 net.cpp:444] res3c <- res3c_branch2c
I1022 15:39:00.643628 27315 net.cpp:418] res3c -> res3c
I1022 15:39:00.643668 27315 net.cpp:150] Setting up res3c
I1022 15:39:00.643676 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.643678 27315 net.cpp:165] Memory required for data: 155545612
I1022 15:39:00.643682 27315 layer_factory.hpp:77] Creating layer res3c_relu
I1022 15:39:00.643687 27315 net.cpp:100] Creating Layer res3c_relu
I1022 15:39:00.643689 27315 net.cpp:444] res3c_relu <- res3c
I1022 15:39:00.643694 27315 net.cpp:405] res3c_relu -> res3c (in-place)
I1022 15:39:00.643930 27315 net.cpp:150] Setting up res3c_relu
I1022 15:39:00.643942 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.643945 27315 net.cpp:165] Memory required for data: 157151244
I1022 15:39:00.643949 27315 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I1022 15:39:00.643954 27315 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I1022 15:39:00.643959 27315 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I1022 15:39:00.643966 27315 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I1022 15:39:00.643975 27315 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I1022 15:39:00.644047 27315 net.cpp:150] Setting up res3c_res3c_relu_0_split
I1022 15:39:00.644055 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.644059 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.644062 27315 net.cpp:165] Memory required for data: 160362508
I1022 15:39:00.644067 27315 layer_factory.hpp:77] Creating layer res3d_branch2a
I1022 15:39:00.644078 27315 net.cpp:100] Creating Layer res3d_branch2a
I1022 15:39:00.644083 27315 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I1022 15:39:00.644089 27315 net.cpp:418] res3d_branch2a -> res3d_branch2a
I1022 15:39:00.651182 27315 net.cpp:150] Setting up res3d_branch2a
I1022 15:39:00.651197 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.651201 27315 net.cpp:165] Memory required for data: 160763916
I1022 15:39:00.651206 27315 layer_factory.hpp:77] Creating layer bn3d_branch2a
I1022 15:39:00.651213 27315 net.cpp:100] Creating Layer bn3d_branch2a
I1022 15:39:00.651217 27315 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I1022 15:39:00.651226 27315 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I1022 15:39:00.651604 27315 net.cpp:150] Setting up bn3d_branch2a
I1022 15:39:00.651612 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.651615 27315 net.cpp:165] Memory required for data: 161165324
I1022 15:39:00.651635 27315 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1022 15:39:00.651643 27315 net.cpp:100] Creating Layer scale3d_branch2a
I1022 15:39:00.651648 27315 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I1022 15:39:00.651652 27315 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I1022 15:39:00.651720 27315 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1022 15:39:00.651924 27315 net.cpp:150] Setting up scale3d_branch2a
I1022 15:39:00.651932 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.651935 27315 net.cpp:165] Memory required for data: 161566732
I1022 15:39:00.651942 27315 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I1022 15:39:00.651947 27315 net.cpp:100] Creating Layer res3d_branch2a_relu
I1022 15:39:00.651949 27315 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I1022 15:39:00.651958 27315 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I1022 15:39:00.652897 27315 net.cpp:150] Setting up res3d_branch2a_relu
I1022 15:39:00.652910 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.652915 27315 net.cpp:165] Memory required for data: 161968140
I1022 15:39:00.652920 27315 layer_factory.hpp:77] Creating layer res3d_branch2b
I1022 15:39:00.652927 27315 net.cpp:100] Creating Layer res3d_branch2b
I1022 15:39:00.652931 27315 net.cpp:444] res3d_branch2b <- res3d_branch2a
I1022 15:39:00.652938 27315 net.cpp:418] res3d_branch2b -> res3d_branch2b
I1022 15:39:00.657085 27315 net.cpp:150] Setting up res3d_branch2b
I1022 15:39:00.657100 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.657104 27315 net.cpp:165] Memory required for data: 162369548
I1022 15:39:00.657110 27315 layer_factory.hpp:77] Creating layer bn3d_branch2b
I1022 15:39:00.657119 27315 net.cpp:100] Creating Layer bn3d_branch2b
I1022 15:39:00.657124 27315 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I1022 15:39:00.657130 27315 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I1022 15:39:00.657524 27315 net.cpp:150] Setting up bn3d_branch2b
I1022 15:39:00.657533 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.657536 27315 net.cpp:165] Memory required for data: 162770956
I1022 15:39:00.657543 27315 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1022 15:39:00.657552 27315 net.cpp:100] Creating Layer scale3d_branch2b
I1022 15:39:00.657554 27315 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I1022 15:39:00.657562 27315 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I1022 15:39:00.657627 27315 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1022 15:39:00.657831 27315 net.cpp:150] Setting up scale3d_branch2b
I1022 15:39:00.657840 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.657842 27315 net.cpp:165] Memory required for data: 163172364
I1022 15:39:00.657848 27315 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I1022 15:39:00.657860 27315 net.cpp:100] Creating Layer res3d_branch2b_relu
I1022 15:39:00.657866 27315 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I1022 15:39:00.657871 27315 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I1022 15:39:00.658123 27315 net.cpp:150] Setting up res3d_branch2b_relu
I1022 15:39:00.658133 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.658136 27315 net.cpp:165] Memory required for data: 163573772
I1022 15:39:00.658140 27315 layer_factory.hpp:77] Creating layer res3d_branch2c
I1022 15:39:00.658149 27315 net.cpp:100] Creating Layer res3d_branch2c
I1022 15:39:00.658154 27315 net.cpp:444] res3d_branch2c <- res3d_branch2b
I1022 15:39:00.658159 27315 net.cpp:418] res3d_branch2c -> res3d_branch2c
I1022 15:39:00.664186 27315 net.cpp:150] Setting up res3d_branch2c
I1022 15:39:00.664202 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.664206 27315 net.cpp:165] Memory required for data: 165179404
I1022 15:39:00.664212 27315 layer_factory.hpp:77] Creating layer bn3d_branch2c
I1022 15:39:00.664222 27315 net.cpp:100] Creating Layer bn3d_branch2c
I1022 15:39:00.664227 27315 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I1022 15:39:00.664233 27315 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I1022 15:39:00.664616 27315 net.cpp:150] Setting up bn3d_branch2c
I1022 15:39:00.664625 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.664628 27315 net.cpp:165] Memory required for data: 166785036
I1022 15:39:00.664635 27315 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1022 15:39:00.664654 27315 net.cpp:100] Creating Layer scale3d_branch2c
I1022 15:39:00.664659 27315 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I1022 15:39:00.664664 27315 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I1022 15:39:00.664748 27315 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1022 15:39:00.664953 27315 net.cpp:150] Setting up scale3d_branch2c
I1022 15:39:00.664960 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.664963 27315 net.cpp:165] Memory required for data: 168390668
I1022 15:39:00.664968 27315 layer_factory.hpp:77] Creating layer res3d
I1022 15:39:00.664976 27315 net.cpp:100] Creating Layer res3d
I1022 15:39:00.664981 27315 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I1022 15:39:00.664985 27315 net.cpp:444] res3d <- res3d_branch2c
I1022 15:39:00.664990 27315 net.cpp:418] res3d -> res3d
I1022 15:39:00.665030 27315 net.cpp:150] Setting up res3d
I1022 15:39:00.665036 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.665040 27315 net.cpp:165] Memory required for data: 169996300
I1022 15:39:00.665042 27315 layer_factory.hpp:77] Creating layer res3d_relu
I1022 15:39:00.665047 27315 net.cpp:100] Creating Layer res3d_relu
I1022 15:39:00.665050 27315 net.cpp:444] res3d_relu <- res3d
I1022 15:39:00.665066 27315 net.cpp:405] res3d_relu -> res3d (in-place)
I1022 15:39:00.665318 27315 net.cpp:150] Setting up res3d_relu
I1022 15:39:00.665328 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.665331 27315 net.cpp:165] Memory required for data: 171601932
I1022 15:39:00.665334 27315 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I1022 15:39:00.665341 27315 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I1022 15:39:00.665345 27315 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I1022 15:39:00.665350 27315 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I1022 15:39:00.665357 27315 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I1022 15:39:00.665364 27315 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_2
I1022 15:39:00.665462 27315 net.cpp:150] Setting up res3d_res3d_relu_0_split
I1022 15:39:00.665467 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.665472 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.665474 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.665477 27315 net.cpp:165] Memory required for data: 176418828
I1022 15:39:00.665480 27315 layer_factory.hpp:77] Creating layer res4a_branch1
I1022 15:39:00.665489 27315 net.cpp:100] Creating Layer res4a_branch1
I1022 15:39:00.665493 27315 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I1022 15:39:00.665498 27315 net.cpp:418] res4a_branch1 -> res4a_branch1
I1022 15:39:00.671615 27315 net.cpp:150] Setting up res4a_branch1
I1022 15:39:00.671629 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.671633 27315 net.cpp:165] Memory required for data: 177221644
I1022 15:39:00.671648 27315 layer_factory.hpp:77] Creating layer bn4a_branch1
I1022 15:39:00.671658 27315 net.cpp:100] Creating Layer bn4a_branch1
I1022 15:39:00.671660 27315 net.cpp:444] bn4a_branch1 <- res4a_branch1
I1022 15:39:00.671667 27315 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I1022 15:39:00.672097 27315 net.cpp:150] Setting up bn4a_branch1
I1022 15:39:00.672106 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.672108 27315 net.cpp:165] Memory required for data: 178024460
I1022 15:39:00.672124 27315 layer_factory.hpp:77] Creating layer scale4a_branch1
I1022 15:39:00.672130 27315 net.cpp:100] Creating Layer scale4a_branch1
I1022 15:39:00.672133 27315 net.cpp:444] scale4a_branch1 <- res4a_branch1
I1022 15:39:00.672140 27315 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I1022 15:39:00.672202 27315 layer_factory.hpp:77] Creating layer scale4a_branch1
I1022 15:39:00.672413 27315 net.cpp:150] Setting up scale4a_branch1
I1022 15:39:00.672421 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.672425 27315 net.cpp:165] Memory required for data: 178827276
I1022 15:39:00.672430 27315 layer_factory.hpp:77] Creating layer res4a_branch2a
I1022 15:39:00.672437 27315 net.cpp:100] Creating Layer res4a_branch2a
I1022 15:39:00.672441 27315 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I1022 15:39:00.672447 27315 net.cpp:418] res4a_branch2a -> res4a_branch2a
I1022 15:39:00.674835 27315 net.cpp:150] Setting up res4a_branch2a
I1022 15:39:00.674852 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.674855 27315 net.cpp:165] Memory required for data: 179027980
I1022 15:39:00.674861 27315 layer_factory.hpp:77] Creating layer bn4a_branch2a
I1022 15:39:00.674872 27315 net.cpp:100] Creating Layer bn4a_branch2a
I1022 15:39:00.674877 27315 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I1022 15:39:00.674882 27315 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I1022 15:39:00.675263 27315 net.cpp:150] Setting up bn4a_branch2a
I1022 15:39:00.675271 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.675273 27315 net.cpp:165] Memory required for data: 179228684
I1022 15:39:00.675282 27315 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1022 15:39:00.675288 27315 net.cpp:100] Creating Layer scale4a_branch2a
I1022 15:39:00.675292 27315 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I1022 15:39:00.675297 27315 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I1022 15:39:00.675366 27315 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1022 15:39:00.675567 27315 net.cpp:150] Setting up scale4a_branch2a
I1022 15:39:00.675575 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.675578 27315 net.cpp:165] Memory required for data: 179429388
I1022 15:39:00.675583 27315 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I1022 15:39:00.675590 27315 net.cpp:100] Creating Layer res4a_branch2a_relu
I1022 15:39:00.675595 27315 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I1022 15:39:00.675603 27315 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I1022 15:39:00.677021 27315 net.cpp:150] Setting up res4a_branch2a_relu
I1022 15:39:00.677033 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.677037 27315 net.cpp:165] Memory required for data: 179630092
I1022 15:39:00.677040 27315 layer_factory.hpp:77] Creating layer res4a_branch2b
I1022 15:39:00.677052 27315 net.cpp:100] Creating Layer res4a_branch2b
I1022 15:39:00.677055 27315 net.cpp:444] res4a_branch2b <- res4a_branch2a
I1022 15:39:00.677073 27315 net.cpp:418] res4a_branch2b -> res4a_branch2b
I1022 15:39:00.682001 27315 net.cpp:150] Setting up res4a_branch2b
I1022 15:39:00.682020 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.682024 27315 net.cpp:165] Memory required for data: 179830796
I1022 15:39:00.682039 27315 layer_factory.hpp:77] Creating layer bn4a_branch2b
I1022 15:39:00.682050 27315 net.cpp:100] Creating Layer bn4a_branch2b
I1022 15:39:00.682056 27315 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I1022 15:39:00.682065 27315 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I1022 15:39:00.682466 27315 net.cpp:150] Setting up bn4a_branch2b
I1022 15:39:00.682472 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.682476 27315 net.cpp:165] Memory required for data: 180031500
I1022 15:39:00.682492 27315 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1022 15:39:00.682502 27315 net.cpp:100] Creating Layer scale4a_branch2b
I1022 15:39:00.682505 27315 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I1022 15:39:00.682512 27315 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I1022 15:39:00.682582 27315 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1022 15:39:00.682790 27315 net.cpp:150] Setting up scale4a_branch2b
I1022 15:39:00.682797 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.682801 27315 net.cpp:165] Memory required for data: 180232204
I1022 15:39:00.682806 27315 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I1022 15:39:00.682813 27315 net.cpp:100] Creating Layer res4a_branch2b_relu
I1022 15:39:00.682819 27315 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I1022 15:39:00.682823 27315 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I1022 15:39:00.683076 27315 net.cpp:150] Setting up res4a_branch2b_relu
I1022 15:39:00.683087 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.683091 27315 net.cpp:165] Memory required for data: 180432908
I1022 15:39:00.683094 27315 layer_factory.hpp:77] Creating layer res4a_branch2c
I1022 15:39:00.683104 27315 net.cpp:100] Creating Layer res4a_branch2c
I1022 15:39:00.683107 27315 net.cpp:444] res4a_branch2c <- res4a_branch2b
I1022 15:39:00.683115 27315 net.cpp:418] res4a_branch2c -> res4a_branch2c
I1022 15:39:00.687065 27315 net.cpp:150] Setting up res4a_branch2c
I1022 15:39:00.687083 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.687098 27315 net.cpp:165] Memory required for data: 181235724
I1022 15:39:00.687104 27315 layer_factory.hpp:77] Creating layer bn4a_branch2c
I1022 15:39:00.687111 27315 net.cpp:100] Creating Layer bn4a_branch2c
I1022 15:39:00.687116 27315 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I1022 15:39:00.687124 27315 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I1022 15:39:00.687520 27315 net.cpp:150] Setting up bn4a_branch2c
I1022 15:39:00.687527 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.687530 27315 net.cpp:165] Memory required for data: 182038540
I1022 15:39:00.687546 27315 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1022 15:39:00.687556 27315 net.cpp:100] Creating Layer scale4a_branch2c
I1022 15:39:00.687559 27315 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I1022 15:39:00.687566 27315 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I1022 15:39:00.687629 27315 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1022 15:39:00.687850 27315 net.cpp:150] Setting up scale4a_branch2c
I1022 15:39:00.687858 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.687860 27315 net.cpp:165] Memory required for data: 182841356
I1022 15:39:00.687866 27315 layer_factory.hpp:77] Creating layer res4a
I1022 15:39:00.687875 27315 net.cpp:100] Creating Layer res4a
I1022 15:39:00.687878 27315 net.cpp:444] res4a <- res4a_branch1
I1022 15:39:00.687882 27315 net.cpp:444] res4a <- res4a_branch2c
I1022 15:39:00.687887 27315 net.cpp:418] res4a -> res4a
I1022 15:39:00.687929 27315 net.cpp:150] Setting up res4a
I1022 15:39:00.687937 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.687939 27315 net.cpp:165] Memory required for data: 183644172
I1022 15:39:00.687942 27315 layer_factory.hpp:77] Creating layer res4a_relu
I1022 15:39:00.687947 27315 net.cpp:100] Creating Layer res4a_relu
I1022 15:39:00.687950 27315 net.cpp:444] res4a_relu <- res4a
I1022 15:39:00.687957 27315 net.cpp:405] res4a_relu -> res4a (in-place)
I1022 15:39:00.689039 27315 net.cpp:150] Setting up res4a_relu
I1022 15:39:00.689054 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.689056 27315 net.cpp:165] Memory required for data: 184446988
I1022 15:39:00.689059 27315 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I1022 15:39:00.689074 27315 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I1022 15:39:00.689079 27315 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I1022 15:39:00.689093 27315 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I1022 15:39:00.689100 27315 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I1022 15:39:00.689188 27315 net.cpp:150] Setting up res4a_res4a_relu_0_split
I1022 15:39:00.689194 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.689199 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.689203 27315 net.cpp:165] Memory required for data: 186052620
I1022 15:39:00.689205 27315 layer_factory.hpp:77] Creating layer res4b_branch2a
I1022 15:39:00.689229 27315 net.cpp:100] Creating Layer res4b_branch2a
I1022 15:39:00.689234 27315 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I1022 15:39:00.689239 27315 net.cpp:418] res4b_branch2a -> res4b_branch2a
I1022 15:39:00.691248 27315 net.cpp:150] Setting up res4b_branch2a
I1022 15:39:00.691262 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.691265 27315 net.cpp:165] Memory required for data: 186253324
I1022 15:39:00.691277 27315 layer_factory.hpp:77] Creating layer bn4b_branch2a
I1022 15:39:00.691287 27315 net.cpp:100] Creating Layer bn4b_branch2a
I1022 15:39:00.691290 27315 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I1022 15:39:00.691298 27315 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I1022 15:39:00.691679 27315 net.cpp:150] Setting up bn4b_branch2a
I1022 15:39:00.691686 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.691690 27315 net.cpp:165] Memory required for data: 186454028
I1022 15:39:00.691705 27315 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1022 15:39:00.691714 27315 net.cpp:100] Creating Layer scale4b_branch2a
I1022 15:39:00.691716 27315 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I1022 15:39:00.691725 27315 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I1022 15:39:00.691792 27315 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1022 15:39:00.691998 27315 net.cpp:150] Setting up scale4b_branch2a
I1022 15:39:00.692005 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.692009 27315 net.cpp:165] Memory required for data: 186654732
I1022 15:39:00.692014 27315 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I1022 15:39:00.692024 27315 net.cpp:100] Creating Layer res4b_branch2a_relu
I1022 15:39:00.692028 27315 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I1022 15:39:00.692032 27315 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I1022 15:39:00.693455 27315 net.cpp:150] Setting up res4b_branch2a_relu
I1022 15:39:00.693473 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.693476 27315 net.cpp:165] Memory required for data: 186855436
I1022 15:39:00.693485 27315 layer_factory.hpp:77] Creating layer res4b_branch2b
I1022 15:39:00.693498 27315 net.cpp:100] Creating Layer res4b_branch2b
I1022 15:39:00.693502 27315 net.cpp:444] res4b_branch2b <- res4b_branch2a
I1022 15:39:00.693508 27315 net.cpp:418] res4b_branch2b -> res4b_branch2b
I1022 15:39:00.700536 27315 net.cpp:150] Setting up res4b_branch2b
I1022 15:39:00.700572 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.700575 27315 net.cpp:165] Memory required for data: 187056140
I1022 15:39:00.700584 27315 layer_factory.hpp:77] Creating layer bn4b_branch2b
I1022 15:39:00.700595 27315 net.cpp:100] Creating Layer bn4b_branch2b
I1022 15:39:00.700599 27315 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I1022 15:39:00.700634 27315 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I1022 15:39:00.701056 27315 net.cpp:150] Setting up bn4b_branch2b
I1022 15:39:00.701066 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.701068 27315 net.cpp:165] Memory required for data: 187256844
I1022 15:39:00.701084 27315 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1022 15:39:00.701092 27315 net.cpp:100] Creating Layer scale4b_branch2b
I1022 15:39:00.701095 27315 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I1022 15:39:00.701102 27315 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I1022 15:39:00.701176 27315 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1022 15:39:00.701385 27315 net.cpp:150] Setting up scale4b_branch2b
I1022 15:39:00.701393 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.701396 27315 net.cpp:165] Memory required for data: 187457548
I1022 15:39:00.701402 27315 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I1022 15:39:00.701407 27315 net.cpp:100] Creating Layer res4b_branch2b_relu
I1022 15:39:00.701413 27315 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I1022 15:39:00.701419 27315 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I1022 15:39:00.701673 27315 net.cpp:150] Setting up res4b_branch2b_relu
I1022 15:39:00.701681 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.701685 27315 net.cpp:165] Memory required for data: 187658252
I1022 15:39:00.701689 27315 layer_factory.hpp:77] Creating layer res4b_branch2c
I1022 15:39:00.701700 27315 net.cpp:100] Creating Layer res4b_branch2c
I1022 15:39:00.701704 27315 net.cpp:444] res4b_branch2c <- res4b_branch2b
I1022 15:39:00.701710 27315 net.cpp:418] res4b_branch2c -> res4b_branch2c
I1022 15:39:00.705663 27315 net.cpp:150] Setting up res4b_branch2c
I1022 15:39:00.705679 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.705693 27315 net.cpp:165] Memory required for data: 188461068
I1022 15:39:00.705699 27315 layer_factory.hpp:77] Creating layer bn4b_branch2c
I1022 15:39:00.705709 27315 net.cpp:100] Creating Layer bn4b_branch2c
I1022 15:39:00.705713 27315 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I1022 15:39:00.705719 27315 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I1022 15:39:00.706132 27315 net.cpp:150] Setting up bn4b_branch2c
I1022 15:39:00.706140 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.706143 27315 net.cpp:165] Memory required for data: 189263884
I1022 15:39:00.706159 27315 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1022 15:39:00.706168 27315 net.cpp:100] Creating Layer scale4b_branch2c
I1022 15:39:00.706172 27315 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I1022 15:39:00.706176 27315 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I1022 15:39:00.706241 27315 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1022 15:39:00.706465 27315 net.cpp:150] Setting up scale4b_branch2c
I1022 15:39:00.706472 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.706475 27315 net.cpp:165] Memory required for data: 190066700
I1022 15:39:00.706480 27315 layer_factory.hpp:77] Creating layer res4b
I1022 15:39:00.706488 27315 net.cpp:100] Creating Layer res4b
I1022 15:39:00.706495 27315 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I1022 15:39:00.706498 27315 net.cpp:444] res4b <- res4b_branch2c
I1022 15:39:00.706503 27315 net.cpp:418] res4b -> res4b
I1022 15:39:00.706547 27315 net.cpp:150] Setting up res4b
I1022 15:39:00.706555 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.706558 27315 net.cpp:165] Memory required for data: 190869516
I1022 15:39:00.706562 27315 layer_factory.hpp:77] Creating layer res4b_relu
I1022 15:39:00.706567 27315 net.cpp:100] Creating Layer res4b_relu
I1022 15:39:00.706569 27315 net.cpp:444] res4b_relu <- res4b
I1022 15:39:00.706573 27315 net.cpp:405] res4b_relu -> res4b (in-place)
I1022 15:39:00.706820 27315 net.cpp:150] Setting up res4b_relu
I1022 15:39:00.706828 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.706831 27315 net.cpp:165] Memory required for data: 191672332
I1022 15:39:00.706835 27315 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I1022 15:39:00.706841 27315 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I1022 15:39:00.706846 27315 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I1022 15:39:00.706854 27315 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I1022 15:39:00.706862 27315 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I1022 15:39:00.706939 27315 net.cpp:150] Setting up res4b_res4b_relu_0_split
I1022 15:39:00.706946 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.706950 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.706954 27315 net.cpp:165] Memory required for data: 193277964
I1022 15:39:00.706956 27315 layer_factory.hpp:77] Creating layer res4c_branch2a
I1022 15:39:00.706966 27315 net.cpp:100] Creating Layer res4c_branch2a
I1022 15:39:00.706971 27315 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I1022 15:39:00.706979 27315 net.cpp:418] res4c_branch2a -> res4c_branch2a
I1022 15:39:00.709635 27315 net.cpp:150] Setting up res4c_branch2a
I1022 15:39:00.709648 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.709651 27315 net.cpp:165] Memory required for data: 193478668
I1022 15:39:00.709661 27315 layer_factory.hpp:77] Creating layer bn4c_branch2a
I1022 15:39:00.709671 27315 net.cpp:100] Creating Layer bn4c_branch2a
I1022 15:39:00.709674 27315 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I1022 15:39:00.709681 27315 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I1022 15:39:00.710072 27315 net.cpp:150] Setting up bn4c_branch2a
I1022 15:39:00.710079 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.710083 27315 net.cpp:165] Memory required for data: 193679372
I1022 15:39:00.710098 27315 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1022 15:39:00.710106 27315 net.cpp:100] Creating Layer scale4c_branch2a
I1022 15:39:00.710109 27315 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I1022 15:39:00.710115 27315 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I1022 15:39:00.710184 27315 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1022 15:39:00.710393 27315 net.cpp:150] Setting up scale4c_branch2a
I1022 15:39:00.710402 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.710404 27315 net.cpp:165] Memory required for data: 193880076
I1022 15:39:00.710409 27315 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I1022 15:39:00.710417 27315 net.cpp:100] Creating Layer res4c_branch2a_relu
I1022 15:39:00.710422 27315 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I1022 15:39:00.710427 27315 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I1022 15:39:00.710662 27315 net.cpp:150] Setting up res4c_branch2a_relu
I1022 15:39:00.710671 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.710675 27315 net.cpp:165] Memory required for data: 194080780
I1022 15:39:00.710677 27315 layer_factory.hpp:77] Creating layer res4c_branch2b
I1022 15:39:00.710690 27315 net.cpp:100] Creating Layer res4c_branch2b
I1022 15:39:00.710695 27315 net.cpp:444] res4c_branch2b <- res4c_branch2a
I1022 15:39:00.710700 27315 net.cpp:418] res4c_branch2b -> res4c_branch2b
I1022 15:39:00.716964 27315 net.cpp:150] Setting up res4c_branch2b
I1022 15:39:00.716990 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.716995 27315 net.cpp:165] Memory required for data: 194281484
I1022 15:39:00.717000 27315 layer_factory.hpp:77] Creating layer bn4c_branch2b
I1022 15:39:00.717010 27315 net.cpp:100] Creating Layer bn4c_branch2b
I1022 15:39:00.717013 27315 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I1022 15:39:00.717020 27315 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I1022 15:39:00.717456 27315 net.cpp:150] Setting up bn4c_branch2b
I1022 15:39:00.717464 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.717468 27315 net.cpp:165] Memory required for data: 194482188
I1022 15:39:00.717484 27315 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1022 15:39:00.717492 27315 net.cpp:100] Creating Layer scale4c_branch2b
I1022 15:39:00.717496 27315 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I1022 15:39:00.717504 27315 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I1022 15:39:00.717574 27315 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1022 15:39:00.717784 27315 net.cpp:150] Setting up scale4c_branch2b
I1022 15:39:00.717792 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.717794 27315 net.cpp:165] Memory required for data: 194682892
I1022 15:39:00.717800 27315 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I1022 15:39:00.717805 27315 net.cpp:100] Creating Layer res4c_branch2b_relu
I1022 15:39:00.717810 27315 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I1022 15:39:00.717818 27315 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I1022 15:39:00.718760 27315 net.cpp:150] Setting up res4c_branch2b_relu
I1022 15:39:00.718773 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.718776 27315 net.cpp:165] Memory required for data: 194883596
I1022 15:39:00.718787 27315 layer_factory.hpp:77] Creating layer res4c_branch2c
I1022 15:39:00.718797 27315 net.cpp:100] Creating Layer res4c_branch2c
I1022 15:39:00.718801 27315 net.cpp:444] res4c_branch2c <- res4c_branch2b
I1022 15:39:00.718808 27315 net.cpp:418] res4c_branch2c -> res4c_branch2c
I1022 15:39:00.722755 27315 net.cpp:150] Setting up res4c_branch2c
I1022 15:39:00.722769 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.722774 27315 net.cpp:165] Memory required for data: 195686412
I1022 15:39:00.722779 27315 layer_factory.hpp:77] Creating layer bn4c_branch2c
I1022 15:39:00.722789 27315 net.cpp:100] Creating Layer bn4c_branch2c
I1022 15:39:00.722791 27315 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I1022 15:39:00.722796 27315 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I1022 15:39:00.723196 27315 net.cpp:150] Setting up bn4c_branch2c
I1022 15:39:00.723204 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.723207 27315 net.cpp:165] Memory required for data: 196489228
I1022 15:39:00.723214 27315 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1022 15:39:00.723227 27315 net.cpp:100] Creating Layer scale4c_branch2c
I1022 15:39:00.723229 27315 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I1022 15:39:00.723233 27315 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I1022 15:39:00.723300 27315 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1022 15:39:00.723522 27315 net.cpp:150] Setting up scale4c_branch2c
I1022 15:39:00.723529 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.723532 27315 net.cpp:165] Memory required for data: 197292044
I1022 15:39:00.723538 27315 layer_factory.hpp:77] Creating layer res4c
I1022 15:39:00.723548 27315 net.cpp:100] Creating Layer res4c
I1022 15:39:00.723551 27315 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I1022 15:39:00.723556 27315 net.cpp:444] res4c <- res4c_branch2c
I1022 15:39:00.723561 27315 net.cpp:418] res4c -> res4c
I1022 15:39:00.723603 27315 net.cpp:150] Setting up res4c
I1022 15:39:00.723609 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.723613 27315 net.cpp:165] Memory required for data: 198094860
I1022 15:39:00.723615 27315 layer_factory.hpp:77] Creating layer res4c_relu
I1022 15:39:00.723620 27315 net.cpp:100] Creating Layer res4c_relu
I1022 15:39:00.723623 27315 net.cpp:444] res4c_relu <- res4c
I1022 15:39:00.723628 27315 net.cpp:405] res4c_relu -> res4c (in-place)
I1022 15:39:00.723867 27315 net.cpp:150] Setting up res4c_relu
I1022 15:39:00.723876 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.723879 27315 net.cpp:165] Memory required for data: 198897676
I1022 15:39:00.723882 27315 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I1022 15:39:00.723888 27315 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I1022 15:39:00.723894 27315 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I1022 15:39:00.723902 27315 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I1022 15:39:00.723908 27315 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I1022 15:39:00.723987 27315 net.cpp:150] Setting up res4c_res4c_relu_0_split
I1022 15:39:00.723994 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.723999 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.724000 27315 net.cpp:165] Memory required for data: 200503308
I1022 15:39:00.724004 27315 layer_factory.hpp:77] Creating layer res4d_branch2a
I1022 15:39:00.724014 27315 net.cpp:100] Creating Layer res4d_branch2a
I1022 15:39:00.724018 27315 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I1022 15:39:00.724026 27315 net.cpp:418] res4d_branch2a -> res4d_branch2a
I1022 15:39:00.726083 27315 net.cpp:150] Setting up res4d_branch2a
I1022 15:39:00.726099 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.726101 27315 net.cpp:165] Memory required for data: 200704012
I1022 15:39:00.726109 27315 layer_factory.hpp:77] Creating layer bn4d_branch2a
I1022 15:39:00.726114 27315 net.cpp:100] Creating Layer bn4d_branch2a
I1022 15:39:00.726119 27315 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I1022 15:39:00.726125 27315 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I1022 15:39:00.726517 27315 net.cpp:150] Setting up bn4d_branch2a
I1022 15:39:00.726524 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.726528 27315 net.cpp:165] Memory required for data: 200904716
I1022 15:39:00.726543 27315 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1022 15:39:00.726552 27315 net.cpp:100] Creating Layer scale4d_branch2a
I1022 15:39:00.726554 27315 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I1022 15:39:00.726562 27315 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I1022 15:39:00.726635 27315 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1022 15:39:00.726864 27315 net.cpp:150] Setting up scale4d_branch2a
I1022 15:39:00.726872 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.726876 27315 net.cpp:165] Memory required for data: 201105420
I1022 15:39:00.726881 27315 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I1022 15:39:00.726891 27315 net.cpp:100] Creating Layer res4d_branch2a_relu
I1022 15:39:00.726894 27315 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I1022 15:39:00.726902 27315 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I1022 15:39:00.727152 27315 net.cpp:150] Setting up res4d_branch2a_relu
I1022 15:39:00.727161 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.727164 27315 net.cpp:165] Memory required for data: 201306124
I1022 15:39:00.727169 27315 layer_factory.hpp:77] Creating layer res4d_branch2b
I1022 15:39:00.727177 27315 net.cpp:100] Creating Layer res4d_branch2b
I1022 15:39:00.727181 27315 net.cpp:444] res4d_branch2b <- res4d_branch2a
I1022 15:39:00.727190 27315 net.cpp:418] res4d_branch2b -> res4d_branch2b
I1022 15:39:00.733398 27315 net.cpp:150] Setting up res4d_branch2b
I1022 15:39:00.733422 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.733430 27315 net.cpp:165] Memory required for data: 201506828
I1022 15:39:00.733439 27315 layer_factory.hpp:77] Creating layer bn4d_branch2b
I1022 15:39:00.733464 27315 net.cpp:100] Creating Layer bn4d_branch2b
I1022 15:39:00.733469 27315 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I1022 15:39:00.733474 27315 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I1022 15:39:00.733901 27315 net.cpp:150] Setting up bn4d_branch2b
I1022 15:39:00.733909 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.733912 27315 net.cpp:165] Memory required for data: 201707532
I1022 15:39:00.733930 27315 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1022 15:39:00.733939 27315 net.cpp:100] Creating Layer scale4d_branch2b
I1022 15:39:00.733943 27315 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I1022 15:39:00.733947 27315 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I1022 15:39:00.734021 27315 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1022 15:39:00.734242 27315 net.cpp:150] Setting up scale4d_branch2b
I1022 15:39:00.734251 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.734253 27315 net.cpp:165] Memory required for data: 201908236
I1022 15:39:00.734259 27315 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I1022 15:39:00.734266 27315 net.cpp:100] Creating Layer res4d_branch2b_relu
I1022 15:39:00.734272 27315 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I1022 15:39:00.734277 27315 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I1022 15:39:00.735239 27315 net.cpp:150] Setting up res4d_branch2b_relu
I1022 15:39:00.735251 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.735255 27315 net.cpp:165] Memory required for data: 202108940
I1022 15:39:00.735267 27315 layer_factory.hpp:77] Creating layer res4d_branch2c
I1022 15:39:00.735280 27315 net.cpp:100] Creating Layer res4d_branch2c
I1022 15:39:00.735283 27315 net.cpp:444] res4d_branch2c <- res4d_branch2b
I1022 15:39:00.735293 27315 net.cpp:418] res4d_branch2c -> res4d_branch2c
I1022 15:39:00.739437 27315 net.cpp:150] Setting up res4d_branch2c
I1022 15:39:00.739454 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.739467 27315 net.cpp:165] Memory required for data: 202911756
I1022 15:39:00.739473 27315 layer_factory.hpp:77] Creating layer bn4d_branch2c
I1022 15:39:00.739483 27315 net.cpp:100] Creating Layer bn4d_branch2c
I1022 15:39:00.739487 27315 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I1022 15:39:00.739495 27315 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I1022 15:39:00.739917 27315 net.cpp:150] Setting up bn4d_branch2c
I1022 15:39:00.739924 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.739926 27315 net.cpp:165] Memory required for data: 203714572
I1022 15:39:00.739943 27315 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1022 15:39:00.739951 27315 net.cpp:100] Creating Layer scale4d_branch2c
I1022 15:39:00.739954 27315 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I1022 15:39:00.739962 27315 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I1022 15:39:00.740029 27315 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1022 15:39:00.740257 27315 net.cpp:150] Setting up scale4d_branch2c
I1022 15:39:00.740265 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.740268 27315 net.cpp:165] Memory required for data: 204517388
I1022 15:39:00.740273 27315 layer_factory.hpp:77] Creating layer res4d
I1022 15:39:00.740283 27315 net.cpp:100] Creating Layer res4d
I1022 15:39:00.740286 27315 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I1022 15:39:00.740290 27315 net.cpp:444] res4d <- res4d_branch2c
I1022 15:39:00.740295 27315 net.cpp:418] res4d -> res4d
I1022 15:39:00.740339 27315 net.cpp:150] Setting up res4d
I1022 15:39:00.740346 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.740350 27315 net.cpp:165] Memory required for data: 205320204
I1022 15:39:00.740352 27315 layer_factory.hpp:77] Creating layer res4d_relu
I1022 15:39:00.740357 27315 net.cpp:100] Creating Layer res4d_relu
I1022 15:39:00.740360 27315 net.cpp:444] res4d_relu <- res4d
I1022 15:39:00.740366 27315 net.cpp:405] res4d_relu -> res4d (in-place)
I1022 15:39:00.740636 27315 net.cpp:150] Setting up res4d_relu
I1022 15:39:00.740650 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.740653 27315 net.cpp:165] Memory required for data: 206123020
I1022 15:39:00.740658 27315 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I1022 15:39:00.740664 27315 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I1022 15:39:00.740669 27315 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I1022 15:39:00.740675 27315 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I1022 15:39:00.740682 27315 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I1022 15:39:00.740766 27315 net.cpp:150] Setting up res4d_res4d_relu_0_split
I1022 15:39:00.740772 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.740777 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.740780 27315 net.cpp:165] Memory required for data: 207728652
I1022 15:39:00.740783 27315 layer_factory.hpp:77] Creating layer res4e_branch2a
I1022 15:39:00.740794 27315 net.cpp:100] Creating Layer res4e_branch2a
I1022 15:39:00.740799 27315 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I1022 15:39:00.740806 27315 net.cpp:418] res4e_branch2a -> res4e_branch2a
I1022 15:39:00.742895 27315 net.cpp:150] Setting up res4e_branch2a
I1022 15:39:00.742910 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.742913 27315 net.cpp:165] Memory required for data: 207929356
I1022 15:39:00.742926 27315 layer_factory.hpp:77] Creating layer bn4e_branch2a
I1022 15:39:00.742935 27315 net.cpp:100] Creating Layer bn4e_branch2a
I1022 15:39:00.742939 27315 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I1022 15:39:00.742946 27315 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I1022 15:39:00.743366 27315 net.cpp:150] Setting up bn4e_branch2a
I1022 15:39:00.743372 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.743376 27315 net.cpp:165] Memory required for data: 208130060
I1022 15:39:00.743391 27315 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1022 15:39:00.743398 27315 net.cpp:100] Creating Layer scale4e_branch2a
I1022 15:39:00.743402 27315 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I1022 15:39:00.743407 27315 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I1022 15:39:00.743477 27315 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1022 15:39:00.743695 27315 net.cpp:150] Setting up scale4e_branch2a
I1022 15:39:00.743701 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.743705 27315 net.cpp:165] Memory required for data: 208330764
I1022 15:39:00.743710 27315 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I1022 15:39:00.743717 27315 net.cpp:100] Creating Layer res4e_branch2a_relu
I1022 15:39:00.743723 27315 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I1022 15:39:00.743727 27315 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I1022 15:39:00.743969 27315 net.cpp:150] Setting up res4e_branch2a_relu
I1022 15:39:00.743978 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.743980 27315 net.cpp:165] Memory required for data: 208531468
I1022 15:39:00.743984 27315 layer_factory.hpp:77] Creating layer res4e_branch2b
I1022 15:39:00.743994 27315 net.cpp:100] Creating Layer res4e_branch2b
I1022 15:39:00.743999 27315 net.cpp:444] res4e_branch2b <- res4e_branch2a
I1022 15:39:00.744005 27315 net.cpp:418] res4e_branch2b -> res4e_branch2b
I1022 15:39:00.750383 27315 net.cpp:150] Setting up res4e_branch2b
I1022 15:39:00.750399 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.750402 27315 net.cpp:165] Memory required for data: 208732172
I1022 15:39:00.750414 27315 layer_factory.hpp:77] Creating layer bn4e_branch2b
I1022 15:39:00.750424 27315 net.cpp:100] Creating Layer bn4e_branch2b
I1022 15:39:00.750428 27315 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I1022 15:39:00.750437 27315 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I1022 15:39:00.750864 27315 net.cpp:150] Setting up bn4e_branch2b
I1022 15:39:00.750871 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.750874 27315 net.cpp:165] Memory required for data: 208932876
I1022 15:39:00.750891 27315 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1022 15:39:00.750900 27315 net.cpp:100] Creating Layer scale4e_branch2b
I1022 15:39:00.750902 27315 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I1022 15:39:00.750910 27315 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I1022 15:39:00.750986 27315 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1022 15:39:00.751205 27315 net.cpp:150] Setting up scale4e_branch2b
I1022 15:39:00.751214 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.751216 27315 net.cpp:165] Memory required for data: 209133580
I1022 15:39:00.751222 27315 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I1022 15:39:00.751230 27315 net.cpp:100] Creating Layer res4e_branch2b_relu
I1022 15:39:00.751233 27315 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I1022 15:39:00.751237 27315 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I1022 15:39:00.753304 27315 net.cpp:150] Setting up res4e_branch2b_relu
I1022 15:39:00.753319 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.753332 27315 net.cpp:165] Memory required for data: 209334284
I1022 15:39:00.753335 27315 layer_factory.hpp:77] Creating layer res4e_branch2c
I1022 15:39:00.753347 27315 net.cpp:100] Creating Layer res4e_branch2c
I1022 15:39:00.753353 27315 net.cpp:444] res4e_branch2c <- res4e_branch2b
I1022 15:39:00.753361 27315 net.cpp:418] res4e_branch2c -> res4e_branch2c
I1022 15:39:00.759119 27315 net.cpp:150] Setting up res4e_branch2c
I1022 15:39:00.759135 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.759150 27315 net.cpp:165] Memory required for data: 210137100
I1022 15:39:00.759157 27315 layer_factory.hpp:77] Creating layer bn4e_branch2c
I1022 15:39:00.759166 27315 net.cpp:100] Creating Layer bn4e_branch2c
I1022 15:39:00.759171 27315 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I1022 15:39:00.759178 27315 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I1022 15:39:00.759594 27315 net.cpp:150] Setting up bn4e_branch2c
I1022 15:39:00.759603 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.759605 27315 net.cpp:165] Memory required for data: 210939916
I1022 15:39:00.759613 27315 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1022 15:39:00.759619 27315 net.cpp:100] Creating Layer scale4e_branch2c
I1022 15:39:00.759622 27315 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I1022 15:39:00.759629 27315 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I1022 15:39:00.759696 27315 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1022 15:39:00.759932 27315 net.cpp:150] Setting up scale4e_branch2c
I1022 15:39:00.759939 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.759943 27315 net.cpp:165] Memory required for data: 211742732
I1022 15:39:00.759948 27315 layer_factory.hpp:77] Creating layer res4e
I1022 15:39:00.759958 27315 net.cpp:100] Creating Layer res4e
I1022 15:39:00.759961 27315 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I1022 15:39:00.759965 27315 net.cpp:444] res4e <- res4e_branch2c
I1022 15:39:00.759973 27315 net.cpp:418] res4e -> res4e
I1022 15:39:00.760015 27315 net.cpp:150] Setting up res4e
I1022 15:39:00.760022 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.760025 27315 net.cpp:165] Memory required for data: 212545548
I1022 15:39:00.760028 27315 layer_factory.hpp:77] Creating layer res4e_relu
I1022 15:39:00.760033 27315 net.cpp:100] Creating Layer res4e_relu
I1022 15:39:00.760036 27315 net.cpp:444] res4e_relu <- res4e
I1022 15:39:00.760042 27315 net.cpp:405] res4e_relu -> res4e (in-place)
I1022 15:39:00.760284 27315 net.cpp:150] Setting up res4e_relu
I1022 15:39:00.760293 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.760296 27315 net.cpp:165] Memory required for data: 213348364
I1022 15:39:00.760299 27315 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I1022 15:39:00.760308 27315 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I1022 15:39:00.760313 27315 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I1022 15:39:00.760320 27315 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I1022 15:39:00.760329 27315 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I1022 15:39:00.760408 27315 net.cpp:150] Setting up res4e_res4e_relu_0_split
I1022 15:39:00.760416 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.760421 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.760422 27315 net.cpp:165] Memory required for data: 214953996
I1022 15:39:00.760426 27315 layer_factory.hpp:77] Creating layer res4f_branch2a
I1022 15:39:00.760437 27315 net.cpp:100] Creating Layer res4f_branch2a
I1022 15:39:00.760442 27315 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I1022 15:39:00.760447 27315 net.cpp:418] res4f_branch2a -> res4f_branch2a
I1022 15:39:00.762531 27315 net.cpp:150] Setting up res4f_branch2a
I1022 15:39:00.762545 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.762548 27315 net.cpp:165] Memory required for data: 215154700
I1022 15:39:00.762553 27315 layer_factory.hpp:77] Creating layer bn4f_branch2a
I1022 15:39:00.762567 27315 net.cpp:100] Creating Layer bn4f_branch2a
I1022 15:39:00.762570 27315 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I1022 15:39:00.762578 27315 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I1022 15:39:00.762995 27315 net.cpp:150] Setting up bn4f_branch2a
I1022 15:39:00.763002 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.763005 27315 net.cpp:165] Memory required for data: 215355404
I1022 15:39:00.763021 27315 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1022 15:39:00.763028 27315 net.cpp:100] Creating Layer scale4f_branch2a
I1022 15:39:00.763031 27315 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I1022 15:39:00.763036 27315 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I1022 15:39:00.763109 27315 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1022 15:39:00.763330 27315 net.cpp:150] Setting up scale4f_branch2a
I1022 15:39:00.763339 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.763342 27315 net.cpp:165] Memory required for data: 215556108
I1022 15:39:00.763348 27315 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I1022 15:39:00.763355 27315 net.cpp:100] Creating Layer res4f_branch2a_relu
I1022 15:39:00.763357 27315 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I1022 15:39:00.763362 27315 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I1022 15:39:00.763612 27315 net.cpp:150] Setting up res4f_branch2a_relu
I1022 15:39:00.763623 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.763626 27315 net.cpp:165] Memory required for data: 215756812
I1022 15:39:00.763630 27315 layer_factory.hpp:77] Creating layer res4f_branch2b
I1022 15:39:00.763639 27315 net.cpp:100] Creating Layer res4f_branch2b
I1022 15:39:00.763644 27315 net.cpp:444] res4f_branch2b <- res4f_branch2a
I1022 15:39:00.763649 27315 net.cpp:418] res4f_branch2b -> res4f_branch2b
I1022 15:39:00.770231 27315 net.cpp:150] Setting up res4f_branch2b
I1022 15:39:00.770270 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.770277 27315 net.cpp:165] Memory required for data: 215957516
I1022 15:39:00.770288 27315 layer_factory.hpp:77] Creating layer bn4f_branch2b
I1022 15:39:00.770303 27315 net.cpp:100] Creating Layer bn4f_branch2b
I1022 15:39:00.770310 27315 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I1022 15:39:00.770331 27315 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I1022 15:39:00.770784 27315 net.cpp:150] Setting up bn4f_branch2b
I1022 15:39:00.770794 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.770797 27315 net.cpp:165] Memory required for data: 216158220
I1022 15:39:00.770812 27315 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1022 15:39:00.770819 27315 net.cpp:100] Creating Layer scale4f_branch2b
I1022 15:39:00.770823 27315 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I1022 15:39:00.770838 27315 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I1022 15:39:00.770911 27315 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1022 15:39:00.771129 27315 net.cpp:150] Setting up scale4f_branch2b
I1022 15:39:00.771137 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.771140 27315 net.cpp:165] Memory required for data: 216358924
I1022 15:39:00.771147 27315 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I1022 15:39:00.771154 27315 net.cpp:100] Creating Layer res4f_branch2b_relu
I1022 15:39:00.771158 27315 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I1022 15:39:00.771164 27315 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I1022 15:39:00.771412 27315 net.cpp:150] Setting up res4f_branch2b_relu
I1022 15:39:00.771422 27315 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:39:00.771425 27315 net.cpp:165] Memory required for data: 216559628
I1022 15:39:00.771428 27315 layer_factory.hpp:77] Creating layer res4f_branch2c
I1022 15:39:00.771440 27315 net.cpp:100] Creating Layer res4f_branch2c
I1022 15:39:00.771445 27315 net.cpp:444] res4f_branch2c <- res4f_branch2b
I1022 15:39:00.771453 27315 net.cpp:418] res4f_branch2c -> res4f_branch2c
I1022 15:39:00.775463 27315 net.cpp:150] Setting up res4f_branch2c
I1022 15:39:00.775478 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.775481 27315 net.cpp:165] Memory required for data: 217362444
I1022 15:39:00.775492 27315 layer_factory.hpp:77] Creating layer bn4f_branch2c
I1022 15:39:00.775501 27315 net.cpp:100] Creating Layer bn4f_branch2c
I1022 15:39:00.775506 27315 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I1022 15:39:00.775511 27315 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I1022 15:39:00.775928 27315 net.cpp:150] Setting up bn4f_branch2c
I1022 15:39:00.775934 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.775938 27315 net.cpp:165] Memory required for data: 218165260
I1022 15:39:00.775974 27315 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1022 15:39:00.775980 27315 net.cpp:100] Creating Layer scale4f_branch2c
I1022 15:39:00.775984 27315 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I1022 15:39:00.775988 27315 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I1022 15:39:00.776058 27315 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1022 15:39:00.776293 27315 net.cpp:150] Setting up scale4f_branch2c
I1022 15:39:00.776299 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.776302 27315 net.cpp:165] Memory required for data: 218968076
I1022 15:39:00.776309 27315 layer_factory.hpp:77] Creating layer res4f
I1022 15:39:00.776314 27315 net.cpp:100] Creating Layer res4f
I1022 15:39:00.776320 27315 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I1022 15:39:00.776324 27315 net.cpp:444] res4f <- res4f_branch2c
I1022 15:39:00.776329 27315 net.cpp:418] res4f -> res4f
I1022 15:39:00.776374 27315 net.cpp:150] Setting up res4f
I1022 15:39:00.776381 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.776383 27315 net.cpp:165] Memory required for data: 219770892
I1022 15:39:00.776386 27315 layer_factory.hpp:77] Creating layer res4f_relu
I1022 15:39:00.776391 27315 net.cpp:100] Creating Layer res4f_relu
I1022 15:39:00.776394 27315 net.cpp:444] res4f_relu <- res4f
I1022 15:39:00.776398 27315 net.cpp:405] res4f_relu -> res4f (in-place)
I1022 15:39:00.777364 27315 net.cpp:150] Setting up res4f_relu
I1022 15:39:00.777379 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.777382 27315 net.cpp:165] Memory required for data: 220573708
I1022 15:39:00.777391 27315 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I1022 15:39:00.777398 27315 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I1022 15:39:00.777402 27315 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I1022 15:39:00.777410 27315 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I1022 15:39:00.777417 27315 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I1022 15:39:00.777422 27315 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I1022 15:39:00.777539 27315 net.cpp:150] Setting up res4f_res4f_relu_0_split
I1022 15:39:00.777545 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.777549 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.777552 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:00.777555 27315 net.cpp:165] Memory required for data: 222982156
I1022 15:39:00.777559 27315 layer_factory.hpp:77] Creating layer res5a_branch1
I1022 15:39:00.777568 27315 net.cpp:100] Creating Layer res5a_branch1
I1022 15:39:00.777573 27315 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I1022 15:39:00.777580 27315 net.cpp:418] res5a_branch1 -> res5a_branch1
I1022 15:39:00.785388 27315 net.cpp:150] Setting up res5a_branch1
I1022 15:39:00.785404 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.785418 27315 net.cpp:165] Memory required for data: 223383564
I1022 15:39:00.785424 27315 layer_factory.hpp:77] Creating layer bn5a_branch1
I1022 15:39:00.785434 27315 net.cpp:100] Creating Layer bn5a_branch1
I1022 15:39:00.785439 27315 net.cpp:444] bn5a_branch1 <- res5a_branch1
I1022 15:39:00.785446 27315 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I1022 15:39:00.785928 27315 net.cpp:150] Setting up bn5a_branch1
I1022 15:39:00.785934 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.785938 27315 net.cpp:165] Memory required for data: 223784972
I1022 15:39:00.785953 27315 layer_factory.hpp:77] Creating layer scale5a_branch1
I1022 15:39:00.785961 27315 net.cpp:100] Creating Layer scale5a_branch1
I1022 15:39:00.785965 27315 net.cpp:444] scale5a_branch1 <- res5a_branch1
I1022 15:39:00.785969 27315 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I1022 15:39:00.786042 27315 layer_factory.hpp:77] Creating layer scale5a_branch1
I1022 15:39:00.786280 27315 net.cpp:150] Setting up scale5a_branch1
I1022 15:39:00.786288 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.786291 27315 net.cpp:165] Memory required for data: 224186380
I1022 15:39:00.786296 27315 layer_factory.hpp:77] Creating layer res5a_branch2a
I1022 15:39:00.786306 27315 net.cpp:100] Creating Layer res5a_branch2a
I1022 15:39:00.786312 27315 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I1022 15:39:00.786317 27315 net.cpp:418] res5a_branch2a -> res5a_branch2a
I1022 15:39:00.797726 27315 net.cpp:150] Setting up res5a_branch2a
I1022 15:39:00.797741 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.797745 27315 net.cpp:165] Memory required for data: 224286732
I1022 15:39:00.797757 27315 layer_factory.hpp:77] Creating layer bn5a_branch2a
I1022 15:39:00.797767 27315 net.cpp:100] Creating Layer bn5a_branch2a
I1022 15:39:00.797771 27315 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I1022 15:39:00.797776 27315 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I1022 15:39:00.798207 27315 net.cpp:150] Setting up bn5a_branch2a
I1022 15:39:00.798214 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.798218 27315 net.cpp:165] Memory required for data: 224387084
I1022 15:39:00.798234 27315 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1022 15:39:00.798243 27315 net.cpp:100] Creating Layer scale5a_branch2a
I1022 15:39:00.798246 27315 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I1022 15:39:00.798251 27315 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I1022 15:39:00.798321 27315 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1022 15:39:00.798555 27315 net.cpp:150] Setting up scale5a_branch2a
I1022 15:39:00.798563 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.798566 27315 net.cpp:165] Memory required for data: 224487436
I1022 15:39:00.798571 27315 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I1022 15:39:00.798581 27315 net.cpp:100] Creating Layer res5a_branch2a_relu
I1022 15:39:00.798585 27315 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I1022 15:39:00.798589 27315 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I1022 15:39:00.798832 27315 net.cpp:150] Setting up res5a_branch2a_relu
I1022 15:39:00.798842 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.798844 27315 net.cpp:165] Memory required for data: 224587788
I1022 15:39:00.798848 27315 layer_factory.hpp:77] Creating layer res5a_branch2b
I1022 15:39:00.798858 27315 net.cpp:100] Creating Layer res5a_branch2b
I1022 15:39:00.798863 27315 net.cpp:444] res5a_branch2b <- res5a_branch2a
I1022 15:39:00.798871 27315 net.cpp:418] res5a_branch2b -> res5a_branch2b
I1022 15:39:00.805853 27315 net.cpp:150] Setting up res5a_branch2b
I1022 15:39:00.805868 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.805871 27315 net.cpp:165] Memory required for data: 224688140
I1022 15:39:00.805886 27315 layer_factory.hpp:77] Creating layer bn5a_branch2b
I1022 15:39:00.805896 27315 net.cpp:100] Creating Layer bn5a_branch2b
I1022 15:39:00.805899 27315 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I1022 15:39:00.805909 27315 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I1022 15:39:00.806341 27315 net.cpp:150] Setting up bn5a_branch2b
I1022 15:39:00.806351 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.806354 27315 net.cpp:165] Memory required for data: 224788492
I1022 15:39:00.806371 27315 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1022 15:39:00.806377 27315 net.cpp:100] Creating Layer scale5a_branch2b
I1022 15:39:00.806381 27315 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I1022 15:39:00.806390 27315 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I1022 15:39:00.806458 27315 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1022 15:39:00.806699 27315 net.cpp:150] Setting up scale5a_branch2b
I1022 15:39:00.806707 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.806710 27315 net.cpp:165] Memory required for data: 224888844
I1022 15:39:00.806716 27315 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I1022 15:39:00.806721 27315 net.cpp:100] Creating Layer res5a_branch2b_relu
I1022 15:39:00.806726 27315 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I1022 15:39:00.806733 27315 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I1022 15:39:00.806979 27315 net.cpp:150] Setting up res5a_branch2b_relu
I1022 15:39:00.806989 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.806993 27315 net.cpp:165] Memory required for data: 224989196
I1022 15:39:00.806996 27315 layer_factory.hpp:77] Creating layer res5a_branch2c
I1022 15:39:00.807005 27315 net.cpp:100] Creating Layer res5a_branch2c
I1022 15:39:00.807009 27315 net.cpp:444] res5a_branch2c <- res5a_branch2b
I1022 15:39:00.807016 27315 net.cpp:418] res5a_branch2c -> res5a_branch2c
I1022 15:39:00.812376 27315 net.cpp:150] Setting up res5a_branch2c
I1022 15:39:00.812389 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.812392 27315 net.cpp:165] Memory required for data: 225390604
I1022 15:39:00.812409 27315 layer_factory.hpp:77] Creating layer bn5a_branch2c
I1022 15:39:00.812418 27315 net.cpp:100] Creating Layer bn5a_branch2c
I1022 15:39:00.812423 27315 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I1022 15:39:00.812428 27315 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I1022 15:39:00.812913 27315 net.cpp:150] Setting up bn5a_branch2c
I1022 15:39:00.812934 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.812937 27315 net.cpp:165] Memory required for data: 225792012
I1022 15:39:00.812944 27315 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1022 15:39:00.812954 27315 net.cpp:100] Creating Layer scale5a_branch2c
I1022 15:39:00.812959 27315 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I1022 15:39:00.812963 27315 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I1022 15:39:00.813045 27315 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1022 15:39:00.813302 27315 net.cpp:150] Setting up scale5a_branch2c
I1022 15:39:00.813308 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.813311 27315 net.cpp:165] Memory required for data: 226193420
I1022 15:39:00.813316 27315 layer_factory.hpp:77] Creating layer res5a
I1022 15:39:00.813323 27315 net.cpp:100] Creating Layer res5a
I1022 15:39:00.813328 27315 net.cpp:444] res5a <- res5a_branch1
I1022 15:39:00.813333 27315 net.cpp:444] res5a <- res5a_branch2c
I1022 15:39:00.813338 27315 net.cpp:418] res5a -> res5a
I1022 15:39:00.813382 27315 net.cpp:150] Setting up res5a
I1022 15:39:00.813388 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.813391 27315 net.cpp:165] Memory required for data: 226594828
I1022 15:39:00.813395 27315 layer_factory.hpp:77] Creating layer res5a_relu
I1022 15:39:00.813400 27315 net.cpp:100] Creating Layer res5a_relu
I1022 15:39:00.813403 27315 net.cpp:444] res5a_relu <- res5a
I1022 15:39:00.813407 27315 net.cpp:405] res5a_relu -> res5a (in-place)
I1022 15:39:00.818727 27315 net.cpp:150] Setting up res5a_relu
I1022 15:39:00.818756 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.818759 27315 net.cpp:165] Memory required for data: 226996236
I1022 15:39:00.818763 27315 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I1022 15:39:00.818780 27315 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I1022 15:39:00.818785 27315 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I1022 15:39:00.818794 27315 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I1022 15:39:00.818801 27315 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I1022 15:39:00.818892 27315 net.cpp:150] Setting up res5a_res5a_relu_0_split
I1022 15:39:00.818900 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.818905 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.818907 27315 net.cpp:165] Memory required for data: 227799052
I1022 15:39:00.818910 27315 layer_factory.hpp:77] Creating layer res5b_branch2a
I1022 15:39:00.818922 27315 net.cpp:100] Creating Layer res5b_branch2a
I1022 15:39:00.818926 27315 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I1022 15:39:00.818931 27315 net.cpp:418] res5b_branch2a -> res5b_branch2a
I1022 15:39:00.824323 27315 net.cpp:150] Setting up res5b_branch2a
I1022 15:39:00.824337 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.824340 27315 net.cpp:165] Memory required for data: 227899404
I1022 15:39:00.824354 27315 layer_factory.hpp:77] Creating layer bn5b_branch2a
I1022 15:39:00.824367 27315 net.cpp:100] Creating Layer bn5b_branch2a
I1022 15:39:00.824373 27315 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I1022 15:39:00.824378 27315 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I1022 15:39:00.824841 27315 net.cpp:150] Setting up bn5b_branch2a
I1022 15:39:00.824849 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.824853 27315 net.cpp:165] Memory required for data: 227999756
I1022 15:39:00.824870 27315 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1022 15:39:00.824877 27315 net.cpp:100] Creating Layer scale5b_branch2a
I1022 15:39:00.824879 27315 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I1022 15:39:00.824887 27315 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I1022 15:39:00.824965 27315 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1022 15:39:00.825218 27315 net.cpp:150] Setting up scale5b_branch2a
I1022 15:39:00.825227 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.825229 27315 net.cpp:165] Memory required for data: 228100108
I1022 15:39:00.825235 27315 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I1022 15:39:00.825242 27315 net.cpp:100] Creating Layer res5b_branch2a_relu
I1022 15:39:00.825247 27315 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I1022 15:39:00.825253 27315 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I1022 15:39:00.825495 27315 net.cpp:150] Setting up res5b_branch2a_relu
I1022 15:39:00.825503 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.825505 27315 net.cpp:165] Memory required for data: 228200460
I1022 15:39:00.825510 27315 layer_factory.hpp:77] Creating layer res5b_branch2b
I1022 15:39:00.825520 27315 net.cpp:100] Creating Layer res5b_branch2b
I1022 15:39:00.825525 27315 net.cpp:444] res5b_branch2b <- res5b_branch2a
I1022 15:39:00.825533 27315 net.cpp:418] res5b_branch2b -> res5b_branch2b
I1022 15:39:00.832429 27315 net.cpp:150] Setting up res5b_branch2b
I1022 15:39:00.832444 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.832448 27315 net.cpp:165] Memory required for data: 228300812
I1022 15:39:00.832461 27315 layer_factory.hpp:77] Creating layer bn5b_branch2b
I1022 15:39:00.832469 27315 net.cpp:100] Creating Layer bn5b_branch2b
I1022 15:39:00.832473 27315 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I1022 15:39:00.832482 27315 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I1022 15:39:00.832947 27315 net.cpp:150] Setting up bn5b_branch2b
I1022 15:39:00.832955 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.832958 27315 net.cpp:165] Memory required for data: 228401164
I1022 15:39:00.832975 27315 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1022 15:39:00.832981 27315 net.cpp:100] Creating Layer scale5b_branch2b
I1022 15:39:00.832985 27315 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I1022 15:39:00.832993 27315 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I1022 15:39:00.833071 27315 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1022 15:39:00.833317 27315 net.cpp:150] Setting up scale5b_branch2b
I1022 15:39:00.833328 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.833330 27315 net.cpp:165] Memory required for data: 228501516
I1022 15:39:00.833336 27315 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I1022 15:39:00.833341 27315 net.cpp:100] Creating Layer res5b_branch2b_relu
I1022 15:39:00.833345 27315 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I1022 15:39:00.833350 27315 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I1022 15:39:00.833601 27315 net.cpp:150] Setting up res5b_branch2b_relu
I1022 15:39:00.833613 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.833616 27315 net.cpp:165] Memory required for data: 228601868
I1022 15:39:00.833621 27315 layer_factory.hpp:77] Creating layer res5b_branch2c
I1022 15:39:00.833628 27315 net.cpp:100] Creating Layer res5b_branch2c
I1022 15:39:00.833631 27315 net.cpp:444] res5b_branch2c <- res5b_branch2b
I1022 15:39:00.833639 27315 net.cpp:418] res5b_branch2c -> res5b_branch2c
I1022 15:39:00.844580 27315 net.cpp:150] Setting up res5b_branch2c
I1022 15:39:00.844597 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.844621 27315 net.cpp:165] Memory required for data: 229003276
I1022 15:39:00.844640 27315 layer_factory.hpp:77] Creating layer bn5b_branch2c
I1022 15:39:00.844647 27315 net.cpp:100] Creating Layer bn5b_branch2c
I1022 15:39:00.844651 27315 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I1022 15:39:00.844658 27315 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I1022 15:39:00.845118 27315 net.cpp:150] Setting up bn5b_branch2c
I1022 15:39:00.845126 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.845129 27315 net.cpp:165] Memory required for data: 229404684
I1022 15:39:00.845146 27315 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1022 15:39:00.845155 27315 net.cpp:100] Creating Layer scale5b_branch2c
I1022 15:39:00.845158 27315 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I1022 15:39:00.845165 27315 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I1022 15:39:00.845237 27315 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1022 15:39:00.845485 27315 net.cpp:150] Setting up scale5b_branch2c
I1022 15:39:00.845492 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.845495 27315 net.cpp:165] Memory required for data: 229806092
I1022 15:39:00.845501 27315 layer_factory.hpp:77] Creating layer res5b
I1022 15:39:00.845510 27315 net.cpp:100] Creating Layer res5b
I1022 15:39:00.845516 27315 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I1022 15:39:00.845520 27315 net.cpp:444] res5b <- res5b_branch2c
I1022 15:39:00.845525 27315 net.cpp:418] res5b -> res5b
I1022 15:39:00.845571 27315 net.cpp:150] Setting up res5b
I1022 15:39:00.845577 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.845580 27315 net.cpp:165] Memory required for data: 230207500
I1022 15:39:00.845583 27315 layer_factory.hpp:77] Creating layer res5b_relu
I1022 15:39:00.845588 27315 net.cpp:100] Creating Layer res5b_relu
I1022 15:39:00.845592 27315 net.cpp:444] res5b_relu <- res5b
I1022 15:39:00.845597 27315 net.cpp:405] res5b_relu -> res5b (in-place)
I1022 15:39:00.846599 27315 net.cpp:150] Setting up res5b_relu
I1022 15:39:00.846612 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.846616 27315 net.cpp:165] Memory required for data: 230608908
I1022 15:39:00.846624 27315 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I1022 15:39:00.846633 27315 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I1022 15:39:00.846637 27315 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I1022 15:39:00.846643 27315 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I1022 15:39:00.846654 27315 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I1022 15:39:00.846743 27315 net.cpp:150] Setting up res5b_res5b_relu_0_split
I1022 15:39:00.846751 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.846755 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.846757 27315 net.cpp:165] Memory required for data: 231411724
I1022 15:39:00.846760 27315 layer_factory.hpp:77] Creating layer res5c_branch2a
I1022 15:39:00.846772 27315 net.cpp:100] Creating Layer res5c_branch2a
I1022 15:39:00.846777 27315 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I1022 15:39:00.846782 27315 net.cpp:418] res5c_branch2a -> res5c_branch2a
I1022 15:39:00.852248 27315 net.cpp:150] Setting up res5c_branch2a
I1022 15:39:00.852262 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.852265 27315 net.cpp:165] Memory required for data: 231512076
I1022 15:39:00.852282 27315 layer_factory.hpp:77] Creating layer bn5c_branch2a
I1022 15:39:00.852290 27315 net.cpp:100] Creating Layer bn5c_branch2a
I1022 15:39:00.852294 27315 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I1022 15:39:00.852301 27315 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I1022 15:39:00.852780 27315 net.cpp:150] Setting up bn5c_branch2a
I1022 15:39:00.852789 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.852792 27315 net.cpp:165] Memory required for data: 231612428
I1022 15:39:00.852808 27315 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1022 15:39:00.852816 27315 net.cpp:100] Creating Layer scale5c_branch2a
I1022 15:39:00.852820 27315 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I1022 15:39:00.852828 27315 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I1022 15:39:00.852900 27315 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1022 15:39:00.853161 27315 net.cpp:150] Setting up scale5c_branch2a
I1022 15:39:00.853168 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.853173 27315 net.cpp:165] Memory required for data: 231712780
I1022 15:39:00.853178 27315 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I1022 15:39:00.853183 27315 net.cpp:100] Creating Layer res5c_branch2a_relu
I1022 15:39:00.853186 27315 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I1022 15:39:00.853191 27315 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I1022 15:39:00.853437 27315 net.cpp:150] Setting up res5c_branch2a_relu
I1022 15:39:00.853446 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.853449 27315 net.cpp:165] Memory required for data: 231813132
I1022 15:39:00.853453 27315 layer_factory.hpp:77] Creating layer res5c_branch2b
I1022 15:39:00.853464 27315 net.cpp:100] Creating Layer res5c_branch2b
I1022 15:39:00.853469 27315 net.cpp:444] res5c_branch2b <- res5c_branch2a
I1022 15:39:00.853474 27315 net.cpp:418] res5c_branch2b -> res5c_branch2b
I1022 15:39:00.867439 27315 net.cpp:150] Setting up res5c_branch2b
I1022 15:39:00.867453 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.867456 27315 net.cpp:165] Memory required for data: 231913484
I1022 15:39:00.867468 27315 layer_factory.hpp:77] Creating layer bn5c_branch2b
I1022 15:39:00.867477 27315 net.cpp:100] Creating Layer bn5c_branch2b
I1022 15:39:00.867480 27315 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I1022 15:39:00.867488 27315 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I1022 15:39:00.867930 27315 net.cpp:150] Setting up bn5c_branch2b
I1022 15:39:00.867938 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.867941 27315 net.cpp:165] Memory required for data: 232013836
I1022 15:39:00.867959 27315 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1022 15:39:00.867965 27315 net.cpp:100] Creating Layer scale5c_branch2b
I1022 15:39:00.867971 27315 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I1022 15:39:00.867975 27315 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I1022 15:39:00.868047 27315 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1022 15:39:00.868294 27315 net.cpp:150] Setting up scale5c_branch2b
I1022 15:39:00.868302 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.868305 27315 net.cpp:165] Memory required for data: 232114188
I1022 15:39:00.868311 27315 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I1022 15:39:00.868320 27315 net.cpp:100] Creating Layer res5c_branch2b_relu
I1022 15:39:00.868324 27315 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I1022 15:39:00.868329 27315 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I1022 15:39:00.868589 27315 net.cpp:150] Setting up res5c_branch2b_relu
I1022 15:39:00.868598 27315 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:39:00.868602 27315 net.cpp:165] Memory required for data: 232214540
I1022 15:39:00.868605 27315 layer_factory.hpp:77] Creating layer res5c_branch2c
I1022 15:39:00.868633 27315 net.cpp:100] Creating Layer res5c_branch2c
I1022 15:39:00.868636 27315 net.cpp:444] res5c_branch2c <- res5c_branch2b
I1022 15:39:00.868644 27315 net.cpp:418] res5c_branch2c -> res5c_branch2c
I1022 15:39:00.874121 27315 net.cpp:150] Setting up res5c_branch2c
I1022 15:39:00.874135 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.874138 27315 net.cpp:165] Memory required for data: 232615948
I1022 15:39:00.874153 27315 layer_factory.hpp:77] Creating layer bn5c_branch2c
I1022 15:39:00.874162 27315 net.cpp:100] Creating Layer bn5c_branch2c
I1022 15:39:00.874166 27315 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I1022 15:39:00.874171 27315 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I1022 15:39:00.874624 27315 net.cpp:150] Setting up bn5c_branch2c
I1022 15:39:00.874632 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.874634 27315 net.cpp:165] Memory required for data: 233017356
I1022 15:39:00.874651 27315 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1022 15:39:00.874660 27315 net.cpp:100] Creating Layer scale5c_branch2c
I1022 15:39:00.874663 27315 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I1022 15:39:00.874670 27315 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I1022 15:39:00.874744 27315 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1022 15:39:00.875001 27315 net.cpp:150] Setting up scale5c_branch2c
I1022 15:39:00.875008 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.875011 27315 net.cpp:165] Memory required for data: 233418764
I1022 15:39:00.875017 27315 layer_factory.hpp:77] Creating layer res5c
I1022 15:39:00.875025 27315 net.cpp:100] Creating Layer res5c
I1022 15:39:00.875032 27315 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I1022 15:39:00.875036 27315 net.cpp:444] res5c <- res5c_branch2c
I1022 15:39:00.875042 27315 net.cpp:418] res5c -> res5c
I1022 15:39:00.875087 27315 net.cpp:150] Setting up res5c
I1022 15:39:00.875093 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.875097 27315 net.cpp:165] Memory required for data: 233820172
I1022 15:39:00.875099 27315 layer_factory.hpp:77] Creating layer res5c_relu
I1022 15:39:00.875106 27315 net.cpp:100] Creating Layer res5c_relu
I1022 15:39:00.875110 27315 net.cpp:444] res5c_relu <- res5c
I1022 15:39:00.875116 27315 net.cpp:405] res5c_relu -> res5c (in-place)
I1022 15:39:00.875361 27315 net.cpp:150] Setting up res5c_relu
I1022 15:39:00.875371 27315 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:39:00.875375 27315 net.cpp:165] Memory required for data: 234221580
I1022 15:39:00.875377 27315 layer_factory.hpp:77] Creating layer upP4
I1022 15:39:00.875386 27315 net.cpp:100] Creating Layer upP4
I1022 15:39:00.875392 27315 net.cpp:444] upP4 <- res5c
I1022 15:39:00.875396 27315 net.cpp:418] upP4 -> upP4
I1022 15:39:00.877439 27315 net.cpp:150] Setting up upP4
I1022 15:39:00.877446 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.877449 27315 net.cpp:165] Memory required for data: 234622988
I1022 15:39:00.877462 27315 layer_factory.hpp:77] Creating layer newC4
I1022 15:39:00.877472 27315 net.cpp:100] Creating Layer newC4
I1022 15:39:00.877476 27315 net.cpp:444] newC4 <- res4f_res4f_relu_0_split_2
I1022 15:39:00.877485 27315 net.cpp:418] newC4 -> c4
I1022 15:39:00.890661 27315 net.cpp:150] Setting up newC4
I1022 15:39:00.890676 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.890679 27315 net.cpp:165] Memory required for data: 235024396
I1022 15:39:00.890694 27315 layer_factory.hpp:77] Creating layer eltwise_bnc4_bnp4
I1022 15:39:00.890702 27315 net.cpp:100] Creating Layer eltwise_bnc4_bnp4
I1022 15:39:00.890705 27315 net.cpp:444] eltwise_bnc4_bnp4 <- c4
I1022 15:39:00.890710 27315 net.cpp:444] eltwise_bnc4_bnp4 <- upP4
I1022 15:39:00.890718 27315 net.cpp:418] eltwise_bnc4_bnp4 -> skip_eltwise1
I1022 15:39:00.890784 27315 net.cpp:150] Setting up eltwise_bnc4_bnp4
I1022 15:39:00.890792 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.890796 27315 net.cpp:165] Memory required for data: 235425804
I1022 15:39:00.890799 27315 layer_factory.hpp:77] Creating layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 15:39:00.890807 27315 net.cpp:100] Creating Layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 15:39:00.890813 27315 net.cpp:444] skip_eltwise1_eltwise_bnc4_bnp4_0_split <- skip_eltwise1
I1022 15:39:00.890818 27315 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1022 15:39:00.890827 27315 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1022 15:39:00.890903 27315 net.cpp:150] Setting up skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 15:39:00.890910 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.890914 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.890918 27315 net.cpp:165] Memory required for data: 236228620
I1022 15:39:00.890920 27315 layer_factory.hpp:77] Creating layer bnp4_conv
I1022 15:39:00.890933 27315 net.cpp:100] Creating Layer bnp4_conv
I1022 15:39:00.890938 27315 net.cpp:444] bnp4_conv <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1022 15:39:00.890944 27315 net.cpp:418] bnp4_conv -> bnp4_conv
I1022 15:39:00.893653 27315 net.cpp:150] Setting up bnp4_conv
I1022 15:39:00.893666 27315 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:39:00.893669 27315 net.cpp:165] Memory required for data: 236328972
I1022 15:39:00.893683 27315 layer_factory.hpp:77] Creating layer bnp4_bn
I1022 15:39:00.893692 27315 net.cpp:100] Creating Layer bnp4_bn
I1022 15:39:00.893697 27315 net.cpp:444] bnp4_bn <- bnp4_conv
I1022 15:39:00.893703 27315 net.cpp:405] bnp4_bn -> bnp4_conv (in-place)
I1022 15:39:00.894148 27315 net.cpp:150] Setting up bnp4_bn
I1022 15:39:00.894157 27315 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:39:00.894160 27315 net.cpp:165] Memory required for data: 236429324
I1022 15:39:00.894176 27315 layer_factory.hpp:77] Creating layer bnp4_scale
I1022 15:39:00.894182 27315 net.cpp:100] Creating Layer bnp4_scale
I1022 15:39:00.894186 27315 net.cpp:444] bnp4_scale <- bnp4_conv
I1022 15:39:00.894191 27315 net.cpp:405] bnp4_scale -> bnp4_conv (in-place)
I1022 15:39:00.894268 27315 layer_factory.hpp:77] Creating layer bnp4_scale
I1022 15:39:00.894500 27315 net.cpp:150] Setting up bnp4_scale
I1022 15:39:00.894507 27315 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:39:00.894510 27315 net.cpp:165] Memory required for data: 236529676
I1022 15:39:00.894515 27315 layer_factory.hpp:77] Creating layer bnp4_ReLU
I1022 15:39:00.894523 27315 net.cpp:100] Creating Layer bnp4_ReLU
I1022 15:39:00.894526 27315 net.cpp:444] bnp4_ReLU <- bnp4_conv
I1022 15:39:00.894531 27315 net.cpp:405] bnp4_ReLU -> bnp4_conv (in-place)
I1022 15:39:00.895547 27315 net.cpp:150] Setting up bnp4_ReLU
I1022 15:39:00.895563 27315 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:39:00.895575 27315 net.cpp:165] Memory required for data: 236630028
I1022 15:39:00.895578 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_conv
I1022 15:39:00.895589 27315 net.cpp:100] Creating Layer bn_eltwise_1_1_conv
I1022 15:39:00.895594 27315 net.cpp:444] bn_eltwise_1_1_conv <- bnp4_conv
I1022 15:39:00.895601 27315 net.cpp:418] bn_eltwise_1_1_conv -> bn_eltwise_1_1_conv
I1022 15:39:00.905653 27315 net.cpp:150] Setting up bn_eltwise_1_1_conv
I1022 15:39:00.905668 27315 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:39:00.905673 27315 net.cpp:165] Memory required for data: 236730380
I1022 15:39:00.905686 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_bn
I1022 15:39:00.905694 27315 net.cpp:100] Creating Layer bn_eltwise_1_1_bn
I1022 15:39:00.905697 27315 net.cpp:444] bn_eltwise_1_1_bn <- bn_eltwise_1_1_conv
I1022 15:39:00.905704 27315 net.cpp:405] bn_eltwise_1_1_bn -> bn_eltwise_1_1_conv (in-place)
I1022 15:39:00.906155 27315 net.cpp:150] Setting up bn_eltwise_1_1_bn
I1022 15:39:00.906163 27315 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:39:00.906167 27315 net.cpp:165] Memory required for data: 236830732
I1022 15:39:00.906181 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1022 15:39:00.906190 27315 net.cpp:100] Creating Layer bn_eltwise_1_1_scale
I1022 15:39:00.906193 27315 net.cpp:444] bn_eltwise_1_1_scale <- bn_eltwise_1_1_conv
I1022 15:39:00.906198 27315 net.cpp:405] bn_eltwise_1_1_scale -> bn_eltwise_1_1_conv (in-place)
I1022 15:39:00.906282 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1022 15:39:00.906518 27315 net.cpp:150] Setting up bn_eltwise_1_1_scale
I1022 15:39:00.906527 27315 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:39:00.906529 27315 net.cpp:165] Memory required for data: 236931084
I1022 15:39:00.906535 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_ReLU
I1022 15:39:00.906543 27315 net.cpp:100] Creating Layer bn_eltwise_1_1_ReLU
I1022 15:39:00.906546 27315 net.cpp:444] bn_eltwise_1_1_ReLU <- bn_eltwise_1_1_conv
I1022 15:39:00.906550 27315 net.cpp:405] bn_eltwise_1_1_ReLU -> bn_eltwise_1_1_conv (in-place)
I1022 15:39:00.906805 27315 net.cpp:150] Setting up bn_eltwise_1_1_ReLU
I1022 15:39:00.906816 27315 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:39:00.906818 27315 net.cpp:165] Memory required for data: 237031436
I1022 15:39:00.906821 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_conv
I1022 15:39:00.906831 27315 net.cpp:100] Creating Layer bn_eltwise_1_2_conv
I1022 15:39:00.906836 27315 net.cpp:444] bn_eltwise_1_2_conv <- bn_eltwise_1_1_conv
I1022 15:39:00.906842 27315 net.cpp:418] bn_eltwise_1_2_conv -> bn_eltwise_1_2_conv
I1022 15:39:00.909600 27315 net.cpp:150] Setting up bn_eltwise_1_2_conv
I1022 15:39:00.909613 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.909616 27315 net.cpp:165] Memory required for data: 237432844
I1022 15:39:00.909629 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_bn
I1022 15:39:00.909637 27315 net.cpp:100] Creating Layer bn_eltwise_1_2_bn
I1022 15:39:00.909641 27315 net.cpp:444] bn_eltwise_1_2_bn <- bn_eltwise_1_2_conv
I1022 15:39:00.909648 27315 net.cpp:405] bn_eltwise_1_2_bn -> bn_eltwise_1_2_conv (in-place)
I1022 15:39:00.910094 27315 net.cpp:150] Setting up bn_eltwise_1_2_bn
I1022 15:39:00.910100 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.910104 27315 net.cpp:165] Memory required for data: 237834252
I1022 15:39:00.910121 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1022 15:39:00.910143 27315 net.cpp:100] Creating Layer bn_eltwise_1_2_scale
I1022 15:39:00.910147 27315 net.cpp:444] bn_eltwise_1_2_scale <- bn_eltwise_1_2_conv
I1022 15:39:00.910152 27315 net.cpp:405] bn_eltwise_1_2_scale -> bn_eltwise_1_2_conv (in-place)
I1022 15:39:00.910219 27315 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1022 15:39:00.910471 27315 net.cpp:150] Setting up bn_eltwise_1_2_scale
I1022 15:39:00.910478 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.910482 27315 net.cpp:165] Memory required for data: 238235660
I1022 15:39:00.910488 27315 layer_factory.hpp:77] Creating layer p3
I1022 15:39:00.910495 27315 net.cpp:100] Creating Layer p3
I1022 15:39:00.910499 27315 net.cpp:444] p3 <- bn_eltwise_1_2_conv
I1022 15:39:00.910504 27315 net.cpp:444] p3 <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1022 15:39:00.910511 27315 net.cpp:418] p3 -> p3
I1022 15:39:00.910559 27315 net.cpp:150] Setting up p3
I1022 15:39:00.910567 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.910569 27315 net.cpp:165] Memory required for data: 238637068
I1022 15:39:00.910573 27315 layer_factory.hpp:77] Creating layer p3_relu
I1022 15:39:00.910579 27315 net.cpp:100] Creating Layer p3_relu
I1022 15:39:00.910583 27315 net.cpp:444] p3_relu <- p3
I1022 15:39:00.910588 27315 net.cpp:405] p3_relu -> p3 (in-place)
I1022 15:39:00.910825 27315 net.cpp:150] Setting up p3_relu
I1022 15:39:00.910833 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.910836 27315 net.cpp:165] Memory required for data: 239038476
I1022 15:39:00.910840 27315 layer_factory.hpp:77] Creating layer p3_p3_relu_0_split
I1022 15:39:00.910848 27315 net.cpp:100] Creating Layer p3_p3_relu_0_split
I1022 15:39:00.910852 27315 net.cpp:444] p3_p3_relu_0_split <- p3
I1022 15:39:00.910857 27315 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_0
I1022 15:39:00.910867 27315 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_1
I1022 15:39:00.910874 27315 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_2
I1022 15:39:00.910989 27315 net.cpp:150] Setting up p3_p3_relu_0_split
I1022 15:39:00.910995 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.911000 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.911002 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:00.911005 27315 net.cpp:165] Memory required for data: 240242700
I1022 15:39:00.911008 27315 layer_factory.hpp:77] Creating layer newC3
I1022 15:39:00.911021 27315 net.cpp:100] Creating Layer newC3
I1022 15:39:00.911025 27315 net.cpp:444] newC3 <- res3d_res3d_relu_0_split_2
I1022 15:39:00.911031 27315 net.cpp:418] newC3 -> c3
I1022 15:39:00.919417 27315 net.cpp:150] Setting up newC3
I1022 15:39:00.919433 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.919436 27315 net.cpp:165] Memory required for data: 241848332
I1022 15:39:00.919446 27315 layer_factory.hpp:77] Creating layer upP3
I1022 15:39:00.919458 27315 net.cpp:100] Creating Layer upP3
I1022 15:39:00.919463 27315 net.cpp:444] upP3 <- p3_p3_relu_0_split_0
I1022 15:39:00.919469 27315 net.cpp:418] upP3 -> upP3
I1022 15:39:00.920307 27315 net.cpp:150] Setting up upP3
I1022 15:39:00.920316 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.920320 27315 net.cpp:165] Memory required for data: 243453964
I1022 15:39:00.920325 27315 layer_factory.hpp:77] Creating layer eltwise_bnc3_bnp3
I1022 15:39:00.920332 27315 net.cpp:100] Creating Layer eltwise_bnc3_bnp3
I1022 15:39:00.920336 27315 net.cpp:444] eltwise_bnc3_bnp3 <- c3
I1022 15:39:00.920341 27315 net.cpp:444] eltwise_bnc3_bnp3 <- upP3
I1022 15:39:00.920347 27315 net.cpp:418] eltwise_bnc3_bnp3 -> skip_eltwise2
I1022 15:39:00.920395 27315 net.cpp:150] Setting up eltwise_bnc3_bnp3
I1022 15:39:00.920403 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.920405 27315 net.cpp:165] Memory required for data: 245059596
I1022 15:39:00.920408 27315 layer_factory.hpp:77] Creating layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 15:39:00.920415 27315 net.cpp:100] Creating Layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 15:39:00.920419 27315 net.cpp:444] skip_eltwise2_eltwise_bnc3_bnp3_0_split <- skip_eltwise2
I1022 15:39:00.920424 27315 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1022 15:39:00.920430 27315 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1022 15:39:00.920506 27315 net.cpp:150] Setting up skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 15:39:00.920513 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.920518 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.920521 27315 net.cpp:165] Memory required for data: 248270860
I1022 15:39:00.920523 27315 layer_factory.hpp:77] Creating layer bnp3_conv
I1022 15:39:00.920531 27315 net.cpp:100] Creating Layer bnp3_conv
I1022 15:39:00.920536 27315 net.cpp:444] bnp3_conv <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1022 15:39:00.920544 27315 net.cpp:418] bnp3_conv -> bnp3_conv
I1022 15:39:00.923710 27315 net.cpp:150] Setting up bnp3_conv
I1022 15:39:00.923725 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.923729 27315 net.cpp:165] Memory required for data: 248672268
I1022 15:39:00.923735 27315 layer_factory.hpp:77] Creating layer bnp3_bn
I1022 15:39:00.923744 27315 net.cpp:100] Creating Layer bnp3_bn
I1022 15:39:00.923748 27315 net.cpp:444] bnp3_bn <- bnp3_conv
I1022 15:39:00.923755 27315 net.cpp:405] bnp3_bn -> bnp3_conv (in-place)
I1022 15:39:00.924214 27315 net.cpp:150] Setting up bnp3_bn
I1022 15:39:00.924222 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.924226 27315 net.cpp:165] Memory required for data: 249073676
I1022 15:39:00.924232 27315 layer_factory.hpp:77] Creating layer bnp3_scale
I1022 15:39:00.924242 27315 net.cpp:100] Creating Layer bnp3_scale
I1022 15:39:00.924245 27315 net.cpp:444] bnp3_scale <- bnp3_conv
I1022 15:39:00.924252 27315 net.cpp:405] bnp3_scale -> bnp3_conv (in-place)
I1022 15:39:00.924327 27315 layer_factory.hpp:77] Creating layer bnp3_scale
I1022 15:39:00.924574 27315 net.cpp:150] Setting up bnp3_scale
I1022 15:39:00.924582 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.924584 27315 net.cpp:165] Memory required for data: 249475084
I1022 15:39:00.924590 27315 layer_factory.hpp:77] Creating layer bnp3_ReLU
I1022 15:39:00.924597 27315 net.cpp:100] Creating Layer bnp3_ReLU
I1022 15:39:00.924603 27315 net.cpp:444] bnp3_ReLU <- bnp3_conv
I1022 15:39:00.924618 27315 net.cpp:405] bnp3_ReLU -> bnp3_conv (in-place)
I1022 15:39:00.925639 27315 net.cpp:150] Setting up bnp3_ReLU
I1022 15:39:00.925652 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.925655 27315 net.cpp:165] Memory required for data: 249876492
I1022 15:39:00.925658 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_conv
I1022 15:39:00.925675 27315 net.cpp:100] Creating Layer bn_eltwise_2_1_conv
I1022 15:39:00.925679 27315 net.cpp:444] bn_eltwise_2_1_conv <- bnp3_conv
I1022 15:39:00.925688 27315 net.cpp:418] bn_eltwise_2_1_conv -> bn_eltwise_2_1_conv
I1022 15:39:00.929975 27315 net.cpp:150] Setting up bn_eltwise_2_1_conv
I1022 15:39:00.929989 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.930001 27315 net.cpp:165] Memory required for data: 250277900
I1022 15:39:00.930007 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_bn
I1022 15:39:00.930017 27315 net.cpp:100] Creating Layer bn_eltwise_2_1_bn
I1022 15:39:00.930022 27315 net.cpp:444] bn_eltwise_2_1_bn <- bn_eltwise_2_1_conv
I1022 15:39:00.930027 27315 net.cpp:405] bn_eltwise_2_1_bn -> bn_eltwise_2_1_conv (in-place)
I1022 15:39:00.930485 27315 net.cpp:150] Setting up bn_eltwise_2_1_bn
I1022 15:39:00.930492 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.930496 27315 net.cpp:165] Memory required for data: 250679308
I1022 15:39:00.930503 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1022 15:39:00.930511 27315 net.cpp:100] Creating Layer bn_eltwise_2_1_scale
I1022 15:39:00.930516 27315 net.cpp:444] bn_eltwise_2_1_scale <- bn_eltwise_2_1_conv
I1022 15:39:00.930521 27315 net.cpp:405] bn_eltwise_2_1_scale -> bn_eltwise_2_1_conv (in-place)
I1022 15:39:00.930601 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1022 15:39:00.930846 27315 net.cpp:150] Setting up bn_eltwise_2_1_scale
I1022 15:39:00.930853 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.930856 27315 net.cpp:165] Memory required for data: 251080716
I1022 15:39:00.930862 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_ReLU
I1022 15:39:00.930871 27315 net.cpp:100] Creating Layer bn_eltwise_2_1_ReLU
I1022 15:39:00.930874 27315 net.cpp:444] bn_eltwise_2_1_ReLU <- bn_eltwise_2_1_conv
I1022 15:39:00.930881 27315 net.cpp:405] bn_eltwise_2_1_ReLU -> bn_eltwise_2_1_conv (in-place)
I1022 15:39:00.931134 27315 net.cpp:150] Setting up bn_eltwise_2_1_ReLU
I1022 15:39:00.931143 27315 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:39:00.931146 27315 net.cpp:165] Memory required for data: 251482124
I1022 15:39:00.931150 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_conv
I1022 15:39:00.931162 27315 net.cpp:100] Creating Layer bn_eltwise_2_2_conv
I1022 15:39:00.931166 27315 net.cpp:444] bn_eltwise_2_2_conv <- bn_eltwise_2_1_conv
I1022 15:39:00.931172 27315 net.cpp:418] bn_eltwise_2_2_conv -> bn_eltwise_2_2_conv
I1022 15:39:00.933923 27315 net.cpp:150] Setting up bn_eltwise_2_2_conv
I1022 15:39:00.933936 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.933939 27315 net.cpp:165] Memory required for data: 253087756
I1022 15:39:00.933944 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_bn
I1022 15:39:00.933954 27315 net.cpp:100] Creating Layer bn_eltwise_2_2_bn
I1022 15:39:00.933957 27315 net.cpp:444] bn_eltwise_2_2_bn <- bn_eltwise_2_2_conv
I1022 15:39:00.933964 27315 net.cpp:405] bn_eltwise_2_2_bn -> bn_eltwise_2_2_conv (in-place)
I1022 15:39:00.934417 27315 net.cpp:150] Setting up bn_eltwise_2_2_bn
I1022 15:39:00.934425 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.934428 27315 net.cpp:165] Memory required for data: 254693388
I1022 15:39:00.934435 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1022 15:39:00.934444 27315 net.cpp:100] Creating Layer bn_eltwise_2_2_scale
I1022 15:39:00.934448 27315 net.cpp:444] bn_eltwise_2_2_scale <- bn_eltwise_2_2_conv
I1022 15:39:00.934454 27315 net.cpp:405] bn_eltwise_2_2_scale -> bn_eltwise_2_2_conv (in-place)
I1022 15:39:00.934538 27315 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1022 15:39:00.934785 27315 net.cpp:150] Setting up bn_eltwise_2_2_scale
I1022 15:39:00.934793 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.934797 27315 net.cpp:165] Memory required for data: 256299020
I1022 15:39:00.934803 27315 layer_factory.hpp:77] Creating layer p2
I1022 15:39:00.934810 27315 net.cpp:100] Creating Layer p2
I1022 15:39:00.934816 27315 net.cpp:444] p2 <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1022 15:39:00.934821 27315 net.cpp:444] p2 <- bn_eltwise_2_2_conv
I1022 15:39:00.934826 27315 net.cpp:418] p2 -> p2
I1022 15:39:00.934872 27315 net.cpp:150] Setting up p2
I1022 15:39:00.934880 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.934882 27315 net.cpp:165] Memory required for data: 257904652
I1022 15:39:00.934885 27315 layer_factory.hpp:77] Creating layer p2_relu
I1022 15:39:00.934890 27315 net.cpp:100] Creating Layer p2_relu
I1022 15:39:00.934895 27315 net.cpp:444] p2_relu <- p2
I1022 15:39:00.934900 27315 net.cpp:405] p2_relu -> p2 (in-place)
I1022 15:39:00.935150 27315 net.cpp:150] Setting up p2_relu
I1022 15:39:00.935159 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.935163 27315 net.cpp:165] Memory required for data: 259510284
I1022 15:39:00.935165 27315 layer_factory.hpp:77] Creating layer p2_p2_relu_0_split
I1022 15:39:00.935173 27315 net.cpp:100] Creating Layer p2_p2_relu_0_split
I1022 15:39:00.935178 27315 net.cpp:444] p2_p2_relu_0_split <- p2
I1022 15:39:00.935184 27315 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_0
I1022 15:39:00.935194 27315 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_1
I1022 15:39:00.935293 27315 net.cpp:150] Setting up p2_p2_relu_0_split
I1022 15:39:00.935300 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.935305 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.935308 27315 net.cpp:165] Memory required for data: 262721548
I1022 15:39:00.935312 27315 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p2
I1022 15:39:00.935322 27315 net.cpp:100] Creating Layer rpn_conv/3x3_p2
I1022 15:39:00.935328 27315 net.cpp:444] rpn_conv/3x3_p2 <- p2_p2_relu_0_split_0
I1022 15:39:00.935336 27315 net.cpp:418] rpn_conv/3x3_p2 -> rpn/output_p2
I1022 15:39:00.969357 27315 net.cpp:150] Setting up rpn_conv/3x3_p2
I1022 15:39:00.969373 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.969377 27315 net.cpp:165] Memory required for data: 264327180
I1022 15:39:00.969384 27315 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p2
I1022 15:39:00.969391 27315 net.cpp:100] Creating Layer rpn_relu/3x3_p2
I1022 15:39:00.969395 27315 net.cpp:444] rpn_relu/3x3_p2 <- rpn/output_p2
I1022 15:39:00.969400 27315 net.cpp:405] rpn_relu/3x3_p2 -> rpn/output_p2 (in-place)
I1022 15:39:00.970438 27315 net.cpp:150] Setting up rpn_relu/3x3_p2
I1022 15:39:00.970450 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.970453 27315 net.cpp:165] Memory required for data: 265932812
I1022 15:39:00.970458 27315 layer_factory.hpp:77] Creating layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 15:39:00.970463 27315 net.cpp:100] Creating Layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 15:39:00.970468 27315 net.cpp:444] rpn/output_p2_rpn_relu/3x3_p2_0_split <- rpn/output_p2
I1022 15:39:00.970475 27315 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1022 15:39:00.970484 27315 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1022 15:39:00.970578 27315 net.cpp:150] Setting up rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 15:39:00.970587 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.970592 27315 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:39:00.970594 27315 net.cpp:165] Memory required for data: 269144076
I1022 15:39:00.970597 27315 layer_factory.hpp:77] Creating layer rpn_cls_score_p2
I1022 15:39:00.970608 27315 net.cpp:100] Creating Layer rpn_cls_score_p2
I1022 15:39:00.970613 27315 net.cpp:444] rpn_cls_score_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1022 15:39:00.970623 27315 net.cpp:418] rpn_cls_score_p2 -> rpn_cls_score_p2
I1022 15:39:00.975584 27315 net.cpp:150] Setting up rpn_cls_score_p2
I1022 15:39:00.975597 27315 net.cpp:157] Top shape: 1 22 28 28 (17248)
I1022 15:39:00.975601 27315 net.cpp:165] Memory required for data: 269213068
I1022 15:39:00.975608 27315 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p2
I1022 15:39:00.975622 27315 net.cpp:100] Creating Layer rpn_bbox_pred_p2
I1022 15:39:00.975627 27315 net.cpp:444] rpn_bbox_pred_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1022 15:39:00.975634 27315 net.cpp:418] rpn_bbox_pred_p2 -> rpn_bbox_pred_p2
I1022 15:39:00.978062 27315 net.cpp:150] Setting up rpn_bbox_pred_p2
I1022 15:39:00.978076 27315 net.cpp:157] Top shape: 1 44 28 28 (34496)
I1022 15:39:00.978080 27315 net.cpp:165] Memory required for data: 269351052
I1022 15:39:00.978086 27315 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p2
I1022 15:39:00.978097 27315 net.cpp:100] Creating Layer rpn_cls_score_reshape_p2
I1022 15:39:00.978101 27315 net.cpp:444] rpn_cls_score_reshape_p2 <- rpn_cls_score_p2
I1022 15:39:00.978108 27315 net.cpp:418] rpn_cls_score_reshape_p2 -> rpn_cls_score_reshape_p2
I1022 15:39:00.978168 27315 net.cpp:150] Setting up rpn_cls_score_reshape_p2
I1022 15:39:00.978176 27315 net.cpp:157] Top shape: 1 2 308 28 (17248)
I1022 15:39:00.978179 27315 net.cpp:165] Memory required for data: 269420044
I1022 15:39:00.978183 27315 layer_factory.hpp:77] Creating layer rpn_cls_prob_p2
I1022 15:39:00.978199 27315 net.cpp:100] Creating Layer rpn_cls_prob_p2
I1022 15:39:00.978205 27315 net.cpp:444] rpn_cls_prob_p2 <- rpn_cls_score_reshape_p2
I1022 15:39:00.978211 27315 net.cpp:418] rpn_cls_prob_p2 -> rpn_cls_prob_p2
I1022 15:39:00.978605 27315 net.cpp:150] Setting up rpn_cls_prob_p2
I1022 15:39:00.978613 27315 net.cpp:157] Top shape: 1 2 308 28 (17248)
I1022 15:39:00.978616 27315 net.cpp:165] Memory required for data: 269489036
I1022 15:39:00.978621 27315 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p2
I1022 15:39:00.978626 27315 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p2
I1022 15:39:00.978629 27315 net.cpp:444] rpn_cls_prob_reshape_p2 <- rpn_cls_prob_p2
I1022 15:39:00.978637 27315 net.cpp:418] rpn_cls_prob_reshape_p2 -> rpn_cls_prob_reshape_p2
I1022 15:39:00.978687 27315 net.cpp:150] Setting up rpn_cls_prob_reshape_p2
I1022 15:39:00.978693 27315 net.cpp:157] Top shape: 1 22 28 28 (17248)
I1022 15:39:00.978695 27315 net.cpp:165] Memory required for data: 269558028
I1022 15:39:00.978699 27315 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p3
I1022 15:39:00.978713 27315 net.cpp:100] Creating Layer rpn_conv/3x3_p3
I1022 15:39:00.978718 27315 net.cpp:444] rpn_conv/3x3_p3 <- p3_p3_relu_0_split_1
I1022 15:39:00.978724 27315 net.cpp:418] rpn_conv/3x3_p3 -> rpn/output_p3
I1022 15:39:01.011921 27315 net.cpp:150] Setting up rpn_conv/3x3_p3
I1022 15:39:01.011940 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:01.011942 27315 net.cpp:165] Memory required for data: 269959436
I1022 15:39:01.011950 27315 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p3
I1022 15:39:01.011956 27315 net.cpp:100] Creating Layer rpn_relu/3x3_p3
I1022 15:39:01.011960 27315 net.cpp:444] rpn_relu/3x3_p3 <- rpn/output_p3
I1022 15:39:01.011965 27315 net.cpp:405] rpn_relu/3x3_p3 -> rpn/output_p3 (in-place)
I1022 15:39:01.012234 27315 net.cpp:150] Setting up rpn_relu/3x3_p3
I1022 15:39:01.012244 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:01.012248 27315 net.cpp:165] Memory required for data: 270360844
I1022 15:39:01.012250 27315 layer_factory.hpp:77] Creating layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 15:39:01.012256 27315 net.cpp:100] Creating Layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 15:39:01.012260 27315 net.cpp:444] rpn/output_p3_rpn_relu/3x3_p3_0_split <- rpn/output_p3
I1022 15:39:01.012271 27315 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1022 15:39:01.012280 27315 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1022 15:39:01.012387 27315 net.cpp:150] Setting up rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 15:39:01.012393 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:01.012398 27315 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:39:01.012400 27315 net.cpp:165] Memory required for data: 271163660
I1022 15:39:01.012403 27315 layer_factory.hpp:77] Creating layer rpn_cls_score_p3
I1022 15:39:01.012415 27315 net.cpp:100] Creating Layer rpn_cls_score_p3
I1022 15:39:01.012423 27315 net.cpp:444] rpn_cls_score_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1022 15:39:01.012428 27315 net.cpp:418] rpn_cls_score_p3 -> rpn_cls_score_p3
I1022 15:39:01.019799 27315 net.cpp:150] Setting up rpn_cls_score_p3
I1022 15:39:01.019815 27315 net.cpp:157] Top shape: 1 22 14 14 (4312)
I1022 15:39:01.019819 27315 net.cpp:165] Memory required for data: 271180908
I1022 15:39:01.019825 27315 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p3
I1022 15:39:01.019840 27315 net.cpp:100] Creating Layer rpn_bbox_pred_p3
I1022 15:39:01.019846 27315 net.cpp:444] rpn_bbox_pred_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1022 15:39:01.019853 27315 net.cpp:418] rpn_bbox_pred_p3 -> rpn_bbox_pred_p3
I1022 15:39:01.022292 27315 net.cpp:150] Setting up rpn_bbox_pred_p3
I1022 15:39:01.022306 27315 net.cpp:157] Top shape: 1 44 14 14 (8624)
I1022 15:39:01.022310 27315 net.cpp:165] Memory required for data: 271215404
I1022 15:39:01.022316 27315 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p3
I1022 15:39:01.022326 27315 net.cpp:100] Creating Layer rpn_cls_score_reshape_p3
I1022 15:39:01.022330 27315 net.cpp:444] rpn_cls_score_reshape_p3 <- rpn_cls_score_p3
I1022 15:39:01.022338 27315 net.cpp:418] rpn_cls_score_reshape_p3 -> rpn_cls_score_reshape_p3
I1022 15:39:01.022395 27315 net.cpp:150] Setting up rpn_cls_score_reshape_p3
I1022 15:39:01.022403 27315 net.cpp:157] Top shape: 1 2 154 14 (4312)
I1022 15:39:01.022405 27315 net.cpp:165] Memory required for data: 271232652
I1022 15:39:01.022408 27315 layer_factory.hpp:77] Creating layer rpn_cls_prob_p3
I1022 15:39:01.022416 27315 net.cpp:100] Creating Layer rpn_cls_prob_p3
I1022 15:39:01.022423 27315 net.cpp:444] rpn_cls_prob_p3 <- rpn_cls_score_reshape_p3
I1022 15:39:01.022428 27315 net.cpp:418] rpn_cls_prob_p3 -> rpn_cls_prob_p3
I1022 15:39:01.022815 27315 net.cpp:150] Setting up rpn_cls_prob_p3
I1022 15:39:01.022826 27315 net.cpp:157] Top shape: 1 2 154 14 (4312)
I1022 15:39:01.022830 27315 net.cpp:165] Memory required for data: 271249900
I1022 15:39:01.022832 27315 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p3
I1022 15:39:01.022838 27315 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p3
I1022 15:39:01.022842 27315 net.cpp:444] rpn_cls_prob_reshape_p3 <- rpn_cls_prob_p3
I1022 15:39:01.022850 27315 net.cpp:418] rpn_cls_prob_reshape_p3 -> rpn_cls_prob_reshape_p3
I1022 15:39:01.022900 27315 net.cpp:150] Setting up rpn_cls_prob_reshape_p3
I1022 15:39:01.022907 27315 net.cpp:157] Top shape: 1 22 14 14 (4312)
I1022 15:39:01.022909 27315 net.cpp:165] Memory required for data: 271267148
I1022 15:39:01.022912 27315 layer_factory.hpp:77] Creating layer proposal
I1022 15:39:01.024050 27315 net.cpp:100] Creating Layer proposal
I1022 15:39:01.024062 27315 net.cpp:444] proposal <- im_info
I1022 15:39:01.024067 27315 net.cpp:444] proposal <- rpn_bbox_pred_p2
I1022 15:39:01.024072 27315 net.cpp:444] proposal <- rpn_bbox_pred_p3
I1022 15:39:01.024076 27315 net.cpp:444] proposal <- rpn_cls_prob_reshape_p2
I1022 15:39:01.024080 27315 net.cpp:444] proposal <- rpn_cls_prob_reshape_p3
I1022 15:39:01.024086 27315 net.cpp:418] proposal -> rpn_rois_p2
I1022 15:39:01.024094 27315 net.cpp:418] proposal -> rpn_rois_p3
I1022 15:39:01.025151 27315 net.cpp:150] Setting up proposal
I1022 15:39:01.025166 27315 net.cpp:157] Top shape: 1 5 (5)
I1022 15:39:01.025171 27315 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 15:39:01.025172 27315 net.cpp:165] Memory required for data: 271267172
I1022 15:39:01.025177 27315 layer_factory.hpp:77] Creating layer rpn_rois_p2_proposal_0_split
I1022 15:39:01.025183 27315 net.cpp:100] Creating Layer rpn_rois_p2_proposal_0_split
I1022 15:39:01.025187 27315 net.cpp:444] rpn_rois_p2_proposal_0_split <- rpn_rois_p2
I1022 15:39:01.025193 27315 net.cpp:418] rpn_rois_p2_proposal_0_split -> rpn_rois_p2_proposal_0_split_0
I1022 15:39:01.025202 27315 net.cpp:418] rpn_rois_p2_proposal_0_split -> rpn_rois_p2_proposal_0_split_1
I1022 15:39:01.025285 27315 net.cpp:150] Setting up rpn_rois_p2_proposal_0_split
I1022 15:39:01.025291 27315 net.cpp:157] Top shape: 1 5 (5)
I1022 15:39:01.025295 27315 net.cpp:157] Top shape: 1 5 (5)
I1022 15:39:01.025297 27315 net.cpp:165] Memory required for data: 271267212
I1022 15:39:01.025300 27315 layer_factory.hpp:77] Creating layer rpn_rois_p3_proposal_1_split
I1022 15:39:01.025305 27315 net.cpp:100] Creating Layer rpn_rois_p3_proposal_1_split
I1022 15:39:01.025310 27315 net.cpp:444] rpn_rois_p3_proposal_1_split <- rpn_rois_p3
I1022 15:39:01.025315 27315 net.cpp:418] rpn_rois_p3_proposal_1_split -> rpn_rois_p3_proposal_1_split_0
I1022 15:39:01.025321 27315 net.cpp:418] rpn_rois_p3_proposal_1_split -> rpn_rois_p3_proposal_1_split_1
I1022 15:39:01.025396 27315 net.cpp:150] Setting up rpn_rois_p3_proposal_1_split
I1022 15:39:01.025403 27315 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 15:39:01.025408 27315 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 15:39:01.025410 27315 net.cpp:165] Memory required for data: 271267220
I1022 15:39:01.025413 27315 layer_factory.hpp:77] Creating layer conv_new_p2
I1022 15:39:01.025422 27315 net.cpp:100] Creating Layer conv_new_p2
I1022 15:39:01.025429 27315 net.cpp:444] conv_new_p2 <- p2_p2_relu_0_split_1
I1022 15:39:01.025434 27315 net.cpp:418] conv_new_p2 -> conv_new_p2
I1022 15:39:01.040135 27315 net.cpp:150] Setting up conv_new_p2
I1022 15:39:01.040150 27315 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 15:39:01.040153 27315 net.cpp:165] Memory required for data: 274478484
I1022 15:39:01.040161 27315 layer_factory.hpp:77] Creating layer conv_new_p2_relu
I1022 15:39:01.040169 27315 net.cpp:100] Creating Layer conv_new_p2_relu
I1022 15:39:01.040174 27315 net.cpp:444] conv_new_p2_relu <- conv_new_p2
I1022 15:39:01.040179 27315 net.cpp:405] conv_new_p2_relu -> conv_new_p2 (in-place)
I1022 15:39:01.041260 27315 net.cpp:150] Setting up conv_new_p2_relu
I1022 15:39:01.041272 27315 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 15:39:01.041275 27315 net.cpp:165] Memory required for data: 277689748
I1022 15:39:01.041278 27315 layer_factory.hpp:77] Creating layer conv_new_p2_conv_new_p2_relu_0_split
I1022 15:39:01.041285 27315 net.cpp:100] Creating Layer conv_new_p2_conv_new_p2_relu_0_split
I1022 15:39:01.041288 27315 net.cpp:444] conv_new_p2_conv_new_p2_relu_0_split <- conv_new_p2
I1022 15:39:01.041296 27315 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_0
I1022 15:39:01.041304 27315 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_1
I1022 15:39:01.041401 27315 net.cpp:150] Setting up conv_new_p2_conv_new_p2_relu_0_split
I1022 15:39:01.041409 27315 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 15:39:01.041412 27315 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 15:39:01.041415 27315 net.cpp:165] Memory required for data: 284112276
I1022 15:39:01.041419 27315 layer_factory.hpp:77] Creating layer rfcn_cls_p2
I1022 15:39:01.041430 27315 net.cpp:100] Creating Layer rfcn_cls_p2
I1022 15:39:01.041435 27315 net.cpp:444] rfcn_cls_p2 <- conv_new_p2_conv_new_p2_relu_0_split_0
I1022 15:39:01.041445 27315 net.cpp:418] rfcn_cls_p2 -> rfcn_cls_p2
I1022 15:39:01.044760 27315 net.cpp:150] Setting up rfcn_cls_p2
I1022 15:39:01.044775 27315 net.cpp:157] Top shape: 1 98 28 28 (76832)
I1022 15:39:01.044777 27315 net.cpp:165] Memory required for data: 284419604
I1022 15:39:01.044785 27315 layer_factory.hpp:77] Creating layer rfcn_bbox_p2
I1022 15:39:01.044796 27315 net.cpp:100] Creating Layer rfcn_bbox_p2
I1022 15:39:01.044801 27315 net.cpp:444] rfcn_bbox_p2 <- conv_new_p2_conv_new_p2_relu_0_split_1
I1022 15:39:01.044811 27315 net.cpp:418] rfcn_bbox_p2 -> rfcn_bbox_p2
I1022 15:39:01.053299 27315 net.cpp:150] Setting up rfcn_bbox_p2
I1022 15:39:01.053313 27315 net.cpp:157] Top shape: 1 392 28 28 (307328)
I1022 15:39:01.053316 27315 net.cpp:165] Memory required for data: 285648916
I1022 15:39:01.053331 27315 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p2
I1022 15:39:01.053341 27315 net.cpp:100] Creating Layer psroipooled_cls_rois_p2
I1022 15:39:01.053347 27315 net.cpp:444] psroipooled_cls_rois_p2 <- rfcn_cls_p2
I1022 15:39:01.053352 27315 net.cpp:444] psroipooled_cls_rois_p2 <- rpn_rois_p2_proposal_0_split_0
I1022 15:39:01.053360 27315 net.cpp:418] psroipooled_cls_rois_p2 -> psroipooled_cls_rois_p2
I1022 15:39:01.053369 27315 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1022 15:39:01.053468 27315 net.cpp:150] Setting up psroipooled_cls_rois_p2
I1022 15:39:01.053475 27315 net.cpp:157] Top shape: 1 2 7 7 (98)
I1022 15:39:01.053478 27315 net.cpp:165] Memory required for data: 285649308
I1022 15:39:01.053481 27315 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p2
I1022 15:39:01.053490 27315 net.cpp:100] Creating Layer ave_cls_score_rois_p2
I1022 15:39:01.053495 27315 net.cpp:444] ave_cls_score_rois_p2 <- psroipooled_cls_rois_p2
I1022 15:39:01.053503 27315 net.cpp:418] ave_cls_score_rois_p2 -> cls_score_p2
I1022 15:39:01.053802 27315 net.cpp:150] Setting up ave_cls_score_rois_p2
I1022 15:39:01.053812 27315 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 15:39:01.053814 27315 net.cpp:165] Memory required for data: 285649316
I1022 15:39:01.053817 27315 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p2
I1022 15:39:01.053823 27315 net.cpp:100] Creating Layer psroipooled_loc_rois_p2
I1022 15:39:01.053827 27315 net.cpp:444] psroipooled_loc_rois_p2 <- rfcn_bbox_p2
I1022 15:39:01.053831 27315 net.cpp:444] psroipooled_loc_rois_p2 <- rpn_rois_p2_proposal_0_split_1
I1022 15:39:01.053838 27315 net.cpp:418] psroipooled_loc_rois_p2 -> psroipooled_loc_rois_p2
I1022 15:39:01.053845 27315 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1022 15:39:01.053933 27315 net.cpp:150] Setting up psroipooled_loc_rois_p2
I1022 15:39:01.053941 27315 net.cpp:157] Top shape: 1 8 7 7 (392)
I1022 15:39:01.053943 27315 net.cpp:165] Memory required for data: 285650884
I1022 15:39:01.053946 27315 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p2
I1022 15:39:01.053953 27315 net.cpp:100] Creating Layer ave_bbox_pred_rois_p2
I1022 15:39:01.053958 27315 net.cpp:444] ave_bbox_pred_rois_p2 <- psroipooled_loc_rois_p2
I1022 15:39:01.053963 27315 net.cpp:418] ave_bbox_pred_rois_p2 -> bbox_pred_pre_p2
I1022 15:39:01.054247 27315 net.cpp:150] Setting up ave_bbox_pred_rois_p2
I1022 15:39:01.054256 27315 net.cpp:157] Top shape: 1 8 1 1 (8)
I1022 15:39:01.054260 27315 net.cpp:165] Memory required for data: 285650916
I1022 15:39:01.054262 27315 layer_factory.hpp:77] Creating layer conv_new_p3
I1022 15:39:01.054280 27315 net.cpp:100] Creating Layer conv_new_p3
I1022 15:39:01.054283 27315 net.cpp:444] conv_new_p3 <- p3_p3_relu_0_split_2
I1022 15:39:01.054291 27315 net.cpp:418] conv_new_p3 -> conv_new_p3
I1022 15:39:01.070035 27315 net.cpp:150] Setting up conv_new_p3
I1022 15:39:01.070050 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:01.070055 27315 net.cpp:165] Memory required for data: 286453732
I1022 15:39:01.070070 27315 layer_factory.hpp:77] Creating layer conv_new_p3_relu
I1022 15:39:01.070077 27315 net.cpp:100] Creating Layer conv_new_p3_relu
I1022 15:39:01.070082 27315 net.cpp:444] conv_new_p3_relu <- conv_new_p3
I1022 15:39:01.070087 27315 net.cpp:405] conv_new_p3_relu -> conv_new_p3 (in-place)
I1022 15:39:01.071125 27315 net.cpp:150] Setting up conv_new_p3_relu
I1022 15:39:01.071138 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:01.071141 27315 net.cpp:165] Memory required for data: 287256548
I1022 15:39:01.071146 27315 layer_factory.hpp:77] Creating layer conv_new_p3_conv_new_p3_relu_0_split
I1022 15:39:01.071153 27315 net.cpp:100] Creating Layer conv_new_p3_conv_new_p3_relu_0_split
I1022 15:39:01.071157 27315 net.cpp:444] conv_new_p3_conv_new_p3_relu_0_split <- conv_new_p3
I1022 15:39:01.071164 27315 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_0
I1022 15:39:01.071173 27315 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_1
I1022 15:39:01.071270 27315 net.cpp:150] Setting up conv_new_p3_conv_new_p3_relu_0_split
I1022 15:39:01.071279 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:01.071282 27315 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:39:01.071286 27315 net.cpp:165] Memory required for data: 288862180
I1022 15:39:01.071290 27315 layer_factory.hpp:77] Creating layer rfcn_cls_p3
I1022 15:39:01.071302 27315 net.cpp:100] Creating Layer rfcn_cls_p3
I1022 15:39:01.071307 27315 net.cpp:444] rfcn_cls_p3 <- conv_new_p3_conv_new_p3_relu_0_split_0
I1022 15:39:01.071316 27315 net.cpp:418] rfcn_cls_p3 -> rfcn_cls_p3
I1022 15:39:01.074592 27315 net.cpp:150] Setting up rfcn_cls_p3
I1022 15:39:01.074606 27315 net.cpp:157] Top shape: 1 98 14 14 (19208)
I1022 15:39:01.074609 27315 net.cpp:165] Memory required for data: 288939012
I1022 15:39:01.074617 27315 layer_factory.hpp:77] Creating layer rfcn_bbox_p3
I1022 15:39:01.074630 27315 net.cpp:100] Creating Layer rfcn_bbox_p3
I1022 15:39:01.074633 27315 net.cpp:444] rfcn_bbox_p3 <- conv_new_p3_conv_new_p3_relu_0_split_1
I1022 15:39:01.074640 27315 net.cpp:418] rfcn_bbox_p3 -> rfcn_bbox_p3
I1022 15:39:01.089783 27315 net.cpp:150] Setting up rfcn_bbox_p3
I1022 15:39:01.089798 27315 net.cpp:157] Top shape: 1 392 14 14 (76832)
I1022 15:39:01.089802 27315 net.cpp:165] Memory required for data: 289246340
I1022 15:39:01.089808 27315 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p3
I1022 15:39:01.089818 27315 net.cpp:100] Creating Layer psroipooled_cls_rois_p3
I1022 15:39:01.089823 27315 net.cpp:444] psroipooled_cls_rois_p3 <- rfcn_cls_p3
I1022 15:39:01.089828 27315 net.cpp:444] psroipooled_cls_rois_p3 <- rpn_rois_p3_proposal_1_split_0
I1022 15:39:01.089835 27315 net.cpp:418] psroipooled_cls_rois_p3 -> psroipooled_cls_rois_p3
I1022 15:39:01.089844 27315 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1022 15:39:01.089944 27315 net.cpp:150] Setting up psroipooled_cls_rois_p3
I1022 15:39:01.089952 27315 net.cpp:157] Top shape: 1 2 7 7 (98)
I1022 15:39:01.089954 27315 net.cpp:165] Memory required for data: 289246732
I1022 15:39:01.089958 27315 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p3
I1022 15:39:01.089964 27315 net.cpp:100] Creating Layer ave_cls_score_rois_p3
I1022 15:39:01.089968 27315 net.cpp:444] ave_cls_score_rois_p3 <- psroipooled_cls_rois_p3
I1022 15:39:01.089975 27315 net.cpp:418] ave_cls_score_rois_p3 -> cls_score_p3
I1022 15:39:01.090275 27315 net.cpp:150] Setting up ave_cls_score_rois_p3
I1022 15:39:01.090283 27315 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 15:39:01.090286 27315 net.cpp:165] Memory required for data: 289246740
I1022 15:39:01.090289 27315 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p3
I1022 15:39:01.090296 27315 net.cpp:100] Creating Layer psroipooled_loc_rois_p3
I1022 15:39:01.090299 27315 net.cpp:444] psroipooled_loc_rois_p3 <- rfcn_bbox_p3
I1022 15:39:01.090306 27315 net.cpp:444] psroipooled_loc_rois_p3 <- rpn_rois_p3_proposal_1_split_1
I1022 15:39:01.090312 27315 net.cpp:418] psroipooled_loc_rois_p3 -> psroipooled_loc_rois_p3
I1022 15:39:01.090318 27315 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1022 15:39:01.090405 27315 net.cpp:150] Setting up psroipooled_loc_rois_p3
I1022 15:39:01.090412 27315 net.cpp:157] Top shape: 1 8 7 7 (392)
I1022 15:39:01.090415 27315 net.cpp:165] Memory required for data: 289248308
I1022 15:39:01.090418 27315 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p3
I1022 15:39:01.090425 27315 net.cpp:100] Creating Layer ave_bbox_pred_rois_p3
I1022 15:39:01.090432 27315 net.cpp:444] ave_bbox_pred_rois_p3 <- psroipooled_loc_rois_p3
I1022 15:39:01.090437 27315 net.cpp:418] ave_bbox_pred_rois_p3 -> bbox_pred_pre_p3
I1022 15:39:01.090723 27315 net.cpp:150] Setting up ave_bbox_pred_rois_p3
I1022 15:39:01.090731 27315 net.cpp:157] Top shape: 1 8 1 1 (8)
I1022 15:39:01.090734 27315 net.cpp:165] Memory required for data: 289248340
I1022 15:39:01.090737 27315 layer_factory.hpp:77] Creating layer cls_prob_pre_p2
I1022 15:39:01.090745 27315 net.cpp:100] Creating Layer cls_prob_pre_p2
I1022 15:39:01.090749 27315 net.cpp:444] cls_prob_pre_p2 <- cls_score_p2
I1022 15:39:01.090754 27315 net.cpp:418] cls_prob_pre_p2 -> cls_prob_pre_p2
I1022 15:39:01.091935 27315 net.cpp:150] Setting up cls_prob_pre_p2
I1022 15:39:01.091948 27315 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 15:39:01.091951 27315 net.cpp:165] Memory required for data: 289248348
I1022 15:39:01.091954 27315 layer_factory.hpp:77] Creating layer cls_prob_pre_p3
I1022 15:39:01.091962 27315 net.cpp:100] Creating Layer cls_prob_pre_p3
I1022 15:39:01.091966 27315 net.cpp:444] cls_prob_pre_p3 <- cls_score_p3
I1022 15:39:01.091974 27315 net.cpp:418] cls_prob_pre_p3 -> cls_prob_pre_p3
I1022 15:39:01.092363 27315 net.cpp:150] Setting up cls_prob_pre_p3
I1022 15:39:01.092372 27315 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 15:39:01.092375 27315 net.cpp:165] Memory required for data: 289248356
I1022 15:39:01.092380 27315 layer_factory.hpp:77] Creating layer cls_prob_reshape_p2
I1022 15:39:01.092387 27315 net.cpp:100] Creating Layer cls_prob_reshape_p2
I1022 15:39:01.092391 27315 net.cpp:444] cls_prob_reshape_p2 <- cls_prob_pre_p2
I1022 15:39:01.092397 27315 net.cpp:418] cls_prob_reshape_p2 -> cls_prob_p2
I1022 15:39:01.092448 27315 net.cpp:150] Setting up cls_prob_reshape_p2
I1022 15:39:01.092458 27315 net.cpp:157] Top shape: 1 2 (2)
I1022 15:39:01.092461 27315 net.cpp:165] Memory required for data: 289248364
I1022 15:39:01.092464 27315 layer_factory.hpp:77] Creating layer cls_prob_reshape_p3
I1022 15:39:01.092469 27315 net.cpp:100] Creating Layer cls_prob_reshape_p3
I1022 15:39:01.092473 27315 net.cpp:444] cls_prob_reshape_p3 <- cls_prob_pre_p3
I1022 15:39:01.092478 27315 net.cpp:418] cls_prob_reshape_p3 -> cls_prob_p3
I1022 15:39:01.092528 27315 net.cpp:150] Setting up cls_prob_reshape_p3
I1022 15:39:01.092535 27315 net.cpp:157] Top shape: 1 2 (2)
I1022 15:39:01.092537 27315 net.cpp:165] Memory required for data: 289248372
I1022 15:39:01.092540 27315 layer_factory.hpp:77] Creating layer bbox_pred_reshape_p2
I1022 15:39:01.092545 27315 net.cpp:100] Creating Layer bbox_pred_reshape_p2
I1022 15:39:01.092550 27315 net.cpp:444] bbox_pred_reshape_p2 <- bbox_pred_pre_p2
I1022 15:39:01.092556 27315 net.cpp:418] bbox_pred_reshape_p2 -> bbox_pred_p2
I1022 15:39:01.092603 27315 net.cpp:150] Setting up bbox_pred_reshape_p2
I1022 15:39:01.092628 27315 net.cpp:157] Top shape: 1 8 (8)
I1022 15:39:01.092631 27315 net.cpp:165] Memory required for data: 289248404
I1022 15:39:01.092634 27315 layer_factory.hpp:77] Creating layer bbox_pred_reshape_p3
I1022 15:39:01.092653 27315 net.cpp:100] Creating Layer bbox_pred_reshape_p3
I1022 15:39:01.092658 27315 net.cpp:444] bbox_pred_reshape_p3 <- bbox_pred_pre_p3
I1022 15:39:01.092664 27315 net.cpp:418] bbox_pred_reshape_p3 -> bbox_pred_p3
I1022 15:39:01.092715 27315 net.cpp:150] Setting up bbox_pred_reshape_p3
I1022 15:39:01.092722 27315 net.cpp:157] Top shape: 1 8 (8)
I1022 15:39:01.092725 27315 net.cpp:165] Memory required for data: 289248436
I1022 15:39:01.092728 27315 net.cpp:228] bbox_pred_reshape_p3 does not need backward computation.
I1022 15:39:01.092732 27315 net.cpp:228] bbox_pred_reshape_p2 does not need backward computation.
I1022 15:39:01.092736 27315 net.cpp:228] cls_prob_reshape_p3 does not need backward computation.
I1022 15:39:01.092739 27315 net.cpp:228] cls_prob_reshape_p2 does not need backward computation.
I1022 15:39:01.092742 27315 net.cpp:228] cls_prob_pre_p3 does not need backward computation.
I1022 15:39:01.092746 27315 net.cpp:228] cls_prob_pre_p2 does not need backward computation.
I1022 15:39:01.092748 27315 net.cpp:228] ave_bbox_pred_rois_p3 does not need backward computation.
I1022 15:39:01.092751 27315 net.cpp:228] psroipooled_loc_rois_p3 does not need backward computation.
I1022 15:39:01.092756 27315 net.cpp:228] ave_cls_score_rois_p3 does not need backward computation.
I1022 15:39:01.092758 27315 net.cpp:228] psroipooled_cls_rois_p3 does not need backward computation.
I1022 15:39:01.092762 27315 net.cpp:228] rfcn_bbox_p3 does not need backward computation.
I1022 15:39:01.092766 27315 net.cpp:228] rfcn_cls_p3 does not need backward computation.
I1022 15:39:01.092769 27315 net.cpp:228] conv_new_p3_conv_new_p3_relu_0_split does not need backward computation.
I1022 15:39:01.092772 27315 net.cpp:228] conv_new_p3_relu does not need backward computation.
I1022 15:39:01.092775 27315 net.cpp:228] conv_new_p3 does not need backward computation.
I1022 15:39:01.092779 27315 net.cpp:228] ave_bbox_pred_rois_p2 does not need backward computation.
I1022 15:39:01.092782 27315 net.cpp:228] psroipooled_loc_rois_p2 does not need backward computation.
I1022 15:39:01.092787 27315 net.cpp:228] ave_cls_score_rois_p2 does not need backward computation.
I1022 15:39:01.092789 27315 net.cpp:228] psroipooled_cls_rois_p2 does not need backward computation.
I1022 15:39:01.092797 27315 net.cpp:228] rfcn_bbox_p2 does not need backward computation.
I1022 15:39:01.092799 27315 net.cpp:228] rfcn_cls_p2 does not need backward computation.
I1022 15:39:01.092803 27315 net.cpp:228] conv_new_p2_conv_new_p2_relu_0_split does not need backward computation.
I1022 15:39:01.092805 27315 net.cpp:228] conv_new_p2_relu does not need backward computation.
I1022 15:39:01.092809 27315 net.cpp:228] conv_new_p2 does not need backward computation.
I1022 15:39:01.092813 27315 net.cpp:228] rpn_rois_p3_proposal_1_split does not need backward computation.
I1022 15:39:01.092816 27315 net.cpp:228] rpn_rois_p2_proposal_0_split does not need backward computation.
I1022 15:39:01.092819 27315 net.cpp:228] proposal does not need backward computation.
I1022 15:39:01.092825 27315 net.cpp:228] rpn_cls_prob_reshape_p3 does not need backward computation.
I1022 15:39:01.092829 27315 net.cpp:228] rpn_cls_prob_p3 does not need backward computation.
I1022 15:39:01.092833 27315 net.cpp:228] rpn_cls_score_reshape_p3 does not need backward computation.
I1022 15:39:01.092836 27315 net.cpp:228] rpn_bbox_pred_p3 does not need backward computation.
I1022 15:39:01.092839 27315 net.cpp:228] rpn_cls_score_p3 does not need backward computation.
I1022 15:39:01.092844 27315 net.cpp:228] rpn/output_p3_rpn_relu/3x3_p3_0_split does not need backward computation.
I1022 15:39:01.092847 27315 net.cpp:228] rpn_relu/3x3_p3 does not need backward computation.
I1022 15:39:01.092849 27315 net.cpp:228] rpn_conv/3x3_p3 does not need backward computation.
I1022 15:39:01.092854 27315 net.cpp:228] rpn_cls_prob_reshape_p2 does not need backward computation.
I1022 15:39:01.092857 27315 net.cpp:228] rpn_cls_prob_p2 does not need backward computation.
I1022 15:39:01.092864 27315 net.cpp:228] rpn_cls_score_reshape_p2 does not need backward computation.
I1022 15:39:01.092867 27315 net.cpp:228] rpn_bbox_pred_p2 does not need backward computation.
I1022 15:39:01.092872 27315 net.cpp:228] rpn_cls_score_p2 does not need backward computation.
I1022 15:39:01.092875 27315 net.cpp:228] rpn/output_p2_rpn_relu/3x3_p2_0_split does not need backward computation.
I1022 15:39:01.092880 27315 net.cpp:228] rpn_relu/3x3_p2 does not need backward computation.
I1022 15:39:01.092882 27315 net.cpp:228] rpn_conv/3x3_p2 does not need backward computation.
I1022 15:39:01.092886 27315 net.cpp:228] p2_p2_relu_0_split does not need backward computation.
I1022 15:39:01.092890 27315 net.cpp:228] p2_relu does not need backward computation.
I1022 15:39:01.092893 27315 net.cpp:228] p2 does not need backward computation.
I1022 15:39:01.092898 27315 net.cpp:228] bn_eltwise_2_2_scale does not need backward computation.
I1022 15:39:01.092902 27315 net.cpp:228] bn_eltwise_2_2_bn does not need backward computation.
I1022 15:39:01.092906 27315 net.cpp:228] bn_eltwise_2_2_conv does not need backward computation.
I1022 15:39:01.092909 27315 net.cpp:228] bn_eltwise_2_1_ReLU does not need backward computation.
I1022 15:39:01.092912 27315 net.cpp:228] bn_eltwise_2_1_scale does not need backward computation.
I1022 15:39:01.092916 27315 net.cpp:228] bn_eltwise_2_1_bn does not need backward computation.
I1022 15:39:01.092918 27315 net.cpp:228] bn_eltwise_2_1_conv does not need backward computation.
I1022 15:39:01.092922 27315 net.cpp:228] bnp3_ReLU does not need backward computation.
I1022 15:39:01.092926 27315 net.cpp:228] bnp3_scale does not need backward computation.
I1022 15:39:01.092929 27315 net.cpp:228] bnp3_bn does not need backward computation.
I1022 15:39:01.092931 27315 net.cpp:228] bnp3_conv does not need backward computation.
I1022 15:39:01.092936 27315 net.cpp:228] skip_eltwise2_eltwise_bnc3_bnp3_0_split does not need backward computation.
I1022 15:39:01.092939 27315 net.cpp:228] eltwise_bnc3_bnp3 does not need backward computation.
I1022 15:39:01.092943 27315 net.cpp:228] upP3 does not need backward computation.
I1022 15:39:01.092947 27315 net.cpp:228] newC3 does not need backward computation.
I1022 15:39:01.092952 27315 net.cpp:228] p3_p3_relu_0_split does not need backward computation.
I1022 15:39:01.092959 27315 net.cpp:228] p3_relu does not need backward computation.
I1022 15:39:01.092963 27315 net.cpp:228] p3 does not need backward computation.
I1022 15:39:01.092967 27315 net.cpp:228] bn_eltwise_1_2_scale does not need backward computation.
I1022 15:39:01.092972 27315 net.cpp:228] bn_eltwise_1_2_bn does not need backward computation.
I1022 15:39:01.092974 27315 net.cpp:228] bn_eltwise_1_2_conv does not need backward computation.
I1022 15:39:01.092978 27315 net.cpp:228] bn_eltwise_1_1_ReLU does not need backward computation.
I1022 15:39:01.092981 27315 net.cpp:228] bn_eltwise_1_1_scale does not need backward computation.
I1022 15:39:01.092984 27315 net.cpp:228] bn_eltwise_1_1_bn does not need backward computation.
I1022 15:39:01.092988 27315 net.cpp:228] bn_eltwise_1_1_conv does not need backward computation.
I1022 15:39:01.092993 27315 net.cpp:228] bnp4_ReLU does not need backward computation.
I1022 15:39:01.092995 27315 net.cpp:228] bnp4_scale does not need backward computation.
I1022 15:39:01.092998 27315 net.cpp:228] bnp4_bn does not need backward computation.
I1022 15:39:01.093001 27315 net.cpp:228] bnp4_conv does not need backward computation.
I1022 15:39:01.093006 27315 net.cpp:228] skip_eltwise1_eltwise_bnc4_bnp4_0_split does not need backward computation.
I1022 15:39:01.093010 27315 net.cpp:228] eltwise_bnc4_bnp4 does not need backward computation.
I1022 15:39:01.093015 27315 net.cpp:228] newC4 does not need backward computation.
I1022 15:39:01.093019 27315 net.cpp:228] upP4 does not need backward computation.
I1022 15:39:01.093024 27315 net.cpp:228] res5c_relu does not need backward computation.
I1022 15:39:01.093034 27315 net.cpp:228] res5c does not need backward computation.
I1022 15:39:01.093039 27315 net.cpp:228] scale5c_branch2c does not need backward computation.
I1022 15:39:01.093041 27315 net.cpp:228] bn5c_branch2c does not need backward computation.
I1022 15:39:01.093044 27315 net.cpp:228] res5c_branch2c does not need backward computation.
I1022 15:39:01.093049 27315 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I1022 15:39:01.093052 27315 net.cpp:228] scale5c_branch2b does not need backward computation.
I1022 15:39:01.093055 27315 net.cpp:228] bn5c_branch2b does not need backward computation.
I1022 15:39:01.093058 27315 net.cpp:228] res5c_branch2b does not need backward computation.
I1022 15:39:01.093062 27315 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I1022 15:39:01.093065 27315 net.cpp:228] scale5c_branch2a does not need backward computation.
I1022 15:39:01.093068 27315 net.cpp:228] bn5c_branch2a does not need backward computation.
I1022 15:39:01.093071 27315 net.cpp:228] res5c_branch2a does not need backward computation.
I1022 15:39:01.093076 27315 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I1022 15:39:01.093080 27315 net.cpp:228] res5b_relu does not need backward computation.
I1022 15:39:01.093083 27315 net.cpp:228] res5b does not need backward computation.
I1022 15:39:01.093087 27315 net.cpp:228] scale5b_branch2c does not need backward computation.
I1022 15:39:01.093091 27315 net.cpp:228] bn5b_branch2c does not need backward computation.
I1022 15:39:01.093093 27315 net.cpp:228] res5b_branch2c does not need backward computation.
I1022 15:39:01.093097 27315 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I1022 15:39:01.093101 27315 net.cpp:228] scale5b_branch2b does not need backward computation.
I1022 15:39:01.093103 27315 net.cpp:228] bn5b_branch2b does not need backward computation.
I1022 15:39:01.093107 27315 net.cpp:228] res5b_branch2b does not need backward computation.
I1022 15:39:01.093111 27315 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I1022 15:39:01.093113 27315 net.cpp:228] scale5b_branch2a does not need backward computation.
I1022 15:39:01.093116 27315 net.cpp:228] bn5b_branch2a does not need backward computation.
I1022 15:39:01.093120 27315 net.cpp:228] res5b_branch2a does not need backward computation.
I1022 15:39:01.093124 27315 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I1022 15:39:01.093128 27315 net.cpp:228] res5a_relu does not need backward computation.
I1022 15:39:01.093132 27315 net.cpp:228] res5a does not need backward computation.
I1022 15:39:01.093137 27315 net.cpp:228] scale5a_branch2c does not need backward computation.
I1022 15:39:01.093140 27315 net.cpp:228] bn5a_branch2c does not need backward computation.
I1022 15:39:01.093144 27315 net.cpp:228] res5a_branch2c does not need backward computation.
I1022 15:39:01.093147 27315 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I1022 15:39:01.093150 27315 net.cpp:228] scale5a_branch2b does not need backward computation.
I1022 15:39:01.093154 27315 net.cpp:228] bn5a_branch2b does not need backward computation.
I1022 15:39:01.093158 27315 net.cpp:228] res5a_branch2b does not need backward computation.
I1022 15:39:01.093160 27315 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I1022 15:39:01.093163 27315 net.cpp:228] scale5a_branch2a does not need backward computation.
I1022 15:39:01.093168 27315 net.cpp:228] bn5a_branch2a does not need backward computation.
I1022 15:39:01.093170 27315 net.cpp:228] res5a_branch2a does not need backward computation.
I1022 15:39:01.093174 27315 net.cpp:228] scale5a_branch1 does not need backward computation.
I1022 15:39:01.093178 27315 net.cpp:228] bn5a_branch1 does not need backward computation.
I1022 15:39:01.093180 27315 net.cpp:228] res5a_branch1 does not need backward computation.
I1022 15:39:01.093185 27315 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I1022 15:39:01.093189 27315 net.cpp:228] res4f_relu does not need backward computation.
I1022 15:39:01.093192 27315 net.cpp:228] res4f does not need backward computation.
I1022 15:39:01.093197 27315 net.cpp:228] scale4f_branch2c does not need backward computation.
I1022 15:39:01.093200 27315 net.cpp:228] bn4f_branch2c does not need backward computation.
I1022 15:39:01.093204 27315 net.cpp:228] res4f_branch2c does not need backward computation.
I1022 15:39:01.093209 27315 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I1022 15:39:01.093211 27315 net.cpp:228] scale4f_branch2b does not need backward computation.
I1022 15:39:01.093214 27315 net.cpp:228] bn4f_branch2b does not need backward computation.
I1022 15:39:01.093217 27315 net.cpp:228] res4f_branch2b does not need backward computation.
I1022 15:39:01.093221 27315 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I1022 15:39:01.093225 27315 net.cpp:228] scale4f_branch2a does not need backward computation.
I1022 15:39:01.093228 27315 net.cpp:228] bn4f_branch2a does not need backward computation.
I1022 15:39:01.093231 27315 net.cpp:228] res4f_branch2a does not need backward computation.
I1022 15:39:01.093235 27315 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I1022 15:39:01.093240 27315 net.cpp:228] res4e_relu does not need backward computation.
I1022 15:39:01.093243 27315 net.cpp:228] res4e does not need backward computation.
I1022 15:39:01.093247 27315 net.cpp:228] scale4e_branch2c does not need backward computation.
I1022 15:39:01.093250 27315 net.cpp:228] bn4e_branch2c does not need backward computation.
I1022 15:39:01.093255 27315 net.cpp:228] res4e_branch2c does not need backward computation.
I1022 15:39:01.093257 27315 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I1022 15:39:01.093261 27315 net.cpp:228] scale4e_branch2b does not need backward computation.
I1022 15:39:01.093264 27315 net.cpp:228] bn4e_branch2b does not need backward computation.
I1022 15:39:01.093267 27315 net.cpp:228] res4e_branch2b does not need backward computation.
I1022 15:39:01.093271 27315 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I1022 15:39:01.093274 27315 net.cpp:228] scale4e_branch2a does not need backward computation.
I1022 15:39:01.093277 27315 net.cpp:228] bn4e_branch2a does not need backward computation.
I1022 15:39:01.093281 27315 net.cpp:228] res4e_branch2a does not need backward computation.
I1022 15:39:01.093286 27315 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I1022 15:39:01.093289 27315 net.cpp:228] res4d_relu does not need backward computation.
I1022 15:39:01.093292 27315 net.cpp:228] res4d does not need backward computation.
I1022 15:39:01.093297 27315 net.cpp:228] scale4d_branch2c does not need backward computation.
I1022 15:39:01.093300 27315 net.cpp:228] bn4d_branch2c does not need backward computation.
I1022 15:39:01.093303 27315 net.cpp:228] res4d_branch2c does not need backward computation.
I1022 15:39:01.093307 27315 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I1022 15:39:01.093310 27315 net.cpp:228] scale4d_branch2b does not need backward computation.
I1022 15:39:01.093313 27315 net.cpp:228] bn4d_branch2b does not need backward computation.
I1022 15:39:01.093317 27315 net.cpp:228] res4d_branch2b does not need backward computation.
I1022 15:39:01.093320 27315 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I1022 15:39:01.093323 27315 net.cpp:228] scale4d_branch2a does not need backward computation.
I1022 15:39:01.093328 27315 net.cpp:228] bn4d_branch2a does not need backward computation.
I1022 15:39:01.093331 27315 net.cpp:228] res4d_branch2a does not need backward computation.
I1022 15:39:01.093334 27315 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I1022 15:39:01.093338 27315 net.cpp:228] res4c_relu does not need backward computation.
I1022 15:39:01.093341 27315 net.cpp:228] res4c does not need backward computation.
I1022 15:39:01.093345 27315 net.cpp:228] scale4c_branch2c does not need backward computation.
I1022 15:39:01.093349 27315 net.cpp:228] bn4c_branch2c does not need backward computation.
I1022 15:39:01.093353 27315 net.cpp:228] res4c_branch2c does not need backward computation.
I1022 15:39:01.093356 27315 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I1022 15:39:01.093359 27315 net.cpp:228] scale4c_branch2b does not need backward computation.
I1022 15:39:01.093363 27315 net.cpp:228] bn4c_branch2b does not need backward computation.
I1022 15:39:01.093366 27315 net.cpp:228] res4c_branch2b does not need backward computation.
I1022 15:39:01.093369 27315 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I1022 15:39:01.093372 27315 net.cpp:228] scale4c_branch2a does not need backward computation.
I1022 15:39:01.093376 27315 net.cpp:228] bn4c_branch2a does not need backward computation.
I1022 15:39:01.093379 27315 net.cpp:228] res4c_branch2a does not need backward computation.
I1022 15:39:01.093384 27315 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I1022 15:39:01.093389 27315 net.cpp:228] res4b_relu does not need backward computation.
I1022 15:39:01.093391 27315 net.cpp:228] res4b does not need backward computation.
I1022 15:39:01.093395 27315 net.cpp:228] scale4b_branch2c does not need backward computation.
I1022 15:39:01.093399 27315 net.cpp:228] bn4b_branch2c does not need backward computation.
I1022 15:39:01.093401 27315 net.cpp:228] res4b_branch2c does not need backward computation.
I1022 15:39:01.093405 27315 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I1022 15:39:01.093408 27315 net.cpp:228] scale4b_branch2b does not need backward computation.
I1022 15:39:01.093411 27315 net.cpp:228] bn4b_branch2b does not need backward computation.
I1022 15:39:01.093415 27315 net.cpp:228] res4b_branch2b does not need backward computation.
I1022 15:39:01.093418 27315 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I1022 15:39:01.093422 27315 net.cpp:228] scale4b_branch2a does not need backward computation.
I1022 15:39:01.093425 27315 net.cpp:228] bn4b_branch2a does not need backward computation.
I1022 15:39:01.093428 27315 net.cpp:228] res4b_branch2a does not need backward computation.
I1022 15:39:01.093431 27315 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I1022 15:39:01.093436 27315 net.cpp:228] res4a_relu does not need backward computation.
I1022 15:39:01.093438 27315 net.cpp:228] res4a does not need backward computation.
I1022 15:39:01.093443 27315 net.cpp:228] scale4a_branch2c does not need backward computation.
I1022 15:39:01.093446 27315 net.cpp:228] bn4a_branch2c does not need backward computation.
I1022 15:39:01.093451 27315 net.cpp:228] res4a_branch2c does not need backward computation.
I1022 15:39:01.093453 27315 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I1022 15:39:01.093457 27315 net.cpp:228] scale4a_branch2b does not need backward computation.
I1022 15:39:01.093461 27315 net.cpp:228] bn4a_branch2b does not need backward computation.
I1022 15:39:01.093463 27315 net.cpp:228] res4a_branch2b does not need backward computation.
I1022 15:39:01.093466 27315 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I1022 15:39:01.093470 27315 net.cpp:228] scale4a_branch2a does not need backward computation.
I1022 15:39:01.093473 27315 net.cpp:228] bn4a_branch2a does not need backward computation.
I1022 15:39:01.093477 27315 net.cpp:228] res4a_branch2a does not need backward computation.
I1022 15:39:01.093482 27315 net.cpp:228] scale4a_branch1 does not need backward computation.
I1022 15:39:01.093484 27315 net.cpp:228] bn4a_branch1 does not need backward computation.
I1022 15:39:01.093487 27315 net.cpp:228] res4a_branch1 does not need backward computation.
I1022 15:39:01.093492 27315 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I1022 15:39:01.093497 27315 net.cpp:228] res3d_relu does not need backward computation.
I1022 15:39:01.093503 27315 net.cpp:228] res3d does not need backward computation.
I1022 15:39:01.093508 27315 net.cpp:228] scale3d_branch2c does not need backward computation.
I1022 15:39:01.093513 27315 net.cpp:228] bn3d_branch2c does not need backward computation.
I1022 15:39:01.093516 27315 net.cpp:228] res3d_branch2c does not need backward computation.
I1022 15:39:01.093520 27315 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I1022 15:39:01.093523 27315 net.cpp:228] scale3d_branch2b does not need backward computation.
I1022 15:39:01.093526 27315 net.cpp:228] bn3d_branch2b does not need backward computation.
I1022 15:39:01.093529 27315 net.cpp:228] res3d_branch2b does not need backward computation.
I1022 15:39:01.093533 27315 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I1022 15:39:01.093538 27315 net.cpp:228] scale3d_branch2a does not need backward computation.
I1022 15:39:01.093540 27315 net.cpp:228] bn3d_branch2a does not need backward computation.
I1022 15:39:01.093544 27315 net.cpp:228] res3d_branch2a does not need backward computation.
I1022 15:39:01.093547 27315 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I1022 15:39:01.093551 27315 net.cpp:228] res3c_relu does not need backward computation.
I1022 15:39:01.093555 27315 net.cpp:228] res3c does not need backward computation.
I1022 15:39:01.093559 27315 net.cpp:228] scale3c_branch2c does not need backward computation.
I1022 15:39:01.093564 27315 net.cpp:228] bn3c_branch2c does not need backward computation.
I1022 15:39:01.093565 27315 net.cpp:228] res3c_branch2c does not need backward computation.
I1022 15:39:01.093569 27315 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I1022 15:39:01.093572 27315 net.cpp:228] scale3c_branch2b does not need backward computation.
I1022 15:39:01.093576 27315 net.cpp:228] bn3c_branch2b does not need backward computation.
I1022 15:39:01.093580 27315 net.cpp:228] res3c_branch2b does not need backward computation.
I1022 15:39:01.093582 27315 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I1022 15:39:01.093586 27315 net.cpp:228] scale3c_branch2a does not need backward computation.
I1022 15:39:01.093590 27315 net.cpp:228] bn3c_branch2a does not need backward computation.
I1022 15:39:01.093592 27315 net.cpp:228] res3c_branch2a does not need backward computation.
I1022 15:39:01.093596 27315 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I1022 15:39:01.093600 27315 net.cpp:228] res3b_relu does not need backward computation.
I1022 15:39:01.093602 27315 net.cpp:228] res3b does not need backward computation.
I1022 15:39:01.093606 27315 net.cpp:228] scale3b_branch2c does not need backward computation.
I1022 15:39:01.093611 27315 net.cpp:228] bn3b_branch2c does not need backward computation.
I1022 15:39:01.093613 27315 net.cpp:228] res3b_branch2c does not need backward computation.
I1022 15:39:01.093616 27315 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I1022 15:39:01.093621 27315 net.cpp:228] scale3b_branch2b does not need backward computation.
I1022 15:39:01.093623 27315 net.cpp:228] bn3b_branch2b does not need backward computation.
I1022 15:39:01.093626 27315 net.cpp:228] res3b_branch2b does not need backward computation.
I1022 15:39:01.093631 27315 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I1022 15:39:01.093633 27315 net.cpp:228] scale3b_branch2a does not need backward computation.
I1022 15:39:01.093637 27315 net.cpp:228] bn3b_branch2a does not need backward computation.
I1022 15:39:01.093641 27315 net.cpp:228] res3b_branch2a does not need backward computation.
I1022 15:39:01.093644 27315 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I1022 15:39:01.093647 27315 net.cpp:228] res3a_relu does not need backward computation.
I1022 15:39:01.093652 27315 net.cpp:228] res3a does not need backward computation.
I1022 15:39:01.093657 27315 net.cpp:228] scale3a_branch2c does not need backward computation.
I1022 15:39:01.093660 27315 net.cpp:228] bn3a_branch2c does not need backward computation.
I1022 15:39:01.093663 27315 net.cpp:228] res3a_branch2c does not need backward computation.
I1022 15:39:01.093667 27315 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I1022 15:39:01.093670 27315 net.cpp:228] scale3a_branch2b does not need backward computation.
I1022 15:39:01.093673 27315 net.cpp:228] bn3a_branch2b does not need backward computation.
I1022 15:39:01.093677 27315 net.cpp:228] res3a_branch2b does not need backward computation.
I1022 15:39:01.093680 27315 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I1022 15:39:01.093684 27315 net.cpp:228] scale3a_branch2a does not need backward computation.
I1022 15:39:01.093688 27315 net.cpp:228] bn3a_branch2a does not need backward computation.
I1022 15:39:01.093690 27315 net.cpp:228] res3a_branch2a does not need backward computation.
I1022 15:39:01.093693 27315 net.cpp:228] scale3a_branch1 does not need backward computation.
I1022 15:39:01.093698 27315 net.cpp:228] bn3a_branch1 does not need backward computation.
I1022 15:39:01.093701 27315 net.cpp:228] res3a_branch1 does not need backward computation.
I1022 15:39:01.093704 27315 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I1022 15:39:01.093708 27315 net.cpp:228] res2c_relu does not need backward computation.
I1022 15:39:01.093711 27315 net.cpp:228] res2c does not need backward computation.
I1022 15:39:01.093716 27315 net.cpp:228] scale2c_branch2c does not need backward computation.
I1022 15:39:01.093719 27315 net.cpp:228] bn2c_branch2c does not need backward computation.
I1022 15:39:01.093722 27315 net.cpp:228] res2c_branch2c does not need backward computation.
I1022 15:39:01.093726 27315 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I1022 15:39:01.093729 27315 net.cpp:228] scale2c_branch2b does not need backward computation.
I1022 15:39:01.093732 27315 net.cpp:228] bn2c_branch2b does not need backward computation.
I1022 15:39:01.093736 27315 net.cpp:228] res2c_branch2b does not need backward computation.
I1022 15:39:01.093739 27315 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I1022 15:39:01.093744 27315 net.cpp:228] scale2c_branch2a does not need backward computation.
I1022 15:39:01.093746 27315 net.cpp:228] bn2c_branch2a does not need backward computation.
I1022 15:39:01.093750 27315 net.cpp:228] res2c_branch2a does not need backward computation.
I1022 15:39:01.093753 27315 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I1022 15:39:01.093757 27315 net.cpp:228] res2b_relu does not need backward computation.
I1022 15:39:01.093760 27315 net.cpp:228] res2b does not need backward computation.
I1022 15:39:01.093765 27315 net.cpp:228] scale2b_branch2c does not need backward computation.
I1022 15:39:01.093767 27315 net.cpp:228] bn2b_branch2c does not need backward computation.
I1022 15:39:01.093770 27315 net.cpp:228] res2b_branch2c does not need backward computation.
I1022 15:39:01.093775 27315 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I1022 15:39:01.093777 27315 net.cpp:228] scale2b_branch2b does not need backward computation.
I1022 15:39:01.093780 27315 net.cpp:228] bn2b_branch2b does not need backward computation.
I1022 15:39:01.093785 27315 net.cpp:228] res2b_branch2b does not need backward computation.
I1022 15:39:01.093787 27315 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I1022 15:39:01.093791 27315 net.cpp:228] scale2b_branch2a does not need backward computation.
I1022 15:39:01.093794 27315 net.cpp:228] bn2b_branch2a does not need backward computation.
I1022 15:39:01.093797 27315 net.cpp:228] res2b_branch2a does not need backward computation.
I1022 15:39:01.093801 27315 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I1022 15:39:01.093804 27315 net.cpp:228] res2a_relu does not need backward computation.
I1022 15:39:01.093808 27315 net.cpp:228] res2a does not need backward computation.
I1022 15:39:01.093812 27315 net.cpp:228] scale2a_branch2c does not need backward computation.
I1022 15:39:01.093816 27315 net.cpp:228] bn2a_branch2c does not need backward computation.
I1022 15:39:01.093819 27315 net.cpp:228] res2a_branch2c does not need backward computation.
I1022 15:39:01.093822 27315 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I1022 15:39:01.093825 27315 net.cpp:228] scale2a_branch2b does not need backward computation.
I1022 15:39:01.093829 27315 net.cpp:228] bn2a_branch2b does not need backward computation.
I1022 15:39:01.093832 27315 net.cpp:228] res2a_branch2b does not need backward computation.
I1022 15:39:01.093837 27315 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I1022 15:39:01.093839 27315 net.cpp:228] scale2a_branch2a does not need backward computation.
I1022 15:39:01.093842 27315 net.cpp:228] bn2a_branch2a does not need backward computation.
I1022 15:39:01.093845 27315 net.cpp:228] res2a_branch2a does not need backward computation.
I1022 15:39:01.093849 27315 net.cpp:228] scale2a_branch1 does not need backward computation.
I1022 15:39:01.093852 27315 net.cpp:228] bn2a_branch1 does not need backward computation.
I1022 15:39:01.093855 27315 net.cpp:228] res2a_branch1 does not need backward computation.
I1022 15:39:01.093860 27315 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I1022 15:39:01.093865 27315 net.cpp:228] pool1 does not need backward computation.
I1022 15:39:01.093869 27315 net.cpp:228] conv1_relu does not need backward computation.
I1022 15:39:01.093873 27315 net.cpp:228] scale_conv1 does not need backward computation.
I1022 15:39:01.093875 27315 net.cpp:228] bn_conv1 does not need backward computation.
I1022 15:39:01.093878 27315 net.cpp:228] conv1 does not need backward computation.
I1022 15:39:01.093883 27315 net.cpp:228] input does not need backward computation.
I1022 15:39:01.093885 27315 net.cpp:270] This network produces output bbox_pred_p2
I1022 15:39:01.093888 27315 net.cpp:270] This network produces output bbox_pred_p3
I1022 15:39:01.093894 27315 net.cpp:270] This network produces output cls_prob_p2
I1022 15:39:01.093897 27315 net.cpp:270] This network produces output cls_prob_p3
I1022 15:39:01.094077 27315 net.cpp:283] Network initialization done.
I1022 15:39:01.194617 27315 net.cpp:771] Ignoring source layer input-data
I1022 15:39:01.194643 27315 net.cpp:771] Ignoring source layer data_input-data_0_split
I1022 15:39:01.194648 27315 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I1022 15:39:01.194650 27315 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I1022 15:39:01.194653 27315 net.cpp:774] Copying source layer conv1
I1022 15:39:01.194670 27315 net.cpp:774] Copying source layer bn_conv1
I1022 15:39:01.194676 27315 net.cpp:774] Copying source layer scale_conv1
I1022 15:39:01.194682 27315 net.cpp:774] Copying source layer conv1_relu
I1022 15:39:01.194684 27315 net.cpp:774] Copying source layer pool1
I1022 15:39:01.194689 27315 net.cpp:774] Copying source layer pool1_pool1_0_split
I1022 15:39:01.194690 27315 net.cpp:774] Copying source layer res2a_branch1
I1022 15:39:01.194711 27315 net.cpp:774] Copying source layer bn2a_branch1
I1022 15:39:01.194722 27315 net.cpp:774] Copying source layer scale2a_branch1
I1022 15:39:01.194728 27315 net.cpp:774] Copying source layer res2a_branch2a
I1022 15:39:01.194737 27315 net.cpp:774] Copying source layer bn2a_branch2a
I1022 15:39:01.194743 27315 net.cpp:774] Copying source layer scale2a_branch2a
I1022 15:39:01.194748 27315 net.cpp:774] Copying source layer res2a_branch2a_relu
I1022 15:39:01.194752 27315 net.cpp:774] Copying source layer res2a_branch2b
I1022 15:39:01.194792 27315 net.cpp:774] Copying source layer bn2a_branch2b
I1022 15:39:01.194798 27315 net.cpp:774] Copying source layer scale2a_branch2b
I1022 15:39:01.194803 27315 net.cpp:774] Copying source layer res2a_branch2b_relu
I1022 15:39:01.194808 27315 net.cpp:774] Copying source layer res2a_branch2c
I1022 15:39:01.194828 27315 net.cpp:774] Copying source layer bn2a_branch2c
I1022 15:39:01.194836 27315 net.cpp:774] Copying source layer scale2a_branch2c
I1022 15:39:01.194842 27315 net.cpp:774] Copying source layer res2a
I1022 15:39:01.194846 27315 net.cpp:774] Copying source layer res2a_relu
I1022 15:39:01.194849 27315 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I1022 15:39:01.194851 27315 net.cpp:774] Copying source layer res2b_branch2a
I1022 15:39:01.194872 27315 net.cpp:774] Copying source layer bn2b_branch2a
I1022 15:39:01.194880 27315 net.cpp:774] Copying source layer scale2b_branch2a
I1022 15:39:01.194885 27315 net.cpp:774] Copying source layer res2b_branch2a_relu
I1022 15:39:01.194888 27315 net.cpp:774] Copying source layer res2b_branch2b
I1022 15:39:01.194926 27315 net.cpp:774] Copying source layer bn2b_branch2b
I1022 15:39:01.194933 27315 net.cpp:774] Copying source layer scale2b_branch2b
I1022 15:39:01.194937 27315 net.cpp:774] Copying source layer res2b_branch2b_relu
I1022 15:39:01.194941 27315 net.cpp:774] Copying source layer res2b_branch2c
I1022 15:39:01.194962 27315 net.cpp:774] Copying source layer bn2b_branch2c
I1022 15:39:01.194969 27315 net.cpp:774] Copying source layer scale2b_branch2c
I1022 15:39:01.194974 27315 net.cpp:774] Copying source layer res2b
I1022 15:39:01.194977 27315 net.cpp:774] Copying source layer res2b_relu
I1022 15:39:01.194980 27315 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I1022 15:39:01.194983 27315 net.cpp:774] Copying source layer res2c_branch2a
I1022 15:39:01.195005 27315 net.cpp:774] Copying source layer bn2c_branch2a
I1022 15:39:01.195011 27315 net.cpp:774] Copying source layer scale2c_branch2a
I1022 15:39:01.195016 27315 net.cpp:774] Copying source layer res2c_branch2a_relu
I1022 15:39:01.195019 27315 net.cpp:774] Copying source layer res2c_branch2b
I1022 15:39:01.195057 27315 net.cpp:774] Copying source layer bn2c_branch2b
I1022 15:39:01.195065 27315 net.cpp:774] Copying source layer scale2c_branch2b
I1022 15:39:01.195070 27315 net.cpp:774] Copying source layer res2c_branch2b_relu
I1022 15:39:01.195072 27315 net.cpp:774] Copying source layer res2c_branch2c
I1022 15:39:01.195094 27315 net.cpp:774] Copying source layer bn2c_branch2c
I1022 15:39:01.195102 27315 net.cpp:774] Copying source layer scale2c_branch2c
I1022 15:39:01.195107 27315 net.cpp:774] Copying source layer res2c
I1022 15:39:01.195112 27315 net.cpp:774] Copying source layer res2c_relu
I1022 15:39:01.195116 27315 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I1022 15:39:01.195118 27315 net.cpp:774] Copying source layer res3a_branch1
I1022 15:39:01.195235 27315 net.cpp:774] Copying source layer bn3a_branch1
I1022 15:39:01.195245 27315 net.cpp:774] Copying source layer scale3a_branch1
I1022 15:39:01.195250 27315 net.cpp:774] Copying source layer res3a_branch2a
I1022 15:39:01.195286 27315 net.cpp:774] Copying source layer bn3a_branch2a
I1022 15:39:01.195294 27315 net.cpp:774] Copying source layer scale3a_branch2a
I1022 15:39:01.195299 27315 net.cpp:774] Copying source layer res3a_branch2a_relu
I1022 15:39:01.195302 27315 net.cpp:774] Copying source layer res3a_branch2b
I1022 15:39:01.195438 27315 net.cpp:774] Copying source layer bn3a_branch2b
I1022 15:39:01.195446 27315 net.cpp:774] Copying source layer scale3a_branch2b
I1022 15:39:01.195451 27315 net.cpp:774] Copying source layer res3a_branch2b_relu
I1022 15:39:01.195453 27315 net.cpp:774] Copying source layer res3a_branch2c
I1022 15:39:01.195516 27315 net.cpp:774] Copying source layer bn3a_branch2c
I1022 15:39:01.195524 27315 net.cpp:774] Copying source layer scale3a_branch2c
I1022 15:39:01.195531 27315 net.cpp:774] Copying source layer res3a
I1022 15:39:01.195535 27315 net.cpp:774] Copying source layer res3a_relu
I1022 15:39:01.195538 27315 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I1022 15:39:01.195541 27315 net.cpp:774] Copying source layer res3b_branch2a
I1022 15:39:01.195601 27315 net.cpp:774] Copying source layer bn3b_branch2a
I1022 15:39:01.195610 27315 net.cpp:774] Copying source layer scale3b_branch2a
I1022 15:39:01.195614 27315 net.cpp:774] Copying source layer res3b_branch2a_relu
I1022 15:39:01.195617 27315 net.cpp:774] Copying source layer res3b_branch2b
I1022 15:39:01.195750 27315 net.cpp:774] Copying source layer bn3b_branch2b
I1022 15:39:01.195757 27315 net.cpp:774] Copying source layer scale3b_branch2b
I1022 15:39:01.195763 27315 net.cpp:774] Copying source layer res3b_branch2b_relu
I1022 15:39:01.195766 27315 net.cpp:774] Copying source layer res3b_branch2c
I1022 15:39:01.195827 27315 net.cpp:774] Copying source layer bn3b_branch2c
I1022 15:39:01.195837 27315 net.cpp:774] Copying source layer scale3b_branch2c
I1022 15:39:01.195842 27315 net.cpp:774] Copying source layer res3b
I1022 15:39:01.195845 27315 net.cpp:774] Copying source layer res3b_relu
I1022 15:39:01.195849 27315 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I1022 15:39:01.195852 27315 net.cpp:774] Copying source layer res3c_branch2a
I1022 15:39:01.195914 27315 net.cpp:774] Copying source layer bn3c_branch2a
I1022 15:39:01.195921 27315 net.cpp:774] Copying source layer scale3c_branch2a
I1022 15:39:01.195927 27315 net.cpp:774] Copying source layer res3c_branch2a_relu
I1022 15:39:01.195930 27315 net.cpp:774] Copying source layer res3c_branch2b
I1022 15:39:01.196056 27315 net.cpp:774] Copying source layer bn3c_branch2b
I1022 15:39:01.196063 27315 net.cpp:774] Copying source layer scale3c_branch2b
I1022 15:39:01.196069 27315 net.cpp:774] Copying source layer res3c_branch2b_relu
I1022 15:39:01.196071 27315 net.cpp:774] Copying source layer res3c_branch2c
I1022 15:39:01.196132 27315 net.cpp:774] Copying source layer bn3c_branch2c
I1022 15:39:01.196141 27315 net.cpp:774] Copying source layer scale3c_branch2c
I1022 15:39:01.196147 27315 net.cpp:774] Copying source layer res3c
I1022 15:39:01.196151 27315 net.cpp:774] Copying source layer res3c_relu
I1022 15:39:01.196153 27315 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I1022 15:39:01.196156 27315 net.cpp:774] Copying source layer res3d_branch2a
I1022 15:39:01.196218 27315 net.cpp:774] Copying source layer bn3d_branch2a
I1022 15:39:01.196225 27315 net.cpp:774] Copying source layer scale3d_branch2a
I1022 15:39:01.196231 27315 net.cpp:774] Copying source layer res3d_branch2a_relu
I1022 15:39:01.196234 27315 net.cpp:774] Copying source layer res3d_branch2b
I1022 15:39:01.196359 27315 net.cpp:774] Copying source layer bn3d_branch2b
I1022 15:39:01.196367 27315 net.cpp:774] Copying source layer scale3d_branch2b
I1022 15:39:01.196372 27315 net.cpp:774] Copying source layer res3d_branch2b_relu
I1022 15:39:01.196375 27315 net.cpp:774] Copying source layer res3d_branch2c
I1022 15:39:01.196436 27315 net.cpp:774] Copying source layer bn3d_branch2c
I1022 15:39:01.196444 27315 net.cpp:774] Copying source layer scale3d_branch2c
I1022 15:39:01.196450 27315 net.cpp:774] Copying source layer res3d
I1022 15:39:01.196455 27315 net.cpp:774] Copying source layer res3d_relu
I1022 15:39:01.196458 27315 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I1022 15:39:01.196462 27315 net.cpp:774] Copying source layer res4a_branch1
I1022 15:39:01.196933 27315 net.cpp:774] Copying source layer bn4a_branch1
I1022 15:39:01.196943 27315 net.cpp:774] Copying source layer scale4a_branch1
I1022 15:39:01.196951 27315 net.cpp:774] Copying source layer res4a_branch2a
I1022 15:39:01.197072 27315 net.cpp:774] Copying source layer bn4a_branch2a
I1022 15:39:01.197079 27315 net.cpp:774] Copying source layer scale4a_branch2a
I1022 15:39:01.197084 27315 net.cpp:774] Copying source layer res4a_branch2a_relu
I1022 15:39:01.197088 27315 net.cpp:774] Copying source layer res4a_branch2b
I1022 15:39:01.197566 27315 net.cpp:774] Copying source layer bn4a_branch2b
I1022 15:39:01.197576 27315 net.cpp:774] Copying source layer scale4a_branch2b
I1022 15:39:01.197580 27315 net.cpp:774] Copying source layer res4a_branch2b_relu
I1022 15:39:01.197584 27315 net.cpp:774] Copying source layer res4a_branch2c
I1022 15:39:01.197801 27315 net.cpp:774] Copying source layer bn4a_branch2c
I1022 15:39:01.197811 27315 net.cpp:774] Copying source layer scale4a_branch2c
I1022 15:39:01.197818 27315 net.cpp:774] Copying source layer res4a
I1022 15:39:01.197823 27315 net.cpp:774] Copying source layer res4a_relu
I1022 15:39:01.197825 27315 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I1022 15:39:01.197829 27315 net.cpp:774] Copying source layer res4b_branch2a
I1022 15:39:01.198043 27315 net.cpp:774] Copying source layer bn4b_branch2a
I1022 15:39:01.198051 27315 net.cpp:774] Copying source layer scale4b_branch2a
I1022 15:39:01.198057 27315 net.cpp:774] Copying source layer res4b_branch2a_relu
I1022 15:39:01.198060 27315 net.cpp:774] Copying source layer res4b_branch2b
I1022 15:39:01.198545 27315 net.cpp:774] Copying source layer bn4b_branch2b
I1022 15:39:01.198554 27315 net.cpp:774] Copying source layer scale4b_branch2b
I1022 15:39:01.198559 27315 net.cpp:774] Copying source layer res4b_branch2b_relu
I1022 15:39:01.198561 27315 net.cpp:774] Copying source layer res4b_branch2c
I1022 15:39:01.198791 27315 net.cpp:774] Copying source layer bn4b_branch2c
I1022 15:39:01.198801 27315 net.cpp:774] Copying source layer scale4b_branch2c
I1022 15:39:01.198807 27315 net.cpp:774] Copying source layer res4b
I1022 15:39:01.198812 27315 net.cpp:774] Copying source layer res4b_relu
I1022 15:39:01.198817 27315 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I1022 15:39:01.198819 27315 net.cpp:774] Copying source layer res4c_branch2a
I1022 15:39:01.199034 27315 net.cpp:774] Copying source layer bn4c_branch2a
I1022 15:39:01.199043 27315 net.cpp:774] Copying source layer scale4c_branch2a
I1022 15:39:01.199049 27315 net.cpp:774] Copying source layer res4c_branch2a_relu
I1022 15:39:01.199053 27315 net.cpp:774] Copying source layer res4c_branch2b
I1022 15:39:01.199534 27315 net.cpp:774] Copying source layer bn4c_branch2b
I1022 15:39:01.199542 27315 net.cpp:774] Copying source layer scale4c_branch2b
I1022 15:39:01.199548 27315 net.cpp:774] Copying source layer res4c_branch2b_relu
I1022 15:39:01.199551 27315 net.cpp:774] Copying source layer res4c_branch2c
I1022 15:39:01.199771 27315 net.cpp:774] Copying source layer bn4c_branch2c
I1022 15:39:01.199782 27315 net.cpp:774] Copying source layer scale4c_branch2c
I1022 15:39:01.199790 27315 net.cpp:774] Copying source layer res4c
I1022 15:39:01.199795 27315 net.cpp:774] Copying source layer res4c_relu
I1022 15:39:01.199798 27315 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I1022 15:39:01.199801 27315 net.cpp:774] Copying source layer res4d_branch2a
I1022 15:39:01.200017 27315 net.cpp:774] Copying source layer bn4d_branch2a
I1022 15:39:01.200026 27315 net.cpp:774] Copying source layer scale4d_branch2a
I1022 15:39:01.200031 27315 net.cpp:774] Copying source layer res4d_branch2a_relu
I1022 15:39:01.200034 27315 net.cpp:774] Copying source layer res4d_branch2b
I1022 15:39:01.200520 27315 net.cpp:774] Copying source layer bn4d_branch2b
I1022 15:39:01.200528 27315 net.cpp:774] Copying source layer scale4d_branch2b
I1022 15:39:01.200538 27315 net.cpp:774] Copying source layer res4d_branch2b_relu
I1022 15:39:01.200541 27315 net.cpp:774] Copying source layer res4d_branch2c
I1022 15:39:01.200788 27315 net.cpp:774] Copying source layer bn4d_branch2c
I1022 15:39:01.200798 27315 net.cpp:774] Copying source layer scale4d_branch2c
I1022 15:39:01.200805 27315 net.cpp:774] Copying source layer res4d
I1022 15:39:01.200809 27315 net.cpp:774] Copying source layer res4d_relu
I1022 15:39:01.200812 27315 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I1022 15:39:01.200816 27315 net.cpp:774] Copying source layer res4e_branch2a
I1022 15:39:01.201030 27315 net.cpp:774] Copying source layer bn4e_branch2a
I1022 15:39:01.201038 27315 net.cpp:774] Copying source layer scale4e_branch2a
I1022 15:39:01.201045 27315 net.cpp:774] Copying source layer res4e_branch2a_relu
I1022 15:39:01.201048 27315 net.cpp:774] Copying source layer res4e_branch2b
I1022 15:39:01.201552 27315 net.cpp:774] Copying source layer bn4e_branch2b
I1022 15:39:01.201560 27315 net.cpp:774] Copying source layer scale4e_branch2b
I1022 15:39:01.201566 27315 net.cpp:774] Copying source layer res4e_branch2b_relu
I1022 15:39:01.201570 27315 net.cpp:774] Copying source layer res4e_branch2c
I1022 15:39:01.201794 27315 net.cpp:774] Copying source layer bn4e_branch2c
I1022 15:39:01.201805 27315 net.cpp:774] Copying source layer scale4e_branch2c
I1022 15:39:01.201812 27315 net.cpp:774] Copying source layer res4e
I1022 15:39:01.201817 27315 net.cpp:774] Copying source layer res4e_relu
I1022 15:39:01.201820 27315 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I1022 15:39:01.201823 27315 net.cpp:774] Copying source layer res4f_branch2a
I1022 15:39:01.202034 27315 net.cpp:774] Copying source layer bn4f_branch2a
I1022 15:39:01.202044 27315 net.cpp:774] Copying source layer scale4f_branch2a
I1022 15:39:01.202049 27315 net.cpp:774] Copying source layer res4f_branch2a_relu
I1022 15:39:01.202052 27315 net.cpp:774] Copying source layer res4f_branch2b
I1022 15:39:01.202519 27315 net.cpp:774] Copying source layer bn4f_branch2b
I1022 15:39:01.202527 27315 net.cpp:774] Copying source layer scale4f_branch2b
I1022 15:39:01.202533 27315 net.cpp:774] Copying source layer res4f_branch2b_relu
I1022 15:39:01.202535 27315 net.cpp:774] Copying source layer res4f_branch2c
I1022 15:39:01.202747 27315 net.cpp:774] Copying source layer bn4f_branch2c
I1022 15:39:01.202757 27315 net.cpp:774] Copying source layer scale4f_branch2c
I1022 15:39:01.202765 27315 net.cpp:774] Copying source layer res4f
I1022 15:39:01.202769 27315 net.cpp:774] Copying source layer res4f_relu
I1022 15:39:01.202774 27315 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I1022 15:39:01.202777 27315 net.cpp:774] Copying source layer res5a_branch1
I1022 15:39:01.204434 27315 net.cpp:774] Copying source layer bn5a_branch1
I1022 15:39:01.204450 27315 net.cpp:774] Copying source layer scale5a_branch1
I1022 15:39:01.204463 27315 net.cpp:774] Copying source layer res5a_branch2a
I1022 15:39:01.204941 27315 net.cpp:774] Copying source layer bn5a_branch2a
I1022 15:39:01.204952 27315 net.cpp:774] Copying source layer scale5a_branch2a
I1022 15:39:01.204959 27315 net.cpp:774] Copying source layer res5a_branch2a_relu
I1022 15:39:01.204962 27315 net.cpp:774] Copying source layer res5a_branch2b
I1022 15:39:01.206854 27315 net.cpp:774] Copying source layer bn5a_branch2b
I1022 15:39:01.206866 27315 net.cpp:774] Copying source layer scale5a_branch2b
I1022 15:39:01.206872 27315 net.cpp:774] Copying source layer res5a_branch2b_relu
I1022 15:39:01.206876 27315 net.cpp:774] Copying source layer res5a_branch2c
I1022 15:39:01.207711 27315 net.cpp:774] Copying source layer bn5a_branch2c
I1022 15:39:01.207726 27315 net.cpp:774] Copying source layer scale5a_branch2c
I1022 15:39:01.207738 27315 net.cpp:774] Copying source layer res5a
I1022 15:39:01.207741 27315 net.cpp:774] Copying source layer res5a_relu
I1022 15:39:01.207746 27315 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I1022 15:39:01.207749 27315 net.cpp:774] Copying source layer res5b_branch2a
I1022 15:39:01.208577 27315 net.cpp:774] Copying source layer bn5b_branch2a
I1022 15:39:01.208588 27315 net.cpp:774] Copying source layer scale5b_branch2a
I1022 15:39:01.208595 27315 net.cpp:774] Copying source layer res5b_branch2a_relu
I1022 15:39:01.208598 27315 net.cpp:774] Copying source layer res5b_branch2b
I1022 15:39:01.210536 27315 net.cpp:774] Copying source layer bn5b_branch2b
I1022 15:39:01.210549 27315 net.cpp:774] Copying source layer scale5b_branch2b
I1022 15:39:01.210556 27315 net.cpp:774] Copying source layer res5b_branch2b_relu
I1022 15:39:01.210558 27315 net.cpp:774] Copying source layer res5b_branch2c
I1022 15:39:01.211400 27315 net.cpp:774] Copying source layer bn5b_branch2c
I1022 15:39:01.211413 27315 net.cpp:774] Copying source layer scale5b_branch2c
I1022 15:39:01.211423 27315 net.cpp:774] Copying source layer res5b
I1022 15:39:01.211426 27315 net.cpp:774] Copying source layer res5b_relu
I1022 15:39:01.211431 27315 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I1022 15:39:01.211433 27315 net.cpp:774] Copying source layer res5c_branch2a
I1022 15:39:01.212296 27315 net.cpp:774] Copying source layer bn5c_branch2a
I1022 15:39:01.212306 27315 net.cpp:774] Copying source layer scale5c_branch2a
I1022 15:39:01.212311 27315 net.cpp:774] Copying source layer res5c_branch2a_relu
I1022 15:39:01.212316 27315 net.cpp:774] Copying source layer res5c_branch2b
I1022 15:39:01.214233 27315 net.cpp:774] Copying source layer bn5c_branch2b
I1022 15:39:01.214246 27315 net.cpp:774] Copying source layer scale5c_branch2b
I1022 15:39:01.214251 27315 net.cpp:774] Copying source layer res5c_branch2b_relu
I1022 15:39:01.214256 27315 net.cpp:774] Copying source layer res5c_branch2c
I1022 15:39:01.215102 27315 net.cpp:774] Copying source layer bn5c_branch2c
I1022 15:39:01.215116 27315 net.cpp:774] Copying source layer scale5c_branch2c
I1022 15:39:01.215128 27315 net.cpp:774] Copying source layer res5c
I1022 15:39:01.215131 27315 net.cpp:774] Copying source layer res5c_relu
I1022 15:39:01.215134 27315 net.cpp:774] Copying source layer upP4
I1022 15:39:01.215167 27315 net.cpp:774] Copying source layer newC4
I1022 15:39:01.215605 27315 net.cpp:774] Copying source layer eltwise_bnc4_bnp4
I1022 15:39:01.215610 27315 net.cpp:774] Copying source layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 15:39:01.215613 27315 net.cpp:774] Copying source layer bnp4_conv
I1022 15:39:01.215677 27315 net.cpp:774] Copying source layer bnp4_bn
I1022 15:39:01.215685 27315 net.cpp:774] Copying source layer bnp4_scale
I1022 15:39:01.215690 27315 net.cpp:774] Copying source layer bnp4_ReLU
I1022 15:39:01.215694 27315 net.cpp:774] Copying source layer bn_eltwise_1_1_conv
I1022 15:39:01.215821 27315 net.cpp:774] Copying source layer bn_eltwise_1_1_bn
I1022 15:39:01.215827 27315 net.cpp:774] Copying source layer bn_eltwise_1_1_scale
I1022 15:39:01.215833 27315 net.cpp:774] Copying source layer bn_eltwise_1_1_ReLU
I1022 15:39:01.215837 27315 net.cpp:774] Copying source layer bn_eltwise_1_2_conv
I1022 15:39:01.215896 27315 net.cpp:774] Copying source layer bn_eltwise_1_2_bn
I1022 15:39:01.215905 27315 net.cpp:774] Copying source layer bn_eltwise_1_2_scale
I1022 15:39:01.215911 27315 net.cpp:774] Copying source layer p3
I1022 15:39:01.215914 27315 net.cpp:774] Copying source layer p3_relu
I1022 15:39:01.215917 27315 net.cpp:774] Copying source layer p3_p3_relu_0_split
I1022 15:39:01.215921 27315 net.cpp:774] Copying source layer newC3
I1022 15:39:01.216138 27315 net.cpp:774] Copying source layer upP3
I1022 15:39:01.216154 27315 net.cpp:774] Copying source layer eltwise_bnc3_bnp3
I1022 15:39:01.216159 27315 net.cpp:774] Copying source layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 15:39:01.216162 27315 net.cpp:774] Copying source layer bnp3_conv
I1022 15:39:01.216223 27315 net.cpp:774] Copying source layer bnp3_bn
I1022 15:39:01.216230 27315 net.cpp:774] Copying source layer bnp3_scale
I1022 15:39:01.216235 27315 net.cpp:774] Copying source layer bnp3_ReLU
I1022 15:39:01.216239 27315 net.cpp:774] Copying source layer bn_eltwise_2_1_conv
I1022 15:39:01.216367 27315 net.cpp:774] Copying source layer bn_eltwise_2_1_bn
I1022 15:39:01.216374 27315 net.cpp:774] Copying source layer bn_eltwise_2_1_scale
I1022 15:39:01.216380 27315 net.cpp:774] Copying source layer bn_eltwise_2_1_ReLU
I1022 15:39:01.216383 27315 net.cpp:774] Copying source layer bn_eltwise_2_2_conv
I1022 15:39:01.216445 27315 net.cpp:774] Copying source layer bn_eltwise_2_2_bn
I1022 15:39:01.216454 27315 net.cpp:774] Copying source layer bn_eltwise_2_2_scale
I1022 15:39:01.216459 27315 net.cpp:774] Copying source layer p2
I1022 15:39:01.216462 27315 net.cpp:774] Copying source layer p2_relu
I1022 15:39:01.216466 27315 net.cpp:774] Copying source layer p2_p2_relu_0_split
I1022 15:39:01.216470 27315 net.cpp:774] Copying source layer rpn_conv/3x3_p2
I1022 15:39:01.218435 27315 net.cpp:774] Copying source layer rpn_relu/3x3_p2
I1022 15:39:01.218444 27315 net.cpp:774] Copying source layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 15:39:01.218449 27315 net.cpp:774] Copying source layer rpn_cls_score_p2
I1022 15:39:01.218473 27315 net.cpp:771] Ignoring source layer rpn_cls_score_p2_rpn_cls_score_p2_0_split
I1022 15:39:01.218477 27315 net.cpp:774] Copying source layer rpn_bbox_pred_p2
I1022 15:39:01.218511 27315 net.cpp:771] Ignoring source layer rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split
I1022 15:39:01.218518 27315 net.cpp:774] Copying source layer rpn_cls_score_reshape_p2
I1022 15:39:01.218523 27315 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split
I1022 15:39:01.218525 27315 net.cpp:774] Copying source layer rpn_cls_prob_p2
I1022 15:39:01.218528 27315 net.cpp:774] Copying source layer rpn_cls_prob_reshape_p2
I1022 15:39:01.218531 27315 net.cpp:774] Copying source layer rpn_conv/3x3_p3
I1022 15:39:01.220439 27315 net.cpp:774] Copying source layer rpn_relu/3x3_p3
I1022 15:39:01.220448 27315 net.cpp:774] Copying source layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 15:39:01.220453 27315 net.cpp:774] Copying source layer rpn_cls_score_p3
I1022 15:39:01.220468 27315 net.cpp:771] Ignoring source layer rpn_cls_score_p3_rpn_cls_score_p3_0_split
I1022 15:39:01.220472 27315 net.cpp:774] Copying source layer rpn_bbox_pred_p3
I1022 15:39:01.220497 27315 net.cpp:771] Ignoring source layer rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split
I1022 15:39:01.220504 27315 net.cpp:774] Copying source layer rpn_cls_score_reshape_p3
I1022 15:39:01.220507 27315 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split
I1022 15:39:01.220511 27315 net.cpp:774] Copying source layer rpn_cls_prob_p3
I1022 15:39:01.220515 27315 net.cpp:774] Copying source layer rpn_cls_prob_reshape_p3
I1022 15:39:01.220518 27315 net.cpp:771] Ignoring source layer rpn-data
I1022 15:39:01.220521 27315 net.cpp:771] Ignoring source layer rpn_loss_cls_p2
I1022 15:39:01.220525 27315 net.cpp:771] Ignoring source layer rpn_loss_bbox_p2
I1022 15:39:01.220528 27315 net.cpp:771] Ignoring source layer rpn_loss_cls_p3
I1022 15:39:01.220531 27315 net.cpp:771] Ignoring source layer rpn_loss_bbox_p3
I1022 15:39:01.220535 27315 net.cpp:774] Copying source layer proposal
I1022 15:39:01.220540 27315 net.cpp:771] Ignoring source layer roi-data
I1022 15:39:01.220542 27315 net.cpp:771] Ignoring source layer rois_p2_roi-data_0_split
I1022 15:39:01.220546 27315 net.cpp:771] Ignoring source layer rois_p3_roi-data_1_split
I1022 15:39:01.220548 27315 net.cpp:771] Ignoring source layer labels_p2_roi-data_2_split
I1022 15:39:01.220551 27315 net.cpp:771] Ignoring source layer labels_p3_roi-data_3_split
I1022 15:39:01.220554 27315 net.cpp:771] Ignoring source layer bbox_targets_p2_roi-data_4_split
I1022 15:39:01.220556 27315 net.cpp:771] Ignoring source layer bbox_targets_p3_roi-data_5_split
I1022 15:39:01.220561 27315 net.cpp:771] Ignoring source layer bbox_inside_weights_p2_roi-data_6_split
I1022 15:39:01.220563 27315 net.cpp:771] Ignoring source layer bbox_inside_weights_p3_roi-data_7_split
I1022 15:39:01.220566 27315 net.cpp:774] Copying source layer conv_new_p2
I1022 15:39:01.221037 27315 net.cpp:774] Copying source layer conv_new_p2_relu
I1022 15:39:01.221045 27315 net.cpp:774] Copying source layer conv_new_p2_conv_new_p2_relu_0_split
I1022 15:39:01.221047 27315 net.cpp:774] Copying source layer rfcn_cls_p2
I1022 15:39:01.221165 27315 net.cpp:774] Copying source layer rfcn_bbox_p2
I1022 15:39:01.221505 27315 net.cpp:774] Copying source layer psroipooled_cls_rois_p2
I1022 15:39:01.221510 27315 net.cpp:774] Copying source layer ave_cls_score_rois_p2
I1022 15:39:01.221513 27315 net.cpp:771] Ignoring source layer cls_score_p2_ave_cls_score_rois_p2_0_split
I1022 15:39:01.221516 27315 net.cpp:774] Copying source layer psroipooled_loc_rois_p2
I1022 15:39:01.221519 27315 net.cpp:774] Copying source layer ave_bbox_pred_rois_p2
I1022 15:39:01.221521 27315 net.cpp:771] Ignoring source layer bbox_pred_p2_ave_bbox_pred_rois_p2_0_split
I1022 15:39:01.221529 27315 net.cpp:771] Ignoring source layer per_roi_loss_cls_p2
I1022 15:39:01.221531 27315 net.cpp:771] Ignoring source layer per_roi_loss_bbox_p2
I1022 15:39:01.221534 27315 net.cpp:771] Ignoring source layer per_roi_loss_p2
I1022 15:39:01.221537 27315 net.cpp:771] Ignoring source layer annotator_detector_p2
I1022 15:39:01.221540 27315 net.cpp:771] Ignoring source layer labels_ohem_p2_annotator_detector_p2_0_split
I1022 15:39:01.221544 27315 net.cpp:774] Copying source layer conv_new_p3
I1022 15:39:01.221979 27315 net.cpp:774] Copying source layer conv_new_p3_relu
I1022 15:39:01.221985 27315 net.cpp:774] Copying source layer conv_new_p3_conv_new_p3_relu_0_split
I1022 15:39:01.221988 27315 net.cpp:774] Copying source layer rfcn_cls_p3
I1022 15:39:01.222079 27315 net.cpp:774] Copying source layer rfcn_bbox_p3
I1022 15:39:01.222415 27315 net.cpp:774] Copying source layer psroipooled_cls_rois_p3
I1022 15:39:01.222420 27315 net.cpp:774] Copying source layer ave_cls_score_rois_p3
I1022 15:39:01.222424 27315 net.cpp:771] Ignoring source layer cls_score_p3_ave_cls_score_rois_p3_0_split
I1022 15:39:01.222427 27315 net.cpp:774] Copying source layer psroipooled_loc_rois_p3
I1022 15:39:01.222430 27315 net.cpp:774] Copying source layer ave_bbox_pred_rois_p3
I1022 15:39:01.222432 27315 net.cpp:771] Ignoring source layer bbox_pred_p3_ave_bbox_pred_rois_p3_0_split
I1022 15:39:01.222436 27315 net.cpp:771] Ignoring source layer per_roi_loss_cls_p3
I1022 15:39:01.222440 27315 net.cpp:771] Ignoring source layer per_roi_loss_bbox_p3
I1022 15:39:01.222442 27315 net.cpp:771] Ignoring source layer per_roi_loss_p3
I1022 15:39:01.222446 27315 net.cpp:771] Ignoring source layer annotator_detector_p3
I1022 15:39:01.222450 27315 net.cpp:771] Ignoring source layer labels_ohem_p3_annotator_detector_p3_0_split
I1022 15:39:01.222452 27315 net.cpp:771] Ignoring source layer loss_p2
I1022 15:39:01.222455 27315 net.cpp:771] Ignoring source layer loss_p3
I1022 15:39:01.222458 27315 net.cpp:771] Ignoring source layer accuarcy_p2
I1022 15:39:01.222461 27315 net.cpp:771] Ignoring source layer accuarcy_p3
I1022 15:39:01.222465 27315 net.cpp:771] Ignoring source layer loss_bbox_p2
I1022 15:39:01.222467 27315 net.cpp:771] Ignoring source layer loss_bbox_p3
I1022 15:39:01.222470 27315 net.cpp:771] Ignoring source layer silence
im_detect: 1/4024 1.141s 0.000s
im_detect: 2/4024 0.682s 0.000s
im_detect: 3/4024 0.540s 0.000s
im_detect: 4/4024 0.462s 0.000s
im_detect: 5/4024 0.419s 0.001s
im_detect: 6/4024 0.388s 0.001s
im_detect: 7/4024 0.364s 0.001s
im_detect: 8/4024 0.348s 0.001s
im_detect: 9/4024 0.333s 0.001s
im_detect: 10/4024 0.320s 0.001s
im_detect: 11/4024 0.309s 0.000s
im_detect: 12/4024 0.301s 0.000s
im_detect: 13/4024 0.296s 0.000s
im_detect: 14/4024 0.291s 0.000s
im_detect: 15/4024 0.286s 0.000s
im_detect: 16/4024 0.284s 0.000s
im_detect: 17/4024 0.280s 0.000s
im_detect: 18/4024 0.277s 0.000s
im_detect: 19/4024 0.274s 0.001s
im_detect: 20/4024 0.272s 0.001s
im_detect: 21/4024 0.270s 0.001s
im_detect: 22/4024 0.268s 0.001s
im_detect: 23/4024 0.266s 0.001s
im_detect: 24/4024 0.265s 0.001s
im_detect: 25/4024 0.264s 0.001s
im_detect: 26/4024 0.262s 0.001s
im_detect: 27/4024 0.261s 0.001s
im_detect: 28/4024 0.260s 0.001s
im_detect: 29/4024 0.259s 0.001s
im_detect: 30/4024 0.258s 0.001s
im_detect: 31/4024 0.258s 0.001s
im_detect: 32/4024 0.257s 0.001s
im_detect: 33/4024 0.256s 0.001s
im_detect: 34/4024 0.256s 0.001s
im_detect: 35/4024 0.256s 0.001s
im_detect: 36/4024 0.255s 0.001s
im_detect: 37/4024 0.255s 0.001s
im_detect: 38/4024 0.254s 0.001s
im_detect: 39/4024 0.253s 0.001s
im_detect: 40/4024 0.253s 0.001s
im_detect: 41/4024 0.252s 0.001s
im_detect: 42/4024 0.252s 0.001s
im_detect: 43/4024 0.251s 0.001s
im_detect: 44/4024 0.251s 0.001s
im_detect: 45/4024 0.250s 0.001s
im_detect: 46/4024 0.250s 0.001s
im_detect: 47/4024 0.249s 0.001s
im_detect: 48/4024 0.249s 0.001s
im_detect: 49/4024 0.249s 0.001s
im_detect: 50/4024 0.249s 0.001s
im_detect: 51/4024 0.249s 0.001s
im_detect: 52/4024 0.249s 0.001s
im_detect: 53/4024 0.248s 0.001s
im_detect: 54/4024 0.248s 0.001s
im_detect: 55/4024 0.248s 0.001s
im_detect: 56/4024 0.248s 0.001s
im_detect: 57/4024 0.247s 0.001s
im_detect: 58/4024 0.247s 0.001s
im_detect: 59/4024 0.246s 0.001s
im_detect: 60/4024 0.246s 0.001s
im_detect: 61/4024 0.246s 0.001s
im_detect: 62/4024 0.246s 0.001s
im_detect: 63/4024 0.246s 0.001s
im_detect: 64/4024 0.245s 0.001s
im_detect: 65/4024 0.246s 0.001s
im_detect: 66/4024 0.245s 0.001s
im_detect: 67/4024 0.245s 0.001s
im_detect: 68/4024 0.245s 0.001s
im_detect: 69/4024 0.245s 0.001s
im_detect: 70/4024 0.245s 0.001s
im_detect: 71/4024 0.245s 0.001s
im_detect: 72/4024 0.245s 0.001s
im_detect: 73/4024 0.245s 0.001s
im_detect: 74/4024 0.244s 0.001s
im_detect: 75/4024 0.244s 0.001s
im_detect: 76/4024 0.244s 0.001s
im_detect: 77/4024 0.243s 0.001s
im_detect: 78/4024 0.243s 0.001s
im_detect: 79/4024 0.243s 0.001s
im_detect: 80/4024 0.243s 0.001s
im_detect: 81/4024 0.243s 0.001s
im_detect: 82/4024 0.243s 0.001s
im_detect: 83/4024 0.243s 0.001s
im_detect: 84/4024 0.243s 0.001s
im_detect: 85/4024 0.243s 0.001s
im_detect: 86/4024 0.243s 0.001s
im_detect: 87/4024 0.243s 0.001s
im_detect: 88/4024 0.243s 0.001s
im_detect: 89/4024 0.243s 0.001s
im_detect: 90/4024 0.243s 0.001s
im_detect: 91/4024 0.243s 0.001s
im_detect: 92/4024 0.243s 0.001s
im_detect: 93/4024 0.243s 0.001s
im_detect: 94/4024 0.243s 0.001s
im_detect: 95/4024 0.242s 0.001s
im_detect: 96/4024 0.242s 0.001s
im_detect: 97/4024 0.242s 0.001s
im_detect: 98/4024 0.242s 0.001s
im_detect: 99/4024 0.242s 0.001s
im_detect: 100/4024 0.242s 0.001s
im_detect: 101/4024 0.242s 0.001s
im_detect: 102/4024 0.242s 0.001s
im_detect: 103/4024 0.242s 0.001s
im_detect: 104/4024 0.242s 0.001s
im_detect: 105/4024 0.242s 0.001s
im_detect: 106/4024 0.242s 0.001s
im_detect: 107/4024 0.242s 0.001s
im_detect: 108/4024 0.242s 0.001s
im_detect: 109/4024 0.241s 0.001s
im_detect: 110/4024 0.241s 0.001s
im_detect: 111/4024 0.241s 0.001s
im_detect: 112/4024 0.241s 0.001s
im_detect: 113/4024 0.241s 0.001s
im_detect: 114/4024 0.241s 0.001s
im_detect: 115/4024 0.241s 0.001s
im_detect: 116/4024 0.240s 0.001s
im_detect: 117/4024 0.240s 0.001s
im_detect: 118/4024 0.240s 0.001s
im_detect: 119/4024 0.240s 0.001s
im_detect: 120/4024 0.240s 0.001s
im_detect: 121/4024 0.240s 0.001s
im_detect: 122/4024 0.240s 0.001s
im_detect: 123/4024 0.240s 0.001s
im_detect: 124/4024 0.240s 0.001s
im_detect: 125/4024 0.240s 0.001s
im_detect: 126/4024 0.240s 0.001s
im_detect: 127/4024 0.240s 0.001s
im_detect: 128/4024 0.240s 0.001s
im_detect: 129/4024 0.240s 0.001s
im_detect: 130/4024 0.240s 0.001s
im_detect: 131/4024 0.240s 0.001s
im_detect: 132/4024 0.239s 0.001s
im_detect: 133/4024 0.240s 0.001s
im_detect: 134/4024 0.240s 0.001s
im_detect: 135/4024 0.239s 0.001s
im_detect: 136/4024 0.239s 0.001s
im_detect: 137/4024 0.239s 0.001s
im_detect: 138/4024 0.239s 0.001s
im_detect: 139/4024 0.239s 0.001s
im_detect: 140/4024 0.239s 0.001s
im_detect: 141/4024 0.239s 0.001s
im_detect: 142/4024 0.239s 0.001s
im_detect: 143/4024 0.239s 0.001s
im_detect: 144/4024 0.239s 0.001s
im_detect: 145/4024 0.239s 0.001s
im_detect: 146/4024 0.239s 0.001s
im_detect: 147/4024 0.239s 0.001s
im_detect: 148/4024 0.239s 0.001s
im_detect: 149/4024 0.239s 0.001s
im_detect: 150/4024 0.239s 0.001s
im_detect: 151/4024 0.239s 0.001s
im_detect: 152/4024 0.239s 0.001s
im_detect: 153/4024 0.239s 0.001s
im_detect: 154/4024 0.239s 0.001s
im_detect: 155/4024 0.239s 0.001s
im_detect: 156/4024 0.239s 0.001s
im_detect: 157/4024 0.239s 0.001s
im_detect: 158/4024 0.239s 0.001s
im_detect: 159/4024 0.239s 0.001s
im_detect: 160/4024 0.239s 0.001s
im_detect: 161/4024 0.239s 0.001s
im_detect: 162/4024 0.239s 0.001s
im_detect: 163/4024 0.239s 0.001s
im_detect: 164/4024 0.239s 0.001s
im_detect: 165/4024 0.239s 0.001s
im_detect: 166/4024 0.239s 0.001s
im_detect: 167/4024 0.239s 0.001s
im_detect: 168/4024 0.238s 0.001s
im_detect: 169/4024 0.238s 0.001s
im_detect: 170/4024 0.238s 0.001s
im_detect: 171/4024 0.238s 0.001s
im_detect: 172/4024 0.238s 0.001s
im_detect: 173/4024 0.238s 0.001s
im_detect: 174/4024 0.238s 0.001s
im_detect: 175/4024 0.238s 0.001s
im_detect: 176/4024 0.238s 0.001s
im_detect: 177/4024 0.238s 0.001s
im_detect: 178/4024 0.238s 0.001s
im_detect: 179/4024 0.238s 0.001s
im_detect: 180/4024 0.238s 0.001s
im_detect: 181/4024 0.238s 0.001s
im_detect: 182/4024 0.238s 0.001s
im_detect: 183/4024 0.238s 0.001s
im_detect: 184/4024 0.237s 0.001s
im_detect: 185/4024 0.238s 0.001s
im_detect: 186/4024 0.238s 0.001s
im_detect: 187/4024 0.238s 0.001s
im_detect: 188/4024 0.238s 0.001s
im_detect: 189/4024 0.238s 0.001s
im_detect: 190/4024 0.238s 0.001s
im_detect: 191/4024 0.237s 0.001s
im_detect: 192/4024 0.237s 0.001s
im_detect: 193/4024 0.237s 0.001s
im_detect: 194/4024 0.237s 0.001s
im_detect: 195/4024 0.237s 0.001s
im_detect: 196/4024 0.237s 0.001s
im_detect: 197/4024 0.237s 0.001s
im_detect: 198/4024 0.237s 0.001s
im_detect: 199/4024 0.237s 0.001s
im_detect: 200/4024 0.237s 0.001s
im_detect: 201/4024 0.237s 0.001s
im_detect: 202/4024 0.237s 0.001s
im_detect: 203/4024 0.237s 0.001s
im_detect: 204/4024 0.237s 0.001s
im_detect: 205/4024 0.237s 0.001s
im_detect: 206/4024 0.237s 0.001s
im_detect: 207/4024 0.237s 0.001s
im_detect: 208/4024 0.237s 0.001s
im_detect: 209/4024 0.237s 0.001s
im_detect: 210/4024 0.237s 0.001s
im_detect: 211/4024 0.237s 0.001s
im_detect: 212/4024 0.237s 0.001s
im_detect: 213/4024 0.237s 0.001s
im_detect: 214/4024 0.237s 0.001s
im_detect: 215/4024 0.237s 0.001s
im_detect: 216/4024 0.237s 0.001s
im_detect: 217/4024 0.237s 0.001s
im_detect: 218/4024 0.237s 0.001s
im_detect: 219/4024 0.237s 0.001s
im_detect: 220/4024 0.236s 0.001s
im_detect: 221/4024 0.236s 0.001s
im_detect: 222/4024 0.236s 0.001s
im_detect: 223/4024 0.236s 0.001s
im_detect: 224/4024 0.236s 0.001s
im_detect: 225/4024 0.236s 0.001s
im_detect: 226/4024 0.236s 0.001s
im_detect: 227/4024 0.236s 0.001s
im_detect: 228/4024 0.236s 0.001s
im_detect: 229/4024 0.236s 0.001s
im_detect: 230/4024 0.236s 0.001s
im_detect: 231/4024 0.236s 0.001s
im_detect: 232/4024 0.236s 0.001s
im_detect: 233/4024 0.236s 0.001s
im_detect: 234/4024 0.236s 0.001s
im_detect: 235/4024 0.236s 0.001s
im_detect: 236/4024 0.236s 0.001s
im_detect: 237/4024 0.236s 0.001s
im_detect: 238/4024 0.236s 0.001s
im_detect: 239/4024 0.236s 0.001s
im_detect: 240/4024 0.236s 0.001s
im_detect: 241/4024 0.236s 0.001s
im_detect: 242/4024 0.236s 0.001s
im_detect: 243/4024 0.236s 0.001s
im_detect: 244/4024 0.236s 0.001s
im_detect: 245/4024 0.236s 0.001s
im_detect: 246/4024 0.236s 0.001s
im_detect: 247/4024 0.236s 0.001s
im_detect: 248/4024 0.236s 0.001s
im_detect: 249/4024 0.236s 0.001s
im_detect: 250/4024 0.236s 0.001s
im_detect: 251/4024 0.236s 0.001s
im_detect: 252/4024 0.236s 0.001s
im_detect: 253/4024 0.236s 0.001s
im_detect: 254/4024 0.236s 0.001s
im_detect: 255/4024 0.236s 0.001s
im_detect: 256/4024 0.236s 0.001s
im_detect: 257/4024 0.236s 0.001s
im_detect: 258/4024 0.236s 0.001s
im_detect: 259/4024 0.236s 0.001s
im_detect: 260/4024 0.236s 0.001s
im_detect: 261/4024 0.235s 0.001s
im_detect: 262/4024 0.235s 0.001s
im_detect: 263/4024 0.235s 0.001s
im_detect: 264/4024 0.235s 0.001s
im_detect: 265/4024 0.235s 0.001s
im_detect: 266/4024 0.235s 0.001s
im_detect: 267/4024 0.235s 0.001s
im_detect: 268/4024 0.235s 0.001s
im_detect: 269/4024 0.235s 0.001s
im_detect: 270/4024 0.235s 0.001s
im_detect: 271/4024 0.235s 0.001s
im_detect: 272/4024 0.235s 0.001s
im_detect: 273/4024 0.235s 0.001s
im_detect: 274/4024 0.235s 0.001s
im_detect: 275/4024 0.235s 0.001s
im_detect: 276/4024 0.235s 0.001s
im_detect: 277/4024 0.235s 0.001s
im_detect: 278/4024 0.235s 0.001s
im_detect: 279/4024 0.235s 0.001s
im_detect: 280/4024 0.235s 0.001s
im_detect: 281/4024 0.235s 0.001s
im_detect: 282/4024 0.235s 0.001s
im_detect: 283/4024 0.234s 0.001s
im_detect: 284/4024 0.234s 0.001s
im_detect: 285/4024 0.234s 0.001s
im_detect: 286/4024 0.234s 0.001s
im_detect: 287/4024 0.234s 0.001s
im_detect: 288/4024 0.234s 0.001s
im_detect: 289/4024 0.234s 0.001s
im_detect: 290/4024 0.234s 0.001s
im_detect: 291/4024 0.234s 0.001s
im_detect: 292/4024 0.234s 0.001s
im_detect: 293/4024 0.234s 0.001s
im_detect: 294/4024 0.234s 0.001s
im_detect: 295/4024 0.234s 0.001s
im_detect: 296/4024 0.234s 0.001s
im_detect: 297/4024 0.234s 0.001s
im_detect: 298/4024 0.234s 0.001s
im_detect: 299/4024 0.234s 0.001s
im_detect: 300/4024 0.234s 0.001s
im_detect: 301/4024 0.233s 0.001s
im_detect: 302/4024 0.234s 0.001s
im_detect: 303/4024 0.233s 0.001s
im_detect: 304/4024 0.233s 0.001s
im_detect: 305/4024 0.233s 0.001s
im_detect: 306/4024 0.233s 0.001s
im_detect: 307/4024 0.233s 0.001s
im_detect: 308/4024 0.233s 0.001s
im_detect: 309/4024 0.233s 0.001s
im_detect: 310/4024 0.233s 0.001s
im_detect: 311/4024 0.233s 0.001s
im_detect: 312/4024 0.233s 0.001s
im_detect: 313/4024 0.233s 0.001s
im_detect: 314/4024 0.233s 0.001s
im_detect: 315/4024 0.233s 0.001s
im_detect: 316/4024 0.233s 0.001s
im_detect: 317/4024 0.233s 0.001s
im_detect: 318/4024 0.233s 0.001s
im_detect: 319/4024 0.233s 0.001s
im_detect: 320/4024 0.233s 0.001s
im_detect: 321/4024 0.233s 0.001s
im_detect: 322/4024 0.233s 0.001s
im_detect: 323/4024 0.233s 0.001s
im_detect: 324/4024 0.233s 0.001s
im_detect: 325/4024 0.233s 0.001s
im_detect: 326/4024 0.233s 0.001s
im_detect: 327/4024 0.233s 0.001s
im_detect: 328/4024 0.233s 0.001s
im_detect: 329/4024 0.233s 0.001s
im_detect: 330/4024 0.233s 0.001s
im_detect: 331/4024 0.233s 0.001s
im_detect: 332/4024 0.233s 0.001s
im_detect: 333/4024 0.233s 0.001s
im_detect: 334/4024 0.233s 0.001s
im_detect: 335/4024 0.233s 0.001s
im_detect: 336/4024 0.233s 0.001s
im_detect: 337/4024 0.233s 0.001s
im_detect: 338/4024 0.233s 0.001s
im_detect: 339/4024 0.232s 0.001s
im_detect: 340/4024 0.232s 0.001s
im_detect: 341/4024 0.232s 0.001s
im_detect: 342/4024 0.232s 0.001s
im_detect: 343/4024 0.232s 0.001s
im_detect: 344/4024 0.232s 0.001s
im_detect: 345/4024 0.232s 0.001s
im_detect: 346/4024 0.232s 0.001s
im_detect: 347/4024 0.232s 0.001s
im_detect: 348/4024 0.232s 0.001s
im_detect: 349/4024 0.232s 0.001s
im_detect: 350/4024 0.232s 0.001s
im_detect: 351/4024 0.232s 0.001s
im_detect: 352/4024 0.232s 0.001s
im_detect: 353/4024 0.232s 0.001s
im_detect: 354/4024 0.232s 0.001s
im_detect: 355/4024 0.232s 0.001s
im_detect: 356/4024 0.232s 0.001s
im_detect: 357/4024 0.232s 0.001s
im_detect: 358/4024 0.232s 0.001s
im_detect: 359/4024 0.232s 0.001s
im_detect: 360/4024 0.232s 0.001s
im_detect: 361/4024 0.232s 0.001s
im_detect: 362/4024 0.232s 0.001s
im_detect: 363/4024 0.232s 0.001s
im_detect: 364/4024 0.232s 0.001s
im_detect: 365/4024 0.232s 0.001s
im_detect: 366/4024 0.232s 0.001s
im_detect: 367/4024 0.232s 0.001s
im_detect: 368/4024 0.232s 0.001s
im_detect: 369/4024 0.232s 0.001s
im_detect: 370/4024 0.232s 0.001s
im_detect: 371/4024 0.232s 0.001s
im_detect: 372/4024 0.232s 0.001s
im_detect: 373/4024 0.232s 0.001s
im_detect: 374/4024 0.232s 0.001s
im_detect: 375/4024 0.232s 0.001s
im_detect: 376/4024 0.232s 0.001s
im_detect: 377/4024 0.232s 0.001s
im_detect: 378/4024 0.232s 0.001s
im_detect: 379/4024 0.232s 0.001s
im_detect: 380/4024 0.232s 0.001s
im_detect: 381/4024 0.232s 0.001s
im_detect: 382/4024 0.232s 0.001s
im_detect: 383/4024 0.232s 0.001s
im_detect: 384/4024 0.232s 0.001s
im_detect: 385/4024 0.232s 0.001s
im_detect: 386/4024 0.232s 0.001s
im_detect: 387/4024 0.232s 0.001s
im_detect: 388/4024 0.232s 0.001s
im_detect: 389/4024 0.232s 0.001s
im_detect: 390/4024 0.232s 0.001s
im_detect: 391/4024 0.232s 0.001s
im_detect: 392/4024 0.232s 0.001s
im_detect: 393/4024 0.232s 0.001s
im_detect: 394/4024 0.232s 0.001s
im_detect: 395/4024 0.232s 0.001s
im_detect: 396/4024 0.232s 0.001s
im_detect: 397/4024 0.232s 0.001s
im_detect: 398/4024 0.232s 0.001s
im_detect: 399/4024 0.232s 0.001s
im_detect: 400/4024 0.232s 0.001s
im_detect: 401/4024 0.232s 0.001s
im_detect: 402/4024 0.232s 0.001s
im_detect: 403/4024 0.232s 0.001s
im_detect: 404/4024 0.232s 0.001s
im_detect: 405/4024 0.232s 0.001s
im_detect: 406/4024 0.232s 0.001s
im_detect: 407/4024 0.232s 0.001s
im_detect: 408/4024 0.232s 0.001s
im_detect: 409/4024 0.232s 0.001s
im_detect: 410/4024 0.232s 0.001s
im_detect: 411/4024 0.232s 0.001s
im_detect: 412/4024 0.232s 0.001s
im_detect: 413/4024 0.232s 0.001s
im_detect: 414/4024 0.232s 0.001s
im_detect: 415/4024 0.232s 0.001s
im_detect: 416/4024 0.232s 0.001s
im_detect: 417/4024 0.232s 0.001s
im_detect: 418/4024 0.232s 0.001s
im_detect: 419/4024 0.232s 0.001s
im_detect: 420/4024 0.232s 0.001s
im_detect: 421/4024 0.232s 0.001s
im_detect: 422/4024 0.232s 0.001s
im_detect: 423/4024 0.232s 0.001s
im_detect: 424/4024 0.232s 0.001s
im_detect: 425/4024 0.232s 0.001s
im_detect: 426/4024 0.232s 0.001s
im_detect: 427/4024 0.232s 0.001s
im_detect: 428/4024 0.232s 0.001s
im_detect: 429/4024 0.232s 0.001s
im_detect: 430/4024 0.232s 0.001s
im_detect: 431/4024 0.232s 0.001s
im_detect: 432/4024 0.232s 0.001s
im_detect: 433/4024 0.232s 0.001s
im_detect: 434/4024 0.232s 0.001s
im_detect: 435/4024 0.232s 0.001s
im_detect: 436/4024 0.232s 0.001s
im_detect: 437/4024 0.232s 0.001s
im_detect: 438/4024 0.232s 0.001s
im_detect: 439/4024 0.232s 0.001s
im_detect: 440/4024 0.232s 0.001s
im_detect: 441/4024 0.232s 0.001s
im_detect: 442/4024 0.232s 0.001s
im_detect: 443/4024 0.232s 0.001s
im_detect: 444/4024 0.232s 0.001s
im_detect: 445/4024 0.232s 0.001s
im_detect: 446/4024 0.232s 0.001s
im_detect: 447/4024 0.232s 0.001s
im_detect: 448/4024 0.232s 0.001s
im_detect: 449/4024 0.232s 0.001s
im_detect: 450/4024 0.232s 0.001s
im_detect: 451/4024 0.232s 0.001s
im_detect: 452/4024 0.232s 0.001s
im_detect: 453/4024 0.232s 0.001s
im_detect: 454/4024 0.232s 0.001s
im_detect: 455/4024 0.232s 0.001s
im_detect: 456/4024 0.232s 0.001s
im_detect: 457/4024 0.232s 0.001s
im_detect: 458/4024 0.232s 0.001s
im_detect: 459/4024 0.232s 0.001s
im_detect: 460/4024 0.232s 0.001s
im_detect: 461/4024 0.232s 0.001s
im_detect: 462/4024 0.232s 0.001s
im_detect: 463/4024 0.232s 0.001s
im_detect: 464/4024 0.232s 0.001s
im_detect: 465/4024 0.232s 0.001s
im_detect: 466/4024 0.232s 0.001s
im_detect: 467/4024 0.232s 0.001s
im_detect: 468/4024 0.232s 0.001s
im_detect: 469/4024 0.232s 0.001s
im_detect: 470/4024 0.232s 0.001s
im_detect: 471/4024 0.232s 0.001s
im_detect: 472/4024 0.232s 0.001s
im_detect: 473/4024 0.232s 0.001s
im_detect: 474/4024 0.232s 0.001s
im_detect: 475/4024 0.232s 0.001s
im_detect: 476/4024 0.232s 0.001s
im_detect: 477/4024 0.232s 0.001s
im_detect: 478/4024 0.232s 0.001s
im_detect: 479/4024 0.232s 0.001s
im_detect: 480/4024 0.232s 0.001s
im_detect: 481/4024 0.232s 0.001s
im_detect: 482/4024 0.232s 0.001s
im_detect: 483/4024 0.232s 0.001s
im_detect: 484/4024 0.232s 0.001s
im_detect: 485/4024 0.232s 0.001s
im_detect: 486/4024 0.232s 0.001s
im_detect: 487/4024 0.232s 0.001s
im_detect: 488/4024 0.232s 0.001s
im_detect: 489/4024 0.232s 0.001s
im_detect: 490/4024 0.232s 0.001s
im_detect: 491/4024 0.232s 0.001s
im_detect: 492/4024 0.232s 0.001s
im_detect: 493/4024 0.232s 0.001s
im_detect: 494/4024 0.232s 0.001s
im_detect: 495/4024 0.232s 0.001s
im_detect: 496/4024 0.232s 0.001s
im_detect: 497/4024 0.232s 0.001s
im_detect: 498/4024 0.232s 0.001s
im_detect: 499/4024 0.232s 0.001s
im_detect: 500/4024 0.232s 0.001s
im_detect: 501/4024 0.232s 0.001s
im_detect: 502/4024 0.232s 0.001s
im_detect: 503/4024 0.232s 0.001s
im_detect: 504/4024 0.232s 0.001s
im_detect: 505/4024 0.232s 0.001s
im_detect: 506/4024 0.232s 0.001s
im_detect: 507/4024 0.232s 0.001s
im_detect: 508/4024 0.232s 0.001s
im_detect: 509/4024 0.232s 0.001s
im_detect: 510/4024 0.232s 0.001s
im_detect: 511/4024 0.232s 0.001s
im_detect: 512/4024 0.232s 0.001s
im_detect: 513/4024 0.232s 0.001s
im_detect: 514/4024 0.232s 0.001s
im_detect: 515/4024 0.232s 0.001s
im_detect: 516/4024 0.232s 0.001s
im_detect: 517/4024 0.232s 0.001s
im_detect: 518/4024 0.232s 0.001s
im_detect: 519/4024 0.232s 0.001s
im_detect: 520/4024 0.232s 0.001s
im_detect: 521/4024 0.232s 0.001s
im_detect: 522/4024 0.232s 0.001s
im_detect: 523/4024 0.232s 0.001s
im_detect: 524/4024 0.232s 0.001s
im_detect: 525/4024 0.232s 0.001s
im_detect: 526/4024 0.232s 0.001s
im_detect: 527/4024 0.232s 0.001s
im_detect: 528/4024 0.232s 0.001s
im_detect: 529/4024 0.232s 0.001s
im_detect: 530/4024 0.232s 0.001s
im_detect: 531/4024 0.232s 0.001s
im_detect: 532/4024 0.232s 0.001s
im_detect: 533/4024 0.232s 0.001s
im_detect: 534/4024 0.232s 0.001s
im_detect: 535/4024 0.232s 0.001s
im_detect: 536/4024 0.232s 0.001s
im_detect: 537/4024 0.232s 0.001s
im_detect: 538/4024 0.232s 0.001s
im_detect: 539/4024 0.232s 0.001s
im_detect: 540/4024 0.232s 0.001s
im_detect: 541/4024 0.232s 0.001s
im_detect: 542/4024 0.232s 0.001s
im_detect: 543/4024 0.232s 0.001s
im_detect: 544/4024 0.232s 0.001s
im_detect: 545/4024 0.232s 0.001s
im_detect: 546/4024 0.232s 0.001s
im_detect: 547/4024 0.232s 0.001s
im_detect: 548/4024 0.232s 0.001s
im_detect: 549/4024 0.232s 0.001s
im_detect: 550/4024 0.232s 0.001s
im_detect: 551/4024 0.232s 0.001s
im_detect: 552/4024 0.232s 0.001s
im_detect: 553/4024 0.232s 0.001s
im_detect: 554/4024 0.232s 0.001s
im_detect: 555/4024 0.232s 0.001s
im_detect: 556/4024 0.232s 0.001s
im_detect: 557/4024 0.232s 0.001s
im_detect: 558/4024 0.232s 0.001s
im_detect: 559/4024 0.232s 0.001s
im_detect: 560/4024 0.232s 0.001s
im_detect: 561/4024 0.232s 0.001s
im_detect: 562/4024 0.232s 0.001s
im_detect: 563/4024 0.232s 0.001s
im_detect: 564/4024 0.232s 0.001s
im_detect: 565/4024 0.232s 0.001s
im_detect: 566/4024 0.232s 0.001s
im_detect: 567/4024 0.232s 0.001s
im_detect: 568/4024 0.232s 0.001s
im_detect: 569/4024 0.232s 0.001s
im_detect: 570/4024 0.232s 0.001s
im_detect: 571/4024 0.232s 0.001s
im_detect: 572/4024 0.232s 0.001s
im_detect: 573/4024 0.232s 0.001s
im_detect: 574/4024 0.232s 0.001s
im_detect: 575/4024 0.232s 0.001s
im_detect: 576/4024 0.232s 0.001s
im_detect: 577/4024 0.232s 0.001s
im_detect: 578/4024 0.232s 0.001s
im_detect: 579/4024 0.232s 0.001s
im_detect: 580/4024 0.232s 0.001s
im_detect: 581/4024 0.232s 0.001s
im_detect: 582/4024 0.232s 0.001s
im_detect: 583/4024 0.232s 0.001s
im_detect: 584/4024 0.232s 0.001s
im_detect: 585/4024 0.232s 0.001s
im_detect: 586/4024 0.232s 0.001s
im_detect: 587/4024 0.232s 0.001s
im_detect: 588/4024 0.232s 0.001s
im_detect: 589/4024 0.232s 0.001s
im_detect: 590/4024 0.232s 0.001s
im_detect: 591/4024 0.232s 0.001s
im_detect: 592/4024 0.232s 0.001s
im_detect: 593/4024 0.232s 0.001s
im_detect: 594/4024 0.232s 0.001s
im_detect: 595/4024 0.232s 0.001s
im_detect: 596/4024 0.232s 0.001s
im_detect: 597/4024 0.232s 0.001s
im_detect: 598/4024 0.232s 0.001s
im_detect: 599/4024 0.232s 0.001s
im_detect: 600/4024 0.232s 0.001s
im_detect: 601/4024 0.232s 0.001s
im_detect: 602/4024 0.232s 0.001s
im_detect: 603/4024 0.232s 0.001s
im_detect: 604/4024 0.232s 0.001s
im_detect: 605/4024 0.232s 0.001s
im_detect: 606/4024 0.232s 0.001s
im_detect: 607/4024 0.232s 0.001s
im_detect: 608/4024 0.232s 0.001s
im_detect: 609/4024 0.232s 0.001s
im_detect: 610/4024 0.232s 0.001s
im_detect: 611/4024 0.232s 0.001s
im_detect: 612/4024 0.232s 0.001s
im_detect: 613/4024 0.232s 0.001s
im_detect: 614/4024 0.232s 0.001s
im_detect: 615/4024 0.232s 0.001s
im_detect: 616/4024 0.232s 0.001s
im_detect: 617/4024 0.232s 0.001s
im_detect: 618/4024 0.232s 0.001s
im_detect: 619/4024 0.232s 0.001s
im_detect: 620/4024 0.232s 0.001s
im_detect: 621/4024 0.232s 0.001s
im_detect: 622/4024 0.232s 0.001s
im_detect: 623/4024 0.232s 0.001s
im_detect: 624/4024 0.232s 0.001s
im_detect: 625/4024 0.232s 0.001s
im_detect: 626/4024 0.232s 0.001s
im_detect: 627/4024 0.232s 0.001s
im_detect: 628/4024 0.232s 0.001s
im_detect: 629/4024 0.232s 0.001s
im_detect: 630/4024 0.232s 0.001s
im_detect: 631/4024 0.232s 0.001s
im_detect: 632/4024 0.232s 0.001s
im_detect: 633/4024 0.232s 0.001s
im_detect: 634/4024 0.232s 0.001s
im_detect: 635/4024 0.232s 0.001s
im_detect: 636/4024 0.232s 0.001s
im_detect: 637/4024 0.232s 0.001s
im_detect: 638/4024 0.232s 0.001s
im_detect: 639/4024 0.232s 0.001s
im_detect: 640/4024 0.232s 0.001s
im_detect: 641/4024 0.232s 0.001s
im_detect: 642/4024 0.232s 0.001s
im_detect: 643/4024 0.232s 0.001s
im_detect: 644/4024 0.232s 0.001s
im_detect: 645/4024 0.232s 0.001s
im_detect: 646/4024 0.232s 0.001s
im_detect: 647/4024 0.232s 0.001s
im_detect: 648/4024 0.232s 0.001s
im_detect: 649/4024 0.232s 0.001s
im_detect: 650/4024 0.232s 0.001s
im_detect: 651/4024 0.232s 0.001s
im_detect: 652/4024 0.232s 0.001s
im_detect: 653/4024 0.232s 0.001s
im_detect: 654/4024 0.232s 0.001s
im_detect: 655/4024 0.232s 0.001s
im_detect: 656/4024 0.232s 0.001s
im_detect: 657/4024 0.232s 0.001s
im_detect: 658/4024 0.232s 0.001s
im_detect: 659/4024 0.232s 0.001s
im_detect: 660/4024 0.232s 0.001s
im_detect: 661/4024 0.232s 0.001s
im_detect: 662/4024 0.232s 0.001s
im_detect: 663/4024 0.232s 0.001s
im_detect: 664/4024 0.232s 0.001s
im_detect: 665/4024 0.232s 0.001s
im_detect: 666/4024 0.232s 0.001s
im_detect: 667/4024 0.232s 0.001s
im_detect: 668/4024 0.232s 0.001s
im_detect: 669/4024 0.232s 0.001s
im_detect: 670/4024 0.232s 0.001s
im_detect: 671/4024 0.232s 0.001s
im_detect: 672/4024 0.232s 0.001s
im_detect: 673/4024 0.232s 0.001s
im_detect: 674/4024 0.232s 0.001s
im_detect: 675/4024 0.232s 0.001s
im_detect: 676/4024 0.232s 0.001s
im_detect: 677/4024 0.232s 0.001s
im_detect: 678/4024 0.232s 0.001s
im_detect: 679/4024 0.232s 0.001s
im_detect: 680/4024 0.232s 0.001s
im_detect: 681/4024 0.232s 0.001s
im_detect: 682/4024 0.232s 0.001s
im_detect: 683/4024 0.232s 0.001s
im_detect: 684/4024 0.232s 0.001s
im_detect: 685/4024 0.232s 0.001s
im_detect: 686/4024 0.232s 0.001s
im_detect: 687/4024 0.232s 0.001s
im_detect: 688/4024 0.232s 0.001s
im_detect: 689/4024 0.232s 0.001s
im_detect: 690/4024 0.232s 0.001s
im_detect: 691/4024 0.232s 0.001s
im_detect: 692/4024 0.232s 0.001s
im_detect: 693/4024 0.232s 0.001s
im_detect: 694/4024 0.232s 0.001s
im_detect: 695/4024 0.232s 0.001s
im_detect: 696/4024 0.232s 0.001s
im_detect: 697/4024 0.232s 0.001s
im_detect: 698/4024 0.232s 0.001s
im_detect: 699/4024 0.232s 0.001s
im_detect: 700/4024 0.232s 0.001s
im_detect: 701/4024 0.232s 0.001s
im_detect: 702/4024 0.232s 0.001s
im_detect: 703/4024 0.232s 0.001s
im_detect: 704/4024 0.232s 0.001s
im_detect: 705/4024 0.232s 0.001s
im_detect: 706/4024 0.232s 0.001s
im_detect: 707/4024 0.232s 0.001s
im_detect: 708/4024 0.232s 0.001s
im_detect: 709/4024 0.232s 0.001s
im_detect: 710/4024 0.232s 0.001s
im_detect: 711/4024 0.232s 0.001s
im_detect: 712/4024 0.232s 0.001s
im_detect: 713/4024 0.232s 0.001s
im_detect: 714/4024 0.232s 0.001s
im_detect: 715/4024 0.232s 0.001s
im_detect: 716/4024 0.232s 0.001s
im_detect: 717/4024 0.232s 0.001s
im_detect: 718/4024 0.232s 0.001s
im_detect: 719/4024 0.232s 0.001s
im_detect: 720/4024 0.232s 0.001s
im_detect: 721/4024 0.232s 0.001s
im_detect: 722/4024 0.232s 0.001s
im_detect: 723/4024 0.232s 0.001s
im_detect: 724/4024 0.232s 0.001s
im_detect: 725/4024 0.232s 0.001s
im_detect: 726/4024 0.232s 0.001s
im_detect: 727/4024 0.232s 0.001s
im_detect: 728/4024 0.232s 0.001s
im_detect: 729/4024 0.232s 0.001s
im_detect: 730/4024 0.232s 0.001s
im_detect: 731/4024 0.232s 0.001s
im_detect: 732/4024 0.232s 0.001s
im_detect: 733/4024 0.232s 0.001s
im_detect: 734/4024 0.232s 0.001s
im_detect: 735/4024 0.232s 0.001s
im_detect: 736/4024 0.232s 0.001s
im_detect: 737/4024 0.232s 0.001s
im_detect: 738/4024 0.232s 0.001s
im_detect: 739/4024 0.232s 0.001s
im_detect: 740/4024 0.232s 0.001s
im_detect: 741/4024 0.232s 0.001s
im_detect: 742/4024 0.232s 0.001s
im_detect: 743/4024 0.232s 0.001s
im_detect: 744/4024 0.232s 0.001s
im_detect: 745/4024 0.232s 0.001s
im_detect: 746/4024 0.232s 0.001s
im_detect: 747/4024 0.232s 0.001s
im_detect: 748/4024 0.232s 0.001s
im_detect: 749/4024 0.232s 0.001s
im_detect: 750/4024 0.232s 0.001s
im_detect: 751/4024 0.232s 0.001s
im_detect: 752/4024 0.232s 0.001s
im_detect: 753/4024 0.232s 0.001s
im_detect: 754/4024 0.232s 0.001s
im_detect: 755/4024 0.232s 0.001s
im_detect: 756/4024 0.232s 0.001s
im_detect: 757/4024 0.232s 0.001s
im_detect: 758/4024 0.232s 0.001s
im_detect: 759/4024 0.232s 0.001s
im_detect: 760/4024 0.232s 0.001s
im_detect: 761/4024 0.232s 0.001s
im_detect: 762/4024 0.232s 0.001s
im_detect: 763/4024 0.232s 0.001s
im_detect: 764/4024 0.232s 0.001s
im_detect: 765/4024 0.232s 0.001s
im_detect: 766/4024 0.232s 0.001s
im_detect: 767/4024 0.231s 0.001s
im_detect: 768/4024 0.231s 0.001s
im_detect: 769/4024 0.231s 0.001s
im_detect: 770/4024 0.231s 0.001s
im_detect: 771/4024 0.231s 0.001s
im_detect: 772/4024 0.231s 0.001s
im_detect: 773/4024 0.231s 0.001s
im_detect: 774/4024 0.232s 0.001s
im_detect: 775/4024 0.232s 0.001s
im_detect: 776/4024 0.232s 0.001s
im_detect: 777/4024 0.232s 0.001s
im_detect: 778/4024 0.232s 0.001s
im_detect: 779/4024 0.232s 0.001s
im_detect: 780/4024 0.232s 0.001s
im_detect: 781/4024 0.232s 0.001s
im_detect: 782/4024 0.232s 0.001s
im_detect: 783/4024 0.231s 0.001s
im_detect: 784/4024 0.231s 0.001s
im_detect: 785/4024 0.231s 0.001s
im_detect: 786/4024 0.231s 0.001s
im_detect: 787/4024 0.231s 0.001s
im_detect: 788/4024 0.231s 0.001s
im_detect: 789/4024 0.231s 0.001s
im_detect: 790/4024 0.231s 0.001s
im_detect: 791/4024 0.231s 0.001s
im_detect: 792/4024 0.231s 0.001s
im_detect: 793/4024 0.231s 0.001s
im_detect: 794/4024 0.231s 0.001s
im_detect: 795/4024 0.231s 0.001s
im_detect: 796/4024 0.231s 0.001s
im_detect: 797/4024 0.231s 0.001s
im_detect: 798/4024 0.231s 0.001s
im_detect: 799/4024 0.231s 0.001s
im_detect: 800/4024 0.231s 0.001s
im_detect: 801/4024 0.231s 0.001s
im_detect: 802/4024 0.231s 0.001s
im_detect: 803/4024 0.231s 0.001s
im_detect: 804/4024 0.231s 0.001s
im_detect: 805/4024 0.231s 0.001s
im_detect: 806/4024 0.231s 0.001s
im_detect: 807/4024 0.231s 0.001s
im_detect: 808/4024 0.231s 0.001s
im_detect: 809/4024 0.231s 0.001s
im_detect: 810/4024 0.231s 0.001s
im_detect: 811/4024 0.231s 0.001s
im_detect: 812/4024 0.231s 0.001s
im_detect: 813/4024 0.231s 0.001s
im_detect: 814/4024 0.231s 0.001s
im_detect: 815/4024 0.231s 0.001s
im_detect: 816/4024 0.231s 0.001s
im_detect: 817/4024 0.231s 0.001s
im_detect: 818/4024 0.231s 0.001s
im_detect: 819/4024 0.231s 0.001s
im_detect: 820/4024 0.231s 0.001s
im_detect: 821/4024 0.231s 0.001s
im_detect: 822/4024 0.231s 0.001s
im_detect: 823/4024 0.231s 0.001s
im_detect: 824/4024 0.231s 0.001s
im_detect: 825/4024 0.231s 0.001s
im_detect: 826/4024 0.231s 0.001s
im_detect: 827/4024 0.231s 0.001s
im_detect: 828/4024 0.231s 0.001s
im_detect: 829/4024 0.231s 0.001s
im_detect: 830/4024 0.231s 0.001s
im_detect: 831/4024 0.231s 0.001s
im_detect: 832/4024 0.231s 0.001s
im_detect: 833/4024 0.231s 0.001s
im_detect: 834/4024 0.231s 0.001s
im_detect: 835/4024 0.231s 0.001s
im_detect: 836/4024 0.231s 0.001s
im_detect: 837/4024 0.231s 0.001s
im_detect: 838/4024 0.231s 0.001s
im_detect: 839/4024 0.231s 0.001s
im_detect: 840/4024 0.231s 0.001s
im_detect: 841/4024 0.231s 0.001s
im_detect: 842/4024 0.231s 0.001s
im_detect: 843/4024 0.231s 0.001s
im_detect: 844/4024 0.231s 0.001s
im_detect: 845/4024 0.231s 0.001s
im_detect: 846/4024 0.231s 0.001s
im_detect: 847/4024 0.231s 0.001s
im_detect: 848/4024 0.231s 0.001s
im_detect: 849/4024 0.231s 0.001s
im_detect: 850/4024 0.231s 0.001s
im_detect: 851/4024 0.231s 0.001s
im_detect: 852/4024 0.231s 0.001s
im_detect: 853/4024 0.231s 0.001s
im_detect: 854/4024 0.231s 0.001s
im_detect: 855/4024 0.231s 0.001s
im_detect: 856/4024 0.231s 0.001s
im_detect: 857/4024 0.231s 0.001s
im_detect: 858/4024 0.231s 0.001s
im_detect: 859/4024 0.231s 0.001s
im_detect: 860/4024 0.231s 0.001s
im_detect: 861/4024 0.231s 0.001s
im_detect: 862/4024 0.231s 0.001s
im_detect: 863/4024 0.231s 0.001s
im_detect: 864/4024 0.231s 0.001s
im_detect: 865/4024 0.231s 0.001s
im_detect: 866/4024 0.231s 0.001s
im_detect: 867/4024 0.231s 0.001s
im_detect: 868/4024 0.231s 0.001s
im_detect: 869/4024 0.231s 0.001s
im_detect: 870/4024 0.231s 0.001s
im_detect: 871/4024 0.231s 0.001s
im_detect: 872/4024 0.231s 0.001s
im_detect: 873/4024 0.231s 0.001s
im_detect: 874/4024 0.231s 0.001s
im_detect: 875/4024 0.231s 0.001s
im_detect: 876/4024 0.231s 0.001s
im_detect: 877/4024 0.231s 0.001s
im_detect: 878/4024 0.231s 0.001s
im_detect: 879/4024 0.231s 0.001s
im_detect: 880/4024 0.231s 0.001s
im_detect: 881/4024 0.231s 0.001s
im_detect: 882/4024 0.231s 0.001s
im_detect: 883/4024 0.231s 0.001s
im_detect: 884/4024 0.231s 0.001s
im_detect: 885/4024 0.231s 0.001s
im_detect: 886/4024 0.231s 0.001s
im_detect: 887/4024 0.231s 0.001s
im_detect: 888/4024 0.231s 0.001s
im_detect: 889/4024 0.231s 0.001s
im_detect: 890/4024 0.231s 0.001s
im_detect: 891/4024 0.231s 0.001s
im_detect: 892/4024 0.231s 0.001s
im_detect: 893/4024 0.231s 0.001s
im_detect: 894/4024 0.231s 0.001s
im_detect: 895/4024 0.231s 0.001s
im_detect: 896/4024 0.231s 0.001s
im_detect: 897/4024 0.231s 0.001s
im_detect: 898/4024 0.231s 0.001s
im_detect: 899/4024 0.231s 0.001s
im_detect: 900/4024 0.231s 0.001s
im_detect: 901/4024 0.231s 0.001s
im_detect: 902/4024 0.231s 0.001s
im_detect: 903/4024 0.231s 0.001s
im_detect: 904/4024 0.231s 0.001s
im_detect: 905/4024 0.231s 0.001s
im_detect: 906/4024 0.231s 0.001s
im_detect: 907/4024 0.231s 0.001s
im_detect: 908/4024 0.231s 0.001s
im_detect: 909/4024 0.231s 0.001s
im_detect: 910/4024 0.231s 0.001s
im_detect: 911/4024 0.231s 0.001s
im_detect: 912/4024 0.231s 0.001s
im_detect: 913/4024 0.231s 0.001s
im_detect: 914/4024 0.231s 0.001s
im_detect: 915/4024 0.231s 0.001s
im_detect: 916/4024 0.231s 0.001s
im_detect: 917/4024 0.231s 0.001s
im_detect: 918/4024 0.231s 0.001s
im_detect: 919/4024 0.231s 0.001s
im_detect: 920/4024 0.231s 0.001s
im_detect: 921/4024 0.231s 0.001s
im_detect: 922/4024 0.231s 0.001s
im_detect: 923/4024 0.231s 0.001s
im_detect: 924/4024 0.231s 0.001s
im_detect: 925/4024 0.231s 0.001s
im_detect: 926/4024 0.231s 0.001s
im_detect: 927/4024 0.231s 0.001s
im_detect: 928/4024 0.231s 0.001s
im_detect: 929/4024 0.231s 0.001s
im_detect: 930/4024 0.231s 0.001s
im_detect: 931/4024 0.231s 0.001s
im_detect: 932/4024 0.231s 0.001s
im_detect: 933/4024 0.231s 0.001s
im_detect: 934/4024 0.231s 0.001s
im_detect: 935/4024 0.231s 0.001s
im_detect: 936/4024 0.231s 0.001s
im_detect: 937/4024 0.231s 0.001s
im_detect: 938/4024 0.231s 0.001s
im_detect: 939/4024 0.231s 0.001s
im_detect: 940/4024 0.231s 0.001s
im_detect: 941/4024 0.231s 0.001s
im_detect: 942/4024 0.231s 0.001s
im_detect: 943/4024 0.231s 0.001s
im_detect: 944/4024 0.231s 0.001s
im_detect: 945/4024 0.231s 0.001s
im_detect: 946/4024 0.231s 0.001s
im_detect: 947/4024 0.231s 0.001s
im_detect: 948/4024 0.231s 0.001s
im_detect: 949/4024 0.231s 0.001s
im_detect: 950/4024 0.231s 0.001s
im_detect: 951/4024 0.231s 0.001s
im_detect: 952/4024 0.231s 0.001s
im_detect: 953/4024 0.231s 0.001s
im_detect: 954/4024 0.231s 0.001s
im_detect: 955/4024 0.231s 0.001s
im_detect: 956/4024 0.231s 0.001s
im_detect: 957/4024 0.231s 0.001s
im_detect: 958/4024 0.231s 0.001s
im_detect: 959/4024 0.231s 0.001s
im_detect: 960/4024 0.231s 0.001s
im_detect: 961/4024 0.231s 0.001s
im_detect: 962/4024 0.231s 0.001s
im_detect: 963/4024 0.231s 0.001s
im_detect: 964/4024 0.231s 0.001s
im_detect: 965/4024 0.231s 0.001s
im_detect: 966/4024 0.231s 0.001s
im_detect: 967/4024 0.231s 0.001s
im_detect: 968/4024 0.231s 0.001s
im_detect: 969/4024 0.231s 0.001s
im_detect: 970/4024 0.231s 0.001s
im_detect: 971/4024 0.231s 0.001s
im_detect: 972/4024 0.231s 0.001s
im_detect: 973/4024 0.231s 0.001s
im_detect: 974/4024 0.231s 0.001s
im_detect: 975/4024 0.231s 0.001s
im_detect: 976/4024 0.231s 0.001s
im_detect: 977/4024 0.231s 0.001s
im_detect: 978/4024 0.231s 0.001s
im_detect: 979/4024 0.231s 0.001s
im_detect: 980/4024 0.231s 0.001s
im_detect: 981/4024 0.231s 0.001s
im_detect: 982/4024 0.231s 0.001s
im_detect: 983/4024 0.231s 0.001s
im_detect: 984/4024 0.231s 0.001s
im_detect: 985/4024 0.231s 0.001s
im_detect: 986/4024 0.231s 0.001s
im_detect: 987/4024 0.231s 0.001s
im_detect: 988/4024 0.231s 0.001s
im_detect: 989/4024 0.231s 0.001s
im_detect: 990/4024 0.231s 0.001s
im_detect: 991/4024 0.231s 0.001s
im_detect: 992/4024 0.231s 0.001s
im_detect: 993/4024 0.231s 0.001s
im_detect: 994/4024 0.231s 0.001s
im_detect: 995/4024 0.231s 0.001s
im_detect: 996/4024 0.231s 0.001s
im_detect: 997/4024 0.231s 0.001s
im_detect: 998/4024 0.231s 0.001s
im_detect: 999/4024 0.231s 0.001s
im_detect: 1000/4024 0.231s 0.001s
im_detect: 1001/4024 0.231s 0.001s
im_detect: 1002/4024 0.231s 0.001s
im_detect: 1003/4024 0.231s 0.001s
im_detect: 1004/4024 0.231s 0.001s
im_detect: 1005/4024 0.231s 0.001s
im_detect: 1006/4024 0.231s 0.001s
im_detect: 1007/4024 0.231s 0.001s
im_detect: 1008/4024 0.231s 0.001s
im_detect: 1009/4024 0.231s 0.001s
im_detect: 1010/4024 0.231s 0.001s
im_detect: 1011/4024 0.231s 0.001s
im_detect: 1012/4024 0.231s 0.001s
im_detect: 1013/4024 0.231s 0.001s
im_detect: 1014/4024 0.231s 0.001s
im_detect: 1015/4024 0.231s 0.001s
im_detect: 1016/4024 0.231s 0.001s
im_detect: 1017/4024 0.231s 0.001s
im_detect: 1018/4024 0.231s 0.001s
im_detect: 1019/4024 0.231s 0.001s
im_detect: 1020/4024 0.231s 0.001s
im_detect: 1021/4024 0.231s 0.001s
im_detect: 1022/4024 0.231s 0.001s
im_detect: 1023/4024 0.231s 0.001s
im_detect: 1024/4024 0.231s 0.001s
im_detect: 1025/4024 0.231s 0.001s
im_detect: 1026/4024 0.231s 0.001s
im_detect: 1027/4024 0.231s 0.001s
im_detect: 1028/4024 0.231s 0.001s
im_detect: 1029/4024 0.231s 0.001s
im_detect: 1030/4024 0.231s 0.001s
im_detect: 1031/4024 0.231s 0.001s
im_detect: 1032/4024 0.231s 0.001s
im_detect: 1033/4024 0.231s 0.001s
im_detect: 1034/4024 0.231s 0.001s
im_detect: 1035/4024 0.231s 0.001s
im_detect: 1036/4024 0.231s 0.001s
im_detect: 1037/4024 0.231s 0.001s
im_detect: 1038/4024 0.231s 0.001s
im_detect: 1039/4024 0.231s 0.001s
im_detect: 1040/4024 0.231s 0.001s
im_detect: 1041/4024 0.231s 0.001s
im_detect: 1042/4024 0.231s 0.001s
im_detect: 1043/4024 0.231s 0.001s
im_detect: 1044/4024 0.231s 0.001s
im_detect: 1045/4024 0.231s 0.001s
im_detect: 1046/4024 0.231s 0.001s
im_detect: 1047/4024 0.231s 0.001s
im_detect: 1048/4024 0.231s 0.001s
im_detect: 1049/4024 0.231s 0.001s
im_detect: 1050/4024 0.231s 0.001s
im_detect: 1051/4024 0.231s 0.001s
im_detect: 1052/4024 0.231s 0.001s
im_detect: 1053/4024 0.231s 0.001s
im_detect: 1054/4024 0.231s 0.001s
im_detect: 1055/4024 0.231s 0.001s
im_detect: 1056/4024 0.231s 0.001s
im_detect: 1057/4024 0.231s 0.001s
im_detect: 1058/4024 0.231s 0.001s
im_detect: 1059/4024 0.231s 0.001s
im_detect: 1060/4024 0.231s 0.001s
im_detect: 1061/4024 0.231s 0.001s
im_detect: 1062/4024 0.231s 0.001s
im_detect: 1063/4024 0.231s 0.001s
im_detect: 1064/4024 0.231s 0.001s
im_detect: 1065/4024 0.231s 0.001s
im_detect: 1066/4024 0.231s 0.001s
im_detect: 1067/4024 0.231s 0.001s
im_detect: 1068/4024 0.231s 0.001s
im_detect: 1069/4024 0.231s 0.001s
im_detect: 1070/4024 0.231s 0.001s
im_detect: 1071/4024 0.231s 0.001s
im_detect: 1072/4024 0.231s 0.001s
im_detect: 1073/4024 0.231s 0.001s
im_detect: 1074/4024 0.231s 0.001s
im_detect: 1075/4024 0.231s 0.001s
im_detect: 1076/4024 0.231s 0.001s
im_detect: 1077/4024 0.231s 0.001s
im_detect: 1078/4024 0.231s 0.001s
im_detect: 1079/4024 0.231s 0.001s
im_detect: 1080/4024 0.231s 0.001s
im_detect: 1081/4024 0.231s 0.001s
im_detect: 1082/4024 0.231s 0.001s
im_detect: 1083/4024 0.231s 0.001s
im_detect: 1084/4024 0.231s 0.001s
im_detect: 1085/4024 0.231s 0.001s
im_detect: 1086/4024 0.231s 0.001s
im_detect: 1087/4024 0.231s 0.001s
im_detect: 1088/4024 0.231s 0.001s
im_detect: 1089/4024 0.231s 0.001s
im_detect: 1090/4024 0.231s 0.001s
im_detect: 1091/4024 0.231s 0.001s
im_detect: 1092/4024 0.231s 0.001s
im_detect: 1093/4024 0.231s 0.001s
im_detect: 1094/4024 0.231s 0.001s
im_detect: 1095/4024 0.231s 0.001s
im_detect: 1096/4024 0.231s 0.001s
im_detect: 1097/4024 0.231s 0.001s
im_detect: 1098/4024 0.231s 0.001s
im_detect: 1099/4024 0.231s 0.001s
im_detect: 1100/4024 0.231s 0.001s
im_detect: 1101/4024 0.231s 0.001s
im_detect: 1102/4024 0.231s 0.001s
im_detect: 1103/4024 0.231s 0.001s
im_detect: 1104/4024 0.231s 0.001s
im_detect: 1105/4024 0.231s 0.001s
im_detect: 1106/4024 0.231s 0.001s
im_detect: 1107/4024 0.231s 0.001s
im_detect: 1108/4024 0.231s 0.001s
im_detect: 1109/4024 0.231s 0.001s
im_detect: 1110/4024 0.231s 0.001s
im_detect: 1111/4024 0.231s 0.001s
im_detect: 1112/4024 0.231s 0.001s
im_detect: 1113/4024 0.231s 0.001s
im_detect: 1114/4024 0.231s 0.001s
im_detect: 1115/4024 0.231s 0.001s
im_detect: 1116/4024 0.231s 0.001s
im_detect: 1117/4024 0.231s 0.001s
im_detect: 1118/4024 0.231s 0.001s
im_detect: 1119/4024 0.231s 0.001s
im_detect: 1120/4024 0.231s 0.001s
im_detect: 1121/4024 0.231s 0.001s
im_detect: 1122/4024 0.231s 0.001s
im_detect: 1123/4024 0.231s 0.001s
im_detect: 1124/4024 0.231s 0.001s
im_detect: 1125/4024 0.231s 0.001s
im_detect: 1126/4024 0.231s 0.001s
im_detect: 1127/4024 0.231s 0.001s
im_detect: 1128/4024 0.231s 0.001s
im_detect: 1129/4024 0.231s 0.001s
im_detect: 1130/4024 0.231s 0.001s
im_detect: 1131/4024 0.231s 0.001s
im_detect: 1132/4024 0.231s 0.001s
im_detect: 1133/4024 0.231s 0.001s
im_detect: 1134/4024 0.231s 0.001s
im_detect: 1135/4024 0.231s 0.001s
im_detect: 1136/4024 0.231s 0.001s
im_detect: 1137/4024 0.231s 0.001s
im_detect: 1138/4024 0.231s 0.001s
im_detect: 1139/4024 0.231s 0.001s
im_detect: 1140/4024 0.231s 0.001s
im_detect: 1141/4024 0.231s 0.001s
im_detect: 1142/4024 0.231s 0.001s
im_detect: 1143/4024 0.231s 0.001s
im_detect: 1144/4024 0.231s 0.001s
im_detect: 1145/4024 0.231s 0.001s
im_detect: 1146/4024 0.231s 0.001s
im_detect: 1147/4024 0.231s 0.001s
im_detect: 1148/4024 0.231s 0.001s
im_detect: 1149/4024 0.231s 0.001s
im_detect: 1150/4024 0.231s 0.001s
im_detect: 1151/4024 0.231s 0.001s
im_detect: 1152/4024 0.231s 0.001s
im_detect: 1153/4024 0.231s 0.001s
im_detect: 1154/4024 0.231s 0.001s
im_detect: 1155/4024 0.231s 0.001s
im_detect: 1156/4024 0.231s 0.001s
im_detect: 1157/4024 0.231s 0.001s
im_detect: 1158/4024 0.231s 0.001s
im_detect: 1159/4024 0.231s 0.001s
im_detect: 1160/4024 0.231s 0.001s
im_detect: 1161/4024 0.231s 0.001s
im_detect: 1162/4024 0.231s 0.001s
im_detect: 1163/4024 0.231s 0.001s
im_detect: 1164/4024 0.231s 0.001s
im_detect: 1165/4024 0.231s 0.001s
im_detect: 1166/4024 0.231s 0.001s
im_detect: 1167/4024 0.231s 0.001s
im_detect: 1168/4024 0.231s 0.001s
im_detect: 1169/4024 0.231s 0.001s
im_detect: 1170/4024 0.231s 0.001s
im_detect: 1171/4024 0.231s 0.001s
im_detect: 1172/4024 0.231s 0.001s
im_detect: 1173/4024 0.231s 0.001s
im_detect: 1174/4024 0.231s 0.001s
im_detect: 1175/4024 0.231s 0.001s
im_detect: 1176/4024 0.231s 0.001s
im_detect: 1177/4024 0.231s 0.001s
im_detect: 1178/4024 0.231s 0.001s
im_detect: 1179/4024 0.231s 0.001s
im_detect: 1180/4024 0.231s 0.001s
im_detect: 1181/4024 0.231s 0.001s
im_detect: 1182/4024 0.231s 0.001s
im_detect: 1183/4024 0.231s 0.001s
im_detect: 1184/4024 0.231s 0.001s
im_detect: 1185/4024 0.231s 0.001s
im_detect: 1186/4024 0.231s 0.001s
im_detect: 1187/4024 0.231s 0.001s
im_detect: 1188/4024 0.231s 0.001s
im_detect: 1189/4024 0.231s 0.001s
im_detect: 1190/4024 0.231s 0.001s
im_detect: 1191/4024 0.231s 0.001s
im_detect: 1192/4024 0.231s 0.001s
im_detect: 1193/4024 0.231s 0.001s
im_detect: 1194/4024 0.231s 0.001s
im_detect: 1195/4024 0.231s 0.001s
im_detect: 1196/4024 0.231s 0.001s
im_detect: 1197/4024 0.231s 0.001s
im_detect: 1198/4024 0.231s 0.001s
im_detect: 1199/4024 0.231s 0.001s
im_detect: 1200/4024 0.231s 0.001s
im_detect: 1201/4024 0.231s 0.001s
im_detect: 1202/4024 0.231s 0.001s
im_detect: 1203/4024 0.231s 0.001s
im_detect: 1204/4024 0.231s 0.001s
im_detect: 1205/4024 0.231s 0.001s
im_detect: 1206/4024 0.231s 0.001s
im_detect: 1207/4024 0.231s 0.001s
im_detect: 1208/4024 0.230s 0.001s
im_detect: 1209/4024 0.230s 0.001s
im_detect: 1210/4024 0.230s 0.001s
im_detect: 1211/4024 0.230s 0.001s
im_detect: 1212/4024 0.230s 0.001s
im_detect: 1213/4024 0.230s 0.001s
im_detect: 1214/4024 0.230s 0.001s
im_detect: 1215/4024 0.230s 0.001s
im_detect: 1216/4024 0.230s 0.001s
im_detect: 1217/4024 0.230s 0.001s
im_detect: 1218/4024 0.230s 0.001s
im_detect: 1219/4024 0.230s 0.001s
im_detect: 1220/4024 0.230s 0.001s
im_detect: 1221/4024 0.230s 0.001s
im_detect: 1222/4024 0.230s 0.001s
im_detect: 1223/4024 0.230s 0.001s
im_detect: 1224/4024 0.230s 0.001s
im_detect: 1225/4024 0.230s 0.001s
im_detect: 1226/4024 0.230s 0.001s
im_detect: 1227/4024 0.230s 0.001s
im_detect: 1228/4024 0.230s 0.001s
im_detect: 1229/4024 0.230s 0.001s
im_detect: 1230/4024 0.230s 0.001s
im_detect: 1231/4024 0.230s 0.001s
im_detect: 1232/4024 0.230s 0.001s
im_detect: 1233/4024 0.230s 0.001s
im_detect: 1234/4024 0.230s 0.001s
im_detect: 1235/4024 0.230s 0.001s
im_detect: 1236/4024 0.230s 0.001s
im_detect: 1237/4024 0.230s 0.001s
im_detect: 1238/4024 0.230s 0.001s
im_detect: 1239/4024 0.230s 0.001s
im_detect: 1240/4024 0.230s 0.001s
im_detect: 1241/4024 0.230s 0.001s
im_detect: 1242/4024 0.230s 0.001s
im_detect: 1243/4024 0.230s 0.001s
im_detect: 1244/4024 0.230s 0.001s
im_detect: 1245/4024 0.230s 0.001s
im_detect: 1246/4024 0.230s 0.001s
im_detect: 1247/4024 0.230s 0.001s
im_detect: 1248/4024 0.230s 0.001s
im_detect: 1249/4024 0.230s 0.001s
im_detect: 1250/4024 0.230s 0.001s
im_detect: 1251/4024 0.230s 0.001s
im_detect: 1252/4024 0.230s 0.001s
im_detect: 1253/4024 0.230s 0.001s
im_detect: 1254/4024 0.230s 0.001s
im_detect: 1255/4024 0.230s 0.001s
im_detect: 1256/4024 0.230s 0.001s
im_detect: 1257/4024 0.230s 0.001s
im_detect: 1258/4024 0.230s 0.001s
im_detect: 1259/4024 0.230s 0.001s
im_detect: 1260/4024 0.230s 0.001s
im_detect: 1261/4024 0.230s 0.001s
im_detect: 1262/4024 0.230s 0.001s
im_detect: 1263/4024 0.230s 0.001s
im_detect: 1264/4024 0.230s 0.001s
im_detect: 1265/4024 0.230s 0.001s
im_detect: 1266/4024 0.230s 0.001s
im_detect: 1267/4024 0.230s 0.001s
im_detect: 1268/4024 0.230s 0.001s
im_detect: 1269/4024 0.230s 0.001s
im_detect: 1270/4024 0.230s 0.001s
im_detect: 1271/4024 0.230s 0.001s
im_detect: 1272/4024 0.230s 0.001s
im_detect: 1273/4024 0.230s 0.001s
im_detect: 1274/4024 0.230s 0.001s
im_detect: 1275/4024 0.230s 0.001s
im_detect: 1276/4024 0.230s 0.001s
im_detect: 1277/4024 0.230s 0.001s
im_detect: 1278/4024 0.230s 0.001s
im_detect: 1279/4024 0.230s 0.001s
im_detect: 1280/4024 0.230s 0.001s
im_detect: 1281/4024 0.230s 0.001s
im_detect: 1282/4024 0.230s 0.001s
im_detect: 1283/4024 0.230s 0.001s
im_detect: 1284/4024 0.230s 0.001s
im_detect: 1285/4024 0.230s 0.001s
im_detect: 1286/4024 0.230s 0.001s
im_detect: 1287/4024 0.230s 0.001s
im_detect: 1288/4024 0.230s 0.001s
im_detect: 1289/4024 0.230s 0.001s
im_detect: 1290/4024 0.230s 0.001s
im_detect: 1291/4024 0.230s 0.001s
im_detect: 1292/4024 0.230s 0.001s
im_detect: 1293/4024 0.230s 0.001s
im_detect: 1294/4024 0.230s 0.001s
im_detect: 1295/4024 0.230s 0.001s
im_detect: 1296/4024 0.230s 0.001s
im_detect: 1297/4024 0.230s 0.001s
im_detect: 1298/4024 0.230s 0.001s
im_detect: 1299/4024 0.230s 0.001s
im_detect: 1300/4024 0.230s 0.001s
im_detect: 1301/4024 0.230s 0.001s
im_detect: 1302/4024 0.230s 0.001s
im_detect: 1303/4024 0.230s 0.001s
im_detect: 1304/4024 0.230s 0.001s
im_detect: 1305/4024 0.230s 0.001s
im_detect: 1306/4024 0.230s 0.001s
im_detect: 1307/4024 0.230s 0.001s
im_detect: 1308/4024 0.230s 0.001s
im_detect: 1309/4024 0.230s 0.001s
im_detect: 1310/4024 0.230s 0.001s
im_detect: 1311/4024 0.230s 0.001s
im_detect: 1312/4024 0.230s 0.001s
im_detect: 1313/4024 0.230s 0.001s
im_detect: 1314/4024 0.230s 0.001s
im_detect: 1315/4024 0.230s 0.001s
im_detect: 1316/4024 0.230s 0.001s
im_detect: 1317/4024 0.230s 0.001s
im_detect: 1318/4024 0.230s 0.001s
im_detect: 1319/4024 0.230s 0.001s
im_detect: 1320/4024 0.230s 0.001s
im_detect: 1321/4024 0.230s 0.001s
im_detect: 1322/4024 0.230s 0.001s
im_detect: 1323/4024 0.230s 0.001s
im_detect: 1324/4024 0.230s 0.001s
im_detect: 1325/4024 0.230s 0.001s
im_detect: 1326/4024 0.230s 0.001s
im_detect: 1327/4024 0.230s 0.001s
im_detect: 1328/4024 0.230s 0.001s
im_detect: 1329/4024 0.230s 0.001s
im_detect: 1330/4024 0.230s 0.001s
im_detect: 1331/4024 0.230s 0.001s
im_detect: 1332/4024 0.230s 0.001s
im_detect: 1333/4024 0.230s 0.001s
im_detect: 1334/4024 0.230s 0.001s
im_detect: 1335/4024 0.230s 0.001s
im_detect: 1336/4024 0.230s 0.001s
im_detect: 1337/4024 0.230s 0.001s
im_detect: 1338/4024 0.230s 0.001s
im_detect: 1339/4024 0.230s 0.001s
im_detect: 1340/4024 0.230s 0.001s
im_detect: 1341/4024 0.230s 0.001s
im_detect: 1342/4024 0.230s 0.001s
im_detect: 1343/4024 0.230s 0.001s
im_detect: 1344/4024 0.230s 0.001s
im_detect: 1345/4024 0.230s 0.001s
im_detect: 1346/4024 0.230s 0.001s
im_detect: 1347/4024 0.230s 0.001s
im_detect: 1348/4024 0.230s 0.001s
im_detect: 1349/4024 0.230s 0.001s
im_detect: 1350/4024 0.230s 0.001s
im_detect: 1351/4024 0.230s 0.001s
im_detect: 1352/4024 0.230s 0.001s
im_detect: 1353/4024 0.230s 0.001s
im_detect: 1354/4024 0.230s 0.001s
im_detect: 1355/4024 0.230s 0.001s
im_detect: 1356/4024 0.230s 0.001s
im_detect: 1357/4024 0.230s 0.001s
im_detect: 1358/4024 0.230s 0.001s
im_detect: 1359/4024 0.230s 0.001s
im_detect: 1360/4024 0.230s 0.001s
im_detect: 1361/4024 0.230s 0.001s
im_detect: 1362/4024 0.230s 0.001s
im_detect: 1363/4024 0.230s 0.001s
im_detect: 1364/4024 0.230s 0.001s
im_detect: 1365/4024 0.230s 0.001s
im_detect: 1366/4024 0.230s 0.001s
im_detect: 1367/4024 0.230s 0.001s
im_detect: 1368/4024 0.230s 0.001s
im_detect: 1369/4024 0.230s 0.001s
im_detect: 1370/4024 0.230s 0.001s
im_detect: 1371/4024 0.230s 0.001s
im_detect: 1372/4024 0.230s 0.001s
im_detect: 1373/4024 0.230s 0.001s
im_detect: 1374/4024 0.230s 0.001s
im_detect: 1375/4024 0.230s 0.001s
im_detect: 1376/4024 0.230s 0.001s
im_detect: 1377/4024 0.230s 0.001s
im_detect: 1378/4024 0.230s 0.001s
im_detect: 1379/4024 0.230s 0.001s
im_detect: 1380/4024 0.230s 0.001s
im_detect: 1381/4024 0.230s 0.001s
im_detect: 1382/4024 0.230s 0.001s
im_detect: 1383/4024 0.230s 0.001s
im_detect: 1384/4024 0.230s 0.001s
im_detect: 1385/4024 0.230s 0.001s
im_detect: 1386/4024 0.230s 0.001s
im_detect: 1387/4024 0.230s 0.001s
im_detect: 1388/4024 0.230s 0.001s
im_detect: 1389/4024 0.230s 0.001s
im_detect: 1390/4024 0.230s 0.001s
im_detect: 1391/4024 0.229s 0.001s
im_detect: 1392/4024 0.229s 0.001s
im_detect: 1393/4024 0.229s 0.001s
im_detect: 1394/4024 0.229s 0.001s
im_detect: 1395/4024 0.229s 0.001s
im_detect: 1396/4024 0.229s 0.001s
im_detect: 1397/4024 0.229s 0.001s
im_detect: 1398/4024 0.229s 0.001s
im_detect: 1399/4024 0.229s 0.001s
im_detect: 1400/4024 0.229s 0.001s
im_detect: 1401/4024 0.229s 0.001s
im_detect: 1402/4024 0.229s 0.001s
im_detect: 1403/4024 0.229s 0.001s
im_detect: 1404/4024 0.229s 0.001s
im_detect: 1405/4024 0.229s 0.001s
im_detect: 1406/4024 0.229s 0.001s
im_detect: 1407/4024 0.229s 0.001s
im_detect: 1408/4024 0.229s 0.001s
im_detect: 1409/4024 0.229s 0.001s
im_detect: 1410/4024 0.229s 0.001s
im_detect: 1411/4024 0.229s 0.001s
im_detect: 1412/4024 0.229s 0.001s
im_detect: 1413/4024 0.229s 0.001s
im_detect: 1414/4024 0.229s 0.001s
im_detect: 1415/4024 0.229s 0.001s
im_detect: 1416/4024 0.229s 0.001s
im_detect: 1417/4024 0.229s 0.001s
im_detect: 1418/4024 0.229s 0.001s
im_detect: 1419/4024 0.229s 0.001s
im_detect: 1420/4024 0.229s 0.001s
im_detect: 1421/4024 0.229s 0.001s
im_detect: 1422/4024 0.229s 0.001s
im_detect: 1423/4024 0.229s 0.001s
im_detect: 1424/4024 0.229s 0.001s
im_detect: 1425/4024 0.229s 0.001s
im_detect: 1426/4024 0.229s 0.001s
im_detect: 1427/4024 0.229s 0.001s
im_detect: 1428/4024 0.229s 0.001s
im_detect: 1429/4024 0.229s 0.001s
im_detect: 1430/4024 0.229s 0.001s
im_detect: 1431/4024 0.229s 0.001s
im_detect: 1432/4024 0.229s 0.001s
im_detect: 1433/4024 0.229s 0.001s
im_detect: 1434/4024 0.229s 0.001s
im_detect: 1435/4024 0.229s 0.001s
im_detect: 1436/4024 0.229s 0.001s
im_detect: 1437/4024 0.229s 0.001s
im_detect: 1438/4024 0.229s 0.001s
im_detect: 1439/4024 0.229s 0.001s
im_detect: 1440/4024 0.229s 0.001s
im_detect: 1441/4024 0.229s 0.001s
im_detect: 1442/4024 0.229s 0.001s
im_detect: 1443/4024 0.229s 0.001s
im_detect: 1444/4024 0.229s 0.001s
im_detect: 1445/4024 0.229s 0.001s
im_detect: 1446/4024 0.229s 0.001s
im_detect: 1447/4024 0.229s 0.001s
im_detect: 1448/4024 0.229s 0.001s
im_detect: 1449/4024 0.230s 0.001s
im_detect: 1450/4024 0.229s 0.001s
im_detect: 1451/4024 0.229s 0.001s
im_detect: 1452/4024 0.229s 0.001s
im_detect: 1453/4024 0.229s 0.001s
im_detect: 1454/4024 0.229s 0.001s
im_detect: 1455/4024 0.229s 0.001s
im_detect: 1456/4024 0.229s 0.001s
im_detect: 1457/4024 0.230s 0.001s
im_detect: 1458/4024 0.230s 0.001s
im_detect: 1459/4024 0.230s 0.001s
im_detect: 1460/4024 0.229s 0.001s
im_detect: 1461/4024 0.229s 0.001s
im_detect: 1462/4024 0.229s 0.001s
im_detect: 1463/4024 0.229s 0.001s
im_detect: 1464/4024 0.229s 0.001s
im_detect: 1465/4024 0.229s 0.001s
im_detect: 1466/4024 0.229s 0.001s
im_detect: 1467/4024 0.229s 0.001s
im_detect: 1468/4024 0.229s 0.001s
im_detect: 1469/4024 0.229s 0.001s
im_detect: 1470/4024 0.229s 0.001s
im_detect: 1471/4024 0.229s 0.001s
im_detect: 1472/4024 0.229s 0.001s
im_detect: 1473/4024 0.229s 0.001s
im_detect: 1474/4024 0.229s 0.001s
im_detect: 1475/4024 0.229s 0.001s
im_detect: 1476/4024 0.229s 0.001s
im_detect: 1477/4024 0.229s 0.001s
im_detect: 1478/4024 0.229s 0.001s
im_detect: 1479/4024 0.229s 0.001s
im_detect: 1480/4024 0.229s 0.001s
im_detect: 1481/4024 0.229s 0.001s
im_detect: 1482/4024 0.229s 0.001s
im_detect: 1483/4024 0.229s 0.001s
im_detect: 1484/4024 0.229s 0.001s
im_detect: 1485/4024 0.229s 0.001s
im_detect: 1486/4024 0.229s 0.001s
im_detect: 1487/4024 0.229s 0.001s
im_detect: 1488/4024 0.229s 0.001s
im_detect: 1489/4024 0.229s 0.001s
im_detect: 1490/4024 0.229s 0.001s
im_detect: 1491/4024 0.229s 0.001s
im_detect: 1492/4024 0.229s 0.001s
im_detect: 1493/4024 0.229s 0.001s
im_detect: 1494/4024 0.229s 0.001s
im_detect: 1495/4024 0.229s 0.001s
im_detect: 1496/4024 0.229s 0.001s
im_detect: 1497/4024 0.229s 0.001s
im_detect: 1498/4024 0.229s 0.001s
im_detect: 1499/4024 0.229s 0.001s
im_detect: 1500/4024 0.229s 0.001s
im_detect: 1501/4024 0.229s 0.001s
im_detect: 1502/4024 0.229s 0.001s
im_detect: 1503/4024 0.229s 0.001s
im_detect: 1504/4024 0.229s 0.001s
im_detect: 1505/4024 0.229s 0.001s
im_detect: 1506/4024 0.229s 0.001s
im_detect: 1507/4024 0.229s 0.001s
im_detect: 1508/4024 0.229s 0.001s
im_detect: 1509/4024 0.229s 0.001s
im_detect: 1510/4024 0.229s 0.001s
im_detect: 1511/4024 0.229s 0.001s
im_detect: 1512/4024 0.229s 0.001s
im_detect: 1513/4024 0.229s 0.001s
im_detect: 1514/4024 0.229s 0.001s
im_detect: 1515/4024 0.229s 0.001s
im_detect: 1516/4024 0.229s 0.001s
im_detect: 1517/4024 0.229s 0.001s
im_detect: 1518/4024 0.229s 0.001s
im_detect: 1519/4024 0.229s 0.001s
im_detect: 1520/4024 0.229s 0.001s
im_detect: 1521/4024 0.229s 0.001s
im_detect: 1522/4024 0.229s 0.001s
im_detect: 1523/4024 0.229s 0.001s
im_detect: 1524/4024 0.229s 0.001s
im_detect: 1525/4024 0.229s 0.001s
im_detect: 1526/4024 0.229s 0.001s
im_detect: 1527/4024 0.229s 0.001s
im_detect: 1528/4024 0.229s 0.001s
im_detect: 1529/4024 0.229s 0.001s
im_detect: 1530/4024 0.229s 0.001s
im_detect: 1531/4024 0.229s 0.001s
im_detect: 1532/4024 0.229s 0.001s
im_detect: 1533/4024 0.229s 0.001s
im_detect: 1534/4024 0.229s 0.001s
im_detect: 1535/4024 0.229s 0.001s
im_detect: 1536/4024 0.229s 0.001s
im_detect: 1537/4024 0.229s 0.001s
im_detect: 1538/4024 0.229s 0.001s
im_detect: 1539/4024 0.229s 0.001s
im_detect: 1540/4024 0.229s 0.001s
im_detect: 1541/4024 0.229s 0.001s
im_detect: 1542/4024 0.229s 0.001s
im_detect: 1543/4024 0.229s 0.001s
im_detect: 1544/4024 0.229s 0.001s
im_detect: 1545/4024 0.229s 0.001s
im_detect: 1546/4024 0.229s 0.001s
im_detect: 1547/4024 0.229s 0.001s
im_detect: 1548/4024 0.229s 0.001s
im_detect: 1549/4024 0.229s 0.001s
im_detect: 1550/4024 0.229s 0.001s
im_detect: 1551/4024 0.229s 0.001s
im_detect: 1552/4024 0.229s 0.001s
im_detect: 1553/4024 0.229s 0.001s
im_detect: 1554/4024 0.229s 0.001s
im_detect: 1555/4024 0.229s 0.001s
im_detect: 1556/4024 0.229s 0.001s
im_detect: 1557/4024 0.229s 0.001s
im_detect: 1558/4024 0.229s 0.001s
im_detect: 1559/4024 0.229s 0.001s
im_detect: 1560/4024 0.229s 0.001s
im_detect: 1561/4024 0.229s 0.001s
im_detect: 1562/4024 0.229s 0.001s
im_detect: 1563/4024 0.229s 0.001s
im_detect: 1564/4024 0.229s 0.001s
im_detect: 1565/4024 0.229s 0.001s
im_detect: 1566/4024 0.229s 0.001s
im_detect: 1567/4024 0.229s 0.001s
im_detect: 1568/4024 0.229s 0.001s
im_detect: 1569/4024 0.229s 0.001s
im_detect: 1570/4024 0.229s 0.001s
im_detect: 1571/4024 0.229s 0.001s
im_detect: 1572/4024 0.229s 0.001s
im_detect: 1573/4024 0.229s 0.001s
im_detect: 1574/4024 0.229s 0.001s
im_detect: 1575/4024 0.229s 0.001s
im_detect: 1576/4024 0.229s 0.001s
im_detect: 1577/4024 0.229s 0.001s
im_detect: 1578/4024 0.229s 0.001s
im_detect: 1579/4024 0.229s 0.001s
im_detect: 1580/4024 0.229s 0.001s
im_detect: 1581/4024 0.229s 0.001s
im_detect: 1582/4024 0.229s 0.001s
im_detect: 1583/4024 0.229s 0.001s
im_detect: 1584/4024 0.229s 0.001s
im_detect: 1585/4024 0.229s 0.001s
im_detect: 1586/4024 0.229s 0.001s
im_detect: 1587/4024 0.229s 0.001s
im_detect: 1588/4024 0.229s 0.001s
im_detect: 1589/4024 0.229s 0.001s
im_detect: 1590/4024 0.229s 0.001s
im_detect: 1591/4024 0.229s 0.001s
im_detect: 1592/4024 0.229s 0.001s
im_detect: 1593/4024 0.229s 0.001s
im_detect: 1594/4024 0.229s 0.001s
im_detect: 1595/4024 0.229s 0.001s
im_detect: 1596/4024 0.229s 0.001s
im_detect: 1597/4024 0.229s 0.001s
im_detect: 1598/4024 0.229s 0.001s
im_detect: 1599/4024 0.229s 0.001s
im_detect: 1600/4024 0.229s 0.001s
im_detect: 1601/4024 0.229s 0.001s
im_detect: 1602/4024 0.229s 0.001s
im_detect: 1603/4024 0.229s 0.001s
im_detect: 1604/4024 0.229s 0.001s
im_detect: 1605/4024 0.229s 0.001s
im_detect: 1606/4024 0.229s 0.001s
im_detect: 1607/4024 0.229s 0.001s
im_detect: 1608/4024 0.229s 0.001s
im_detect: 1609/4024 0.229s 0.001s
im_detect: 1610/4024 0.229s 0.001s
im_detect: 1611/4024 0.229s 0.001s
im_detect: 1612/4024 0.229s 0.001s
im_detect: 1613/4024 0.229s 0.001s
im_detect: 1614/4024 0.229s 0.001s
im_detect: 1615/4024 0.229s 0.001s
im_detect: 1616/4024 0.229s 0.001s
im_detect: 1617/4024 0.229s 0.001s
im_detect: 1618/4024 0.229s 0.001s
im_detect: 1619/4024 0.229s 0.001s
im_detect: 1620/4024 0.229s 0.001s
im_detect: 1621/4024 0.229s 0.001s
im_detect: 1622/4024 0.229s 0.001s
im_detect: 1623/4024 0.229s 0.001s
im_detect: 1624/4024 0.229s 0.001s
im_detect: 1625/4024 0.229s 0.001s
im_detect: 1626/4024 0.229s 0.001s
im_detect: 1627/4024 0.229s 0.001s
im_detect: 1628/4024 0.229s 0.001s
im_detect: 1629/4024 0.229s 0.001s
im_detect: 1630/4024 0.229s 0.001s
im_detect: 1631/4024 0.229s 0.001s
im_detect: 1632/4024 0.229s 0.001s
im_detect: 1633/4024 0.229s 0.001s
im_detect: 1634/4024 0.229s 0.001s
im_detect: 1635/4024 0.229s 0.001s
im_detect: 1636/4024 0.229s 0.001s
im_detect: 1637/4024 0.229s 0.001s
im_detect: 1638/4024 0.229s 0.001s
im_detect: 1639/4024 0.229s 0.001s
im_detect: 1640/4024 0.229s 0.001s
im_detect: 1641/4024 0.229s 0.001s
im_detect: 1642/4024 0.229s 0.001s
im_detect: 1643/4024 0.229s 0.001s
im_detect: 1644/4024 0.229s 0.001s
im_detect: 1645/4024 0.229s 0.001s
im_detect: 1646/4024 0.229s 0.001s
im_detect: 1647/4024 0.229s 0.001s
im_detect: 1648/4024 0.229s 0.001s
im_detect: 1649/4024 0.229s 0.001s
im_detect: 1650/4024 0.229s 0.001s
im_detect: 1651/4024 0.229s 0.001s
im_detect: 1652/4024 0.229s 0.001s
im_detect: 1653/4024 0.229s 0.001s
im_detect: 1654/4024 0.229s 0.001s
im_detect: 1655/4024 0.229s 0.001s
im_detect: 1656/4024 0.229s 0.001s
im_detect: 1657/4024 0.229s 0.001s
im_detect: 1658/4024 0.229s 0.001s
im_detect: 1659/4024 0.229s 0.001s
im_detect: 1660/4024 0.229s 0.001s
im_detect: 1661/4024 0.229s 0.001s
im_detect: 1662/4024 0.229s 0.001s
im_detect: 1663/4024 0.229s 0.001s
im_detect: 1664/4024 0.229s 0.001s
im_detect: 1665/4024 0.229s 0.001s
im_detect: 1666/4024 0.229s 0.001s
im_detect: 1667/4024 0.229s 0.001s
im_detect: 1668/4024 0.229s 0.001s
im_detect: 1669/4024 0.229s 0.001s
im_detect: 1670/4024 0.229s 0.001s
im_detect: 1671/4024 0.229s 0.001s
im_detect: 1672/4024 0.229s 0.001s
im_detect: 1673/4024 0.229s 0.001s
im_detect: 1674/4024 0.229s 0.001s
im_detect: 1675/4024 0.229s 0.001s
im_detect: 1676/4024 0.229s 0.001s
im_detect: 1677/4024 0.229s 0.001s
im_detect: 1678/4024 0.229s 0.001s
im_detect: 1679/4024 0.229s 0.001s
im_detect: 1680/4024 0.229s 0.001s
im_detect: 1681/4024 0.229s 0.001s
im_detect: 1682/4024 0.229s 0.001s
im_detect: 1683/4024 0.229s 0.001s
im_detect: 1684/4024 0.229s 0.001s
im_detect: 1685/4024 0.229s 0.001s
im_detect: 1686/4024 0.229s 0.001s
im_detect: 1687/4024 0.229s 0.001s
im_detect: 1688/4024 0.229s 0.001s
im_detect: 1689/4024 0.229s 0.001s
im_detect: 1690/4024 0.229s 0.001s
im_detect: 1691/4024 0.229s 0.001s
im_detect: 1692/4024 0.229s 0.001s
im_detect: 1693/4024 0.229s 0.001s
im_detect: 1694/4024 0.229s 0.001s
im_detect: 1695/4024 0.229s 0.001s
im_detect: 1696/4024 0.229s 0.001s
im_detect: 1697/4024 0.228s 0.001s
im_detect: 1698/4024 0.228s 0.001s
im_detect: 1699/4024 0.228s 0.001s
im_detect: 1700/4024 0.228s 0.001s
im_detect: 1701/4024 0.228s 0.001s
im_detect: 1702/4024 0.228s 0.001s
im_detect: 1703/4024 0.228s 0.001s
im_detect: 1704/4024 0.228s 0.001s
im_detect: 1705/4024 0.228s 0.001s
im_detect: 1706/4024 0.228s 0.001s
im_detect: 1707/4024 0.228s 0.001s
im_detect: 1708/4024 0.228s 0.001s
im_detect: 1709/4024 0.228s 0.001s
im_detect: 1710/4024 0.228s 0.001s
im_detect: 1711/4024 0.228s 0.001s
im_detect: 1712/4024 0.228s 0.001s
im_detect: 1713/4024 0.228s 0.001s
im_detect: 1714/4024 0.228s 0.001s
im_detect: 1715/4024 0.228s 0.001s
im_detect: 1716/4024 0.228s 0.001s
im_detect: 1717/4024 0.228s 0.001s
im_detect: 1718/4024 0.228s 0.001s
im_detect: 1719/4024 0.228s 0.001s
im_detect: 1720/4024 0.228s 0.001s
im_detect: 1721/4024 0.228s 0.001s
im_detect: 1722/4024 0.228s 0.001s
im_detect: 1723/4024 0.228s 0.001s
im_detect: 1724/4024 0.228s 0.001s
im_detect: 1725/4024 0.228s 0.001s
im_detect: 1726/4024 0.228s 0.001s
im_detect: 1727/4024 0.228s 0.001s
im_detect: 1728/4024 0.228s 0.001s
im_detect: 1729/4024 0.228s 0.001s
im_detect: 1730/4024 0.228s 0.001s
im_detect: 1731/4024 0.228s 0.001s
im_detect: 1732/4024 0.228s 0.001s
im_detect: 1733/4024 0.228s 0.001s
im_detect: 1734/4024 0.228s 0.001s
im_detect: 1735/4024 0.228s 0.001s
im_detect: 1736/4024 0.228s 0.001s
im_detect: 1737/4024 0.228s 0.001s
im_detect: 1738/4024 0.228s 0.001s
im_detect: 1739/4024 0.228s 0.001s
im_detect: 1740/4024 0.229s 0.001s
im_detect: 1741/4024 0.229s 0.001s
im_detect: 1742/4024 0.229s 0.001s
im_detect: 1743/4024 0.229s 0.001s
im_detect: 1744/4024 0.229s 0.001s
im_detect: 1745/4024 0.229s 0.001s
im_detect: 1746/4024 0.229s 0.001s
im_detect: 1747/4024 0.229s 0.001s
im_detect: 1748/4024 0.229s 0.001s
im_detect: 1749/4024 0.229s 0.001s
im_detect: 1750/4024 0.228s 0.001s
im_detect: 1751/4024 0.229s 0.001s
im_detect: 1752/4024 0.229s 0.001s
im_detect: 1753/4024 0.228s 0.001s
im_detect: 1754/4024 0.228s 0.001s
im_detect: 1755/4024 0.229s 0.001s
im_detect: 1756/4024 0.229s 0.001s
im_detect: 1757/4024 0.229s 0.001s
im_detect: 1758/4024 0.228s 0.001s
im_detect: 1759/4024 0.228s 0.001s
im_detect: 1760/4024 0.228s 0.001s
im_detect: 1761/4024 0.228s 0.001s
im_detect: 1762/4024 0.229s 0.001s
im_detect: 1763/4024 0.229s 0.001s
im_detect: 1764/4024 0.229s 0.001s
im_detect: 1765/4024 0.228s 0.001s
im_detect: 1766/4024 0.229s 0.001s
im_detect: 1767/4024 0.229s 0.001s
im_detect: 1768/4024 0.229s 0.001s
im_detect: 1769/4024 0.229s 0.001s
im_detect: 1770/4024 0.229s 0.001s
im_detect: 1771/4024 0.229s 0.001s
im_detect: 1772/4024 0.229s 0.001s
im_detect: 1773/4024 0.229s 0.001s
im_detect: 1774/4024 0.229s 0.001s
im_detect: 1775/4024 0.229s 0.001s
im_detect: 1776/4024 0.229s 0.001s
im_detect: 1777/4024 0.229s 0.001s
im_detect: 1778/4024 0.229s 0.001s
im_detect: 1779/4024 0.229s 0.001s
im_detect: 1780/4024 0.229s 0.001s
im_detect: 1781/4024 0.229s 0.001s
im_detect: 1782/4024 0.229s 0.001s
im_detect: 1783/4024 0.229s 0.001s
im_detect: 1784/4024 0.229s 0.001s
im_detect: 1785/4024 0.229s 0.001s
im_detect: 1786/4024 0.229s 0.001s
im_detect: 1787/4024 0.229s 0.001s
im_detect: 1788/4024 0.229s 0.001s
im_detect: 1789/4024 0.229s 0.001s
im_detect: 1790/4024 0.229s 0.001s
im_detect: 1791/4024 0.229s 0.001s
im_detect: 1792/4024 0.229s 0.001s
im_detect: 1793/4024 0.229s 0.001s
im_detect: 1794/4024 0.229s 0.001s
im_detect: 1795/4024 0.229s 0.001s
im_detect: 1796/4024 0.229s 0.001s
im_detect: 1797/4024 0.229s 0.001s
im_detect: 1798/4024 0.229s 0.001s
im_detect: 1799/4024 0.229s 0.001s
im_detect: 1800/4024 0.229s 0.001s
im_detect: 1801/4024 0.229s 0.001s
im_detect: 1802/4024 0.229s 0.001s
im_detect: 1803/4024 0.229s 0.001s
im_detect: 1804/4024 0.229s 0.001s
im_detect: 1805/4024 0.229s 0.001s
im_detect: 1806/4024 0.229s 0.001s
im_detect: 1807/4024 0.229s 0.001s
im_detect: 1808/4024 0.229s 0.001s
im_detect: 1809/4024 0.229s 0.001s
im_detect: 1810/4024 0.229s 0.001s
im_detect: 1811/4024 0.229s 0.001s
im_detect: 1812/4024 0.229s 0.001s
im_detect: 1813/4024 0.229s 0.001s
im_detect: 1814/4024 0.229s 0.001s
im_detect: 1815/4024 0.229s 0.001s
im_detect: 1816/4024 0.229s 0.001s
im_detect: 1817/4024 0.229s 0.001s
im_detect: 1818/4024 0.229s 0.001s
im_detect: 1819/4024 0.229s 0.001s
im_detect: 1820/4024 0.229s 0.001s
im_detect: 1821/4024 0.229s 0.001s
im_detect: 1822/4024 0.229s 0.001s
im_detect: 1823/4024 0.229s 0.001s
im_detect: 1824/4024 0.229s 0.001s
im_detect: 1825/4024 0.229s 0.001s
im_detect: 1826/4024 0.229s 0.001s
im_detect: 1827/4024 0.229s 0.001s
im_detect: 1828/4024 0.229s 0.001s
im_detect: 1829/4024 0.229s 0.001s
im_detect: 1830/4024 0.229s 0.001s
im_detect: 1831/4024 0.229s 0.001s
im_detect: 1832/4024 0.229s 0.001s
im_detect: 1833/4024 0.229s 0.001s
im_detect: 1834/4024 0.229s 0.001s
im_detect: 1835/4024 0.229s 0.001s
im_detect: 1836/4024 0.229s 0.001s
im_detect: 1837/4024 0.229s 0.001s
im_detect: 1838/4024 0.229s 0.001s
im_detect: 1839/4024 0.229s 0.001s
im_detect: 1840/4024 0.229s 0.001s
im_detect: 1841/4024 0.229s 0.001s
im_detect: 1842/4024 0.229s 0.001s
im_detect: 1843/4024 0.229s 0.001s
im_detect: 1844/4024 0.229s 0.001s
im_detect: 1845/4024 0.229s 0.001s
im_detect: 1846/4024 0.229s 0.001s
im_detect: 1847/4024 0.229s 0.001s
im_detect: 1848/4024 0.229s 0.001s
im_detect: 1849/4024 0.229s 0.001s
im_detect: 1850/4024 0.229s 0.001s
im_detect: 1851/4024 0.229s 0.001s
im_detect: 1852/4024 0.229s 0.001s
im_detect: 1853/4024 0.229s 0.001s
im_detect: 1854/4024 0.229s 0.001s
im_detect: 1855/4024 0.229s 0.001s
im_detect: 1856/4024 0.229s 0.001s
im_detect: 1857/4024 0.229s 0.001s
im_detect: 1858/4024 0.229s 0.001s
im_detect: 1859/4024 0.229s 0.001s
im_detect: 1860/4024 0.229s 0.001s
im_detect: 1861/4024 0.229s 0.001s
im_detect: 1862/4024 0.229s 0.001s
im_detect: 1863/4024 0.229s 0.001s
im_detect: 1864/4024 0.229s 0.001s
im_detect: 1865/4024 0.229s 0.001s
im_detect: 1866/4024 0.229s 0.001s
im_detect: 1867/4024 0.229s 0.001s
im_detect: 1868/4024 0.229s 0.001s
im_detect: 1869/4024 0.229s 0.001s
im_detect: 1870/4024 0.229s 0.001s
im_detect: 1871/4024 0.229s 0.001s
im_detect: 1872/4024 0.229s 0.001s
im_detect: 1873/4024 0.229s 0.001s
im_detect: 1874/4024 0.229s 0.001s
im_detect: 1875/4024 0.229s 0.001s
im_detect: 1876/4024 0.229s 0.001s
im_detect: 1877/4024 0.229s 0.001s
im_detect: 1878/4024 0.229s 0.001s
im_detect: 1879/4024 0.229s 0.001s
im_detect: 1880/4024 0.229s 0.001s
im_detect: 1881/4024 0.229s 0.001s
im_detect: 1882/4024 0.229s 0.001s
im_detect: 1883/4024 0.229s 0.001s
im_detect: 1884/4024 0.229s 0.001s
im_detect: 1885/4024 0.229s 0.001s
im_detect: 1886/4024 0.229s 0.001s
im_detect: 1887/4024 0.229s 0.001s
im_detect: 1888/4024 0.229s 0.001s
im_detect: 1889/4024 0.229s 0.001s
im_detect: 1890/4024 0.229s 0.001s
im_detect: 1891/4024 0.229s 0.001s
im_detect: 1892/4024 0.229s 0.001s
im_detect: 1893/4024 0.229s 0.001s
im_detect: 1894/4024 0.229s 0.001s
im_detect: 1895/4024 0.229s 0.001s
im_detect: 1896/4024 0.229s 0.001s
im_detect: 1897/4024 0.229s 0.001s
im_detect: 1898/4024 0.229s 0.001s
im_detect: 1899/4024 0.229s 0.001s
im_detect: 1900/4024 0.229s 0.001s
im_detect: 1901/4024 0.229s 0.001s
im_detect: 1902/4024 0.229s 0.001s
im_detect: 1903/4024 0.229s 0.001s
im_detect: 1904/4024 0.229s 0.001s
im_detect: 1905/4024 0.229s 0.001s
im_detect: 1906/4024 0.229s 0.001s
im_detect: 1907/4024 0.229s 0.001s
im_detect: 1908/4024 0.229s 0.001s
im_detect: 1909/4024 0.229s 0.001s
im_detect: 1910/4024 0.229s 0.001s
im_detect: 1911/4024 0.229s 0.001s
im_detect: 1912/4024 0.229s 0.001s
im_detect: 1913/4024 0.229s 0.001s
im_detect: 1914/4024 0.229s 0.001s
im_detect: 1915/4024 0.229s 0.001s
im_detect: 1916/4024 0.229s 0.001s
im_detect: 1917/4024 0.229s 0.001s
im_detect: 1918/4024 0.229s 0.001s
im_detect: 1919/4024 0.229s 0.001s
im_detect: 1920/4024 0.229s 0.001s
im_detect: 1921/4024 0.229s 0.001s
im_detect: 1922/4024 0.229s 0.001s
im_detect: 1923/4024 0.229s 0.001s
im_detect: 1924/4024 0.229s 0.001s
im_detect: 1925/4024 0.229s 0.001s
im_detect: 1926/4024 0.229s 0.001s
im_detect: 1927/4024 0.229s 0.001s
im_detect: 1928/4024 0.229s 0.001s
im_detect: 1929/4024 0.229s 0.001s
im_detect: 1930/4024 0.229s 0.001s
im_detect: 1931/4024 0.229s 0.001s
im_detect: 1932/4024 0.229s 0.001s
im_detect: 1933/4024 0.229s 0.001s
im_detect: 1934/4024 0.229s 0.001s
im_detect: 1935/4024 0.229s 0.001s
im_detect: 1936/4024 0.229s 0.001s
im_detect: 1937/4024 0.229s 0.001s
im_detect: 1938/4024 0.229s 0.001s
im_detect: 1939/4024 0.229s 0.001s
im_detect: 1940/4024 0.229s 0.001s
im_detect: 1941/4024 0.229s 0.001s
im_detect: 1942/4024 0.229s 0.001s
im_detect: 1943/4024 0.229s 0.001s
im_detect: 1944/4024 0.229s 0.001s
im_detect: 1945/4024 0.229s 0.001s
im_detect: 1946/4024 0.229s 0.001s
im_detect: 1947/4024 0.229s 0.001s
im_detect: 1948/4024 0.229s 0.001s
im_detect: 1949/4024 0.229s 0.001s
im_detect: 1950/4024 0.229s 0.001s
im_detect: 1951/4024 0.229s 0.001s
im_detect: 1952/4024 0.229s 0.001s
im_detect: 1953/4024 0.229s 0.001s
im_detect: 1954/4024 0.229s 0.001s
im_detect: 1955/4024 0.229s 0.001s
im_detect: 1956/4024 0.229s 0.001s
im_detect: 1957/4024 0.229s 0.001s
im_detect: 1958/4024 0.229s 0.001s
im_detect: 1959/4024 0.229s 0.001s
im_detect: 1960/4024 0.229s 0.001s
im_detect: 1961/4024 0.229s 0.001s
im_detect: 1962/4024 0.229s 0.001s
im_detect: 1963/4024 0.229s 0.001s
im_detect: 1964/4024 0.229s 0.001s
im_detect: 1965/4024 0.229s 0.001s
im_detect: 1966/4024 0.229s 0.001s
im_detect: 1967/4024 0.229s 0.001s
im_detect: 1968/4024 0.229s 0.001s
im_detect: 1969/4024 0.229s 0.001s
im_detect: 1970/4024 0.229s 0.001s
im_detect: 1971/4024 0.229s 0.001s
im_detect: 1972/4024 0.229s 0.001s
im_detect: 1973/4024 0.229s 0.001s
im_detect: 1974/4024 0.229s 0.001s
im_detect: 1975/4024 0.229s 0.001s
im_detect: 1976/4024 0.229s 0.001s
im_detect: 1977/4024 0.229s 0.001s
im_detect: 1978/4024 0.229s 0.001s
im_detect: 1979/4024 0.229s 0.001s
im_detect: 1980/4024 0.229s 0.001s
im_detect: 1981/4024 0.229s 0.001s
im_detect: 1982/4024 0.229s 0.001s
im_detect: 1983/4024 0.229s 0.001s
im_detect: 1984/4024 0.229s 0.001s
im_detect: 1985/4024 0.229s 0.001s
im_detect: 1986/4024 0.229s 0.001s
im_detect: 1987/4024 0.229s 0.001s
im_detect: 1988/4024 0.229s 0.001s
im_detect: 1989/4024 0.229s 0.001s
im_detect: 1990/4024 0.229s 0.001s
im_detect: 1991/4024 0.229s 0.001s
im_detect: 1992/4024 0.229s 0.001s
im_detect: 1993/4024 0.229s 0.001s
im_detect: 1994/4024 0.229s 0.001s
im_detect: 1995/4024 0.229s 0.001s
im_detect: 1996/4024 0.229s 0.001s
im_detect: 1997/4024 0.229s 0.001s
im_detect: 1998/4024 0.229s 0.001s
im_detect: 1999/4024 0.229s 0.001s
im_detect: 2000/4024 0.229s 0.001s
im_detect: 2001/4024 0.229s 0.001s
im_detect: 2002/4024 0.229s 0.001s
im_detect: 2003/4024 0.229s 0.001s
im_detect: 2004/4024 0.229s 0.001s
im_detect: 2005/4024 0.229s 0.001s
im_detect: 2006/4024 0.229s 0.001s
im_detect: 2007/4024 0.229s 0.001s
im_detect: 2008/4024 0.229s 0.001s
im_detect: 2009/4024 0.229s 0.001s
im_detect: 2010/4024 0.229s 0.001s
im_detect: 2011/4024 0.229s 0.001s
im_detect: 2012/4024 0.229s 0.001s
im_detect: 2013/4024 0.229s 0.001s
im_detect: 2014/4024 0.229s 0.001s
im_detect: 2015/4024 0.229s 0.001s
im_detect: 2016/4024 0.229s 0.001s
im_detect: 2017/4024 0.229s 0.001s
im_detect: 2018/4024 0.229s 0.001s
im_detect: 2019/4024 0.229s 0.001s
im_detect: 2020/4024 0.229s 0.001s
im_detect: 2021/4024 0.229s 0.001s
im_detect: 2022/4024 0.229s 0.001s
im_detect: 2023/4024 0.229s 0.001s
im_detect: 2024/4024 0.229s 0.001s
im_detect: 2025/4024 0.229s 0.001s
im_detect: 2026/4024 0.229s 0.001s
im_detect: 2027/4024 0.229s 0.001s
im_detect: 2028/4024 0.229s 0.001s
im_detect: 2029/4024 0.229s 0.001s
im_detect: 2030/4024 0.229s 0.001s
im_detect: 2031/4024 0.229s 0.001s
im_detect: 2032/4024 0.229s 0.001s
im_detect: 2033/4024 0.229s 0.001s
im_detect: 2034/4024 0.229s 0.001s
im_detect: 2035/4024 0.229s 0.001s
im_detect: 2036/4024 0.229s 0.001s
im_detect: 2037/4024 0.229s 0.001s
im_detect: 2038/4024 0.229s 0.001s
im_detect: 2039/4024 0.229s 0.001s
im_detect: 2040/4024 0.229s 0.001s
im_detect: 2041/4024 0.229s 0.001s
im_detect: 2042/4024 0.229s 0.001s
im_detect: 2043/4024 0.229s 0.001s
im_detect: 2044/4024 0.229s 0.001s
im_detect: 2045/4024 0.229s 0.001s
im_detect: 2046/4024 0.229s 0.001s
im_detect: 2047/4024 0.229s 0.001s
im_detect: 2048/4024 0.229s 0.001s
im_detect: 2049/4024 0.229s 0.001s
im_detect: 2050/4024 0.229s 0.001s
im_detect: 2051/4024 0.229s 0.001s
im_detect: 2052/4024 0.229s 0.001s
im_detect: 2053/4024 0.229s 0.001s
im_detect: 2054/4024 0.229s 0.001s
im_detect: 2055/4024 0.229s 0.001s
im_detect: 2056/4024 0.229s 0.001s
im_detect: 2057/4024 0.229s 0.001s
im_detect: 2058/4024 0.229s 0.001s
im_detect: 2059/4024 0.229s 0.001s
im_detect: 2060/4024 0.229s 0.001s
im_detect: 2061/4024 0.229s 0.001s
im_detect: 2062/4024 0.229s 0.001s
im_detect: 2063/4024 0.229s 0.001s
im_detect: 2064/4024 0.229s 0.001s
im_detect: 2065/4024 0.229s 0.001s
im_detect: 2066/4024 0.229s 0.001s
im_detect: 2067/4024 0.229s 0.001s
im_detect: 2068/4024 0.228s 0.001s
im_detect: 2069/4024 0.228s 0.001s
im_detect: 2070/4024 0.228s 0.001s
im_detect: 2071/4024 0.228s 0.001s
im_detect: 2072/4024 0.228s 0.001s
im_detect: 2073/4024 0.228s 0.001s
im_detect: 2074/4024 0.228s 0.001s
im_detect: 2075/4024 0.229s 0.001s
im_detect: 2076/4024 0.229s 0.001s
im_detect: 2077/4024 0.229s 0.001s
im_detect: 2078/4024 0.229s 0.001s
im_detect: 2079/4024 0.229s 0.001s
im_detect: 2080/4024 0.229s 0.001s
im_detect: 2081/4024 0.228s 0.001s
im_detect: 2082/4024 0.228s 0.001s
im_detect: 2083/4024 0.228s 0.001s
im_detect: 2084/4024 0.228s 0.001s
im_detect: 2085/4024 0.228s 0.001s
im_detect: 2086/4024 0.228s 0.001s
im_detect: 2087/4024 0.228s 0.001s
im_detect: 2088/4024 0.228s 0.001s
im_detect: 2089/4024 0.228s 0.001s
im_detect: 2090/4024 0.228s 0.001s
im_detect: 2091/4024 0.228s 0.001s
im_detect: 2092/4024 0.228s 0.001s
im_detect: 2093/4024 0.228s 0.001s
im_detect: 2094/4024 0.228s 0.001s
im_detect: 2095/4024 0.228s 0.001s
im_detect: 2096/4024 0.228s 0.001s
im_detect: 2097/4024 0.228s 0.001s
im_detect: 2098/4024 0.228s 0.001s
im_detect: 2099/4024 0.228s 0.001s
im_detect: 2100/4024 0.228s 0.001s
im_detect: 2101/4024 0.228s 0.001s
im_detect: 2102/4024 0.228s 0.001s
im_detect: 2103/4024 0.228s 0.001s
im_detect: 2104/4024 0.228s 0.001s
im_detect: 2105/4024 0.228s 0.001s
im_detect: 2106/4024 0.228s 0.001s
im_detect: 2107/4024 0.228s 0.001s
im_detect: 2108/4024 0.228s 0.001s
im_detect: 2109/4024 0.228s 0.001s
im_detect: 2110/4024 0.228s 0.001s
im_detect: 2111/4024 0.228s 0.001s
im_detect: 2112/4024 0.228s 0.001s
im_detect: 2113/4024 0.228s 0.001s
im_detect: 2114/4024 0.228s 0.001s
im_detect: 2115/4024 0.228s 0.001s
im_detect: 2116/4024 0.228s 0.001s
im_detect: 2117/4024 0.228s 0.001s
im_detect: 2118/4024 0.228s 0.001s
im_detect: 2119/4024 0.228s 0.001s
im_detect: 2120/4024 0.228s 0.001s
im_detect: 2121/4024 0.228s 0.001s
im_detect: 2122/4024 0.228s 0.001s
im_detect: 2123/4024 0.228s 0.001s
im_detect: 2124/4024 0.228s 0.001s
im_detect: 2125/4024 0.228s 0.001s
im_detect: 2126/4024 0.228s 0.001s
im_detect: 2127/4024 0.228s 0.001s
im_detect: 2128/4024 0.228s 0.001s
im_detect: 2129/4024 0.228s 0.001s
im_detect: 2130/4024 0.228s 0.001s
im_detect: 2131/4024 0.228s 0.001s
im_detect: 2132/4024 0.228s 0.001s
im_detect: 2133/4024 0.228s 0.001s
im_detect: 2134/4024 0.228s 0.001s
im_detect: 2135/4024 0.228s 0.001s
im_detect: 2136/4024 0.228s 0.001s
im_detect: 2137/4024 0.228s 0.001s
im_detect: 2138/4024 0.228s 0.001s
im_detect: 2139/4024 0.228s 0.001s
im_detect: 2140/4024 0.228s 0.001s
im_detect: 2141/4024 0.228s 0.001s
im_detect: 2142/4024 0.228s 0.001s
im_detect: 2143/4024 0.228s 0.001s
im_detect: 2144/4024 0.228s 0.001s
im_detect: 2145/4024 0.228s 0.001s
im_detect: 2146/4024 0.228s 0.001s
im_detect: 2147/4024 0.228s 0.001s
im_detect: 2148/4024 0.228s 0.001s
im_detect: 2149/4024 0.228s 0.001s
im_detect: 2150/4024 0.228s 0.001s
im_detect: 2151/4024 0.228s 0.001s
im_detect: 2152/4024 0.228s 0.001s
im_detect: 2153/4024 0.228s 0.001s
im_detect: 2154/4024 0.228s 0.001s
im_detect: 2155/4024 0.228s 0.001s
im_detect: 2156/4024 0.228s 0.001s
im_detect: 2157/4024 0.228s 0.001s
im_detect: 2158/4024 0.228s 0.001s
im_detect: 2159/4024 0.228s 0.001s
im_detect: 2160/4024 0.228s 0.001s
im_detect: 2161/4024 0.228s 0.001s
im_detect: 2162/4024 0.228s 0.001s
im_detect: 2163/4024 0.228s 0.001s
im_detect: 2164/4024 0.228s 0.001s
im_detect: 2165/4024 0.228s 0.001s
im_detect: 2166/4024 0.228s 0.001s
im_detect: 2167/4024 0.228s 0.001s
im_detect: 2168/4024 0.228s 0.001s
im_detect: 2169/4024 0.228s 0.001s
im_detect: 2170/4024 0.228s 0.001s
im_detect: 2171/4024 0.228s 0.001s
im_detect: 2172/4024 0.228s 0.001s
im_detect: 2173/4024 0.228s 0.001s
im_detect: 2174/4024 0.228s 0.001s
im_detect: 2175/4024 0.228s 0.001s
im_detect: 2176/4024 0.228s 0.001s
im_detect: 2177/4024 0.228s 0.001s
im_detect: 2178/4024 0.228s 0.001s
im_detect: 2179/4024 0.228s 0.001s
im_detect: 2180/4024 0.228s 0.001s
im_detect: 2181/4024 0.228s 0.001s
im_detect: 2182/4024 0.228s 0.001s
im_detect: 2183/4024 0.228s 0.001s
im_detect: 2184/4024 0.228s 0.001s
im_detect: 2185/4024 0.228s 0.001s
im_detect: 2186/4024 0.228s 0.001s
im_detect: 2187/4024 0.228s 0.001s
im_detect: 2188/4024 0.228s 0.001s
im_detect: 2189/4024 0.228s 0.001s
im_detect: 2190/4024 0.228s 0.001s
im_detect: 2191/4024 0.228s 0.001s
im_detect: 2192/4024 0.228s 0.001s
im_detect: 2193/4024 0.228s 0.001s
im_detect: 2194/4024 0.228s 0.001s
im_detect: 2195/4024 0.228s 0.001s
im_detect: 2196/4024 0.228s 0.001s
im_detect: 2197/4024 0.228s 0.001s
im_detect: 2198/4024 0.228s 0.001s
im_detect: 2199/4024 0.228s 0.001s
im_detect: 2200/4024 0.228s 0.001s
im_detect: 2201/4024 0.228s 0.001s
im_detect: 2202/4024 0.228s 0.001s
im_detect: 2203/4024 0.228s 0.001s
im_detect: 2204/4024 0.228s 0.001s
im_detect: 2205/4024 0.228s 0.001s
im_detect: 2206/4024 0.228s 0.001s
im_detect: 2207/4024 0.228s 0.001s
im_detect: 2208/4024 0.228s 0.001s
im_detect: 2209/4024 0.228s 0.001s
im_detect: 2210/4024 0.228s 0.001s
im_detect: 2211/4024 0.228s 0.001s
im_detect: 2212/4024 0.228s 0.001s
im_detect: 2213/4024 0.228s 0.001s
im_detect: 2214/4024 0.228s 0.001s
im_detect: 2215/4024 0.228s 0.001s
im_detect: 2216/4024 0.228s 0.001s
im_detect: 2217/4024 0.228s 0.001s
im_detect: 2218/4024 0.228s 0.001s
im_detect: 2219/4024 0.228s 0.001s
im_detect: 2220/4024 0.228s 0.001s
im_detect: 2221/4024 0.228s 0.001s
im_detect: 2222/4024 0.228s 0.001s
im_detect: 2223/4024 0.228s 0.001s
im_detect: 2224/4024 0.228s 0.001s
im_detect: 2225/4024 0.228s 0.001s
im_detect: 2226/4024 0.228s 0.001s
im_detect: 2227/4024 0.228s 0.001s
im_detect: 2228/4024 0.228s 0.001s
im_detect: 2229/4024 0.228s 0.001s
im_detect: 2230/4024 0.228s 0.001s
im_detect: 2231/4024 0.228s 0.001s
im_detect: 2232/4024 0.228s 0.001s
im_detect: 2233/4024 0.228s 0.001s
im_detect: 2234/4024 0.228s 0.001s
im_detect: 2235/4024 0.228s 0.001s
im_detect: 2236/4024 0.228s 0.001s
im_detect: 2237/4024 0.228s 0.001s
im_detect: 2238/4024 0.228s 0.001s
im_detect: 2239/4024 0.228s 0.001s
im_detect: 2240/4024 0.228s 0.001s
im_detect: 2241/4024 0.228s 0.001s
im_detect: 2242/4024 0.228s 0.001s
im_detect: 2243/4024 0.228s 0.001s
im_detect: 2244/4024 0.228s 0.001s
im_detect: 2245/4024 0.228s 0.001s
im_detect: 2246/4024 0.228s 0.001s
im_detect: 2247/4024 0.228s 0.001s
im_detect: 2248/4024 0.228s 0.001s
im_detect: 2249/4024 0.228s 0.001s
im_detect: 2250/4024 0.228s 0.001s
im_detect: 2251/4024 0.228s 0.001s
im_detect: 2252/4024 0.228s 0.001s
im_detect: 2253/4024 0.228s 0.001s
im_detect: 2254/4024 0.228s 0.001s
im_detect: 2255/4024 0.228s 0.001s
im_detect: 2256/4024 0.228s 0.001s
im_detect: 2257/4024 0.228s 0.001s
im_detect: 2258/4024 0.228s 0.001s
im_detect: 2259/4024 0.228s 0.001s
im_detect: 2260/4024 0.228s 0.001s
im_detect: 2261/4024 0.228s 0.001s
im_detect: 2262/4024 0.228s 0.001s
im_detect: 2263/4024 0.228s 0.001s
im_detect: 2264/4024 0.228s 0.001s
im_detect: 2265/4024 0.228s 0.001s
im_detect: 2266/4024 0.228s 0.001s
im_detect: 2267/4024 0.228s 0.001s
im_detect: 2268/4024 0.228s 0.001s
im_detect: 2269/4024 0.228s 0.001s
im_detect: 2270/4024 0.228s 0.001s
im_detect: 2271/4024 0.228s 0.001s
im_detect: 2272/4024 0.228s 0.001s
im_detect: 2273/4024 0.228s 0.001s
im_detect: 2274/4024 0.228s 0.001s
im_detect: 2275/4024 0.228s 0.001s
im_detect: 2276/4024 0.228s 0.001s
im_detect: 2277/4024 0.228s 0.001s
im_detect: 2278/4024 0.228s 0.001s
im_detect: 2279/4024 0.228s 0.001s
im_detect: 2280/4024 0.228s 0.001s
im_detect: 2281/4024 0.228s 0.001s
im_detect: 2282/4024 0.228s 0.001s
im_detect: 2283/4024 0.228s 0.001s
im_detect: 2284/4024 0.228s 0.001s
im_detect: 2285/4024 0.228s 0.001s
im_detect: 2286/4024 0.228s 0.001s
im_detect: 2287/4024 0.228s 0.001s
im_detect: 2288/4024 0.228s 0.001s
im_detect: 2289/4024 0.228s 0.001s
im_detect: 2290/4024 0.228s 0.001s
im_detect: 2291/4024 0.228s 0.001s
im_detect: 2292/4024 0.228s 0.001s
im_detect: 2293/4024 0.228s 0.001s
im_detect: 2294/4024 0.228s 0.001s
im_detect: 2295/4024 0.228s 0.001s
im_detect: 2296/4024 0.228s 0.001s
im_detect: 2297/4024 0.228s 0.001s
im_detect: 2298/4024 0.228s 0.001s
im_detect: 2299/4024 0.228s 0.001s
im_detect: 2300/4024 0.228s 0.001s
im_detect: 2301/4024 0.228s 0.001s
im_detect: 2302/4024 0.228s 0.001s
im_detect: 2303/4024 0.228s 0.001s
im_detect: 2304/4024 0.228s 0.001s
im_detect: 2305/4024 0.228s 0.001s
im_detect: 2306/4024 0.228s 0.001s
im_detect: 2307/4024 0.228s 0.001s
im_detect: 2308/4024 0.228s 0.001s
im_detect: 2309/4024 0.228s 0.001s
im_detect: 2310/4024 0.228s 0.001s
im_detect: 2311/4024 0.228s 0.001s
im_detect: 2312/4024 0.228s 0.001s
im_detect: 2313/4024 0.228s 0.001s
im_detect: 2314/4024 0.228s 0.001s
im_detect: 2315/4024 0.228s 0.001s
im_detect: 2316/4024 0.228s 0.001s
im_detect: 2317/4024 0.228s 0.001s
im_detect: 2318/4024 0.228s 0.001s
im_detect: 2319/4024 0.228s 0.001s
im_detect: 2320/4024 0.228s 0.001s
im_detect: 2321/4024 0.228s 0.001s
im_detect: 2322/4024 0.228s 0.001s
im_detect: 2323/4024 0.228s 0.001s
im_detect: 2324/4024 0.228s 0.001s
im_detect: 2325/4024 0.228s 0.001s
im_detect: 2326/4024 0.228s 0.001s
im_detect: 2327/4024 0.228s 0.001s
im_detect: 2328/4024 0.228s 0.001s
im_detect: 2329/4024 0.228s 0.001s
im_detect: 2330/4024 0.228s 0.001s
im_detect: 2331/4024 0.228s 0.001s
im_detect: 2332/4024 0.228s 0.001s
im_detect: 2333/4024 0.228s 0.001s
im_detect: 2334/4024 0.228s 0.001s
im_detect: 2335/4024 0.228s 0.001s
im_detect: 2336/4024 0.228s 0.001s
im_detect: 2337/4024 0.228s 0.001s
im_detect: 2338/4024 0.228s 0.001s
im_detect: 2339/4024 0.228s 0.001s
im_detect: 2340/4024 0.228s 0.001s
im_detect: 2341/4024 0.228s 0.001s
im_detect: 2342/4024 0.228s 0.001s
im_detect: 2343/4024 0.228s 0.001s
im_detect: 2344/4024 0.228s 0.001s
im_detect: 2345/4024 0.228s 0.001s
im_detect: 2346/4024 0.228s 0.001s
im_detect: 2347/4024 0.228s 0.001s
im_detect: 2348/4024 0.228s 0.001s
im_detect: 2349/4024 0.228s 0.001s
im_detect: 2350/4024 0.228s 0.001s
im_detect: 2351/4024 0.228s 0.001s
im_detect: 2352/4024 0.228s 0.001s
im_detect: 2353/4024 0.228s 0.001s
im_detect: 2354/4024 0.228s 0.001s
im_detect: 2355/4024 0.228s 0.001s
im_detect: 2356/4024 0.228s 0.001s
im_detect: 2357/4024 0.228s 0.001s
im_detect: 2358/4024 0.228s 0.001s
im_detect: 2359/4024 0.228s 0.001s
im_detect: 2360/4024 0.228s 0.001s
im_detect: 2361/4024 0.228s 0.001s
im_detect: 2362/4024 0.228s 0.001s
im_detect: 2363/4024 0.228s 0.001s
im_detect: 2364/4024 0.228s 0.001s
im_detect: 2365/4024 0.228s 0.001s
im_detect: 2366/4024 0.228s 0.001s
im_detect: 2367/4024 0.228s 0.001s
im_detect: 2368/4024 0.228s 0.001s
im_detect: 2369/4024 0.228s 0.001s
im_detect: 2370/4024 0.228s 0.001s
im_detect: 2371/4024 0.228s 0.001s
im_detect: 2372/4024 0.228s 0.001s
im_detect: 2373/4024 0.228s 0.001s
im_detect: 2374/4024 0.228s 0.001s
im_detect: 2375/4024 0.228s 0.001s
im_detect: 2376/4024 0.228s 0.001s
im_detect: 2377/4024 0.228s 0.001s
im_detect: 2378/4024 0.228s 0.001s
im_detect: 2379/4024 0.228s 0.001s
im_detect: 2380/4024 0.228s 0.001s
im_detect: 2381/4024 0.228s 0.001s
im_detect: 2382/4024 0.228s 0.001s
im_detect: 2383/4024 0.228s 0.001s
im_detect: 2384/4024 0.228s 0.001s
im_detect: 2385/4024 0.228s 0.001s
im_detect: 2386/4024 0.228s 0.001s
im_detect: 2387/4024 0.228s 0.001s
im_detect: 2388/4024 0.228s 0.001s
im_detect: 2389/4024 0.228s 0.001s
im_detect: 2390/4024 0.228s 0.001s
im_detect: 2391/4024 0.228s 0.001s
im_detect: 2392/4024 0.228s 0.001s
im_detect: 2393/4024 0.228s 0.001s
im_detect: 2394/4024 0.228s 0.001s
im_detect: 2395/4024 0.228s 0.001s
im_detect: 2396/4024 0.228s 0.001s
im_detect: 2397/4024 0.228s 0.001s
im_detect: 2398/4024 0.228s 0.001s
im_detect: 2399/4024 0.228s 0.001s
im_detect: 2400/4024 0.228s 0.001s
im_detect: 2401/4024 0.228s 0.001s
im_detect: 2402/4024 0.228s 0.001s
im_detect: 2403/4024 0.228s 0.001s
im_detect: 2404/4024 0.228s 0.001s
im_detect: 2405/4024 0.228s 0.001s
im_detect: 2406/4024 0.228s 0.001s
im_detect: 2407/4024 0.228s 0.001s
im_detect: 2408/4024 0.228s 0.001s
im_detect: 2409/4024 0.228s 0.001s
im_detect: 2410/4024 0.228s 0.001s
im_detect: 2411/4024 0.228s 0.001s
im_detect: 2412/4024 0.228s 0.001s
im_detect: 2413/4024 0.228s 0.001s
im_detect: 2414/4024 0.228s 0.001s
im_detect: 2415/4024 0.228s 0.001s
im_detect: 2416/4024 0.228s 0.001s
im_detect: 2417/4024 0.228s 0.001s
im_detect: 2418/4024 0.228s 0.001s
im_detect: 2419/4024 0.228s 0.001s
im_detect: 2420/4024 0.228s 0.001s
im_detect: 2421/4024 0.228s 0.001s
im_detect: 2422/4024 0.228s 0.001s
im_detect: 2423/4024 0.228s 0.001s
im_detect: 2424/4024 0.228s 0.001s
im_detect: 2425/4024 0.228s 0.001s
im_detect: 2426/4024 0.228s 0.001s
im_detect: 2427/4024 0.228s 0.001s
im_detect: 2428/4024 0.228s 0.001s
im_detect: 2429/4024 0.228s 0.001s
im_detect: 2430/4024 0.228s 0.001s
im_detect: 2431/4024 0.228s 0.001s
im_detect: 2432/4024 0.228s 0.001s
im_detect: 2433/4024 0.228s 0.001s
im_detect: 2434/4024 0.228s 0.001s
im_detect: 2435/4024 0.228s 0.001s
im_detect: 2436/4024 0.228s 0.001s
im_detect: 2437/4024 0.228s 0.001s
im_detect: 2438/4024 0.228s 0.001s
im_detect: 2439/4024 0.228s 0.001s
im_detect: 2440/4024 0.228s 0.001s
im_detect: 2441/4024 0.228s 0.001s
im_detect: 2442/4024 0.228s 0.001s
im_detect: 2443/4024 0.228s 0.001s
im_detect: 2444/4024 0.228s 0.001s
im_detect: 2445/4024 0.228s 0.001s
im_detect: 2446/4024 0.228s 0.001s
im_detect: 2447/4024 0.228s 0.001s
im_detect: 2448/4024 0.228s 0.001s
im_detect: 2449/4024 0.228s 0.001s
im_detect: 2450/4024 0.228s 0.001s
im_detect: 2451/4024 0.228s 0.001s
im_detect: 2452/4024 0.228s 0.001s
im_detect: 2453/4024 0.228s 0.001s
im_detect: 2454/4024 0.228s 0.001s
im_detect: 2455/4024 0.228s 0.001s
im_detect: 2456/4024 0.228s 0.001s
im_detect: 2457/4024 0.228s 0.001s
im_detect: 2458/4024 0.228s 0.001s
im_detect: 2459/4024 0.228s 0.001s
im_detect: 2460/4024 0.228s 0.001s
im_detect: 2461/4024 0.228s 0.001s
im_detect: 2462/4024 0.228s 0.001s
im_detect: 2463/4024 0.228s 0.001s
im_detect: 2464/4024 0.228s 0.001s
im_detect: 2465/4024 0.228s 0.001s
im_detect: 2466/4024 0.228s 0.001s
im_detect: 2467/4024 0.228s 0.001s
im_detect: 2468/4024 0.228s 0.001s
im_detect: 2469/4024 0.228s 0.001s
im_detect: 2470/4024 0.228s 0.001s
im_detect: 2471/4024 0.228s 0.001s
im_detect: 2472/4024 0.228s 0.001s
im_detect: 2473/4024 0.228s 0.001s
im_detect: 2474/4024 0.228s 0.001s
im_detect: 2475/4024 0.228s 0.001s
im_detect: 2476/4024 0.228s 0.001s
im_detect: 2477/4024 0.228s 0.001s
im_detect: 2478/4024 0.228s 0.001s
im_detect: 2479/4024 0.228s 0.001s
im_detect: 2480/4024 0.228s 0.001s
im_detect: 2481/4024 0.228s 0.001s
im_detect: 2482/4024 0.228s 0.001s
im_detect: 2483/4024 0.228s 0.001s
im_detect: 2484/4024 0.228s 0.001s
im_detect: 2485/4024 0.228s 0.001s
im_detect: 2486/4024 0.228s 0.001s
im_detect: 2487/4024 0.228s 0.001s
im_detect: 2488/4024 0.228s 0.001s
im_detect: 2489/4024 0.228s 0.001s
im_detect: 2490/4024 0.228s 0.001s
im_detect: 2491/4024 0.228s 0.001s
im_detect: 2492/4024 0.228s 0.001s
im_detect: 2493/4024 0.228s 0.001s
im_detect: 2494/4024 0.228s 0.001s
im_detect: 2495/4024 0.228s 0.001s
im_detect: 2496/4024 0.228s 0.001s
im_detect: 2497/4024 0.228s 0.001s
im_detect: 2498/4024 0.228s 0.001s
im_detect: 2499/4024 0.228s 0.001s
im_detect: 2500/4024 0.228s 0.001s
im_detect: 2501/4024 0.228s 0.001s
im_detect: 2502/4024 0.228s 0.001s
im_detect: 2503/4024 0.228s 0.001s
im_detect: 2504/4024 0.228s 0.001s
im_detect: 2505/4024 0.228s 0.001s
im_detect: 2506/4024 0.228s 0.001s
im_detect: 2507/4024 0.228s 0.001s
im_detect: 2508/4024 0.228s 0.001s
im_detect: 2509/4024 0.228s 0.001s
im_detect: 2510/4024 0.228s 0.001s
im_detect: 2511/4024 0.228s 0.001s
im_detect: 2512/4024 0.228s 0.001s
im_detect: 2513/4024 0.228s 0.001s
im_detect: 2514/4024 0.228s 0.001s
im_detect: 2515/4024 0.228s 0.001s
im_detect: 2516/4024 0.228s 0.001s
im_detect: 2517/4024 0.228s 0.001s
im_detect: 2518/4024 0.228s 0.001s
im_detect: 2519/4024 0.228s 0.001s
im_detect: 2520/4024 0.228s 0.001s
im_detect: 2521/4024 0.228s 0.001s
im_detect: 2522/4024 0.228s 0.001s
im_detect: 2523/4024 0.228s 0.001s
im_detect: 2524/4024 0.227s 0.001s
im_detect: 2525/4024 0.227s 0.001s
im_detect: 2526/4024 0.227s 0.001s
im_detect: 2527/4024 0.227s 0.001s
im_detect: 2528/4024 0.227s 0.001s
im_detect: 2529/4024 0.227s 0.001s
im_detect: 2530/4024 0.227s 0.001s
im_detect: 2531/4024 0.227s 0.001s
im_detect: 2532/4024 0.227s 0.001s
im_detect: 2533/4024 0.227s 0.001s
im_detect: 2534/4024 0.227s 0.001s
im_detect: 2535/4024 0.227s 0.001s
im_detect: 2536/4024 0.227s 0.001s
im_detect: 2537/4024 0.227s 0.001s
im_detect: 2538/4024 0.227s 0.001s
im_detect: 2539/4024 0.227s 0.001s
im_detect: 2540/4024 0.227s 0.001s
im_detect: 2541/4024 0.227s 0.001s
im_detect: 2542/4024 0.227s 0.001s
im_detect: 2543/4024 0.227s 0.001s
im_detect: 2544/4024 0.227s 0.001s
im_detect: 2545/4024 0.227s 0.001s
im_detect: 2546/4024 0.227s 0.001s
im_detect: 2547/4024 0.227s 0.001s
im_detect: 2548/4024 0.227s 0.001s
im_detect: 2549/4024 0.227s 0.001s
im_detect: 2550/4024 0.227s 0.001s
im_detect: 2551/4024 0.227s 0.001s
im_detect: 2552/4024 0.227s 0.001s
im_detect: 2553/4024 0.227s 0.001s
im_detect: 2554/4024 0.227s 0.001s
im_detect: 2555/4024 0.227s 0.001s
im_detect: 2556/4024 0.227s 0.001s
im_detect: 2557/4024 0.227s 0.001s
im_detect: 2558/4024 0.227s 0.001s
im_detect: 2559/4024 0.227s 0.001s
im_detect: 2560/4024 0.227s 0.001s
im_detect: 2561/4024 0.227s 0.001s
im_detect: 2562/4024 0.227s 0.001s
im_detect: 2563/4024 0.227s 0.001s
im_detect: 2564/4024 0.227s 0.001s
im_detect: 2565/4024 0.227s 0.001s
im_detect: 2566/4024 0.227s 0.001s
im_detect: 2567/4024 0.227s 0.001s
im_detect: 2568/4024 0.227s 0.001s
im_detect: 2569/4024 0.227s 0.001s
im_detect: 2570/4024 0.227s 0.001s
im_detect: 2571/4024 0.227s 0.001s
im_detect: 2572/4024 0.227s 0.001s
im_detect: 2573/4024 0.227s 0.001s
im_detect: 2574/4024 0.227s 0.001s
im_detect: 2575/4024 0.227s 0.001s
im_detect: 2576/4024 0.227s 0.001s
im_detect: 2577/4024 0.227s 0.001s
im_detect: 2578/4024 0.227s 0.001s
im_detect: 2579/4024 0.227s 0.001s
im_detect: 2580/4024 0.227s 0.001s
im_detect: 2581/4024 0.227s 0.001s
im_detect: 2582/4024 0.227s 0.001s
im_detect: 2583/4024 0.227s 0.001s
im_detect: 2584/4024 0.227s 0.001s
im_detect: 2585/4024 0.227s 0.001s
im_detect: 2586/4024 0.227s 0.001s
im_detect: 2587/4024 0.227s 0.001s
im_detect: 2588/4024 0.227s 0.001s
im_detect: 2589/4024 0.227s 0.001s
im_detect: 2590/4024 0.227s 0.001s
im_detect: 2591/4024 0.227s 0.001s
im_detect: 2592/4024 0.227s 0.001s
im_detect: 2593/4024 0.227s 0.001s
im_detect: 2594/4024 0.227s 0.001s
im_detect: 2595/4024 0.227s 0.001s
im_detect: 2596/4024 0.227s 0.001s
im_detect: 2597/4024 0.227s 0.001s
im_detect: 2598/4024 0.227s 0.001s
im_detect: 2599/4024 0.227s 0.001s
im_detect: 2600/4024 0.227s 0.001s
im_detect: 2601/4024 0.227s 0.001s
im_detect: 2602/4024 0.227s 0.001s
im_detect: 2603/4024 0.227s 0.001s
im_detect: 2604/4024 0.227s 0.001s
im_detect: 2605/4024 0.227s 0.001s
im_detect: 2606/4024 0.227s 0.001s
im_detect: 2607/4024 0.227s 0.001s
im_detect: 2608/4024 0.227s 0.001s
im_detect: 2609/4024 0.227s 0.001s
im_detect: 2610/4024 0.227s 0.001s
im_detect: 2611/4024 0.227s 0.001s
im_detect: 2612/4024 0.227s 0.001s
im_detect: 2613/4024 0.227s 0.001s
im_detect: 2614/4024 0.227s 0.001s
im_detect: 2615/4024 0.227s 0.001s
im_detect: 2616/4024 0.227s 0.001s
im_detect: 2617/4024 0.227s 0.001s
im_detect: 2618/4024 0.227s 0.001s
im_detect: 2619/4024 0.227s 0.001s
im_detect: 2620/4024 0.227s 0.001s
im_detect: 2621/4024 0.227s 0.001s
im_detect: 2622/4024 0.227s 0.001s
im_detect: 2623/4024 0.227s 0.001s
im_detect: 2624/4024 0.227s 0.001s
im_detect: 2625/4024 0.227s 0.001s
im_detect: 2626/4024 0.227s 0.001s
im_detect: 2627/4024 0.227s 0.001s
im_detect: 2628/4024 0.227s 0.001s
im_detect: 2629/4024 0.227s 0.001s
im_detect: 2630/4024 0.227s 0.001s
im_detect: 2631/4024 0.227s 0.001s
im_detect: 2632/4024 0.227s 0.001s
im_detect: 2633/4024 0.227s 0.001s
im_detect: 2634/4024 0.227s 0.001s
im_detect: 2635/4024 0.227s 0.001s
im_detect: 2636/4024 0.227s 0.001s
im_detect: 2637/4024 0.227s 0.001s
im_detect: 2638/4024 0.227s 0.001s
im_detect: 2639/4024 0.227s 0.001s
im_detect: 2640/4024 0.227s 0.001s
im_detect: 2641/4024 0.227s 0.001s
im_detect: 2642/4024 0.227s 0.001s
im_detect: 2643/4024 0.227s 0.001s
im_detect: 2644/4024 0.227s 0.001s
im_detect: 2645/4024 0.227s 0.001s
im_detect: 2646/4024 0.227s 0.001s
im_detect: 2647/4024 0.227s 0.001s
im_detect: 2648/4024 0.227s 0.001s
im_detect: 2649/4024 0.227s 0.001s
im_detect: 2650/4024 0.227s 0.001s
im_detect: 2651/4024 0.227s 0.001s
im_detect: 2652/4024 0.227s 0.001s
im_detect: 2653/4024 0.227s 0.001s
im_detect: 2654/4024 0.227s 0.001s
im_detect: 2655/4024 0.227s 0.001s
im_detect: 2656/4024 0.227s 0.001s
im_detect: 2657/4024 0.227s 0.001s
im_detect: 2658/4024 0.227s 0.001s
im_detect: 2659/4024 0.227s 0.001s
im_detect: 2660/4024 0.227s 0.001s
im_detect: 2661/4024 0.227s 0.001s
im_detect: 2662/4024 0.227s 0.001s
im_detect: 2663/4024 0.227s 0.001s
im_detect: 2664/4024 0.227s 0.001s
im_detect: 2665/4024 0.227s 0.001s
im_detect: 2666/4024 0.227s 0.001s
im_detect: 2667/4024 0.227s 0.001s
im_detect: 2668/4024 0.227s 0.001s
im_detect: 2669/4024 0.227s 0.001s
im_detect: 2670/4024 0.227s 0.001s
im_detect: 2671/4024 0.227s 0.001s
im_detect: 2672/4024 0.227s 0.001s
im_detect: 2673/4024 0.227s 0.001s
im_detect: 2674/4024 0.227s 0.001s
im_detect: 2675/4024 0.227s 0.001s
im_detect: 2676/4024 0.227s 0.001s
im_detect: 2677/4024 0.227s 0.001s
im_detect: 2678/4024 0.227s 0.001s
im_detect: 2679/4024 0.227s 0.001s
im_detect: 2680/4024 0.227s 0.001s
im_detect: 2681/4024 0.227s 0.001s
im_detect: 2682/4024 0.227s 0.001s
im_detect: 2683/4024 0.227s 0.001s
im_detect: 2684/4024 0.227s 0.001s
im_detect: 2685/4024 0.227s 0.001s
im_detect: 2686/4024 0.227s 0.001s
im_detect: 2687/4024 0.227s 0.001s
im_detect: 2688/4024 0.227s 0.001s
im_detect: 2689/4024 0.227s 0.001s
im_detect: 2690/4024 0.227s 0.001s
im_detect: 2691/4024 0.227s 0.001s
im_detect: 2692/4024 0.227s 0.001s
im_detect: 2693/4024 0.227s 0.001s
im_detect: 2694/4024 0.227s 0.001s
im_detect: 2695/4024 0.227s 0.001s
im_detect: 2696/4024 0.227s 0.001s
im_detect: 2697/4024 0.227s 0.001s
im_detect: 2698/4024 0.227s 0.001s
im_detect: 2699/4024 0.227s 0.001s
im_detect: 2700/4024 0.227s 0.001s
im_detect: 2701/4024 0.227s 0.001s
im_detect: 2702/4024 0.227s 0.001s
im_detect: 2703/4024 0.227s 0.001s
im_detect: 2704/4024 0.227s 0.001s
im_detect: 2705/4024 0.227s 0.001s
im_detect: 2706/4024 0.227s 0.001s
im_detect: 2707/4024 0.227s 0.001s
im_detect: 2708/4024 0.227s 0.001s
im_detect: 2709/4024 0.227s 0.001s
im_detect: 2710/4024 0.227s 0.001s
im_detect: 2711/4024 0.227s 0.001s
im_detect: 2712/4024 0.227s 0.001s
im_detect: 2713/4024 0.227s 0.001s
im_detect: 2714/4024 0.227s 0.001s
im_detect: 2715/4024 0.227s 0.001s
im_detect: 2716/4024 0.227s 0.001s
im_detect: 2717/4024 0.227s 0.001s
im_detect: 2718/4024 0.227s 0.001s
im_detect: 2719/4024 0.227s 0.001s
im_detect: 2720/4024 0.227s 0.001s
im_detect: 2721/4024 0.227s 0.001s
im_detect: 2722/4024 0.227s 0.001s
im_detect: 2723/4024 0.227s 0.001s
im_detect: 2724/4024 0.227s 0.001s
im_detect: 2725/4024 0.227s 0.001s
im_detect: 2726/4024 0.227s 0.001s
im_detect: 2727/4024 0.227s 0.001s
im_detect: 2728/4024 0.227s 0.001s
im_detect: 2729/4024 0.227s 0.001s
im_detect: 2730/4024 0.227s 0.001s
im_detect: 2731/4024 0.227s 0.001s
im_detect: 2732/4024 0.227s 0.001s
im_detect: 2733/4024 0.227s 0.001s
im_detect: 2734/4024 0.227s 0.001s
im_detect: 2735/4024 0.227s 0.001s
im_detect: 2736/4024 0.227s 0.001s
im_detect: 2737/4024 0.227s 0.001s
im_detect: 2738/4024 0.227s 0.001s
im_detect: 2739/4024 0.227s 0.001s
im_detect: 2740/4024 0.226s 0.001s
im_detect: 2741/4024 0.226s 0.001s
im_detect: 2742/4024 0.226s 0.001s
im_detect: 2743/4024 0.226s 0.001s
im_detect: 2744/4024 0.226s 0.001s
im_detect: 2745/4024 0.227s 0.001s
im_detect: 2746/4024 0.226s 0.001s
im_detect: 2747/4024 0.227s 0.001s
im_detect: 2748/4024 0.227s 0.001s
im_detect: 2749/4024 0.226s 0.001s
im_detect: 2750/4024 0.226s 0.001s
im_detect: 2751/4024 0.226s 0.001s
im_detect: 2752/4024 0.226s 0.001s
im_detect: 2753/4024 0.226s 0.001s
im_detect: 2754/4024 0.226s 0.001s
im_detect: 2755/4024 0.226s 0.001s
im_detect: 2756/4024 0.226s 0.001s
im_detect: 2757/4024 0.226s 0.001s
im_detect: 2758/4024 0.226s 0.001s
im_detect: 2759/4024 0.226s 0.001s
im_detect: 2760/4024 0.226s 0.001s
im_detect: 2761/4024 0.226s 0.001s
im_detect: 2762/4024 0.226s 0.001s
im_detect: 2763/4024 0.226s 0.001s
im_detect: 2764/4024 0.226s 0.001s
im_detect: 2765/4024 0.226s 0.001s
im_detect: 2766/4024 0.226s 0.001s
im_detect: 2767/4024 0.226s 0.001s
im_detect: 2768/4024 0.226s 0.001s
im_detect: 2769/4024 0.226s 0.001s
im_detect: 2770/4024 0.226s 0.001s
im_detect: 2771/4024 0.226s 0.001s
im_detect: 2772/4024 0.226s 0.001s
im_detect: 2773/4024 0.226s 0.001s
im_detect: 2774/4024 0.226s 0.001s
im_detect: 2775/4024 0.226s 0.001s
im_detect: 2776/4024 0.226s 0.001s
im_detect: 2777/4024 0.226s 0.001s
im_detect: 2778/4024 0.226s 0.001s
im_detect: 2779/4024 0.226s 0.001s
im_detect: 2780/4024 0.226s 0.001s
im_detect: 2781/4024 0.226s 0.001s
im_detect: 2782/4024 0.226s 0.001s
im_detect: 2783/4024 0.226s 0.001s
im_detect: 2784/4024 0.226s 0.001s
im_detect: 2785/4024 0.226s 0.001s
im_detect: 2786/4024 0.226s 0.001s
im_detect: 2787/4024 0.226s 0.001s
im_detect: 2788/4024 0.226s 0.001s
im_detect: 2789/4024 0.226s 0.001s
im_detect: 2790/4024 0.226s 0.001s
im_detect: 2791/4024 0.226s 0.001s
im_detect: 2792/4024 0.226s 0.001s
im_detect: 2793/4024 0.226s 0.001s
im_detect: 2794/4024 0.226s 0.001s
im_detect: 2795/4024 0.226s 0.001s
im_detect: 2796/4024 0.226s 0.001s
im_detect: 2797/4024 0.226s 0.001s
im_detect: 2798/4024 0.226s 0.001s
im_detect: 2799/4024 0.226s 0.001s
im_detect: 2800/4024 0.226s 0.001s
im_detect: 2801/4024 0.226s 0.001s
im_detect: 2802/4024 0.226s 0.001s
im_detect: 2803/4024 0.226s 0.001s
im_detect: 2804/4024 0.226s 0.001s
im_detect: 2805/4024 0.226s 0.001s
im_detect: 2806/4024 0.226s 0.001s
im_detect: 2807/4024 0.226s 0.001s
im_detect: 2808/4024 0.226s 0.001s
im_detect: 2809/4024 0.226s 0.001s
im_detect: 2810/4024 0.226s 0.001s
im_detect: 2811/4024 0.226s 0.001s
im_detect: 2812/4024 0.226s 0.001s
im_detect: 2813/4024 0.226s 0.001s
im_detect: 2814/4024 0.226s 0.001s
im_detect: 2815/4024 0.226s 0.001s
im_detect: 2816/4024 0.226s 0.001s
im_detect: 2817/4024 0.226s 0.001s
im_detect: 2818/4024 0.226s 0.001s
im_detect: 2819/4024 0.226s 0.001s
im_detect: 2820/4024 0.226s 0.001s
im_detect: 2821/4024 0.226s 0.001s
im_detect: 2822/4024 0.226s 0.001s
im_detect: 2823/4024 0.226s 0.001s
im_detect: 2824/4024 0.226s 0.001s
im_detect: 2825/4024 0.226s 0.001s
im_detect: 2826/4024 0.226s 0.001s
im_detect: 2827/4024 0.226s 0.001s
im_detect: 2828/4024 0.226s 0.001s
im_detect: 2829/4024 0.226s 0.001s
im_detect: 2830/4024 0.226s 0.001s
im_detect: 2831/4024 0.226s 0.001s
im_detect: 2832/4024 0.226s 0.001s
im_detect: 2833/4024 0.226s 0.001s
im_detect: 2834/4024 0.226s 0.001s
im_detect: 2835/4024 0.226s 0.001s
im_detect: 2836/4024 0.226s 0.001s
im_detect: 2837/4024 0.226s 0.001s
im_detect: 2838/4024 0.226s 0.001s
im_detect: 2839/4024 0.226s 0.001s
im_detect: 2840/4024 0.226s 0.001s
im_detect: 2841/4024 0.226s 0.001s
im_detect: 2842/4024 0.226s 0.001s
im_detect: 2843/4024 0.226s 0.001s
im_detect: 2844/4024 0.226s 0.001s
im_detect: 2845/4024 0.226s 0.001s
im_detect: 2846/4024 0.226s 0.001s
im_detect: 2847/4024 0.226s 0.001s
im_detect: 2848/4024 0.226s 0.001s
im_detect: 2849/4024 0.226s 0.001s
im_detect: 2850/4024 0.226s 0.001s
im_detect: 2851/4024 0.226s 0.001s
im_detect: 2852/4024 0.226s 0.001s
im_detect: 2853/4024 0.226s 0.001s
im_detect: 2854/4024 0.226s 0.001s
im_detect: 2855/4024 0.226s 0.001s
im_detect: 2856/4024 0.226s 0.001s
im_detect: 2857/4024 0.226s 0.001s
im_detect: 2858/4024 0.226s 0.001s
im_detect: 2859/4024 0.226s 0.001s
im_detect: 2860/4024 0.226s 0.001s
im_detect: 2861/4024 0.226s 0.001s
im_detect: 2862/4024 0.226s 0.001s
im_detect: 2863/4024 0.226s 0.001s
im_detect: 2864/4024 0.226s 0.001s
im_detect: 2865/4024 0.226s 0.001s
im_detect: 2866/4024 0.226s 0.001s
im_detect: 2867/4024 0.226s 0.001s
im_detect: 2868/4024 0.226s 0.001s
im_detect: 2869/4024 0.226s 0.001s
im_detect: 2870/4024 0.226s 0.001s
im_detect: 2871/4024 0.226s 0.001s
im_detect: 2872/4024 0.226s 0.001s
im_detect: 2873/4024 0.226s 0.001s
im_detect: 2874/4024 0.226s 0.001s
im_detect: 2875/4024 0.226s 0.001s
im_detect: 2876/4024 0.226s 0.001s
im_detect: 2877/4024 0.226s 0.001s
im_detect: 2878/4024 0.226s 0.001s
im_detect: 2879/4024 0.226s 0.001s
im_detect: 2880/4024 0.226s 0.001s
im_detect: 2881/4024 0.226s 0.001s
im_detect: 2882/4024 0.226s 0.001s
im_detect: 2883/4024 0.226s 0.001s
im_detect: 2884/4024 0.226s 0.001s
im_detect: 2885/4024 0.226s 0.001s
im_detect: 2886/4024 0.226s 0.001s
im_detect: 2887/4024 0.226s 0.001s
im_detect: 2888/4024 0.226s 0.001s
im_detect: 2889/4024 0.226s 0.001s
im_detect: 2890/4024 0.226s 0.001s
im_detect: 2891/4024 0.226s 0.001s
im_detect: 2892/4024 0.226s 0.001s
im_detect: 2893/4024 0.226s 0.001s
im_detect: 2894/4024 0.226s 0.001s
im_detect: 2895/4024 0.226s 0.001s
im_detect: 2896/4024 0.226s 0.001s
im_detect: 2897/4024 0.226s 0.001s
im_detect: 2898/4024 0.226s 0.001s
im_detect: 2899/4024 0.226s 0.001s
im_detect: 2900/4024 0.226s 0.001s
im_detect: 2901/4024 0.226s 0.001s
im_detect: 2902/4024 0.226s 0.001s
im_detect: 2903/4024 0.226s 0.001s
im_detect: 2904/4024 0.226s 0.001s
im_detect: 2905/4024 0.226s 0.001s
im_detect: 2906/4024 0.226s 0.001s
im_detect: 2907/4024 0.226s 0.001s
im_detect: 2908/4024 0.226s 0.001s
im_detect: 2909/4024 0.226s 0.001s
im_detect: 2910/4024 0.226s 0.001s
im_detect: 2911/4024 0.226s 0.001s
im_detect: 2912/4024 0.226s 0.001s
im_detect: 2913/4024 0.226s 0.001s
im_detect: 2914/4024 0.226s 0.001s
im_detect: 2915/4024 0.226s 0.001s
im_detect: 2916/4024 0.226s 0.001s
im_detect: 2917/4024 0.226s 0.001s
im_detect: 2918/4024 0.226s 0.001s
im_detect: 2919/4024 0.226s 0.001s
im_detect: 2920/4024 0.226s 0.001s
im_detect: 2921/4024 0.226s 0.001s
im_detect: 2922/4024 0.226s 0.001s
im_detect: 2923/4024 0.226s 0.001s
im_detect: 2924/4024 0.226s 0.001s
im_detect: 2925/4024 0.226s 0.001s
im_detect: 2926/4024 0.226s 0.001s
im_detect: 2927/4024 0.226s 0.001s
im_detect: 2928/4024 0.226s 0.001s
im_detect: 2929/4024 0.226s 0.001s
im_detect: 2930/4024 0.226s 0.001s
im_detect: 2931/4024 0.226s 0.001s
im_detect: 2932/4024 0.226s 0.001s
im_detect: 2933/4024 0.226s 0.001s
im_detect: 2934/4024 0.225s 0.001s
im_detect: 2935/4024 0.225s 0.001s
im_detect: 2936/4024 0.225s 0.001s
im_detect: 2937/4024 0.225s 0.001s
im_detect: 2938/4024 0.225s 0.001s
im_detect: 2939/4024 0.225s 0.001s
im_detect: 2940/4024 0.225s 0.001s
im_detect: 2941/4024 0.225s 0.001s
im_detect: 2942/4024 0.225s 0.001s
im_detect: 2943/4024 0.225s 0.001s
im_detect: 2944/4024 0.225s 0.001s
im_detect: 2945/4024 0.225s 0.001s
im_detect: 2946/4024 0.225s 0.001s
im_detect: 2947/4024 0.225s 0.001s
im_detect: 2948/4024 0.225s 0.001s
im_detect: 2949/4024 0.225s 0.001s
im_detect: 2950/4024 0.225s 0.001s
im_detect: 2951/4024 0.225s 0.001s
im_detect: 2952/4024 0.225s 0.001s
im_detect: 2953/4024 0.225s 0.001s
im_detect: 2954/4024 0.225s 0.001s
im_detect: 2955/4024 0.225s 0.001s
im_detect: 2956/4024 0.225s 0.001s
im_detect: 2957/4024 0.225s 0.001s
im_detect: 2958/4024 0.225s 0.001s
im_detect: 2959/4024 0.225s 0.001s
im_detect: 2960/4024 0.225s 0.001s
im_detect: 2961/4024 0.225s 0.001s
im_detect: 2962/4024 0.225s 0.001s
im_detect: 2963/4024 0.225s 0.001s
im_detect: 2964/4024 0.225s 0.001s
im_detect: 2965/4024 0.225s 0.001s
im_detect: 2966/4024 0.225s 0.001s
im_detect: 2967/4024 0.225s 0.001s
im_detect: 2968/4024 0.225s 0.001s
im_detect: 2969/4024 0.225s 0.001s
im_detect: 2970/4024 0.225s 0.001s
im_detect: 2971/4024 0.225s 0.001s
im_detect: 2972/4024 0.225s 0.001s
im_detect: 2973/4024 0.225s 0.001s
im_detect: 2974/4024 0.225s 0.001s
im_detect: 2975/4024 0.225s 0.001s
im_detect: 2976/4024 0.225s 0.001s
im_detect: 2977/4024 0.225s 0.001s
im_detect: 2978/4024 0.225s 0.001s
im_detect: 2979/4024 0.225s 0.001s
im_detect: 2980/4024 0.225s 0.001s
im_detect: 2981/4024 0.225s 0.001s
im_detect: 2982/4024 0.225s 0.001s
im_detect: 2983/4024 0.225s 0.001s
im_detect: 2984/4024 0.225s 0.001s
im_detect: 2985/4024 0.225s 0.001s
im_detect: 2986/4024 0.225s 0.001s
im_detect: 2987/4024 0.225s 0.001s
im_detect: 2988/4024 0.225s 0.001s
im_detect: 2989/4024 0.225s 0.001s
im_detect: 2990/4024 0.225s 0.001s
im_detect: 2991/4024 0.225s 0.001s
im_detect: 2992/4024 0.225s 0.001s
im_detect: 2993/4024 0.225s 0.001s
im_detect: 2994/4024 0.225s 0.001s
im_detect: 2995/4024 0.225s 0.001s
im_detect: 2996/4024 0.225s 0.001s
im_detect: 2997/4024 0.225s 0.001s
im_detect: 2998/4024 0.225s 0.001s
im_detect: 2999/4024 0.225s 0.001s
im_detect: 3000/4024 0.225s 0.001s
im_detect: 3001/4024 0.225s 0.001s
im_detect: 3002/4024 0.225s 0.001s
im_detect: 3003/4024 0.225s 0.001s
im_detect: 3004/4024 0.225s 0.001s
im_detect: 3005/4024 0.225s 0.001s
im_detect: 3006/4024 0.225s 0.001s
im_detect: 3007/4024 0.225s 0.001s
im_detect: 3008/4024 0.225s 0.001s
im_detect: 3009/4024 0.225s 0.001s
im_detect: 3010/4024 0.225s 0.001s
im_detect: 3011/4024 0.225s 0.001s
im_detect: 3012/4024 0.225s 0.001s
im_detect: 3013/4024 0.225s 0.001s
im_detect: 3014/4024 0.225s 0.001s
im_detect: 3015/4024 0.225s 0.001s
im_detect: 3016/4024 0.225s 0.001s
im_detect: 3017/4024 0.225s 0.001s
im_detect: 3018/4024 0.225s 0.001s
im_detect: 3019/4024 0.225s 0.001s
im_detect: 3020/4024 0.225s 0.001s
im_detect: 3021/4024 0.225s 0.001s
im_detect: 3022/4024 0.225s 0.001s
im_detect: 3023/4024 0.225s 0.001s
im_detect: 3024/4024 0.225s 0.001s
im_detect: 3025/4024 0.225s 0.001s
im_detect: 3026/4024 0.225s 0.001s
im_detect: 3027/4024 0.225s 0.001s
im_detect: 3028/4024 0.225s 0.001s
im_detect: 3029/4024 0.225s 0.001s
im_detect: 3030/4024 0.225s 0.001s
im_detect: 3031/4024 0.225s 0.001s
im_detect: 3032/4024 0.225s 0.001s
im_detect: 3033/4024 0.225s 0.001s
im_detect: 3034/4024 0.225s 0.001s
im_detect: 3035/4024 0.225s 0.001s
im_detect: 3036/4024 0.225s 0.001s
im_detect: 3037/4024 0.225s 0.001s
im_detect: 3038/4024 0.225s 0.001s
im_detect: 3039/4024 0.225s 0.001s
im_detect: 3040/4024 0.225s 0.001s
im_detect: 3041/4024 0.225s 0.001s
im_detect: 3042/4024 0.225s 0.001s
im_detect: 3043/4024 0.225s 0.001s
im_detect: 3044/4024 0.225s 0.001s
im_detect: 3045/4024 0.225s 0.001s
im_detect: 3046/4024 0.225s 0.001s
im_detect: 3047/4024 0.225s 0.001s
im_detect: 3048/4024 0.225s 0.001s
im_detect: 3049/4024 0.225s 0.001s
im_detect: 3050/4024 0.225s 0.001s
im_detect: 3051/4024 0.225s 0.001s
im_detect: 3052/4024 0.225s 0.001s
im_detect: 3053/4024 0.225s 0.001s
im_detect: 3054/4024 0.225s 0.001s
im_detect: 3055/4024 0.225s 0.001s
im_detect: 3056/4024 0.225s 0.001s
im_detect: 3057/4024 0.225s 0.001s
im_detect: 3058/4024 0.225s 0.001s
im_detect: 3059/4024 0.225s 0.001s
im_detect: 3060/4024 0.225s 0.001s
im_detect: 3061/4024 0.225s 0.001s
im_detect: 3062/4024 0.225s 0.001s
im_detect: 3063/4024 0.225s 0.001s
im_detect: 3064/4024 0.225s 0.001s
im_detect: 3065/4024 0.225s 0.001s
im_detect: 3066/4024 0.225s 0.001s
im_detect: 3067/4024 0.225s 0.001s
im_detect: 3068/4024 0.225s 0.001s
im_detect: 3069/4024 0.225s 0.001s
im_detect: 3070/4024 0.225s 0.001s
im_detect: 3071/4024 0.225s 0.001s
im_detect: 3072/4024 0.225s 0.001s
im_detect: 3073/4024 0.225s 0.001s
im_detect: 3074/4024 0.225s 0.001s
im_detect: 3075/4024 0.225s 0.001s
im_detect: 3076/4024 0.225s 0.001s
im_detect: 3077/4024 0.225s 0.001s
im_detect: 3078/4024 0.225s 0.001s
im_detect: 3079/4024 0.225s 0.001s
im_detect: 3080/4024 0.225s 0.001s
im_detect: 3081/4024 0.225s 0.001s
im_detect: 3082/4024 0.225s 0.001s
im_detect: 3083/4024 0.225s 0.001s
im_detect: 3084/4024 0.225s 0.001s
im_detect: 3085/4024 0.225s 0.001s
im_detect: 3086/4024 0.225s 0.001s
im_detect: 3087/4024 0.225s 0.001s
im_detect: 3088/4024 0.225s 0.001s
im_detect: 3089/4024 0.225s 0.001s
im_detect: 3090/4024 0.225s 0.001s
im_detect: 3091/4024 0.225s 0.001s
im_detect: 3092/4024 0.225s 0.001s
im_detect: 3093/4024 0.225s 0.001s
im_detect: 3094/4024 0.225s 0.001s
im_detect: 3095/4024 0.225s 0.001s
im_detect: 3096/4024 0.225s 0.001s
im_detect: 3097/4024 0.225s 0.001s
im_detect: 3098/4024 0.225s 0.001s
im_detect: 3099/4024 0.225s 0.001s
im_detect: 3100/4024 0.225s 0.001s
im_detect: 3101/4024 0.225s 0.001s
im_detect: 3102/4024 0.225s 0.001s
im_detect: 3103/4024 0.225s 0.001s
im_detect: 3104/4024 0.225s 0.001s
im_detect: 3105/4024 0.225s 0.001s
im_detect: 3106/4024 0.225s 0.001s
im_detect: 3107/4024 0.225s 0.001s
im_detect: 3108/4024 0.225s 0.001s
im_detect: 3109/4024 0.225s 0.001s
im_detect: 3110/4024 0.225s 0.001s
im_detect: 3111/4024 0.225s 0.001s
im_detect: 3112/4024 0.225s 0.001s
im_detect: 3113/4024 0.225s 0.001s
im_detect: 3114/4024 0.225s 0.001s
im_detect: 3115/4024 0.225s 0.001s
im_detect: 3116/4024 0.225s 0.001s
im_detect: 3117/4024 0.225s 0.001s
im_detect: 3118/4024 0.225s 0.001s
im_detect: 3119/4024 0.225s 0.001s
im_detect: 3120/4024 0.225s 0.001s
im_detect: 3121/4024 0.225s 0.001s
im_detect: 3122/4024 0.225s 0.001s
im_detect: 3123/4024 0.225s 0.001s
im_detect: 3124/4024 0.225s 0.001s
im_detect: 3125/4024 0.225s 0.001s
im_detect: 3126/4024 0.225s 0.001s
im_detect: 3127/4024 0.225s 0.001s
im_detect: 3128/4024 0.225s 0.001s
im_detect: 3129/4024 0.225s 0.001s
im_detect: 3130/4024 0.225s 0.001s
im_detect: 3131/4024 0.225s 0.001s
im_detect: 3132/4024 0.225s 0.001s
im_detect: 3133/4024 0.225s 0.001s
im_detect: 3134/4024 0.225s 0.001s
im_detect: 3135/4024 0.225s 0.001s
im_detect: 3136/4024 0.225s 0.001s
im_detect: 3137/4024 0.225s 0.001s
im_detect: 3138/4024 0.225s 0.001s
im_detect: 3139/4024 0.225s 0.001s
im_detect: 3140/4024 0.225s 0.001s
im_detect: 3141/4024 0.225s 0.001s
im_detect: 3142/4024 0.225s 0.001s
im_detect: 3143/4024 0.225s 0.001s
im_detect: 3144/4024 0.225s 0.001s
im_detect: 3145/4024 0.225s 0.001s
im_detect: 3146/4024 0.225s 0.001s
im_detect: 3147/4024 0.225s 0.001s
im_detect: 3148/4024 0.225s 0.001s
im_detect: 3149/4024 0.225s 0.001s
im_detect: 3150/4024 0.225s 0.001s
im_detect: 3151/4024 0.225s 0.001s
im_detect: 3152/4024 0.225s 0.001s
im_detect: 3153/4024 0.225s 0.001s
im_detect: 3154/4024 0.225s 0.001s
im_detect: 3155/4024 0.225s 0.001s
im_detect: 3156/4024 0.225s 0.001s
im_detect: 3157/4024 0.225s 0.001s
im_detect: 3158/4024 0.225s 0.001s
im_detect: 3159/4024 0.225s 0.001s
im_detect: 3160/4024 0.225s 0.001s
im_detect: 3161/4024 0.225s 0.001s
im_detect: 3162/4024 0.225s 0.001s
im_detect: 3163/4024 0.225s 0.001s
im_detect: 3164/4024 0.225s 0.001s
im_detect: 3165/4024 0.225s 0.001s
im_detect: 3166/4024 0.225s 0.001s
im_detect: 3167/4024 0.225s 0.001s
im_detect: 3168/4024 0.225s 0.001s
im_detect: 3169/4024 0.225s 0.001s
im_detect: 3170/4024 0.225s 0.001s
im_detect: 3171/4024 0.225s 0.001s
im_detect: 3172/4024 0.225s 0.001s
im_detect: 3173/4024 0.225s 0.001s
im_detect: 3174/4024 0.225s 0.001s
im_detect: 3175/4024 0.225s 0.001s
im_detect: 3176/4024 0.225s 0.001s
im_detect: 3177/4024 0.225s 0.001s
im_detect: 3178/4024 0.225s 0.001s
im_detect: 3179/4024 0.225s 0.001s
im_detect: 3180/4024 0.225s 0.001s
im_detect: 3181/4024 0.225s 0.001s
im_detect: 3182/4024 0.225s 0.001s
im_detect: 3183/4024 0.225s 0.001s
im_detect: 3184/4024 0.225s 0.001s
im_detect: 3185/4024 0.225s 0.001s
im_detect: 3186/4024 0.225s 0.001s
im_detect: 3187/4024 0.225s 0.001s
im_detect: 3188/4024 0.225s 0.001s
im_detect: 3189/4024 0.225s 0.001s
im_detect: 3190/4024 0.225s 0.001s
im_detect: 3191/4024 0.225s 0.001s
im_detect: 3192/4024 0.225s 0.001s
im_detect: 3193/4024 0.225s 0.001s
im_detect: 3194/4024 0.225s 0.001s
im_detect: 3195/4024 0.225s 0.001s
im_detect: 3196/4024 0.225s 0.001s
im_detect: 3197/4024 0.225s 0.001s
im_detect: 3198/4024 0.225s 0.001s
im_detect: 3199/4024 0.225s 0.001s
im_detect: 3200/4024 0.225s 0.001s
im_detect: 3201/4024 0.225s 0.001s
im_detect: 3202/4024 0.225s 0.001s
im_detect: 3203/4024 0.225s 0.001s
im_detect: 3204/4024 0.225s 0.001s
im_detect: 3205/4024 0.225s 0.001s
im_detect: 3206/4024 0.225s 0.001s
im_detect: 3207/4024 0.225s 0.001s
im_detect: 3208/4024 0.225s 0.001s
im_detect: 3209/4024 0.225s 0.001s
im_detect: 3210/4024 0.225s 0.001s
im_detect: 3211/4024 0.225s 0.001s
im_detect: 3212/4024 0.225s 0.001s
im_detect: 3213/4024 0.225s 0.001s
im_detect: 3214/4024 0.225s 0.001s
im_detect: 3215/4024 0.225s 0.001s
im_detect: 3216/4024 0.225s 0.001s
im_detect: 3217/4024 0.225s 0.001s
im_detect: 3218/4024 0.225s 0.001s
im_detect: 3219/4024 0.225s 0.001s
im_detect: 3220/4024 0.225s 0.001s
im_detect: 3221/4024 0.225s 0.001s
im_detect: 3222/4024 0.225s 0.001s
im_detect: 3223/4024 0.225s 0.001s
im_detect: 3224/4024 0.225s 0.001s
im_detect: 3225/4024 0.225s 0.001s
im_detect: 3226/4024 0.225s 0.001s
im_detect: 3227/4024 0.225s 0.001s
im_detect: 3228/4024 0.225s 0.001s
im_detect: 3229/4024 0.225s 0.001s
im_detect: 3230/4024 0.225s 0.001s
im_detect: 3231/4024 0.225s 0.001s
im_detect: 3232/4024 0.225s 0.001s
im_detect: 3233/4024 0.225s 0.001s
im_detect: 3234/4024 0.225s 0.001s
im_detect: 3235/4024 0.225s 0.001s
im_detect: 3236/4024 0.225s 0.001s
im_detect: 3237/4024 0.225s 0.001s
im_detect: 3238/4024 0.225s 0.001s
im_detect: 3239/4024 0.225s 0.001s
im_detect: 3240/4024 0.225s 0.001s
im_detect: 3241/4024 0.225s 0.001s
im_detect: 3242/4024 0.225s 0.001s
im_detect: 3243/4024 0.225s 0.001s
im_detect: 3244/4024 0.225s 0.001s
im_detect: 3245/4024 0.225s 0.001s
im_detect: 3246/4024 0.225s 0.001s
im_detect: 3247/4024 0.225s 0.001s
im_detect: 3248/4024 0.225s 0.001s
im_detect: 3249/4024 0.225s 0.001s
im_detect: 3250/4024 0.225s 0.001s
im_detect: 3251/4024 0.225s 0.001s
im_detect: 3252/4024 0.225s 0.001s
im_detect: 3253/4024 0.225s 0.001s
im_detect: 3254/4024 0.225s 0.001s
im_detect: 3255/4024 0.225s 0.001s
im_detect: 3256/4024 0.225s 0.001s
im_detect: 3257/4024 0.224s 0.001s
im_detect: 3258/4024 0.224s 0.001s
im_detect: 3259/4024 0.224s 0.001s
im_detect: 3260/4024 0.224s 0.001s
im_detect: 3261/4024 0.224s 0.001s
im_detect: 3262/4024 0.224s 0.001s
im_detect: 3263/4024 0.224s 0.001s
im_detect: 3264/4024 0.224s 0.001s
im_detect: 3265/4024 0.224s 0.001s
im_detect: 3266/4024 0.224s 0.001s
im_detect: 3267/4024 0.224s 0.001s
im_detect: 3268/4024 0.224s 0.001s
im_detect: 3269/4024 0.224s 0.001s
im_detect: 3270/4024 0.224s 0.001s
im_detect: 3271/4024 0.224s 0.001s
im_detect: 3272/4024 0.224s 0.001s
im_detect: 3273/4024 0.224s 0.001s
im_detect: 3274/4024 0.224s 0.001s
im_detect: 3275/4024 0.224s 0.001s
im_detect: 3276/4024 0.224s 0.001s
im_detect: 3277/4024 0.224s 0.001s
im_detect: 3278/4024 0.224s 0.001s
im_detect: 3279/4024 0.224s 0.001s
im_detect: 3280/4024 0.224s 0.001s
im_detect: 3281/4024 0.224s 0.001s
im_detect: 3282/4024 0.224s 0.001s
im_detect: 3283/4024 0.224s 0.001s
im_detect: 3284/4024 0.224s 0.001s
im_detect: 3285/4024 0.224s 0.001s
im_detect: 3286/4024 0.224s 0.001s
im_detect: 3287/4024 0.224s 0.001s
im_detect: 3288/4024 0.224s 0.001s
im_detect: 3289/4024 0.224s 0.001s
im_detect: 3290/4024 0.224s 0.001s
im_detect: 3291/4024 0.224s 0.001s
im_detect: 3292/4024 0.224s 0.001s
im_detect: 3293/4024 0.224s 0.001s
im_detect: 3294/4024 0.224s 0.001s
im_detect: 3295/4024 0.224s 0.001s
im_detect: 3296/4024 0.224s 0.001s
im_detect: 3297/4024 0.224s 0.001s
im_detect: 3298/4024 0.224s 0.001s
im_detect: 3299/4024 0.224s 0.001s
im_detect: 3300/4024 0.224s 0.001s
im_detect: 3301/4024 0.224s 0.001s
im_detect: 3302/4024 0.224s 0.001s
im_detect: 3303/4024 0.224s 0.001s
im_detect: 3304/4024 0.224s 0.001s
im_detect: 3305/4024 0.224s 0.001s
im_detect: 3306/4024 0.224s 0.001s
im_detect: 3307/4024 0.224s 0.001s
im_detect: 3308/4024 0.224s 0.001s
im_detect: 3309/4024 0.224s 0.001s
im_detect: 3310/4024 0.224s 0.001s
im_detect: 3311/4024 0.224s 0.001s
im_detect: 3312/4024 0.224s 0.001s
im_detect: 3313/4024 0.224s 0.001s
im_detect: 3314/4024 0.224s 0.001s
im_detect: 3315/4024 0.224s 0.001s
im_detect: 3316/4024 0.224s 0.001s
im_detect: 3317/4024 0.224s 0.001s
im_detect: 3318/4024 0.224s 0.001s
im_detect: 3319/4024 0.224s 0.001s
im_detect: 3320/4024 0.224s 0.001s
im_detect: 3321/4024 0.224s 0.001s
im_detect: 3322/4024 0.224s 0.001s
im_detect: 3323/4024 0.224s 0.001s
im_detect: 3324/4024 0.224s 0.001s
im_detect: 3325/4024 0.224s 0.001s
im_detect: 3326/4024 0.224s 0.001s
im_detect: 3327/4024 0.224s 0.001s
im_detect: 3328/4024 0.224s 0.001s
im_detect: 3329/4024 0.224s 0.001s
im_detect: 3330/4024 0.224s 0.001s
im_detect: 3331/4024 0.224s 0.001s
im_detect: 3332/4024 0.224s 0.001s
im_detect: 3333/4024 0.224s 0.001s
im_detect: 3334/4024 0.224s 0.001s
im_detect: 3335/4024 0.224s 0.001s
im_detect: 3336/4024 0.224s 0.001s
im_detect: 3337/4024 0.224s 0.001s
im_detect: 3338/4024 0.224s 0.001s
im_detect: 3339/4024 0.224s 0.001s
im_detect: 3340/4024 0.224s 0.001s
im_detect: 3341/4024 0.224s 0.001s
im_detect: 3342/4024 0.224s 0.001s
im_detect: 3343/4024 0.224s 0.001s
im_detect: 3344/4024 0.224s 0.001s
im_detect: 3345/4024 0.224s 0.001s
im_detect: 3346/4024 0.224s 0.001s
im_detect: 3347/4024 0.224s 0.001s
im_detect: 3348/4024 0.224s 0.001s
im_detect: 3349/4024 0.224s 0.001s
im_detect: 3350/4024 0.224s 0.001s
im_detect: 3351/4024 0.224s 0.001s
im_detect: 3352/4024 0.224s 0.001s
im_detect: 3353/4024 0.224s 0.001s
im_detect: 3354/4024 0.224s 0.001s
im_detect: 3355/4024 0.224s 0.001s
im_detect: 3356/4024 0.224s 0.001s
im_detect: 3357/4024 0.224s 0.001s
im_detect: 3358/4024 0.224s 0.001s
im_detect: 3359/4024 0.224s 0.001s
im_detect: 3360/4024 0.224s 0.001s
im_detect: 3361/4024 0.224s 0.001s
im_detect: 3362/4024 0.224s 0.001s
im_detect: 3363/4024 0.224s 0.001s
im_detect: 3364/4024 0.224s 0.001s
im_detect: 3365/4024 0.224s 0.001s
im_detect: 3366/4024 0.224s 0.001s
im_detect: 3367/4024 0.224s 0.001s
im_detect: 3368/4024 0.224s 0.001s
im_detect: 3369/4024 0.224s 0.001s
im_detect: 3370/4024 0.224s 0.001s
im_detect: 3371/4024 0.224s 0.001s
im_detect: 3372/4024 0.224s 0.001s
im_detect: 3373/4024 0.224s 0.001s
im_detect: 3374/4024 0.224s 0.001s
im_detect: 3375/4024 0.224s 0.001s
im_detect: 3376/4024 0.224s 0.001s
im_detect: 3377/4024 0.224s 0.001s
im_detect: 3378/4024 0.224s 0.001s
im_detect: 3379/4024 0.224s 0.001s
im_detect: 3380/4024 0.224s 0.001s
im_detect: 3381/4024 0.224s 0.001s
im_detect: 3382/4024 0.224s 0.001s
im_detect: 3383/4024 0.224s 0.001s
im_detect: 3384/4024 0.224s 0.001s
im_detect: 3385/4024 0.224s 0.001s
im_detect: 3386/4024 0.224s 0.001s
im_detect: 3387/4024 0.224s 0.001s
im_detect: 3388/4024 0.224s 0.001s
im_detect: 3389/4024 0.224s 0.001s
im_detect: 3390/4024 0.224s 0.001s
im_detect: 3391/4024 0.224s 0.001s
im_detect: 3392/4024 0.224s 0.001s
im_detect: 3393/4024 0.224s 0.001s
im_detect: 3394/4024 0.224s 0.001s
im_detect: 3395/4024 0.224s 0.001s
im_detect: 3396/4024 0.224s 0.001s
im_detect: 3397/4024 0.224s 0.001s
im_detect: 3398/4024 0.224s 0.001s
im_detect: 3399/4024 0.224s 0.001s
im_detect: 3400/4024 0.224s 0.001s
im_detect: 3401/4024 0.224s 0.001s
im_detect: 3402/4024 0.224s 0.001s
im_detect: 3403/4024 0.224s 0.001s
im_detect: 3404/4024 0.224s 0.001s
im_detect: 3405/4024 0.224s 0.001s
im_detect: 3406/4024 0.224s 0.001s
im_detect: 3407/4024 0.224s 0.001s
im_detect: 3408/4024 0.224s 0.001s
im_detect: 3409/4024 0.224s 0.001s
im_detect: 3410/4024 0.224s 0.001s
im_detect: 3411/4024 0.224s 0.001s
im_detect: 3412/4024 0.224s 0.001s
im_detect: 3413/4024 0.224s 0.001s
im_detect: 3414/4024 0.224s 0.001s
im_detect: 3415/4024 0.224s 0.001s
im_detect: 3416/4024 0.224s 0.001s
im_detect: 3417/4024 0.224s 0.001s
im_detect: 3418/4024 0.224s 0.001s
im_detect: 3419/4024 0.224s 0.001s
im_detect: 3420/4024 0.224s 0.001s
im_detect: 3421/4024 0.224s 0.001s
im_detect: 3422/4024 0.224s 0.001s
im_detect: 3423/4024 0.224s 0.001s
im_detect: 3424/4024 0.224s 0.001s
im_detect: 3425/4024 0.224s 0.001s
im_detect: 3426/4024 0.224s 0.001s
im_detect: 3427/4024 0.224s 0.001s
im_detect: 3428/4024 0.224s 0.001s
im_detect: 3429/4024 0.224s 0.001s
im_detect: 3430/4024 0.224s 0.001s
im_detect: 3431/4024 0.224s 0.001s
im_detect: 3432/4024 0.224s 0.001s
im_detect: 3433/4024 0.224s 0.001s
im_detect: 3434/4024 0.224s 0.001s
im_detect: 3435/4024 0.224s 0.001s
im_detect: 3436/4024 0.224s 0.001s
im_detect: 3437/4024 0.224s 0.001s
im_detect: 3438/4024 0.224s 0.001s
im_detect: 3439/4024 0.224s 0.001s
im_detect: 3440/4024 0.224s 0.001s
im_detect: 3441/4024 0.224s 0.001s
im_detect: 3442/4024 0.224s 0.001s
im_detect: 3443/4024 0.224s 0.001s
im_detect: 3444/4024 0.224s 0.001s
im_detect: 3445/4024 0.224s 0.001s
im_detect: 3446/4024 0.224s 0.001s
im_detect: 3447/4024 0.224s 0.001s
im_detect: 3448/4024 0.224s 0.001s
im_detect: 3449/4024 0.224s 0.001s
im_detect: 3450/4024 0.224s 0.001s
im_detect: 3451/4024 0.224s 0.001s
im_detect: 3452/4024 0.224s 0.001s
im_detect: 3453/4024 0.224s 0.001s
im_detect: 3454/4024 0.224s 0.001s
im_detect: 3455/4024 0.224s 0.001s
im_detect: 3456/4024 0.224s 0.001s
im_detect: 3457/4024 0.224s 0.001s
im_detect: 3458/4024 0.224s 0.001s
im_detect: 3459/4024 0.224s 0.001s
im_detect: 3460/4024 0.224s 0.001s
im_detect: 3461/4024 0.224s 0.001s
im_detect: 3462/4024 0.224s 0.001s
im_detect: 3463/4024 0.224s 0.001s
im_detect: 3464/4024 0.224s 0.001s
im_detect: 3465/4024 0.224s 0.001s
im_detect: 3466/4024 0.224s 0.001s
im_detect: 3467/4024 0.224s 0.001s
im_detect: 3468/4024 0.224s 0.001s
im_detect: 3469/4024 0.224s 0.001s
im_detect: 3470/4024 0.224s 0.001s
im_detect: 3471/4024 0.224s 0.001s
im_detect: 3472/4024 0.224s 0.001s
im_detect: 3473/4024 0.224s 0.001s
im_detect: 3474/4024 0.224s 0.001s
im_detect: 3475/4024 0.224s 0.001s
im_detect: 3476/4024 0.224s 0.001s
im_detect: 3477/4024 0.224s 0.001s
im_detect: 3478/4024 0.224s 0.001s
im_detect: 3479/4024 0.224s 0.001s
im_detect: 3480/4024 0.224s 0.001s
im_detect: 3481/4024 0.224s 0.001s
im_detect: 3482/4024 0.224s 0.001s
im_detect: 3483/4024 0.224s 0.001s
im_detect: 3484/4024 0.224s 0.001s
im_detect: 3485/4024 0.224s 0.001s
im_detect: 3486/4024 0.224s 0.001s
im_detect: 3487/4024 0.224s 0.001s
im_detect: 3488/4024 0.224s 0.001s
im_detect: 3489/4024 0.224s 0.001s
im_detect: 3490/4024 0.224s 0.001s
im_detect: 3491/4024 0.224s 0.001s
im_detect: 3492/4024 0.224s 0.001s
im_detect: 3493/4024 0.224s 0.001s
im_detect: 3494/4024 0.224s 0.001s
im_detect: 3495/4024 0.224s 0.001s
im_detect: 3496/4024 0.224s 0.001s
im_detect: 3497/4024 0.224s 0.001s
im_detect: 3498/4024 0.224s 0.001s
im_detect: 3499/4024 0.224s 0.001s
im_detect: 3500/4024 0.224s 0.001s
im_detect: 3501/4024 0.224s 0.001s
im_detect: 3502/4024 0.224s 0.001s
im_detect: 3503/4024 0.224s 0.001s
im_detect: 3504/4024 0.224s 0.001s
im_detect: 3505/4024 0.224s 0.001s
im_detect: 3506/4024 0.224s 0.001s
im_detect: 3507/4024 0.224s 0.001s
im_detect: 3508/4024 0.224s 0.001s
im_detect: 3509/4024 0.224s 0.001s
im_detect: 3510/4024 0.224s 0.001s
im_detect: 3511/4024 0.224s 0.001s
im_detect: 3512/4024 0.224s 0.001s
im_detect: 3513/4024 0.224s 0.001s
im_detect: 3514/4024 0.224s 0.001s
im_detect: 3515/4024 0.224s 0.001s
im_detect: 3516/4024 0.224s 0.001s
im_detect: 3517/4024 0.224s 0.001s
im_detect: 3518/4024 0.224s 0.001s
im_detect: 3519/4024 0.224s 0.001s
im_detect: 3520/4024 0.224s 0.001s
im_detect: 3521/4024 0.224s 0.001s
im_detect: 3522/4024 0.224s 0.001s
im_detect: 3523/4024 0.224s 0.001s
im_detect: 3524/4024 0.224s 0.001s
im_detect: 3525/4024 0.224s 0.001s
im_detect: 3526/4024 0.224s 0.001s
im_detect: 3527/4024 0.224s 0.001s
im_detect: 3528/4024 0.224s 0.001s
im_detect: 3529/4024 0.224s 0.001s
im_detect: 3530/4024 0.224s 0.001s
im_detect: 3531/4024 0.224s 0.001s
im_detect: 3532/4024 0.224s 0.001s
im_detect: 3533/4024 0.224s 0.001s
im_detect: 3534/4024 0.224s 0.001s
im_detect: 3535/4024 0.224s 0.001s
im_detect: 3536/4024 0.224s 0.001s
im_detect: 3537/4024 0.224s 0.001s
im_detect: 3538/4024 0.224s 0.001s
im_detect: 3539/4024 0.224s 0.001s
im_detect: 3540/4024 0.224s 0.001s
im_detect: 3541/4024 0.224s 0.001s
im_detect: 3542/4024 0.224s 0.001s
im_detect: 3543/4024 0.224s 0.001s
im_detect: 3544/4024 0.224s 0.001s
im_detect: 3545/4024 0.224s 0.001s
im_detect: 3546/4024 0.224s 0.001s
im_detect: 3547/4024 0.224s 0.001s
im_detect: 3548/4024 0.224s 0.001s
im_detect: 3549/4024 0.224s 0.001s
im_detect: 3550/4024 0.224s 0.001s
im_detect: 3551/4024 0.224s 0.001s
im_detect: 3552/4024 0.224s 0.001s
im_detect: 3553/4024 0.224s 0.001s
im_detect: 3554/4024 0.224s 0.001s
im_detect: 3555/4024 0.224s 0.001s
im_detect: 3556/4024 0.224s 0.001s
im_detect: 3557/4024 0.224s 0.001s
im_detect: 3558/4024 0.224s 0.001s
im_detect: 3559/4024 0.224s 0.001s
im_detect: 3560/4024 0.224s 0.001s
im_detect: 3561/4024 0.224s 0.001s
im_detect: 3562/4024 0.224s 0.001s
im_detect: 3563/4024 0.224s 0.001s
im_detect: 3564/4024 0.224s 0.001s
im_detect: 3565/4024 0.224s 0.001s
im_detect: 3566/4024 0.224s 0.001s
im_detect: 3567/4024 0.224s 0.001s
im_detect: 3568/4024 0.224s 0.001s
im_detect: 3569/4024 0.224s 0.001s
im_detect: 3570/4024 0.224s 0.001s
im_detect: 3571/4024 0.224s 0.001s
im_detect: 3572/4024 0.224s 0.001s
im_detect: 3573/4024 0.224s 0.001s
im_detect: 3574/4024 0.224s 0.001s
im_detect: 3575/4024 0.224s 0.001s
im_detect: 3576/4024 0.224s 0.001s
im_detect: 3577/4024 0.224s 0.001s
im_detect: 3578/4024 0.224s 0.001s
im_detect: 3579/4024 0.224s 0.001s
im_detect: 3580/4024 0.224s 0.001s
im_detect: 3581/4024 0.224s 0.001s
im_detect: 3582/4024 0.224s 0.001s
im_detect: 3583/4024 0.224s 0.001s
im_detect: 3584/4024 0.224s 0.001s
im_detect: 3585/4024 0.224s 0.001s
im_detect: 3586/4024 0.224s 0.001s
im_detect: 3587/4024 0.224s 0.001s
im_detect: 3588/4024 0.224s 0.001s
im_detect: 3589/4024 0.223s 0.001s
im_detect: 3590/4024 0.223s 0.001s
im_detect: 3591/4024 0.223s 0.001s
im_detect: 3592/4024 0.223s 0.001s
im_detect: 3593/4024 0.223s 0.001s
im_detect: 3594/4024 0.223s 0.001s
im_detect: 3595/4024 0.223s 0.001s
im_detect: 3596/4024 0.223s 0.001s
im_detect: 3597/4024 0.223s 0.001s
im_detect: 3598/4024 0.223s 0.001s
im_detect: 3599/4024 0.223s 0.001s
im_detect: 3600/4024 0.223s 0.001s
im_detect: 3601/4024 0.223s 0.001s
im_detect: 3602/4024 0.223s 0.001s
im_detect: 3603/4024 0.223s 0.001s
im_detect: 3604/4024 0.223s 0.001s
im_detect: 3605/4024 0.223s 0.001s
im_detect: 3606/4024 0.223s 0.001s
im_detect: 3607/4024 0.223s 0.001s
im_detect: 3608/4024 0.223s 0.001s
im_detect: 3609/4024 0.223s 0.001s
im_detect: 3610/4024 0.223s 0.001s
im_detect: 3611/4024 0.223s 0.001s
im_detect: 3612/4024 0.223s 0.001s
im_detect: 3613/4024 0.223s 0.001s
im_detect: 3614/4024 0.223s 0.001s
im_detect: 3615/4024 0.223s 0.001s
im_detect: 3616/4024 0.223s 0.001s
im_detect: 3617/4024 0.223s 0.001s
im_detect: 3618/4024 0.223s 0.001s
im_detect: 3619/4024 0.223s 0.001s
im_detect: 3620/4024 0.223s 0.001s
im_detect: 3621/4024 0.223s 0.001s
im_detect: 3622/4024 0.223s 0.001s
im_detect: 3623/4024 0.223s 0.001s
im_detect: 3624/4024 0.223s 0.001s
im_detect: 3625/4024 0.223s 0.001s
im_detect: 3626/4024 0.223s 0.001s
im_detect: 3627/4024 0.223s 0.001s
im_detect: 3628/4024 0.223s 0.001s
im_detect: 3629/4024 0.223s 0.001s
im_detect: 3630/4024 0.223s 0.001s
im_detect: 3631/4024 0.223s 0.001s
im_detect: 3632/4024 0.223s 0.001s
im_detect: 3633/4024 0.223s 0.001s
im_detect: 3634/4024 0.223s 0.001s
im_detect: 3635/4024 0.223s 0.001s
im_detect: 3636/4024 0.223s 0.001s
im_detect: 3637/4024 0.223s 0.001s
im_detect: 3638/4024 0.223s 0.001s
im_detect: 3639/4024 0.223s 0.001s
im_detect: 3640/4024 0.223s 0.001s
im_detect: 3641/4024 0.223s 0.001s
im_detect: 3642/4024 0.223s 0.001s
im_detect: 3643/4024 0.223s 0.001s
im_detect: 3644/4024 0.223s 0.001s
im_detect: 3645/4024 0.223s 0.001s
im_detect: 3646/4024 0.223s 0.001s
im_detect: 3647/4024 0.223s 0.001s
im_detect: 3648/4024 0.223s 0.001s
im_detect: 3649/4024 0.223s 0.001s
im_detect: 3650/4024 0.223s 0.001s
im_detect: 3651/4024 0.223s 0.001s
im_detect: 3652/4024 0.223s 0.001s
im_detect: 3653/4024 0.223s 0.001s
im_detect: 3654/4024 0.223s 0.001s
im_detect: 3655/4024 0.223s 0.001s
im_detect: 3656/4024 0.223s 0.001s
im_detect: 3657/4024 0.223s 0.001s
im_detect: 3658/4024 0.223s 0.001s
im_detect: 3659/4024 0.223s 0.001s
im_detect: 3660/4024 0.223s 0.001s
im_detect: 3661/4024 0.223s 0.001s
im_detect: 3662/4024 0.223s 0.001s
im_detect: 3663/4024 0.223s 0.001s
im_detect: 3664/4024 0.223s 0.001s
im_detect: 3665/4024 0.223s 0.001s
im_detect: 3666/4024 0.223s 0.001s
im_detect: 3667/4024 0.223s 0.001s
im_detect: 3668/4024 0.223s 0.001s
im_detect: 3669/4024 0.223s 0.001s
im_detect: 3670/4024 0.223s 0.001s
im_detect: 3671/4024 0.223s 0.001s
im_detect: 3672/4024 0.223s 0.001s
im_detect: 3673/4024 0.223s 0.001s
im_detect: 3674/4024 0.223s 0.001s
im_detect: 3675/4024 0.223s 0.001s
im_detect: 3676/4024 0.223s 0.001s
im_detect: 3677/4024 0.223s 0.001s
im_detect: 3678/4024 0.223s 0.001s
im_detect: 3679/4024 0.223s 0.001s
im_detect: 3680/4024 0.223s 0.001s
im_detect: 3681/4024 0.223s 0.001s
im_detect: 3682/4024 0.223s 0.001s
im_detect: 3683/4024 0.223s 0.001s
im_detect: 3684/4024 0.223s 0.001s
im_detect: 3685/4024 0.223s 0.001s
im_detect: 3686/4024 0.223s 0.001s
im_detect: 3687/4024 0.223s 0.001s
im_detect: 3688/4024 0.223s 0.001s
im_detect: 3689/4024 0.223s 0.001s
im_detect: 3690/4024 0.223s 0.001s
im_detect: 3691/4024 0.223s 0.001s
im_detect: 3692/4024 0.223s 0.001s
im_detect: 3693/4024 0.223s 0.001s
im_detect: 3694/4024 0.223s 0.001s
im_detect: 3695/4024 0.223s 0.001s
im_detect: 3696/4024 0.223s 0.001s
im_detect: 3697/4024 0.223s 0.001s
im_detect: 3698/4024 0.223s 0.001s
im_detect: 3699/4024 0.223s 0.001s
im_detect: 3700/4024 0.223s 0.001s
im_detect: 3701/4024 0.223s 0.001s
im_detect: 3702/4024 0.223s 0.001s
im_detect: 3703/4024 0.223s 0.001s
im_detect: 3704/4024 0.223s 0.001s
im_detect: 3705/4024 0.223s 0.001s
im_detect: 3706/4024 0.223s 0.001s
im_detect: 3707/4024 0.223s 0.001s
im_detect: 3708/4024 0.223s 0.001s
im_detect: 3709/4024 0.223s 0.001s
im_detect: 3710/4024 0.223s 0.001s
im_detect: 3711/4024 0.223s 0.001s
im_detect: 3712/4024 0.223s 0.001s
im_detect: 3713/4024 0.223s 0.001s
im_detect: 3714/4024 0.223s 0.001s
im_detect: 3715/4024 0.223s 0.001s
im_detect: 3716/4024 0.223s 0.001s
im_detect: 3717/4024 0.223s 0.001s
im_detect: 3718/4024 0.223s 0.001s
im_detect: 3719/4024 0.223s 0.001s
im_detect: 3720/4024 0.223s 0.001s
im_detect: 3721/4024 0.223s 0.001s
im_detect: 3722/4024 0.223s 0.001s
im_detect: 3723/4024 0.223s 0.001s
im_detect: 3724/4024 0.223s 0.001s
im_detect: 3725/4024 0.223s 0.001s
im_detect: 3726/4024 0.223s 0.001s
im_detect: 3727/4024 0.223s 0.001s
im_detect: 3728/4024 0.223s 0.001s
im_detect: 3729/4024 0.223s 0.001s
im_detect: 3730/4024 0.223s 0.001s
im_detect: 3731/4024 0.223s 0.001s
im_detect: 3732/4024 0.223s 0.001s
im_detect: 3733/4024 0.223s 0.001s
im_detect: 3734/4024 0.223s 0.001s
im_detect: 3735/4024 0.223s 0.001s
im_detect: 3736/4024 0.223s 0.001s
im_detect: 3737/4024 0.223s 0.001s
im_detect: 3738/4024 0.223s 0.001s
im_detect: 3739/4024 0.223s 0.001s
im_detect: 3740/4024 0.223s 0.001s
im_detect: 3741/4024 0.223s 0.001s
im_detect: 3742/4024 0.223s 0.001s
im_detect: 3743/4024 0.223s 0.001s
im_detect: 3744/4024 0.223s 0.001s
im_detect: 3745/4024 0.223s 0.001s
im_detect: 3746/4024 0.223s 0.001s
im_detect: 3747/4024 0.223s 0.001s
im_detect: 3748/4024 0.223s 0.001s
im_detect: 3749/4024 0.223s 0.001s
im_detect: 3750/4024 0.223s 0.001s
im_detect: 3751/4024 0.223s 0.001s
im_detect: 3752/4024 0.223s 0.001s
im_detect: 3753/4024 0.223s 0.001s
im_detect: 3754/4024 0.223s 0.001s
im_detect: 3755/4024 0.223s 0.001s
im_detect: 3756/4024 0.223s 0.001s
im_detect: 3757/4024 0.223s 0.001s
im_detect: 3758/4024 0.223s 0.001s
im_detect: 3759/4024 0.223s 0.001s
im_detect: 3760/4024 0.223s 0.001s
im_detect: 3761/4024 0.223s 0.001s
im_detect: 3762/4024 0.223s 0.001s
im_detect: 3763/4024 0.223s 0.001s
im_detect: 3764/4024 0.223s 0.001s
im_detect: 3765/4024 0.223s 0.001s
im_detect: 3766/4024 0.223s 0.001s
im_detect: 3767/4024 0.223s 0.001s
im_detect: 3768/4024 0.223s 0.001s
im_detect: 3769/4024 0.223s 0.001s
im_detect: 3770/4024 0.223s 0.001s
im_detect: 3771/4024 0.223s 0.001s
im_detect: 3772/4024 0.223s 0.001s
im_detect: 3773/4024 0.223s 0.001s
im_detect: 3774/4024 0.223s 0.001s
im_detect: 3775/4024 0.223s 0.001s
im_detect: 3776/4024 0.223s 0.001s
im_detect: 3777/4024 0.223s 0.001s
im_detect: 3778/4024 0.223s 0.001s
im_detect: 3779/4024 0.223s 0.001s
im_detect: 3780/4024 0.223s 0.001s
im_detect: 3781/4024 0.223s 0.001s
im_detect: 3782/4024 0.223s 0.001s
im_detect: 3783/4024 0.223s 0.001s
im_detect: 3784/4024 0.223s 0.001s
im_detect: 3785/4024 0.223s 0.001s
im_detect: 3786/4024 0.223s 0.001s
im_detect: 3787/4024 0.223s 0.001s
im_detect: 3788/4024 0.223s 0.001s
im_detect: 3789/4024 0.223s 0.001s
im_detect: 3790/4024 0.223s 0.001s
im_detect: 3791/4024 0.223s 0.001s
im_detect: 3792/4024 0.223s 0.001s
im_detect: 3793/4024 0.223s 0.001s
im_detect: 3794/4024 0.223s 0.001s
im_detect: 3795/4024 0.223s 0.001s
im_detect: 3796/4024 0.223s 0.001s
im_detect: 3797/4024 0.223s 0.001s
im_detect: 3798/4024 0.223s 0.001s
im_detect: 3799/4024 0.223s 0.001s
im_detect: 3800/4024 0.223s 0.001s
im_detect: 3801/4024 0.223s 0.001s
im_detect: 3802/4024 0.223s 0.001s
im_detect: 3803/4024 0.223s 0.001s
im_detect: 3804/4024 0.223s 0.001s
im_detect: 3805/4024 0.223s 0.001s
im_detect: 3806/4024 0.223s 0.001s
im_detect: 3807/4024 0.223s 0.001s
im_detect: 3808/4024 0.223s 0.001s
im_detect: 3809/4024 0.223s 0.001s
im_detect: 3810/4024 0.223s 0.001s
im_detect: 3811/4024 0.223s 0.001s
im_detect: 3812/4024 0.223s 0.001s
im_detect: 3813/4024 0.223s 0.001s
im_detect: 3814/4024 0.223s 0.001s
im_detect: 3815/4024 0.223s 0.001s
im_detect: 3816/4024 0.223s 0.001s
im_detect: 3817/4024 0.223s 0.001s
im_detect: 3818/4024 0.223s 0.001s
im_detect: 3819/4024 0.223s 0.001s
im_detect: 3820/4024 0.223s 0.001s
im_detect: 3821/4024 0.223s 0.001s
im_detect: 3822/4024 0.223s 0.001s
im_detect: 3823/4024 0.223s 0.001s
im_detect: 3824/4024 0.223s 0.001s
im_detect: 3825/4024 0.223s 0.001s
im_detect: 3826/4024 0.223s 0.001s
im_detect: 3827/4024 0.223s 0.001s
im_detect: 3828/4024 0.223s 0.001s
im_detect: 3829/4024 0.223s 0.001s
im_detect: 3830/4024 0.223s 0.001s
im_detect: 3831/4024 0.223s 0.001s
im_detect: 3832/4024 0.223s 0.001s
im_detect: 3833/4024 0.223s 0.001s
im_detect: 3834/4024 0.223s 0.001s
im_detect: 3835/4024 0.223s 0.001s
im_detect: 3836/4024 0.223s 0.001s
im_detect: 3837/4024 0.223s 0.001s
im_detect: 3838/4024 0.223s 0.001s
im_detect: 3839/4024 0.223s 0.001s
im_detect: 3840/4024 0.223s 0.001s
im_detect: 3841/4024 0.223s 0.001s
im_detect: 3842/4024 0.223s 0.001s
im_detect: 3843/4024 0.223s 0.001s
im_detect: 3844/4024 0.223s 0.001s
im_detect: 3845/4024 0.223s 0.001s
im_detect: 3846/4024 0.223s 0.001s
im_detect: 3847/4024 0.223s 0.001s
im_detect: 3848/4024 0.223s 0.001s
im_detect: 3849/4024 0.223s 0.001s
im_detect: 3850/4024 0.223s 0.001s
im_detect: 3851/4024 0.223s 0.001s
im_detect: 3852/4024 0.223s 0.001s
im_detect: 3853/4024 0.223s 0.001s
im_detect: 3854/4024 0.223s 0.001s
im_detect: 3855/4024 0.223s 0.001s
im_detect: 3856/4024 0.223s 0.001s
im_detect: 3857/4024 0.223s 0.001s
im_detect: 3858/4024 0.223s 0.001s
im_detect: 3859/4024 0.223s 0.001s
im_detect: 3860/4024 0.223s 0.001s
im_detect: 3861/4024 0.223s 0.001s
im_detect: 3862/4024 0.223s 0.001s
im_detect: 3863/4024 0.223s 0.001s
im_detect: 3864/4024 0.223s 0.001s
im_detect: 3865/4024 0.223s 0.001s
im_detect: 3866/4024 0.223s 0.001s
im_detect: 3867/4024 0.223s 0.001s
im_detect: 3868/4024 0.223s 0.001s
im_detect: 3869/4024 0.223s 0.001s
im_detect: 3870/4024 0.223s 0.001s
im_detect: 3871/4024 0.223s 0.001s
im_detect: 3872/4024 0.223s 0.001s
im_detect: 3873/4024 0.223s 0.001s
im_detect: 3874/4024 0.223s 0.001s
im_detect: 3875/4024 0.223s 0.001s
im_detect: 3876/4024 0.223s 0.001s
im_detect: 3877/4024 0.223s 0.001s
im_detect: 3878/4024 0.223s 0.001s
im_detect: 3879/4024 0.223s 0.001s
im_detect: 3880/4024 0.223s 0.001s
im_detect: 3881/4024 0.223s 0.001s
im_detect: 3882/4024 0.223s 0.001s
im_detect: 3883/4024 0.223s 0.001s
im_detect: 3884/4024 0.223s 0.001s
im_detect: 3885/4024 0.223s 0.001s
im_detect: 3886/4024 0.223s 0.001s
im_detect: 3887/4024 0.223s 0.001s
im_detect: 3888/4024 0.223s 0.001s
im_detect: 3889/4024 0.223s 0.001s
im_detect: 3890/4024 0.223s 0.001s
im_detect: 3891/4024 0.223s 0.001s
im_detect: 3892/4024 0.223s 0.001s
im_detect: 3893/4024 0.223s 0.001s
im_detect: 3894/4024 0.223s 0.001s
im_detect: 3895/4024 0.223s 0.001s
im_detect: 3896/4024 0.223s 0.001s
im_detect: 3897/4024 0.223s 0.001s
im_detect: 3898/4024 0.223s 0.001s
im_detect: 3899/4024 0.223s 0.001s
im_detect: 3900/4024 0.223s 0.001s
im_detect: 3901/4024 0.223s 0.001s
im_detect: 3902/4024 0.223s 0.001s
im_detect: 3903/4024 0.223s 0.001s
im_detect: 3904/4024 0.223s 0.001s
im_detect: 3905/4024 0.223s 0.001s
im_detect: 3906/4024 0.223s 0.001s
im_detect: 3907/4024 0.223s 0.001s
im_detect: 3908/4024 0.223s 0.001s
im_detect: 3909/4024 0.223s 0.001s
im_detect: 3910/4024 0.223s 0.001s
im_detect: 3911/4024 0.223s 0.001s
im_detect: 3912/4024 0.223s 0.001s
im_detect: 3913/4024 0.223s 0.001s
im_detect: 3914/4024 0.223s 0.001s
im_detect: 3915/4024 0.223s 0.001s
im_detect: 3916/4024 0.223s 0.001s
im_detect: 3917/4024 0.223s 0.001s
im_detect: 3918/4024 0.223s 0.001s
im_detect: 3919/4024 0.223s 0.001s
im_detect: 3920/4024 0.223s 0.001s
im_detect: 3921/4024 0.223s 0.001s
im_detect: 3922/4024 0.223s 0.001s
im_detect: 3923/4024 0.223s 0.001s
im_detect: 3924/4024 0.223s 0.001s
im_detect: 3925/4024 0.223s 0.001s
im_detect: 3926/4024 0.223s 0.001s
im_detect: 3927/4024 0.223s 0.001s
im_detect: 3928/4024 0.223s 0.001s
im_detect: 3929/4024 0.223s 0.001s
im_detect: 3930/4024 0.223s 0.001s
im_detect: 3931/4024 0.223s 0.001s
im_detect: 3932/4024 0.223s 0.001s
im_detect: 3933/4024 0.223s 0.001s
im_detect: 3934/4024 0.223s 0.001s
im_detect: 3935/4024 0.223s 0.001s
im_detect: 3936/4024 0.223s 0.001s
im_detect: 3937/4024 0.223s 0.001s
im_detect: 3938/4024 0.223s 0.001s
im_detect: 3939/4024 0.223s 0.001s
im_detect: 3940/4024 0.223s 0.001s
im_detect: 3941/4024 0.223s 0.001s
im_detect: 3942/4024 0.223s 0.001s
im_detect: 3943/4024 0.223s 0.001s
im_detect: 3944/4024 0.223s 0.001s
im_detect: 3945/4024 0.223s 0.001s
im_detect: 3946/4024 0.223s 0.001s
im_detect: 3947/4024 0.223s 0.001s
im_detect: 3948/4024 0.223s 0.001s
im_detect: 3949/4024 0.223s 0.001s
im_detect: 3950/4024 0.223s 0.001s
im_detect: 3951/4024 0.223s 0.001s
im_detect: 3952/4024 0.223s 0.001s
im_detect: 3953/4024 0.223s 0.001s
im_detect: 3954/4024 0.223s 0.001s
im_detect: 3955/4024 0.223s 0.001s
im_detect: 3956/4024 0.223s 0.001s
im_detect: 3957/4024 0.223s 0.001s
im_detect: 3958/4024 0.223s 0.001s
im_detect: 3959/4024 0.223s 0.001s
im_detect: 3960/4024 0.223s 0.001s
im_detect: 3961/4024 0.223s 0.001s
im_detect: 3962/4024 0.223s 0.001s
im_detect: 3963/4024 0.223s 0.001s
im_detect: 3964/4024 0.223s 0.001s
im_detect: 3965/4024 0.223s 0.001s
im_detect: 3966/4024 0.223s 0.001s
im_detect: 3967/4024 0.223s 0.001s
im_detect: 3968/4024 0.223s 0.001s
im_detect: 3969/4024 0.223s 0.001s
im_detect: 3970/4024 0.223s 0.001s
im_detect: 3971/4024 0.223s 0.001s
im_detect: 3972/4024 0.223s 0.001s
im_detect: 3973/4024 0.223s 0.001s
im_detect: 3974/4024 0.223s 0.001s
im_detect: 3975/4024 0.223s 0.001s
im_detect: 3976/4024 0.223s 0.001s
im_detect: 3977/4024 0.223s 0.001s
im_detect: 3978/4024 0.223s 0.001s
im_detect: 3979/4024 0.223s 0.001s
im_detect: 3980/4024 0.223s 0.001s
im_detect: 3981/4024 0.223s 0.001s
im_detect: 3982/4024 0.223s 0.001s
im_detect: 3983/4024 0.223s 0.001s
im_detect: 3984/4024 0.223s 0.001s
im_detect: 3985/4024 0.223s 0.001s
im_detect: 3986/4024 0.223s 0.001s
im_detect: 3987/4024 0.223s 0.001s
im_detect: 3988/4024 0.223s 0.001s
im_detect: 3989/4024 0.223s 0.001s
im_detect: 3990/4024 0.223s 0.001s
im_detect: 3991/4024 0.223s 0.001s
im_detect: 3992/4024 0.223s 0.001s
im_detect: 3993/4024 0.223s 0.001s
im_detect: 3994/4024 0.223s 0.001s
im_detect: 3995/4024 0.223s 0.001s
im_detect: 3996/4024 0.223s 0.001s
im_detect: 3997/4024 0.223s 0.001s
im_detect: 3998/4024 0.223s 0.001s
im_detect: 3999/4024 0.223s 0.001s
im_detect: 4000/4024 0.223s 0.001s
im_detect: 4001/4024 0.223s 0.001s
im_detect: 4002/4024 0.223s 0.001s
im_detect: 4003/4024 0.223s 0.001s
im_detect: 4004/4024 0.223s 0.001s
im_detect: 4005/4024 0.223s 0.001s
im_detect: 4006/4024 0.223s 0.001s
im_detect: 4007/4024 0.223s 0.001s
im_detect: 4008/4024 0.223s 0.001s
im_detect: 4009/4024 0.223s 0.001s
im_detect: 4010/4024 0.223s 0.001s
im_detect: 4011/4024 0.223s 0.001s
im_detect: 4012/4024 0.223s 0.001s
im_detect: 4013/4024 0.223s 0.001s
im_detect: 4014/4024 0.223s 0.001s
im_detect: 4015/4024 0.223s 0.001s
im_detect: 4016/4024 0.223s 0.001s
im_detect: 4017/4024 0.223s 0.001s
im_detect: 4018/4024 0.223s 0.001s
im_detect: 4019/4024 0.223s 0.001s
im_detect: 4020/4024 0.223s 0.001s
im_detect: 4021/4024 0.223s 0.001s
im_detect: 4022/4024 0.223s 0.001s
im_detect: 4023/4024 0.223s 0.001s
im_detect: 4024/4024 0.223s 0.001s
Evaluating detections
Writing person VOC results file
VOC07 metric? Yes
[      0.       0.       0. ... 1223213. 1223214. 1223215.] [1.00e+00 2.00e+00 3.00e+00 ... 1.64e+03 1.64e+03 1.64e+03] 0.0
/home/neuiva1/sol/10_12/py-R-FCN/tools/../lib/datasets/voc_eval.py:197: RuntimeWarning: divide by zero encountered in divide
  rec = tp / float(npos)
AP for person = 1.0000
Mean AP = 1.0000
~~~~~~~~
Results:
1.000
1.000
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	15m57.436s
user	15m19.724s
sys	1m31.628s
+ ./tools/test_net.py --gpu 3 --def experiments/10_22/model_ohem/multi_test.prototxt --net output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_12000.caffemodel --imdb voc_0712_test --cfg experiments/10_22/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_12000.caffemodel', cfg_file='experiments/10_22/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=3, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/10_22/model_ohem/multi_test.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'DATA_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '10_22/model',
 'GPU_ID': 3,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/models/pascal_voc',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/neuiva1/sol/10_12/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.55,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 20,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 20,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 2000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W1022 15:54:56.747601 27427 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W1022 15:54:56.747669 27427 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W1022 15:54:56.747673 27427 _caffe.cpp:125] Net('experiments/10_22/model_ohem/multi_test.prototxt', 1, weights='output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_12000.caffemodel')
I1022 15:54:56.751292 27427 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/10_22/model_ohem/multi_test.prototxt
I1022 15:54:56.751341 27427 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W1022 15:54:56.751346 27427 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I1022 15:54:56.753497 27427 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b
I1022 15:54:56.754616 27427 layer_factory.hpp:77] Creating layer input
I1022 15:54:56.754628 27427 net.cpp:100] Creating Layer input
I1022 15:54:56.754633 27427 net.cpp:418] input -> data
I1022 15:54:56.754654 27427 net.cpp:418] input -> im_info
I1022 15:54:57.245131 27427 net.cpp:150] Setting up input
I1022 15:54:57.245174 27427 net.cpp:157] Top shape: 1 3 224 224 (150528)
I1022 15:54:57.245180 27427 net.cpp:157] Top shape: 1 3 (3)
I1022 15:54:57.245182 27427 net.cpp:165] Memory required for data: 602124
I1022 15:54:57.245190 27427 layer_factory.hpp:77] Creating layer conv1
I1022 15:54:57.245210 27427 net.cpp:100] Creating Layer conv1
I1022 15:54:57.245215 27427 net.cpp:444] conv1 <- data
I1022 15:54:57.245223 27427 net.cpp:418] conv1 -> conv1
I1022 15:54:57.931365 27427 net.cpp:150] Setting up conv1
I1022 15:54:57.931404 27427 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 15:54:57.931409 27427 net.cpp:165] Memory required for data: 3813388
I1022 15:54:57.931428 27427 layer_factory.hpp:77] Creating layer bn_conv1
I1022 15:54:57.931458 27427 net.cpp:100] Creating Layer bn_conv1
I1022 15:54:57.931463 27427 net.cpp:444] bn_conv1 <- conv1
I1022 15:54:57.931470 27427 net.cpp:405] bn_conv1 -> conv1 (in-place)
I1022 15:54:57.931826 27427 net.cpp:150] Setting up bn_conv1
I1022 15:54:57.931834 27427 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 15:54:57.931838 27427 net.cpp:165] Memory required for data: 7024652
I1022 15:54:57.931849 27427 layer_factory.hpp:77] Creating layer scale_conv1
I1022 15:54:57.931865 27427 net.cpp:100] Creating Layer scale_conv1
I1022 15:54:57.931870 27427 net.cpp:444] scale_conv1 <- conv1
I1022 15:54:57.931875 27427 net.cpp:405] scale_conv1 -> conv1 (in-place)
I1022 15:54:57.931939 27427 layer_factory.hpp:77] Creating layer scale_conv1
I1022 15:54:57.932147 27427 net.cpp:150] Setting up scale_conv1
I1022 15:54:57.932155 27427 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 15:54:57.932158 27427 net.cpp:165] Memory required for data: 10235916
I1022 15:54:57.932164 27427 layer_factory.hpp:77] Creating layer conv1_relu
I1022 15:54:57.932174 27427 net.cpp:100] Creating Layer conv1_relu
I1022 15:54:57.932179 27427 net.cpp:444] conv1_relu <- conv1
I1022 15:54:57.932184 27427 net.cpp:405] conv1_relu -> conv1 (in-place)
I1022 15:54:57.932406 27427 net.cpp:150] Setting up conv1_relu
I1022 15:54:57.932415 27427 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 15:54:57.932418 27427 net.cpp:165] Memory required for data: 13447180
I1022 15:54:57.932421 27427 layer_factory.hpp:77] Creating layer pool1
I1022 15:54:57.932430 27427 net.cpp:100] Creating Layer pool1
I1022 15:54:57.932435 27427 net.cpp:444] pool1 <- conv1
I1022 15:54:57.932440 27427 net.cpp:418] pool1 -> pool1
I1022 15:54:57.932507 27427 net.cpp:150] Setting up pool1
I1022 15:54:57.932514 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.932518 27427 net.cpp:165] Memory required for data: 14249996
I1022 15:54:57.932520 27427 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I1022 15:54:57.932528 27427 net.cpp:100] Creating Layer pool1_pool1_0_split
I1022 15:54:57.932533 27427 net.cpp:444] pool1_pool1_0_split <- pool1
I1022 15:54:57.932538 27427 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1022 15:54:57.932545 27427 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1022 15:54:57.932600 27427 net.cpp:150] Setting up pool1_pool1_0_split
I1022 15:54:57.932628 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.932633 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.932636 27427 net.cpp:165] Memory required for data: 15855628
I1022 15:54:57.932646 27427 layer_factory.hpp:77] Creating layer res2a_branch1
I1022 15:54:57.932657 27427 net.cpp:100] Creating Layer res2a_branch1
I1022 15:54:57.932674 27427 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I1022 15:54:57.932679 27427 net.cpp:418] res2a_branch1 -> res2a_branch1
I1022 15:54:57.934305 27427 net.cpp:150] Setting up res2a_branch1
I1022 15:54:57.934319 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.934321 27427 net.cpp:165] Memory required for data: 19066892
I1022 15:54:57.934327 27427 layer_factory.hpp:77] Creating layer bn2a_branch1
I1022 15:54:57.934335 27427 net.cpp:100] Creating Layer bn2a_branch1
I1022 15:54:57.934340 27427 net.cpp:444] bn2a_branch1 <- res2a_branch1
I1022 15:54:57.934345 27427 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I1022 15:54:57.936565 27427 net.cpp:150] Setting up bn2a_branch1
I1022 15:54:57.936578 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.936583 27427 net.cpp:165] Memory required for data: 22278156
I1022 15:54:57.936594 27427 layer_factory.hpp:77] Creating layer scale2a_branch1
I1022 15:54:57.936600 27427 net.cpp:100] Creating Layer scale2a_branch1
I1022 15:54:57.936604 27427 net.cpp:444] scale2a_branch1 <- res2a_branch1
I1022 15:54:57.936630 27427 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I1022 15:54:57.936693 27427 layer_factory.hpp:77] Creating layer scale2a_branch1
I1022 15:54:57.936872 27427 net.cpp:150] Setting up scale2a_branch1
I1022 15:54:57.936879 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.936882 27427 net.cpp:165] Memory required for data: 25489420
I1022 15:54:57.936888 27427 layer_factory.hpp:77] Creating layer res2a_branch2a
I1022 15:54:57.936898 27427 net.cpp:100] Creating Layer res2a_branch2a
I1022 15:54:57.936903 27427 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I1022 15:54:57.936909 27427 net.cpp:418] res2a_branch2a -> res2a_branch2a
I1022 15:54:57.938531 27427 net.cpp:150] Setting up res2a_branch2a
I1022 15:54:57.938544 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.938547 27427 net.cpp:165] Memory required for data: 26292236
I1022 15:54:57.938554 27427 layer_factory.hpp:77] Creating layer bn2a_branch2a
I1022 15:54:57.938560 27427 net.cpp:100] Creating Layer bn2a_branch2a
I1022 15:54:57.938563 27427 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I1022 15:54:57.938568 27427 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I1022 15:54:57.938886 27427 net.cpp:150] Setting up bn2a_branch2a
I1022 15:54:57.938894 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.938896 27427 net.cpp:165] Memory required for data: 27095052
I1022 15:54:57.938906 27427 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1022 15:54:57.938913 27427 net.cpp:100] Creating Layer scale2a_branch2a
I1022 15:54:57.938916 27427 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I1022 15:54:57.938920 27427 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I1022 15:54:57.938977 27427 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1022 15:54:57.939163 27427 net.cpp:150] Setting up scale2a_branch2a
I1022 15:54:57.939170 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.939173 27427 net.cpp:165] Memory required for data: 27897868
I1022 15:54:57.939179 27427 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I1022 15:54:57.939184 27427 net.cpp:100] Creating Layer res2a_branch2a_relu
I1022 15:54:57.939190 27427 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I1022 15:54:57.939195 27427 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I1022 15:54:57.939407 27427 net.cpp:150] Setting up res2a_branch2a_relu
I1022 15:54:57.939416 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.939419 27427 net.cpp:165] Memory required for data: 28700684
I1022 15:54:57.939422 27427 layer_factory.hpp:77] Creating layer res2a_branch2b
I1022 15:54:57.939430 27427 net.cpp:100] Creating Layer res2a_branch2b
I1022 15:54:57.939435 27427 net.cpp:444] res2a_branch2b <- res2a_branch2a
I1022 15:54:57.939440 27427 net.cpp:418] res2a_branch2b -> res2a_branch2b
I1022 15:54:57.946398 27427 net.cpp:150] Setting up res2a_branch2b
I1022 15:54:57.946414 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.946419 27427 net.cpp:165] Memory required for data: 29503500
I1022 15:54:57.946424 27427 layer_factory.hpp:77] Creating layer bn2a_branch2b
I1022 15:54:57.946432 27427 net.cpp:100] Creating Layer bn2a_branch2b
I1022 15:54:57.946435 27427 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I1022 15:54:57.946441 27427 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I1022 15:54:57.946796 27427 net.cpp:150] Setting up bn2a_branch2b
I1022 15:54:57.946805 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.946807 27427 net.cpp:165] Memory required for data: 30306316
I1022 15:54:57.946815 27427 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1022 15:54:57.946822 27427 net.cpp:100] Creating Layer scale2a_branch2b
I1022 15:54:57.946825 27427 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I1022 15:54:57.946830 27427 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I1022 15:54:57.946889 27427 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1022 15:54:57.947089 27427 net.cpp:150] Setting up scale2a_branch2b
I1022 15:54:57.947098 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.947099 27427 net.cpp:165] Memory required for data: 31109132
I1022 15:54:57.947106 27427 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I1022 15:54:57.947113 27427 net.cpp:100] Creating Layer res2a_branch2b_relu
I1022 15:54:57.947116 27427 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I1022 15:54:57.947121 27427 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I1022 15:54:57.948011 27427 net.cpp:150] Setting up res2a_branch2b_relu
I1022 15:54:57.948024 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.948026 27427 net.cpp:165] Memory required for data: 31911948
I1022 15:54:57.948029 27427 layer_factory.hpp:77] Creating layer res2a_branch2c
I1022 15:54:57.948040 27427 net.cpp:100] Creating Layer res2a_branch2c
I1022 15:54:57.948043 27427 net.cpp:444] res2a_branch2c <- res2a_branch2b
I1022 15:54:57.948050 27427 net.cpp:418] res2a_branch2c -> res2a_branch2c
I1022 15:54:57.951057 27427 net.cpp:150] Setting up res2a_branch2c
I1022 15:54:57.951072 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.951076 27427 net.cpp:165] Memory required for data: 35123212
I1022 15:54:57.951082 27427 layer_factory.hpp:77] Creating layer bn2a_branch2c
I1022 15:54:57.951092 27427 net.cpp:100] Creating Layer bn2a_branch2c
I1022 15:54:57.951095 27427 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I1022 15:54:57.951100 27427 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I1022 15:54:57.951440 27427 net.cpp:150] Setting up bn2a_branch2c
I1022 15:54:57.951447 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.951450 27427 net.cpp:165] Memory required for data: 38334476
I1022 15:54:57.951458 27427 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1022 15:54:57.951467 27427 net.cpp:100] Creating Layer scale2a_branch2c
I1022 15:54:57.951470 27427 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I1022 15:54:57.951474 27427 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I1022 15:54:57.951536 27427 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1022 15:54:57.951725 27427 net.cpp:150] Setting up scale2a_branch2c
I1022 15:54:57.951732 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.951735 27427 net.cpp:165] Memory required for data: 41545740
I1022 15:54:57.951741 27427 layer_factory.hpp:77] Creating layer res2a
I1022 15:54:57.951746 27427 net.cpp:100] Creating Layer res2a
I1022 15:54:57.951751 27427 net.cpp:444] res2a <- res2a_branch1
I1022 15:54:57.951756 27427 net.cpp:444] res2a <- res2a_branch2c
I1022 15:54:57.951762 27427 net.cpp:418] res2a -> res2a
I1022 15:54:57.951802 27427 net.cpp:150] Setting up res2a
I1022 15:54:57.951808 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.951812 27427 net.cpp:165] Memory required for data: 44757004
I1022 15:54:57.951814 27427 layer_factory.hpp:77] Creating layer res2a_relu
I1022 15:54:57.951819 27427 net.cpp:100] Creating Layer res2a_relu
I1022 15:54:57.951822 27427 net.cpp:444] res2a_relu <- res2a
I1022 15:54:57.951828 27427 net.cpp:405] res2a_relu -> res2a (in-place)
I1022 15:54:57.952062 27427 net.cpp:150] Setting up res2a_relu
I1022 15:54:57.952071 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.952075 27427 net.cpp:165] Memory required for data: 47968268
I1022 15:54:57.952077 27427 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I1022 15:54:57.952083 27427 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I1022 15:54:57.952086 27427 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I1022 15:54:57.952093 27427 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I1022 15:54:57.952101 27427 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I1022 15:54:57.952168 27427 net.cpp:150] Setting up res2a_res2a_relu_0_split
I1022 15:54:57.952174 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.952179 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.952183 27427 net.cpp:165] Memory required for data: 54390796
I1022 15:54:57.952184 27427 layer_factory.hpp:77] Creating layer res2b_branch2a
I1022 15:54:57.952194 27427 net.cpp:100] Creating Layer res2b_branch2a
I1022 15:54:57.952199 27427 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I1022 15:54:57.952206 27427 net.cpp:418] res2b_branch2a -> res2b_branch2a
I1022 15:54:57.953955 27427 net.cpp:150] Setting up res2b_branch2a
I1022 15:54:57.953969 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.953971 27427 net.cpp:165] Memory required for data: 55193612
I1022 15:54:57.953977 27427 layer_factory.hpp:77] Creating layer bn2b_branch2a
I1022 15:54:57.953984 27427 net.cpp:100] Creating Layer bn2b_branch2a
I1022 15:54:57.953987 27427 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I1022 15:54:57.953994 27427 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I1022 15:54:57.954349 27427 net.cpp:150] Setting up bn2b_branch2a
I1022 15:54:57.954356 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.954360 27427 net.cpp:165] Memory required for data: 55996428
I1022 15:54:57.954371 27427 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1022 15:54:57.954380 27427 net.cpp:100] Creating Layer scale2b_branch2a
I1022 15:54:57.954382 27427 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I1022 15:54:57.954387 27427 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I1022 15:54:57.954449 27427 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1022 15:54:57.954656 27427 net.cpp:150] Setting up scale2b_branch2a
I1022 15:54:57.954663 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.954666 27427 net.cpp:165] Memory required for data: 56799244
I1022 15:54:57.954672 27427 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I1022 15:54:57.954679 27427 net.cpp:100] Creating Layer res2b_branch2a_relu
I1022 15:54:57.954684 27427 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I1022 15:54:57.954689 27427 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I1022 15:54:57.954922 27427 net.cpp:150] Setting up res2b_branch2a_relu
I1022 15:54:57.954931 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.954934 27427 net.cpp:165] Memory required for data: 57602060
I1022 15:54:57.954937 27427 layer_factory.hpp:77] Creating layer res2b_branch2b
I1022 15:54:57.954948 27427 net.cpp:100] Creating Layer res2b_branch2b
I1022 15:54:57.954953 27427 net.cpp:444] res2b_branch2b <- res2b_branch2a
I1022 15:54:57.954959 27427 net.cpp:418] res2b_branch2b -> res2b_branch2b
I1022 15:54:57.956712 27427 net.cpp:150] Setting up res2b_branch2b
I1022 15:54:57.956724 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.956728 27427 net.cpp:165] Memory required for data: 58404876
I1022 15:54:57.956733 27427 layer_factory.hpp:77] Creating layer bn2b_branch2b
I1022 15:54:57.956743 27427 net.cpp:100] Creating Layer bn2b_branch2b
I1022 15:54:57.956746 27427 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I1022 15:54:57.956753 27427 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I1022 15:54:57.957106 27427 net.cpp:150] Setting up bn2b_branch2b
I1022 15:54:57.957113 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.957115 27427 net.cpp:165] Memory required for data: 59207692
I1022 15:54:57.957123 27427 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1022 15:54:57.957131 27427 net.cpp:100] Creating Layer scale2b_branch2b
I1022 15:54:57.957135 27427 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I1022 15:54:57.957141 27427 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I1022 15:54:57.957206 27427 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1022 15:54:57.957412 27427 net.cpp:150] Setting up scale2b_branch2b
I1022 15:54:57.957419 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.957422 27427 net.cpp:165] Memory required for data: 60010508
I1022 15:54:57.957428 27427 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I1022 15:54:57.957433 27427 net.cpp:100] Creating Layer res2b_branch2b_relu
I1022 15:54:57.957439 27427 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I1022 15:54:57.957443 27427 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I1022 15:54:57.958320 27427 net.cpp:150] Setting up res2b_branch2b_relu
I1022 15:54:57.958334 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.958338 27427 net.cpp:165] Memory required for data: 60813324
I1022 15:54:57.958340 27427 layer_factory.hpp:77] Creating layer res2b_branch2c
I1022 15:54:57.958353 27427 net.cpp:100] Creating Layer res2b_branch2c
I1022 15:54:57.958358 27427 net.cpp:444] res2b_branch2c <- res2b_branch2b
I1022 15:54:57.958364 27427 net.cpp:418] res2b_branch2c -> res2b_branch2c
I1022 15:54:57.960078 27427 net.cpp:150] Setting up res2b_branch2c
I1022 15:54:57.960090 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.960093 27427 net.cpp:165] Memory required for data: 64024588
I1022 15:54:57.960098 27427 layer_factory.hpp:77] Creating layer bn2b_branch2c
I1022 15:54:57.960109 27427 net.cpp:100] Creating Layer bn2b_branch2c
I1022 15:54:57.960114 27427 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I1022 15:54:57.960119 27427 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I1022 15:54:57.960461 27427 net.cpp:150] Setting up bn2b_branch2c
I1022 15:54:57.960469 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.960472 27427 net.cpp:165] Memory required for data: 67235852
I1022 15:54:57.960479 27427 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1022 15:54:57.960487 27427 net.cpp:100] Creating Layer scale2b_branch2c
I1022 15:54:57.960490 27427 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I1022 15:54:57.960494 27427 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I1022 15:54:57.960557 27427 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1022 15:54:57.960765 27427 net.cpp:150] Setting up scale2b_branch2c
I1022 15:54:57.960773 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.960788 27427 net.cpp:165] Memory required for data: 70447116
I1022 15:54:57.960793 27427 layer_factory.hpp:77] Creating layer res2b
I1022 15:54:57.960801 27427 net.cpp:100] Creating Layer res2b
I1022 15:54:57.960806 27427 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I1022 15:54:57.960811 27427 net.cpp:444] res2b <- res2b_branch2c
I1022 15:54:57.960816 27427 net.cpp:418] res2b -> res2b
I1022 15:54:57.960856 27427 net.cpp:150] Setting up res2b
I1022 15:54:57.960863 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.960866 27427 net.cpp:165] Memory required for data: 73658380
I1022 15:54:57.960870 27427 layer_factory.hpp:77] Creating layer res2b_relu
I1022 15:54:57.960875 27427 net.cpp:100] Creating Layer res2b_relu
I1022 15:54:57.960877 27427 net.cpp:444] res2b_relu <- res2b
I1022 15:54:57.960885 27427 net.cpp:405] res2b_relu -> res2b (in-place)
I1022 15:54:57.961113 27427 net.cpp:150] Setting up res2b_relu
I1022 15:54:57.961124 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.961127 27427 net.cpp:165] Memory required for data: 76869644
I1022 15:54:57.961130 27427 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I1022 15:54:57.961136 27427 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I1022 15:54:57.961141 27427 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I1022 15:54:57.961145 27427 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I1022 15:54:57.961155 27427 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I1022 15:54:57.961225 27427 net.cpp:150] Setting up res2b_res2b_relu_0_split
I1022 15:54:57.961231 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.961236 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.961238 27427 net.cpp:165] Memory required for data: 83292172
I1022 15:54:57.961241 27427 layer_factory.hpp:77] Creating layer res2c_branch2a
I1022 15:54:57.961251 27427 net.cpp:100] Creating Layer res2c_branch2a
I1022 15:54:57.961256 27427 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I1022 15:54:57.961261 27427 net.cpp:418] res2c_branch2a -> res2c_branch2a
I1022 15:54:57.964215 27427 net.cpp:150] Setting up res2c_branch2a
I1022 15:54:57.964229 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.964233 27427 net.cpp:165] Memory required for data: 84094988
I1022 15:54:57.964239 27427 layer_factory.hpp:77] Creating layer bn2c_branch2a
I1022 15:54:57.964249 27427 net.cpp:100] Creating Layer bn2c_branch2a
I1022 15:54:57.964252 27427 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I1022 15:54:57.964259 27427 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I1022 15:54:57.964653 27427 net.cpp:150] Setting up bn2c_branch2a
I1022 15:54:57.964661 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.964664 27427 net.cpp:165] Memory required for data: 84897804
I1022 15:54:57.964682 27427 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1022 15:54:57.964690 27427 net.cpp:100] Creating Layer scale2c_branch2a
I1022 15:54:57.964694 27427 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I1022 15:54:57.964701 27427 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I1022 15:54:57.964767 27427 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1022 15:54:57.964978 27427 net.cpp:150] Setting up scale2c_branch2a
I1022 15:54:57.964985 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.964988 27427 net.cpp:165] Memory required for data: 85700620
I1022 15:54:57.964993 27427 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I1022 15:54:57.965004 27427 net.cpp:100] Creating Layer res2c_branch2a_relu
I1022 15:54:57.965008 27427 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I1022 15:54:57.965011 27427 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I1022 15:54:57.965250 27427 net.cpp:150] Setting up res2c_branch2a_relu
I1022 15:54:57.965258 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.965260 27427 net.cpp:165] Memory required for data: 86503436
I1022 15:54:57.965265 27427 layer_factory.hpp:77] Creating layer res2c_branch2b
I1022 15:54:57.965275 27427 net.cpp:100] Creating Layer res2c_branch2b
I1022 15:54:57.965279 27427 net.cpp:444] res2c_branch2b <- res2c_branch2a
I1022 15:54:57.965287 27427 net.cpp:418] res2c_branch2b -> res2c_branch2b
I1022 15:54:57.967627 27427 net.cpp:150] Setting up res2c_branch2b
I1022 15:54:57.967639 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.967643 27427 net.cpp:165] Memory required for data: 87306252
I1022 15:54:57.967648 27427 layer_factory.hpp:77] Creating layer bn2c_branch2b
I1022 15:54:57.967655 27427 net.cpp:100] Creating Layer bn2c_branch2b
I1022 15:54:57.967659 27427 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I1022 15:54:57.967666 27427 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I1022 15:54:57.968046 27427 net.cpp:150] Setting up bn2c_branch2b
I1022 15:54:57.968053 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.968056 27427 net.cpp:165] Memory required for data: 88109068
I1022 15:54:57.968063 27427 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1022 15:54:57.968070 27427 net.cpp:100] Creating Layer scale2c_branch2b
I1022 15:54:57.968072 27427 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I1022 15:54:57.968080 27427 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I1022 15:54:57.968144 27427 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1022 15:54:57.968364 27427 net.cpp:150] Setting up scale2c_branch2b
I1022 15:54:57.968372 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.968375 27427 net.cpp:165] Memory required for data: 88911884
I1022 15:54:57.968382 27427 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I1022 15:54:57.968389 27427 net.cpp:100] Creating Layer res2c_branch2b_relu
I1022 15:54:57.968392 27427 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I1022 15:54:57.968397 27427 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I1022 15:54:57.968663 27427 net.cpp:150] Setting up res2c_branch2b_relu
I1022 15:54:57.968672 27427 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 15:54:57.968675 27427 net.cpp:165] Memory required for data: 89714700
I1022 15:54:57.968678 27427 layer_factory.hpp:77] Creating layer res2c_branch2c
I1022 15:54:57.968688 27427 net.cpp:100] Creating Layer res2c_branch2c
I1022 15:54:57.968693 27427 net.cpp:444] res2c_branch2c <- res2c_branch2b
I1022 15:54:57.968700 27427 net.cpp:418] res2c_branch2c -> res2c_branch2c
I1022 15:54:57.972133 27427 net.cpp:150] Setting up res2c_branch2c
I1022 15:54:57.972148 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.972151 27427 net.cpp:165] Memory required for data: 92925964
I1022 15:54:57.972157 27427 layer_factory.hpp:77] Creating layer bn2c_branch2c
I1022 15:54:57.972167 27427 net.cpp:100] Creating Layer bn2c_branch2c
I1022 15:54:57.972170 27427 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I1022 15:54:57.972175 27427 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I1022 15:54:57.972520 27427 net.cpp:150] Setting up bn2c_branch2c
I1022 15:54:57.972528 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.972532 27427 net.cpp:165] Memory required for data: 96137228
I1022 15:54:57.972548 27427 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1022 15:54:57.972554 27427 net.cpp:100] Creating Layer scale2c_branch2c
I1022 15:54:57.972558 27427 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I1022 15:54:57.972566 27427 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I1022 15:54:57.972664 27427 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1022 15:54:57.972860 27427 net.cpp:150] Setting up scale2c_branch2c
I1022 15:54:57.972868 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.972872 27427 net.cpp:165] Memory required for data: 99348492
I1022 15:54:57.972877 27427 layer_factory.hpp:77] Creating layer res2c
I1022 15:54:57.972887 27427 net.cpp:100] Creating Layer res2c
I1022 15:54:57.972890 27427 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I1022 15:54:57.972895 27427 net.cpp:444] res2c <- res2c_branch2c
I1022 15:54:57.972900 27427 net.cpp:418] res2c -> res2c
I1022 15:54:57.972937 27427 net.cpp:150] Setting up res2c
I1022 15:54:57.972944 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.972947 27427 net.cpp:165] Memory required for data: 102559756
I1022 15:54:57.972950 27427 layer_factory.hpp:77] Creating layer res2c_relu
I1022 15:54:57.972955 27427 net.cpp:100] Creating Layer res2c_relu
I1022 15:54:57.972959 27427 net.cpp:444] res2c_relu <- res2c
I1022 15:54:57.972964 27427 net.cpp:405] res2c_relu -> res2c (in-place)
I1022 15:54:57.973860 27427 net.cpp:150] Setting up res2c_relu
I1022 15:54:57.973873 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.973876 27427 net.cpp:165] Memory required for data: 105771020
I1022 15:54:57.973879 27427 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I1022 15:54:57.973887 27427 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I1022 15:54:57.973891 27427 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I1022 15:54:57.973896 27427 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I1022 15:54:57.973906 27427 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I1022 15:54:57.973976 27427 net.cpp:150] Setting up res2c_res2c_relu_0_split
I1022 15:54:57.973984 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.973987 27427 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 15:54:57.973990 27427 net.cpp:165] Memory required for data: 112193548
I1022 15:54:57.973994 27427 layer_factory.hpp:77] Creating layer res3a_branch1
I1022 15:54:57.974005 27427 net.cpp:100] Creating Layer res3a_branch1
I1022 15:54:57.974010 27427 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I1022 15:54:57.974016 27427 net.cpp:418] res3a_branch1 -> res3a_branch1
I1022 15:54:57.978288 27427 net.cpp:150] Setting up res3a_branch1
I1022 15:54:57.978302 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.978305 27427 net.cpp:165] Memory required for data: 113799180
I1022 15:54:57.978312 27427 layer_factory.hpp:77] Creating layer bn3a_branch1
I1022 15:54:57.978319 27427 net.cpp:100] Creating Layer bn3a_branch1
I1022 15:54:57.978322 27427 net.cpp:444] bn3a_branch1 <- res3a_branch1
I1022 15:54:57.978329 27427 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I1022 15:54:57.980481 27427 net.cpp:150] Setting up bn3a_branch1
I1022 15:54:57.980494 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.980496 27427 net.cpp:165] Memory required for data: 115404812
I1022 15:54:57.980504 27427 layer_factory.hpp:77] Creating layer scale3a_branch1
I1022 15:54:57.980513 27427 net.cpp:100] Creating Layer scale3a_branch1
I1022 15:54:57.980517 27427 net.cpp:444] scale3a_branch1 <- res3a_branch1
I1022 15:54:57.980525 27427 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I1022 15:54:57.980595 27427 layer_factory.hpp:77] Creating layer scale3a_branch1
I1022 15:54:57.980803 27427 net.cpp:150] Setting up scale3a_branch1
I1022 15:54:57.980813 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.980815 27427 net.cpp:165] Memory required for data: 117010444
I1022 15:54:57.980820 27427 layer_factory.hpp:77] Creating layer res3a_branch2a
I1022 15:54:57.980830 27427 net.cpp:100] Creating Layer res3a_branch2a
I1022 15:54:57.980836 27427 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I1022 15:54:57.980841 27427 net.cpp:418] res3a_branch2a -> res3a_branch2a
I1022 15:54:57.983523 27427 net.cpp:150] Setting up res3a_branch2a
I1022 15:54:57.983538 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.983541 27427 net.cpp:165] Memory required for data: 117411852
I1022 15:54:57.983547 27427 layer_factory.hpp:77] Creating layer bn3a_branch2a
I1022 15:54:57.983557 27427 net.cpp:100] Creating Layer bn3a_branch2a
I1022 15:54:57.983561 27427 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I1022 15:54:57.983568 27427 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I1022 15:54:57.983930 27427 net.cpp:150] Setting up bn3a_branch2a
I1022 15:54:57.983937 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.983940 27427 net.cpp:165] Memory required for data: 117813260
I1022 15:54:57.983948 27427 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1022 15:54:57.983954 27427 net.cpp:100] Creating Layer scale3a_branch2a
I1022 15:54:57.983958 27427 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I1022 15:54:57.983964 27427 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I1022 15:54:57.984030 27427 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1022 15:54:57.984226 27427 net.cpp:150] Setting up scale3a_branch2a
I1022 15:54:57.984233 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.984236 27427 net.cpp:165] Memory required for data: 118214668
I1022 15:54:57.984242 27427 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I1022 15:54:57.984251 27427 net.cpp:100] Creating Layer res3a_branch2a_relu
I1022 15:54:57.984253 27427 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I1022 15:54:57.984261 27427 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I1022 15:54:57.985162 27427 net.cpp:150] Setting up res3a_branch2a_relu
I1022 15:54:57.985174 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.985177 27427 net.cpp:165] Memory required for data: 118616076
I1022 15:54:57.985182 27427 layer_factory.hpp:77] Creating layer res3a_branch2b
I1022 15:54:57.985193 27427 net.cpp:100] Creating Layer res3a_branch2b
I1022 15:54:57.985195 27427 net.cpp:444] res3a_branch2b <- res3a_branch2a
I1022 15:54:57.985205 27427 net.cpp:418] res3a_branch2b -> res3a_branch2b
I1022 15:54:57.987756 27427 net.cpp:150] Setting up res3a_branch2b
I1022 15:54:57.987768 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.987771 27427 net.cpp:165] Memory required for data: 119017484
I1022 15:54:57.987776 27427 layer_factory.hpp:77] Creating layer bn3a_branch2b
I1022 15:54:57.987787 27427 net.cpp:100] Creating Layer bn3a_branch2b
I1022 15:54:57.987790 27427 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I1022 15:54:57.987797 27427 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I1022 15:54:57.988159 27427 net.cpp:150] Setting up bn3a_branch2b
I1022 15:54:57.988168 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.988170 27427 net.cpp:165] Memory required for data: 119418892
I1022 15:54:57.988178 27427 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1022 15:54:57.988185 27427 net.cpp:100] Creating Layer scale3a_branch2b
I1022 15:54:57.988189 27427 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I1022 15:54:57.988193 27427 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I1022 15:54:57.988256 27427 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1022 15:54:57.988454 27427 net.cpp:150] Setting up scale3a_branch2b
I1022 15:54:57.988462 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.988466 27427 net.cpp:165] Memory required for data: 119820300
I1022 15:54:57.988471 27427 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I1022 15:54:57.988481 27427 net.cpp:100] Creating Layer res3a_branch2b_relu
I1022 15:54:57.988487 27427 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I1022 15:54:57.988492 27427 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I1022 15:54:57.988736 27427 net.cpp:150] Setting up res3a_branch2b_relu
I1022 15:54:57.988749 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.988751 27427 net.cpp:165] Memory required for data: 120221708
I1022 15:54:57.988755 27427 layer_factory.hpp:77] Creating layer res3a_branch2c
I1022 15:54:57.988762 27427 net.cpp:100] Creating Layer res3a_branch2c
I1022 15:54:57.988767 27427 net.cpp:444] res3a_branch2c <- res3a_branch2b
I1022 15:54:57.988775 27427 net.cpp:418] res3a_branch2c -> res3a_branch2c
I1022 15:54:57.990561 27427 net.cpp:150] Setting up res3a_branch2c
I1022 15:54:57.990573 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.990576 27427 net.cpp:165] Memory required for data: 121827340
I1022 15:54:57.990582 27427 layer_factory.hpp:77] Creating layer bn3a_branch2c
I1022 15:54:57.990597 27427 net.cpp:100] Creating Layer bn3a_branch2c
I1022 15:54:57.990600 27427 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I1022 15:54:57.990605 27427 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I1022 15:54:57.990970 27427 net.cpp:150] Setting up bn3a_branch2c
I1022 15:54:57.990978 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.990980 27427 net.cpp:165] Memory required for data: 123432972
I1022 15:54:57.990988 27427 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1022 15:54:57.990994 27427 net.cpp:100] Creating Layer scale3a_branch2c
I1022 15:54:57.990998 27427 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I1022 15:54:57.991004 27427 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I1022 15:54:57.991073 27427 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1022 15:54:57.991271 27427 net.cpp:150] Setting up scale3a_branch2c
I1022 15:54:57.991278 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.991281 27427 net.cpp:165] Memory required for data: 125038604
I1022 15:54:57.991287 27427 layer_factory.hpp:77] Creating layer res3a
I1022 15:54:57.991294 27427 net.cpp:100] Creating Layer res3a
I1022 15:54:57.991298 27427 net.cpp:444] res3a <- res3a_branch1
I1022 15:54:57.991302 27427 net.cpp:444] res3a <- res3a_branch2c
I1022 15:54:57.991309 27427 net.cpp:418] res3a -> res3a
I1022 15:54:57.991346 27427 net.cpp:150] Setting up res3a
I1022 15:54:57.991353 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.991356 27427 net.cpp:165] Memory required for data: 126644236
I1022 15:54:57.991358 27427 layer_factory.hpp:77] Creating layer res3a_relu
I1022 15:54:57.991364 27427 net.cpp:100] Creating Layer res3a_relu
I1022 15:54:57.991367 27427 net.cpp:444] res3a_relu <- res3a
I1022 15:54:57.991374 27427 net.cpp:405] res3a_relu -> res3a (in-place)
I1022 15:54:57.992276 27427 net.cpp:150] Setting up res3a_relu
I1022 15:54:57.992291 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.992295 27427 net.cpp:165] Memory required for data: 128249868
I1022 15:54:57.992297 27427 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I1022 15:54:57.992305 27427 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I1022 15:54:57.992307 27427 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I1022 15:54:57.992316 27427 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I1022 15:54:57.992323 27427 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I1022 15:54:57.992400 27427 net.cpp:150] Setting up res3a_res3a_relu_0_split
I1022 15:54:57.992408 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.992413 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:57.992415 27427 net.cpp:165] Memory required for data: 131461132
I1022 15:54:57.992419 27427 layer_factory.hpp:77] Creating layer res3b_branch2a
I1022 15:54:57.992429 27427 net.cpp:100] Creating Layer res3b_branch2a
I1022 15:54:57.992431 27427 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I1022 15:54:57.992439 27427 net.cpp:418] res3b_branch2a -> res3b_branch2a
I1022 15:54:57.994240 27427 net.cpp:150] Setting up res3b_branch2a
I1022 15:54:57.994253 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.994256 27427 net.cpp:165] Memory required for data: 131862540
I1022 15:54:57.994262 27427 layer_factory.hpp:77] Creating layer bn3b_branch2a
I1022 15:54:57.994271 27427 net.cpp:100] Creating Layer bn3b_branch2a
I1022 15:54:57.994276 27427 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I1022 15:54:57.994282 27427 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I1022 15:54:57.994639 27427 net.cpp:150] Setting up bn3b_branch2a
I1022 15:54:57.994648 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.994652 27427 net.cpp:165] Memory required for data: 132263948
I1022 15:54:57.994658 27427 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1022 15:54:57.994664 27427 net.cpp:100] Creating Layer scale3b_branch2a
I1022 15:54:57.994668 27427 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I1022 15:54:57.994674 27427 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I1022 15:54:57.994738 27427 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1022 15:54:57.994936 27427 net.cpp:150] Setting up scale3b_branch2a
I1022 15:54:57.994943 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.994947 27427 net.cpp:165] Memory required for data: 132665356
I1022 15:54:57.994952 27427 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I1022 15:54:57.994959 27427 net.cpp:100] Creating Layer res3b_branch2a_relu
I1022 15:54:57.994962 27427 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I1022 15:54:57.994967 27427 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I1022 15:54:57.995200 27427 net.cpp:150] Setting up res3b_branch2a_relu
I1022 15:54:57.995209 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.995213 27427 net.cpp:165] Memory required for data: 133066764
I1022 15:54:57.995215 27427 layer_factory.hpp:77] Creating layer res3b_branch2b
I1022 15:54:57.995224 27427 net.cpp:100] Creating Layer res3b_branch2b
I1022 15:54:57.995229 27427 net.cpp:444] res3b_branch2b <- res3b_branch2a
I1022 15:54:57.995236 27427 net.cpp:418] res3b_branch2b -> res3b_branch2b
I1022 15:54:57.997731 27427 net.cpp:150] Setting up res3b_branch2b
I1022 15:54:57.997745 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.997748 27427 net.cpp:165] Memory required for data: 133468172
I1022 15:54:57.997754 27427 layer_factory.hpp:77] Creating layer bn3b_branch2b
I1022 15:54:57.997763 27427 net.cpp:100] Creating Layer bn3b_branch2b
I1022 15:54:57.997767 27427 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I1022 15:54:57.997772 27427 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I1022 15:54:57.998159 27427 net.cpp:150] Setting up bn3b_branch2b
I1022 15:54:57.998168 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.998170 27427 net.cpp:165] Memory required for data: 133869580
I1022 15:54:57.998178 27427 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1022 15:54:57.998185 27427 net.cpp:100] Creating Layer scale3b_branch2b
I1022 15:54:57.998188 27427 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I1022 15:54:57.998193 27427 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I1022 15:54:57.998255 27427 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1022 15:54:57.998459 27427 net.cpp:150] Setting up scale3b_branch2b
I1022 15:54:57.998466 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.998469 27427 net.cpp:165] Memory required for data: 134270988
I1022 15:54:57.998476 27427 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I1022 15:54:57.998482 27427 net.cpp:100] Creating Layer res3b_branch2b_relu
I1022 15:54:57.998486 27427 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I1022 15:54:57.998492 27427 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I1022 15:54:57.998728 27427 net.cpp:150] Setting up res3b_branch2b_relu
I1022 15:54:57.998737 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:57.998740 27427 net.cpp:165] Memory required for data: 134672396
I1022 15:54:57.998744 27427 layer_factory.hpp:77] Creating layer res3b_branch2c
I1022 15:54:57.998754 27427 net.cpp:100] Creating Layer res3b_branch2c
I1022 15:54:57.998757 27427 net.cpp:444] res3b_branch2c <- res3b_branch2b
I1022 15:54:57.998766 27427 net.cpp:418] res3b_branch2c -> res3b_branch2c
I1022 15:54:58.000557 27427 net.cpp:150] Setting up res3b_branch2c
I1022 15:54:58.000571 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.000573 27427 net.cpp:165] Memory required for data: 136278028
I1022 15:54:58.000581 27427 layer_factory.hpp:77] Creating layer bn3b_branch2c
I1022 15:54:58.000588 27427 net.cpp:100] Creating Layer bn3b_branch2c
I1022 15:54:58.000592 27427 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I1022 15:54:58.000597 27427 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I1022 15:54:58.000995 27427 net.cpp:150] Setting up bn3b_branch2c
I1022 15:54:58.001003 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.001006 27427 net.cpp:165] Memory required for data: 137883660
I1022 15:54:58.001014 27427 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1022 15:54:58.001022 27427 net.cpp:100] Creating Layer scale3b_branch2c
I1022 15:54:58.001026 27427 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I1022 15:54:58.001030 27427 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I1022 15:54:58.001097 27427 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1022 15:54:58.001294 27427 net.cpp:150] Setting up scale3b_branch2c
I1022 15:54:58.001302 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.001304 27427 net.cpp:165] Memory required for data: 139489292
I1022 15:54:58.001310 27427 layer_factory.hpp:77] Creating layer res3b
I1022 15:54:58.001319 27427 net.cpp:100] Creating Layer res3b
I1022 15:54:58.001324 27427 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I1022 15:54:58.001328 27427 net.cpp:444] res3b <- res3b_branch2c
I1022 15:54:58.001333 27427 net.cpp:418] res3b -> res3b
I1022 15:54:58.001371 27427 net.cpp:150] Setting up res3b
I1022 15:54:58.001379 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.001381 27427 net.cpp:165] Memory required for data: 141094924
I1022 15:54:58.001384 27427 layer_factory.hpp:77] Creating layer res3b_relu
I1022 15:54:58.001389 27427 net.cpp:100] Creating Layer res3b_relu
I1022 15:54:58.001392 27427 net.cpp:444] res3b_relu <- res3b
I1022 15:54:58.001396 27427 net.cpp:405] res3b_relu -> res3b (in-place)
I1022 15:54:58.003670 27427 net.cpp:150] Setting up res3b_relu
I1022 15:54:58.003685 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.003690 27427 net.cpp:165] Memory required for data: 142700556
I1022 15:54:58.003692 27427 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I1022 15:54:58.003700 27427 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I1022 15:54:58.003705 27427 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I1022 15:54:58.003712 27427 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I1022 15:54:58.003720 27427 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I1022 15:54:58.003801 27427 net.cpp:150] Setting up res3b_res3b_relu_0_split
I1022 15:54:58.003808 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.003813 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.003815 27427 net.cpp:165] Memory required for data: 145911820
I1022 15:54:58.003818 27427 layer_factory.hpp:77] Creating layer res3c_branch2a
I1022 15:54:58.003829 27427 net.cpp:100] Creating Layer res3c_branch2a
I1022 15:54:58.003834 27427 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I1022 15:54:58.003840 27427 net.cpp:418] res3c_branch2a -> res3c_branch2a
I1022 15:54:58.005689 27427 net.cpp:150] Setting up res3c_branch2a
I1022 15:54:58.005703 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.005707 27427 net.cpp:165] Memory required for data: 146313228
I1022 15:54:58.005712 27427 layer_factory.hpp:77] Creating layer bn3c_branch2a
I1022 15:54:58.005722 27427 net.cpp:100] Creating Layer bn3c_branch2a
I1022 15:54:58.005726 27427 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I1022 15:54:58.005731 27427 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I1022 15:54:58.006103 27427 net.cpp:150] Setting up bn3c_branch2a
I1022 15:54:58.006109 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.006114 27427 net.cpp:165] Memory required for data: 146714636
I1022 15:54:58.006120 27427 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1022 15:54:58.006126 27427 net.cpp:100] Creating Layer scale3c_branch2a
I1022 15:54:58.006129 27427 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I1022 15:54:58.006136 27427 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I1022 15:54:58.006202 27427 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1022 15:54:58.006404 27427 net.cpp:150] Setting up scale3c_branch2a
I1022 15:54:58.006412 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.006415 27427 net.cpp:165] Memory required for data: 147116044
I1022 15:54:58.006420 27427 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I1022 15:54:58.006428 27427 net.cpp:100] Creating Layer res3c_branch2a_relu
I1022 15:54:58.006430 27427 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I1022 15:54:58.006438 27427 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I1022 15:54:58.006672 27427 net.cpp:150] Setting up res3c_branch2a_relu
I1022 15:54:58.006681 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.006683 27427 net.cpp:165] Memory required for data: 147517452
I1022 15:54:58.006687 27427 layer_factory.hpp:77] Creating layer res3c_branch2b
I1022 15:54:58.006696 27427 net.cpp:100] Creating Layer res3c_branch2b
I1022 15:54:58.006703 27427 net.cpp:444] res3c_branch2b <- res3c_branch2a
I1022 15:54:58.006708 27427 net.cpp:418] res3c_branch2b -> res3c_branch2b
I1022 15:54:58.016525 27427 net.cpp:150] Setting up res3c_branch2b
I1022 15:54:58.016541 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.016546 27427 net.cpp:165] Memory required for data: 147918860
I1022 15:54:58.016551 27427 layer_factory.hpp:77] Creating layer bn3c_branch2b
I1022 15:54:58.016559 27427 net.cpp:100] Creating Layer bn3c_branch2b
I1022 15:54:58.016562 27427 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I1022 15:54:58.016571 27427 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I1022 15:54:58.016971 27427 net.cpp:150] Setting up bn3c_branch2b
I1022 15:54:58.016980 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.016983 27427 net.cpp:165] Memory required for data: 148320268
I1022 15:54:58.016991 27427 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1022 15:54:58.017000 27427 net.cpp:100] Creating Layer scale3c_branch2b
I1022 15:54:58.017004 27427 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I1022 15:54:58.017011 27427 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I1022 15:54:58.017077 27427 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1022 15:54:58.017282 27427 net.cpp:150] Setting up scale3c_branch2b
I1022 15:54:58.017290 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.017293 27427 net.cpp:165] Memory required for data: 148721676
I1022 15:54:58.017299 27427 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I1022 15:54:58.017307 27427 net.cpp:100] Creating Layer res3c_branch2b_relu
I1022 15:54:58.017310 27427 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I1022 15:54:58.017316 27427 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I1022 15:54:58.017563 27427 net.cpp:150] Setting up res3c_branch2b_relu
I1022 15:54:58.017572 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.017575 27427 net.cpp:165] Memory required for data: 149123084
I1022 15:54:58.017580 27427 layer_factory.hpp:77] Creating layer res3c_branch2c
I1022 15:54:58.017590 27427 net.cpp:100] Creating Layer res3c_branch2c
I1022 15:54:58.017592 27427 net.cpp:444] res3c_branch2c <- res3c_branch2b
I1022 15:54:58.017601 27427 net.cpp:418] res3c_branch2c -> res3c_branch2c
I1022 15:54:58.019428 27427 net.cpp:150] Setting up res3c_branch2c
I1022 15:54:58.019441 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.019444 27427 net.cpp:165] Memory required for data: 150728716
I1022 15:54:58.019451 27427 layer_factory.hpp:77] Creating layer bn3c_branch2c
I1022 15:54:58.019464 27427 net.cpp:100] Creating Layer bn3c_branch2c
I1022 15:54:58.019467 27427 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I1022 15:54:58.019472 27427 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I1022 15:54:58.019850 27427 net.cpp:150] Setting up bn3c_branch2c
I1022 15:54:58.019857 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.019860 27427 net.cpp:165] Memory required for data: 152334348
I1022 15:54:58.019867 27427 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1022 15:54:58.019873 27427 net.cpp:100] Creating Layer scale3c_branch2c
I1022 15:54:58.019876 27427 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I1022 15:54:58.019882 27427 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I1022 15:54:58.019953 27427 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1022 15:54:58.020153 27427 net.cpp:150] Setting up scale3c_branch2c
I1022 15:54:58.020159 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.020162 27427 net.cpp:165] Memory required for data: 153939980
I1022 15:54:58.020167 27427 layer_factory.hpp:77] Creating layer res3c
I1022 15:54:58.020175 27427 net.cpp:100] Creating Layer res3c
I1022 15:54:58.020179 27427 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I1022 15:54:58.020182 27427 net.cpp:444] res3c <- res3c_branch2c
I1022 15:54:58.020190 27427 net.cpp:418] res3c -> res3c
I1022 15:54:58.020229 27427 net.cpp:150] Setting up res3c
I1022 15:54:58.020236 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.020238 27427 net.cpp:165] Memory required for data: 155545612
I1022 15:54:58.020241 27427 layer_factory.hpp:77] Creating layer res3c_relu
I1022 15:54:58.020249 27427 net.cpp:100] Creating Layer res3c_relu
I1022 15:54:58.020254 27427 net.cpp:444] res3c_relu <- res3c
I1022 15:54:58.020258 27427 net.cpp:405] res3c_relu -> res3c (in-place)
I1022 15:54:58.020493 27427 net.cpp:150] Setting up res3c_relu
I1022 15:54:58.020503 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.020505 27427 net.cpp:165] Memory required for data: 157151244
I1022 15:54:58.020509 27427 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I1022 15:54:58.020519 27427 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I1022 15:54:58.020524 27427 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I1022 15:54:58.020531 27427 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I1022 15:54:58.020539 27427 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I1022 15:54:58.020630 27427 net.cpp:150] Setting up res3c_res3c_relu_0_split
I1022 15:54:58.020637 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.020653 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.020656 27427 net.cpp:165] Memory required for data: 160362508
I1022 15:54:58.020659 27427 layer_factory.hpp:77] Creating layer res3d_branch2a
I1022 15:54:58.020670 27427 net.cpp:100] Creating Layer res3d_branch2a
I1022 15:54:58.020674 27427 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I1022 15:54:58.020681 27427 net.cpp:418] res3d_branch2a -> res3d_branch2a
I1022 15:54:58.026015 27427 net.cpp:150] Setting up res3d_branch2a
I1022 15:54:58.026031 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.026033 27427 net.cpp:165] Memory required for data: 160763916
I1022 15:54:58.026039 27427 layer_factory.hpp:77] Creating layer bn3d_branch2a
I1022 15:54:58.026049 27427 net.cpp:100] Creating Layer bn3d_branch2a
I1022 15:54:58.026053 27427 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I1022 15:54:58.026058 27427 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I1022 15:54:58.026432 27427 net.cpp:150] Setting up bn3d_branch2a
I1022 15:54:58.026438 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.026443 27427 net.cpp:165] Memory required for data: 161165324
I1022 15:54:58.026461 27427 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1022 15:54:58.026469 27427 net.cpp:100] Creating Layer scale3d_branch2a
I1022 15:54:58.026473 27427 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I1022 15:54:58.026479 27427 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I1022 15:54:58.026546 27427 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1022 15:54:58.026749 27427 net.cpp:150] Setting up scale3d_branch2a
I1022 15:54:58.026757 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.026760 27427 net.cpp:165] Memory required for data: 161566732
I1022 15:54:58.026767 27427 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I1022 15:54:58.026772 27427 net.cpp:100] Creating Layer res3d_branch2a_relu
I1022 15:54:58.026775 27427 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I1022 15:54:58.026780 27427 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I1022 15:54:58.027700 27427 net.cpp:150] Setting up res3d_branch2a_relu
I1022 15:54:58.027714 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.027717 27427 net.cpp:165] Memory required for data: 161968140
I1022 15:54:58.027726 27427 layer_factory.hpp:77] Creating layer res3d_branch2b
I1022 15:54:58.027736 27427 net.cpp:100] Creating Layer res3d_branch2b
I1022 15:54:58.027740 27427 net.cpp:444] res3d_branch2b <- res3d_branch2a
I1022 15:54:58.027747 27427 net.cpp:418] res3d_branch2b -> res3d_branch2b
I1022 15:54:58.032006 27427 net.cpp:150] Setting up res3d_branch2b
I1022 15:54:58.032023 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.032027 27427 net.cpp:165] Memory required for data: 162369548
I1022 15:54:58.032033 27427 layer_factory.hpp:77] Creating layer bn3d_branch2b
I1022 15:54:58.032040 27427 net.cpp:100] Creating Layer bn3d_branch2b
I1022 15:54:58.032044 27427 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I1022 15:54:58.032052 27427 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I1022 15:54:58.032443 27427 net.cpp:150] Setting up bn3d_branch2b
I1022 15:54:58.032450 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.032454 27427 net.cpp:165] Memory required for data: 162770956
I1022 15:54:58.032461 27427 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1022 15:54:58.032469 27427 net.cpp:100] Creating Layer scale3d_branch2b
I1022 15:54:58.032472 27427 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I1022 15:54:58.032480 27427 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I1022 15:54:58.032547 27427 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1022 15:54:58.032779 27427 net.cpp:150] Setting up scale3d_branch2b
I1022 15:54:58.032788 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.032790 27427 net.cpp:165] Memory required for data: 163172364
I1022 15:54:58.032797 27427 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I1022 15:54:58.032804 27427 net.cpp:100] Creating Layer res3d_branch2b_relu
I1022 15:54:58.032809 27427 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I1022 15:54:58.032814 27427 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I1022 15:54:58.033062 27427 net.cpp:150] Setting up res3d_branch2b_relu
I1022 15:54:58.033071 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.033074 27427 net.cpp:165] Memory required for data: 163573772
I1022 15:54:58.033077 27427 layer_factory.hpp:77] Creating layer res3d_branch2c
I1022 15:54:58.033087 27427 net.cpp:100] Creating Layer res3d_branch2c
I1022 15:54:58.033092 27427 net.cpp:444] res3d_branch2c <- res3d_branch2b
I1022 15:54:58.033098 27427 net.cpp:418] res3d_branch2c -> res3d_branch2c
I1022 15:54:58.034953 27427 net.cpp:150] Setting up res3d_branch2c
I1022 15:54:58.034966 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.034970 27427 net.cpp:165] Memory required for data: 165179404
I1022 15:54:58.034976 27427 layer_factory.hpp:77] Creating layer bn3d_branch2c
I1022 15:54:58.034986 27427 net.cpp:100] Creating Layer bn3d_branch2c
I1022 15:54:58.034989 27427 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I1022 15:54:58.034996 27427 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I1022 15:54:58.035368 27427 net.cpp:150] Setting up bn3d_branch2c
I1022 15:54:58.035378 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.035380 27427 net.cpp:165] Memory required for data: 166785036
I1022 15:54:58.035387 27427 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1022 15:54:58.035394 27427 net.cpp:100] Creating Layer scale3d_branch2c
I1022 15:54:58.035398 27427 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I1022 15:54:58.035403 27427 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I1022 15:54:58.035475 27427 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1022 15:54:58.035678 27427 net.cpp:150] Setting up scale3d_branch2c
I1022 15:54:58.035686 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.035688 27427 net.cpp:165] Memory required for data: 168390668
I1022 15:54:58.035693 27427 layer_factory.hpp:77] Creating layer res3d
I1022 15:54:58.035701 27427 net.cpp:100] Creating Layer res3d
I1022 15:54:58.035704 27427 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I1022 15:54:58.035708 27427 net.cpp:444] res3d <- res3d_branch2c
I1022 15:54:58.035715 27427 net.cpp:418] res3d -> res3d
I1022 15:54:58.035754 27427 net.cpp:150] Setting up res3d
I1022 15:54:58.035761 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.035764 27427 net.cpp:165] Memory required for data: 169996300
I1022 15:54:58.035768 27427 layer_factory.hpp:77] Creating layer res3d_relu
I1022 15:54:58.035773 27427 net.cpp:100] Creating Layer res3d_relu
I1022 15:54:58.035775 27427 net.cpp:444] res3d_relu <- res3d
I1022 15:54:58.035781 27427 net.cpp:405] res3d_relu -> res3d (in-place)
I1022 15:54:58.036021 27427 net.cpp:150] Setting up res3d_relu
I1022 15:54:58.036031 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.036033 27427 net.cpp:165] Memory required for data: 171601932
I1022 15:54:58.036036 27427 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I1022 15:54:58.036044 27427 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I1022 15:54:58.036049 27427 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I1022 15:54:58.036056 27427 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I1022 15:54:58.036064 27427 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I1022 15:54:58.036072 27427 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_2
I1022 15:54:58.036170 27427 net.cpp:150] Setting up res3d_res3d_relu_0_split
I1022 15:54:58.036176 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.036180 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.036185 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.036187 27427 net.cpp:165] Memory required for data: 176418828
I1022 15:54:58.036190 27427 layer_factory.hpp:77] Creating layer res4a_branch1
I1022 15:54:58.036201 27427 net.cpp:100] Creating Layer res4a_branch1
I1022 15:54:58.036206 27427 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I1022 15:54:58.036212 27427 net.cpp:418] res4a_branch1 -> res4a_branch1
I1022 15:54:58.040125 27427 net.cpp:150] Setting up res4a_branch1
I1022 15:54:58.040139 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.040143 27427 net.cpp:165] Memory required for data: 177221644
I1022 15:54:58.040149 27427 layer_factory.hpp:77] Creating layer bn4a_branch1
I1022 15:54:58.040158 27427 net.cpp:100] Creating Layer bn4a_branch1
I1022 15:54:58.040163 27427 net.cpp:444] bn4a_branch1 <- res4a_branch1
I1022 15:54:58.040170 27427 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I1022 15:54:58.040591 27427 net.cpp:150] Setting up bn4a_branch1
I1022 15:54:58.040597 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.040601 27427 net.cpp:165] Memory required for data: 178024460
I1022 15:54:58.040618 27427 layer_factory.hpp:77] Creating layer scale4a_branch1
I1022 15:54:58.040627 27427 net.cpp:100] Creating Layer scale4a_branch1
I1022 15:54:58.040632 27427 net.cpp:444] scale4a_branch1 <- res4a_branch1
I1022 15:54:58.040637 27427 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I1022 15:54:58.040712 27427 layer_factory.hpp:77] Creating layer scale4a_branch1
I1022 15:54:58.040923 27427 net.cpp:150] Setting up scale4a_branch1
I1022 15:54:58.040931 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.040935 27427 net.cpp:165] Memory required for data: 178827276
I1022 15:54:58.040940 27427 layer_factory.hpp:77] Creating layer res4a_branch2a
I1022 15:54:58.040951 27427 net.cpp:100] Creating Layer res4a_branch2a
I1022 15:54:58.040956 27427 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I1022 15:54:58.040961 27427 net.cpp:418] res4a_branch2a -> res4a_branch2a
I1022 15:54:58.049494 27427 net.cpp:150] Setting up res4a_branch2a
I1022 15:54:58.049509 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.049512 27427 net.cpp:165] Memory required for data: 179027980
I1022 15:54:58.049518 27427 layer_factory.hpp:77] Creating layer bn4a_branch2a
I1022 15:54:58.049527 27427 net.cpp:100] Creating Layer bn4a_branch2a
I1022 15:54:58.049531 27427 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I1022 15:54:58.049537 27427 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I1022 15:54:58.049918 27427 net.cpp:150] Setting up bn4a_branch2a
I1022 15:54:58.049926 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.049929 27427 net.cpp:165] Memory required for data: 179228684
I1022 15:54:58.049937 27427 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1022 15:54:58.049944 27427 net.cpp:100] Creating Layer scale4a_branch2a
I1022 15:54:58.049948 27427 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I1022 15:54:58.049953 27427 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I1022 15:54:58.050019 27427 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1022 15:54:58.050220 27427 net.cpp:150] Setting up scale4a_branch2a
I1022 15:54:58.050227 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.050230 27427 net.cpp:165] Memory required for data: 179429388
I1022 15:54:58.050235 27427 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I1022 15:54:58.050245 27427 net.cpp:100] Creating Layer res4a_branch2a_relu
I1022 15:54:58.050249 27427 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I1022 15:54:58.050254 27427 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I1022 15:54:58.052244 27427 net.cpp:150] Setting up res4a_branch2a_relu
I1022 15:54:58.052259 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.052263 27427 net.cpp:165] Memory required for data: 179630092
I1022 15:54:58.052266 27427 layer_factory.hpp:77] Creating layer res4a_branch2b
I1022 15:54:58.052279 27427 net.cpp:100] Creating Layer res4a_branch2b
I1022 15:54:58.052284 27427 net.cpp:444] res4a_branch2b <- res4a_branch2a
I1022 15:54:58.052292 27427 net.cpp:418] res4a_branch2b -> res4a_branch2b
I1022 15:54:58.057217 27427 net.cpp:150] Setting up res4a_branch2b
I1022 15:54:58.057231 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.057235 27427 net.cpp:165] Memory required for data: 179830796
I1022 15:54:58.057241 27427 layer_factory.hpp:77] Creating layer bn4a_branch2b
I1022 15:54:58.057251 27427 net.cpp:100] Creating Layer bn4a_branch2b
I1022 15:54:58.057255 27427 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I1022 15:54:58.057261 27427 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I1022 15:54:58.057651 27427 net.cpp:150] Setting up bn4a_branch2b
I1022 15:54:58.057660 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.057663 27427 net.cpp:165] Memory required for data: 180031500
I1022 15:54:58.057670 27427 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1022 15:54:58.057678 27427 net.cpp:100] Creating Layer scale4a_branch2b
I1022 15:54:58.057682 27427 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I1022 15:54:58.057688 27427 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I1022 15:54:58.057756 27427 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1022 15:54:58.057956 27427 net.cpp:150] Setting up scale4a_branch2b
I1022 15:54:58.057963 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.057966 27427 net.cpp:165] Memory required for data: 180232204
I1022 15:54:58.057972 27427 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I1022 15:54:58.057981 27427 net.cpp:100] Creating Layer res4a_branch2b_relu
I1022 15:54:58.057987 27427 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I1022 15:54:58.057991 27427 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I1022 15:54:58.058254 27427 net.cpp:150] Setting up res4a_branch2b_relu
I1022 15:54:58.058264 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.058269 27427 net.cpp:165] Memory required for data: 180432908
I1022 15:54:58.058272 27427 layer_factory.hpp:77] Creating layer res4a_branch2c
I1022 15:54:58.058281 27427 net.cpp:100] Creating Layer res4a_branch2c
I1022 15:54:58.058286 27427 net.cpp:444] res4a_branch2c <- res4a_branch2b
I1022 15:54:58.058292 27427 net.cpp:418] res4a_branch2c -> res4a_branch2c
I1022 15:54:58.065091 27427 net.cpp:150] Setting up res4a_branch2c
I1022 15:54:58.065106 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.065109 27427 net.cpp:165] Memory required for data: 181235724
I1022 15:54:58.065116 27427 layer_factory.hpp:77] Creating layer bn4a_branch2c
I1022 15:54:58.065127 27427 net.cpp:100] Creating Layer bn4a_branch2c
I1022 15:54:58.065131 27427 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I1022 15:54:58.065136 27427 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I1022 15:54:58.065521 27427 net.cpp:150] Setting up bn4a_branch2c
I1022 15:54:58.065528 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.065531 27427 net.cpp:165] Memory required for data: 182038540
I1022 15:54:58.065538 27427 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1022 15:54:58.065544 27427 net.cpp:100] Creating Layer scale4a_branch2c
I1022 15:54:58.065548 27427 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I1022 15:54:58.065554 27427 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I1022 15:54:58.065618 27427 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1022 15:54:58.065836 27427 net.cpp:150] Setting up scale4a_branch2c
I1022 15:54:58.065845 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.065847 27427 net.cpp:165] Memory required for data: 182841356
I1022 15:54:58.065852 27427 layer_factory.hpp:77] Creating layer res4a
I1022 15:54:58.065860 27427 net.cpp:100] Creating Layer res4a
I1022 15:54:58.065863 27427 net.cpp:444] res4a <- res4a_branch1
I1022 15:54:58.065867 27427 net.cpp:444] res4a <- res4a_branch2c
I1022 15:54:58.065874 27427 net.cpp:418] res4a -> res4a
I1022 15:54:58.065914 27427 net.cpp:150] Setting up res4a
I1022 15:54:58.065922 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.065924 27427 net.cpp:165] Memory required for data: 183644172
I1022 15:54:58.065927 27427 layer_factory.hpp:77] Creating layer res4a_relu
I1022 15:54:58.065934 27427 net.cpp:100] Creating Layer res4a_relu
I1022 15:54:58.065939 27427 net.cpp:444] res4a_relu <- res4a
I1022 15:54:58.065943 27427 net.cpp:405] res4a_relu -> res4a (in-place)
I1022 15:54:58.066854 27427 net.cpp:150] Setting up res4a_relu
I1022 15:54:58.066869 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.066872 27427 net.cpp:165] Memory required for data: 184446988
I1022 15:54:58.066876 27427 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I1022 15:54:58.066882 27427 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I1022 15:54:58.066886 27427 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I1022 15:54:58.066893 27427 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I1022 15:54:58.066901 27427 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I1022 15:54:58.066983 27427 net.cpp:150] Setting up res4a_res4a_relu_0_split
I1022 15:54:58.066992 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.066996 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.066999 27427 net.cpp:165] Memory required for data: 186052620
I1022 15:54:58.067003 27427 layer_factory.hpp:77] Creating layer res4b_branch2a
I1022 15:54:58.067023 27427 net.cpp:100] Creating Layer res4b_branch2a
I1022 15:54:58.067026 27427 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I1022 15:54:58.067032 27427 net.cpp:418] res4b_branch2a -> res4b_branch2a
I1022 15:54:58.069041 27427 net.cpp:150] Setting up res4b_branch2a
I1022 15:54:58.069054 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.069057 27427 net.cpp:165] Memory required for data: 186253324
I1022 15:54:58.069063 27427 layer_factory.hpp:77] Creating layer bn4b_branch2a
I1022 15:54:58.069072 27427 net.cpp:100] Creating Layer bn4b_branch2a
I1022 15:54:58.069077 27427 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I1022 15:54:58.069083 27427 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I1022 15:54:58.069469 27427 net.cpp:150] Setting up bn4b_branch2a
I1022 15:54:58.069478 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.069481 27427 net.cpp:165] Memory required for data: 186454028
I1022 15:54:58.069489 27427 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1022 15:54:58.069494 27427 net.cpp:100] Creating Layer scale4b_branch2a
I1022 15:54:58.069499 27427 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I1022 15:54:58.069504 27427 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I1022 15:54:58.069574 27427 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1022 15:54:58.069782 27427 net.cpp:150] Setting up scale4b_branch2a
I1022 15:54:58.069789 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.069792 27427 net.cpp:165] Memory required for data: 186654732
I1022 15:54:58.069798 27427 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I1022 15:54:58.069804 27427 net.cpp:100] Creating Layer res4b_branch2a_relu
I1022 15:54:58.069808 27427 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I1022 15:54:58.069814 27427 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I1022 15:54:58.070726 27427 net.cpp:150] Setting up res4b_branch2a_relu
I1022 15:54:58.070739 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.070741 27427 net.cpp:165] Memory required for data: 186855436
I1022 15:54:58.070745 27427 layer_factory.hpp:77] Creating layer res4b_branch2b
I1022 15:54:58.070755 27427 net.cpp:100] Creating Layer res4b_branch2b
I1022 15:54:58.070760 27427 net.cpp:444] res4b_branch2b <- res4b_branch2a
I1022 15:54:58.070765 27427 net.cpp:418] res4b_branch2b -> res4b_branch2b
I1022 15:54:58.075628 27427 net.cpp:150] Setting up res4b_branch2b
I1022 15:54:58.075642 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.075645 27427 net.cpp:165] Memory required for data: 187056140
I1022 15:54:58.075651 27427 layer_factory.hpp:77] Creating layer bn4b_branch2b
I1022 15:54:58.075661 27427 net.cpp:100] Creating Layer bn4b_branch2b
I1022 15:54:58.075665 27427 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I1022 15:54:58.075670 27427 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I1022 15:54:58.076076 27427 net.cpp:150] Setting up bn4b_branch2b
I1022 15:54:58.076084 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.076087 27427 net.cpp:165] Memory required for data: 187256844
I1022 15:54:58.076094 27427 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1022 15:54:58.076102 27427 net.cpp:100] Creating Layer scale4b_branch2b
I1022 15:54:58.076107 27427 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I1022 15:54:58.076112 27427 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I1022 15:54:58.076180 27427 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1022 15:54:58.076387 27427 net.cpp:150] Setting up scale4b_branch2b
I1022 15:54:58.076395 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.076398 27427 net.cpp:165] Memory required for data: 187457548
I1022 15:54:58.076403 27427 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I1022 15:54:58.076411 27427 net.cpp:100] Creating Layer res4b_branch2b_relu
I1022 15:54:58.076414 27427 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I1022 15:54:58.076421 27427 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I1022 15:54:58.076689 27427 net.cpp:150] Setting up res4b_branch2b_relu
I1022 15:54:58.076699 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.076701 27427 net.cpp:165] Memory required for data: 187658252
I1022 15:54:58.076704 27427 layer_factory.hpp:77] Creating layer res4b_branch2c
I1022 15:54:58.076715 27427 net.cpp:100] Creating Layer res4b_branch2c
I1022 15:54:58.076719 27427 net.cpp:444] res4b_branch2c <- res4b_branch2b
I1022 15:54:58.076725 27427 net.cpp:418] res4b_branch2c -> res4b_branch2c
I1022 15:54:58.080628 27427 net.cpp:150] Setting up res4b_branch2c
I1022 15:54:58.080654 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.080657 27427 net.cpp:165] Memory required for data: 188461068
I1022 15:54:58.080663 27427 layer_factory.hpp:77] Creating layer bn4b_branch2c
I1022 15:54:58.080682 27427 net.cpp:100] Creating Layer bn4b_branch2c
I1022 15:54:58.080687 27427 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I1022 15:54:58.080693 27427 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I1022 15:54:58.081090 27427 net.cpp:150] Setting up bn4b_branch2c
I1022 15:54:58.081099 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.081100 27427 net.cpp:165] Memory required for data: 189263884
I1022 15:54:58.081107 27427 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1022 15:54:58.081116 27427 net.cpp:100] Creating Layer scale4b_branch2c
I1022 15:54:58.081120 27427 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I1022 15:54:58.081125 27427 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I1022 15:54:58.081189 27427 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1022 15:54:58.081409 27427 net.cpp:150] Setting up scale4b_branch2c
I1022 15:54:58.081418 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.081420 27427 net.cpp:165] Memory required for data: 190066700
I1022 15:54:58.081425 27427 layer_factory.hpp:77] Creating layer res4b
I1022 15:54:58.081434 27427 net.cpp:100] Creating Layer res4b
I1022 15:54:58.081440 27427 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I1022 15:54:58.081444 27427 net.cpp:444] res4b <- res4b_branch2c
I1022 15:54:58.081449 27427 net.cpp:418] res4b -> res4b
I1022 15:54:58.081491 27427 net.cpp:150] Setting up res4b
I1022 15:54:58.081498 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.081501 27427 net.cpp:165] Memory required for data: 190869516
I1022 15:54:58.081504 27427 layer_factory.hpp:77] Creating layer res4b_relu
I1022 15:54:58.081509 27427 net.cpp:100] Creating Layer res4b_relu
I1022 15:54:58.081512 27427 net.cpp:444] res4b_relu <- res4b
I1022 15:54:58.081518 27427 net.cpp:405] res4b_relu -> res4b (in-place)
I1022 15:54:58.081755 27427 net.cpp:150] Setting up res4b_relu
I1022 15:54:58.081764 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.081768 27427 net.cpp:165] Memory required for data: 191672332
I1022 15:54:58.081770 27427 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I1022 15:54:58.081776 27427 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I1022 15:54:58.081784 27427 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I1022 15:54:58.081789 27427 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I1022 15:54:58.081794 27427 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I1022 15:54:58.081872 27427 net.cpp:150] Setting up res4b_res4b_relu_0_split
I1022 15:54:58.081879 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.081883 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.081885 27427 net.cpp:165] Memory required for data: 193277964
I1022 15:54:58.081888 27427 layer_factory.hpp:77] Creating layer res4c_branch2a
I1022 15:54:58.081898 27427 net.cpp:100] Creating Layer res4c_branch2a
I1022 15:54:58.081902 27427 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I1022 15:54:58.081908 27427 net.cpp:418] res4c_branch2a -> res4c_branch2a
I1022 15:54:58.083889 27427 net.cpp:150] Setting up res4c_branch2a
I1022 15:54:58.083904 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.083906 27427 net.cpp:165] Memory required for data: 193478668
I1022 15:54:58.083911 27427 layer_factory.hpp:77] Creating layer bn4c_branch2a
I1022 15:54:58.083921 27427 net.cpp:100] Creating Layer bn4c_branch2a
I1022 15:54:58.083925 27427 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I1022 15:54:58.083932 27427 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I1022 15:54:58.084316 27427 net.cpp:150] Setting up bn4c_branch2a
I1022 15:54:58.084326 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.084329 27427 net.cpp:165] Memory required for data: 193679372
I1022 15:54:58.084336 27427 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1022 15:54:58.084342 27427 net.cpp:100] Creating Layer scale4c_branch2a
I1022 15:54:58.084347 27427 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I1022 15:54:58.084352 27427 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I1022 15:54:58.084424 27427 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1022 15:54:58.084652 27427 net.cpp:150] Setting up scale4c_branch2a
I1022 15:54:58.084661 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.084663 27427 net.cpp:165] Memory required for data: 193880076
I1022 15:54:58.084669 27427 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I1022 15:54:58.084676 27427 net.cpp:100] Creating Layer res4c_branch2a_relu
I1022 15:54:58.084679 27427 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I1022 15:54:58.084684 27427 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I1022 15:54:58.084923 27427 net.cpp:150] Setting up res4c_branch2a_relu
I1022 15:54:58.084931 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.084934 27427 net.cpp:165] Memory required for data: 194080780
I1022 15:54:58.084939 27427 layer_factory.hpp:77] Creating layer res4c_branch2b
I1022 15:54:58.084949 27427 net.cpp:100] Creating Layer res4c_branch2b
I1022 15:54:58.084954 27427 net.cpp:444] res4c_branch2b <- res4c_branch2a
I1022 15:54:58.084962 27427 net.cpp:418] res4c_branch2b -> res4c_branch2b
I1022 15:54:58.091583 27427 net.cpp:150] Setting up res4c_branch2b
I1022 15:54:58.091599 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.091603 27427 net.cpp:165] Memory required for data: 194281484
I1022 15:54:58.091609 27427 layer_factory.hpp:77] Creating layer bn4c_branch2b
I1022 15:54:58.091619 27427 net.cpp:100] Creating Layer bn4c_branch2b
I1022 15:54:58.091621 27427 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I1022 15:54:58.091627 27427 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I1022 15:54:58.092044 27427 net.cpp:150] Setting up bn4c_branch2b
I1022 15:54:58.092053 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.092056 27427 net.cpp:165] Memory required for data: 194482188
I1022 15:54:58.092063 27427 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1022 15:54:58.092069 27427 net.cpp:100] Creating Layer scale4c_branch2b
I1022 15:54:58.092073 27427 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I1022 15:54:58.092079 27427 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I1022 15:54:58.092154 27427 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1022 15:54:58.092368 27427 net.cpp:150] Setting up scale4c_branch2b
I1022 15:54:58.092375 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.092378 27427 net.cpp:165] Memory required for data: 194682892
I1022 15:54:58.092384 27427 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I1022 15:54:58.092391 27427 net.cpp:100] Creating Layer res4c_branch2b_relu
I1022 15:54:58.092396 27427 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I1022 15:54:58.092401 27427 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I1022 15:54:58.093361 27427 net.cpp:150] Setting up res4c_branch2b_relu
I1022 15:54:58.093375 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.093379 27427 net.cpp:165] Memory required for data: 194883596
I1022 15:54:58.093382 27427 layer_factory.hpp:77] Creating layer res4c_branch2c
I1022 15:54:58.093392 27427 net.cpp:100] Creating Layer res4c_branch2c
I1022 15:54:58.093396 27427 net.cpp:444] res4c_branch2c <- res4c_branch2b
I1022 15:54:58.093405 27427 net.cpp:418] res4c_branch2c -> res4c_branch2c
I1022 15:54:58.097327 27427 net.cpp:150] Setting up res4c_branch2c
I1022 15:54:58.097342 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.097345 27427 net.cpp:165] Memory required for data: 195686412
I1022 15:54:58.097352 27427 layer_factory.hpp:77] Creating layer bn4c_branch2c
I1022 15:54:58.097360 27427 net.cpp:100] Creating Layer bn4c_branch2c
I1022 15:54:58.097364 27427 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I1022 15:54:58.097378 27427 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I1022 15:54:58.097784 27427 net.cpp:150] Setting up bn4c_branch2c
I1022 15:54:58.097791 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.097795 27427 net.cpp:165] Memory required for data: 196489228
I1022 15:54:58.097802 27427 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1022 15:54:58.097810 27427 net.cpp:100] Creating Layer scale4c_branch2c
I1022 15:54:58.097813 27427 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I1022 15:54:58.097820 27427 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I1022 15:54:58.097887 27427 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1022 15:54:58.098111 27427 net.cpp:150] Setting up scale4c_branch2c
I1022 15:54:58.098119 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.098121 27427 net.cpp:165] Memory required for data: 197292044
I1022 15:54:58.098127 27427 layer_factory.hpp:77] Creating layer res4c
I1022 15:54:58.098136 27427 net.cpp:100] Creating Layer res4c
I1022 15:54:58.098141 27427 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I1022 15:54:58.098145 27427 net.cpp:444] res4c <- res4c_branch2c
I1022 15:54:58.098150 27427 net.cpp:418] res4c -> res4c
I1022 15:54:58.098193 27427 net.cpp:150] Setting up res4c
I1022 15:54:58.098199 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.098202 27427 net.cpp:165] Memory required for data: 198094860
I1022 15:54:58.098206 27427 layer_factory.hpp:77] Creating layer res4c_relu
I1022 15:54:58.098210 27427 net.cpp:100] Creating Layer res4c_relu
I1022 15:54:58.098214 27427 net.cpp:444] res4c_relu <- res4c
I1022 15:54:58.098220 27427 net.cpp:405] res4c_relu -> res4c (in-place)
I1022 15:54:58.098460 27427 net.cpp:150] Setting up res4c_relu
I1022 15:54:58.098470 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.098472 27427 net.cpp:165] Memory required for data: 198897676
I1022 15:54:58.098476 27427 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I1022 15:54:58.098482 27427 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I1022 15:54:58.098487 27427 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I1022 15:54:58.098495 27427 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I1022 15:54:58.098502 27427 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I1022 15:54:58.098579 27427 net.cpp:150] Setting up res4c_res4c_relu_0_split
I1022 15:54:58.098587 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.098590 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.098593 27427 net.cpp:165] Memory required for data: 200503308
I1022 15:54:58.098596 27427 layer_factory.hpp:77] Creating layer res4d_branch2a
I1022 15:54:58.098606 27427 net.cpp:100] Creating Layer res4d_branch2a
I1022 15:54:58.098610 27427 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I1022 15:54:58.098618 27427 net.cpp:418] res4d_branch2a -> res4d_branch2a
I1022 15:54:58.100638 27427 net.cpp:150] Setting up res4d_branch2a
I1022 15:54:58.100651 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.100654 27427 net.cpp:165] Memory required for data: 200704012
I1022 15:54:58.100661 27427 layer_factory.hpp:77] Creating layer bn4d_branch2a
I1022 15:54:58.100669 27427 net.cpp:100] Creating Layer bn4d_branch2a
I1022 15:54:58.100673 27427 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I1022 15:54:58.100680 27427 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I1022 15:54:58.101079 27427 net.cpp:150] Setting up bn4d_branch2a
I1022 15:54:58.101086 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.101089 27427 net.cpp:165] Memory required for data: 200904716
I1022 15:54:58.101096 27427 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1022 15:54:58.101104 27427 net.cpp:100] Creating Layer scale4d_branch2a
I1022 15:54:58.101106 27427 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I1022 15:54:58.101114 27427 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I1022 15:54:58.101186 27427 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1022 15:54:58.101399 27427 net.cpp:150] Setting up scale4d_branch2a
I1022 15:54:58.101406 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.101409 27427 net.cpp:165] Memory required for data: 201105420
I1022 15:54:58.101415 27427 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I1022 15:54:58.101423 27427 net.cpp:100] Creating Layer res4d_branch2a_relu
I1022 15:54:58.101425 27427 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I1022 15:54:58.101431 27427 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I1022 15:54:58.101670 27427 net.cpp:150] Setting up res4d_branch2a_relu
I1022 15:54:58.101680 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.101682 27427 net.cpp:165] Memory required for data: 201306124
I1022 15:54:58.101686 27427 layer_factory.hpp:77] Creating layer res4d_branch2b
I1022 15:54:58.101696 27427 net.cpp:100] Creating Layer res4d_branch2b
I1022 15:54:58.101701 27427 net.cpp:444] res4d_branch2b <- res4d_branch2a
I1022 15:54:58.101707 27427 net.cpp:418] res4d_branch2b -> res4d_branch2b
I1022 15:54:58.108105 27427 net.cpp:150] Setting up res4d_branch2b
I1022 15:54:58.108119 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.108124 27427 net.cpp:165] Memory required for data: 201506828
I1022 15:54:58.108129 27427 layer_factory.hpp:77] Creating layer bn4d_branch2b
I1022 15:54:58.108139 27427 net.cpp:100] Creating Layer bn4d_branch2b
I1022 15:54:58.108144 27427 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I1022 15:54:58.108150 27427 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I1022 15:54:58.108574 27427 net.cpp:150] Setting up bn4d_branch2b
I1022 15:54:58.108582 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.108585 27427 net.cpp:165] Memory required for data: 201707532
I1022 15:54:58.108592 27427 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1022 15:54:58.108600 27427 net.cpp:100] Creating Layer scale4d_branch2b
I1022 15:54:58.108604 27427 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I1022 15:54:58.108629 27427 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I1022 15:54:58.108707 27427 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1022 15:54:58.108927 27427 net.cpp:150] Setting up scale4d_branch2b
I1022 15:54:58.108947 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.108949 27427 net.cpp:165] Memory required for data: 201908236
I1022 15:54:58.108955 27427 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I1022 15:54:58.108964 27427 net.cpp:100] Creating Layer res4d_branch2b_relu
I1022 15:54:58.108969 27427 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I1022 15:54:58.108973 27427 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I1022 15:54:58.109923 27427 net.cpp:150] Setting up res4d_branch2b_relu
I1022 15:54:58.109936 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.109939 27427 net.cpp:165] Memory required for data: 202108940
I1022 15:54:58.109943 27427 layer_factory.hpp:77] Creating layer res4d_branch2c
I1022 15:54:58.109953 27427 net.cpp:100] Creating Layer res4d_branch2c
I1022 15:54:58.109956 27427 net.cpp:444] res4d_branch2c <- res4d_branch2b
I1022 15:54:58.109966 27427 net.cpp:418] res4d_branch2c -> res4d_branch2c
I1022 15:54:58.113879 27427 net.cpp:150] Setting up res4d_branch2c
I1022 15:54:58.113895 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.113898 27427 net.cpp:165] Memory required for data: 202911756
I1022 15:54:58.113904 27427 layer_factory.hpp:77] Creating layer bn4d_branch2c
I1022 15:54:58.113911 27427 net.cpp:100] Creating Layer bn4d_branch2c
I1022 15:54:58.113915 27427 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I1022 15:54:58.113922 27427 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I1022 15:54:58.114332 27427 net.cpp:150] Setting up bn4d_branch2c
I1022 15:54:58.114339 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.114342 27427 net.cpp:165] Memory required for data: 203714572
I1022 15:54:58.114349 27427 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1022 15:54:58.114357 27427 net.cpp:100] Creating Layer scale4d_branch2c
I1022 15:54:58.114362 27427 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I1022 15:54:58.114368 27427 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I1022 15:54:58.114436 27427 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1022 15:54:58.114665 27427 net.cpp:150] Setting up scale4d_branch2c
I1022 15:54:58.114672 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.114675 27427 net.cpp:165] Memory required for data: 204517388
I1022 15:54:58.114681 27427 layer_factory.hpp:77] Creating layer res4d
I1022 15:54:58.114688 27427 net.cpp:100] Creating Layer res4d
I1022 15:54:58.114691 27427 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I1022 15:54:58.114696 27427 net.cpp:444] res4d <- res4d_branch2c
I1022 15:54:58.114701 27427 net.cpp:418] res4d -> res4d
I1022 15:54:58.114744 27427 net.cpp:150] Setting up res4d
I1022 15:54:58.114751 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.114754 27427 net.cpp:165] Memory required for data: 205320204
I1022 15:54:58.114758 27427 layer_factory.hpp:77] Creating layer res4d_relu
I1022 15:54:58.114763 27427 net.cpp:100] Creating Layer res4d_relu
I1022 15:54:58.114765 27427 net.cpp:444] res4d_relu <- res4d
I1022 15:54:58.114771 27427 net.cpp:405] res4d_relu -> res4d (in-place)
I1022 15:54:58.115023 27427 net.cpp:150] Setting up res4d_relu
I1022 15:54:58.115033 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.115036 27427 net.cpp:165] Memory required for data: 206123020
I1022 15:54:58.115041 27427 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I1022 15:54:58.115047 27427 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I1022 15:54:58.115051 27427 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I1022 15:54:58.115056 27427 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I1022 15:54:58.115063 27427 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I1022 15:54:58.115144 27427 net.cpp:150] Setting up res4d_res4d_relu_0_split
I1022 15:54:58.115150 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.115154 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.115157 27427 net.cpp:165] Memory required for data: 207728652
I1022 15:54:58.115160 27427 layer_factory.hpp:77] Creating layer res4e_branch2a
I1022 15:54:58.115169 27427 net.cpp:100] Creating Layer res4e_branch2a
I1022 15:54:58.115173 27427 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I1022 15:54:58.115178 27427 net.cpp:418] res4e_branch2a -> res4e_branch2a
I1022 15:54:58.117219 27427 net.cpp:150] Setting up res4e_branch2a
I1022 15:54:58.117233 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.117236 27427 net.cpp:165] Memory required for data: 207929356
I1022 15:54:58.117242 27427 layer_factory.hpp:77] Creating layer bn4e_branch2a
I1022 15:54:58.117251 27427 net.cpp:100] Creating Layer bn4e_branch2a
I1022 15:54:58.117255 27427 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I1022 15:54:58.117260 27427 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I1022 15:54:58.117661 27427 net.cpp:150] Setting up bn4e_branch2a
I1022 15:54:58.117669 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.117672 27427 net.cpp:165] Memory required for data: 208130060
I1022 15:54:58.117679 27427 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1022 15:54:58.117687 27427 net.cpp:100] Creating Layer scale4e_branch2a
I1022 15:54:58.117691 27427 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I1022 15:54:58.117697 27427 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I1022 15:54:58.117768 27427 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1022 15:54:58.117981 27427 net.cpp:150] Setting up scale4e_branch2a
I1022 15:54:58.117988 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.117992 27427 net.cpp:165] Memory required for data: 208330764
I1022 15:54:58.117997 27427 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I1022 15:54:58.118006 27427 net.cpp:100] Creating Layer res4e_branch2a_relu
I1022 15:54:58.118011 27427 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I1022 15:54:58.118016 27427 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I1022 15:54:58.118255 27427 net.cpp:150] Setting up res4e_branch2a_relu
I1022 15:54:58.118265 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.118268 27427 net.cpp:165] Memory required for data: 208531468
I1022 15:54:58.118271 27427 layer_factory.hpp:77] Creating layer res4e_branch2b
I1022 15:54:58.118283 27427 net.cpp:100] Creating Layer res4e_branch2b
I1022 15:54:58.118288 27427 net.cpp:444] res4e_branch2b <- res4e_branch2a
I1022 15:54:58.118294 27427 net.cpp:418] res4e_branch2b -> res4e_branch2b
I1022 15:54:58.126962 27427 net.cpp:150] Setting up res4e_branch2b
I1022 15:54:58.126978 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.126981 27427 net.cpp:165] Memory required for data: 208732172
I1022 15:54:58.126988 27427 layer_factory.hpp:77] Creating layer bn4e_branch2b
I1022 15:54:58.126996 27427 net.cpp:100] Creating Layer bn4e_branch2b
I1022 15:54:58.126999 27427 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I1022 15:54:58.127007 27427 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I1022 15:54:58.127434 27427 net.cpp:150] Setting up bn4e_branch2b
I1022 15:54:58.127442 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.127444 27427 net.cpp:165] Memory required for data: 208932876
I1022 15:54:58.127452 27427 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1022 15:54:58.127460 27427 net.cpp:100] Creating Layer scale4e_branch2b
I1022 15:54:58.127465 27427 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I1022 15:54:58.127470 27427 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I1022 15:54:58.127545 27427 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1022 15:54:58.127764 27427 net.cpp:150] Setting up scale4e_branch2b
I1022 15:54:58.127773 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.127775 27427 net.cpp:165] Memory required for data: 209133580
I1022 15:54:58.127781 27427 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I1022 15:54:58.127789 27427 net.cpp:100] Creating Layer res4e_branch2b_relu
I1022 15:54:58.127794 27427 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I1022 15:54:58.127799 27427 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I1022 15:54:58.128769 27427 net.cpp:150] Setting up res4e_branch2b_relu
I1022 15:54:58.128784 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.128788 27427 net.cpp:165] Memory required for data: 209334284
I1022 15:54:58.128793 27427 layer_factory.hpp:77] Creating layer res4e_branch2c
I1022 15:54:58.128803 27427 net.cpp:100] Creating Layer res4e_branch2c
I1022 15:54:58.128806 27427 net.cpp:444] res4e_branch2c <- res4e_branch2b
I1022 15:54:58.128813 27427 net.cpp:418] res4e_branch2c -> res4e_branch2c
I1022 15:54:58.132740 27427 net.cpp:150] Setting up res4e_branch2c
I1022 15:54:58.132753 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.132756 27427 net.cpp:165] Memory required for data: 210137100
I1022 15:54:58.132762 27427 layer_factory.hpp:77] Creating layer bn4e_branch2c
I1022 15:54:58.132771 27427 net.cpp:100] Creating Layer bn4e_branch2c
I1022 15:54:58.132776 27427 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I1022 15:54:58.132781 27427 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I1022 15:54:58.133193 27427 net.cpp:150] Setting up bn4e_branch2c
I1022 15:54:58.133200 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.133203 27427 net.cpp:165] Memory required for data: 210939916
I1022 15:54:58.133210 27427 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1022 15:54:58.133219 27427 net.cpp:100] Creating Layer scale4e_branch2c
I1022 15:54:58.133222 27427 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I1022 15:54:58.133227 27427 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I1022 15:54:58.133293 27427 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1022 15:54:58.133522 27427 net.cpp:150] Setting up scale4e_branch2c
I1022 15:54:58.133529 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.133532 27427 net.cpp:165] Memory required for data: 211742732
I1022 15:54:58.133538 27427 layer_factory.hpp:77] Creating layer res4e
I1022 15:54:58.133544 27427 net.cpp:100] Creating Layer res4e
I1022 15:54:58.133548 27427 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I1022 15:54:58.133553 27427 net.cpp:444] res4e <- res4e_branch2c
I1022 15:54:58.133558 27427 net.cpp:418] res4e -> res4e
I1022 15:54:58.133600 27427 net.cpp:150] Setting up res4e
I1022 15:54:58.133610 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.133611 27427 net.cpp:165] Memory required for data: 212545548
I1022 15:54:58.133615 27427 layer_factory.hpp:77] Creating layer res4e_relu
I1022 15:54:58.133621 27427 net.cpp:100] Creating Layer res4e_relu
I1022 15:54:58.133625 27427 net.cpp:444] res4e_relu <- res4e
I1022 15:54:58.133630 27427 net.cpp:405] res4e_relu -> res4e (in-place)
I1022 15:54:58.133873 27427 net.cpp:150] Setting up res4e_relu
I1022 15:54:58.133884 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.133888 27427 net.cpp:165] Memory required for data: 213348364
I1022 15:54:58.133890 27427 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I1022 15:54:58.133895 27427 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I1022 15:54:58.133899 27427 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I1022 15:54:58.133906 27427 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I1022 15:54:58.133914 27427 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I1022 15:54:58.133996 27427 net.cpp:150] Setting up res4e_res4e_relu_0_split
I1022 15:54:58.134003 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.134007 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.134011 27427 net.cpp:165] Memory required for data: 214953996
I1022 15:54:58.134013 27427 layer_factory.hpp:77] Creating layer res4f_branch2a
I1022 15:54:58.134023 27427 net.cpp:100] Creating Layer res4f_branch2a
I1022 15:54:58.134027 27427 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I1022 15:54:58.134034 27427 net.cpp:418] res4f_branch2a -> res4f_branch2a
I1022 15:54:58.136039 27427 net.cpp:150] Setting up res4f_branch2a
I1022 15:54:58.136052 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.136055 27427 net.cpp:165] Memory required for data: 215154700
I1022 15:54:58.136060 27427 layer_factory.hpp:77] Creating layer bn4f_branch2a
I1022 15:54:58.136070 27427 net.cpp:100] Creating Layer bn4f_branch2a
I1022 15:54:58.136075 27427 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I1022 15:54:58.136081 27427 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I1022 15:54:58.136487 27427 net.cpp:150] Setting up bn4f_branch2a
I1022 15:54:58.136495 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.136498 27427 net.cpp:165] Memory required for data: 215355404
I1022 15:54:58.136507 27427 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1022 15:54:58.136514 27427 net.cpp:100] Creating Layer scale4f_branch2a
I1022 15:54:58.136518 27427 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I1022 15:54:58.136523 27427 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I1022 15:54:58.136598 27427 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1022 15:54:58.136828 27427 net.cpp:150] Setting up scale4f_branch2a
I1022 15:54:58.136840 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.136843 27427 net.cpp:165] Memory required for data: 215556108
I1022 15:54:58.136849 27427 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I1022 15:54:58.136859 27427 net.cpp:100] Creating Layer res4f_branch2a_relu
I1022 15:54:58.136862 27427 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I1022 15:54:58.136868 27427 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I1022 15:54:58.137109 27427 net.cpp:150] Setting up res4f_branch2a_relu
I1022 15:54:58.137118 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.137120 27427 net.cpp:165] Memory required for data: 215756812
I1022 15:54:58.137125 27427 layer_factory.hpp:77] Creating layer res4f_branch2b
I1022 15:54:58.137133 27427 net.cpp:100] Creating Layer res4f_branch2b
I1022 15:54:58.137138 27427 net.cpp:444] res4f_branch2b <- res4f_branch2a
I1022 15:54:58.137145 27427 net.cpp:418] res4f_branch2b -> res4f_branch2b
I1022 15:54:58.146451 27427 net.cpp:150] Setting up res4f_branch2b
I1022 15:54:58.146466 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.146469 27427 net.cpp:165] Memory required for data: 215957516
I1022 15:54:58.146476 27427 layer_factory.hpp:77] Creating layer bn4f_branch2b
I1022 15:54:58.146483 27427 net.cpp:100] Creating Layer bn4f_branch2b
I1022 15:54:58.146487 27427 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I1022 15:54:58.146494 27427 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I1022 15:54:58.146929 27427 net.cpp:150] Setting up bn4f_branch2b
I1022 15:54:58.146937 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.146940 27427 net.cpp:165] Memory required for data: 216158220
I1022 15:54:58.146947 27427 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1022 15:54:58.146955 27427 net.cpp:100] Creating Layer scale4f_branch2b
I1022 15:54:58.146960 27427 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I1022 15:54:58.146963 27427 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I1022 15:54:58.147038 27427 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1022 15:54:58.147256 27427 net.cpp:150] Setting up scale4f_branch2b
I1022 15:54:58.147264 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.147267 27427 net.cpp:165] Memory required for data: 216358924
I1022 15:54:58.147272 27427 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I1022 15:54:58.147277 27427 net.cpp:100] Creating Layer res4f_branch2b_relu
I1022 15:54:58.147284 27427 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I1022 15:54:58.147289 27427 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I1022 15:54:58.147542 27427 net.cpp:150] Setting up res4f_branch2b_relu
I1022 15:54:58.147552 27427 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 15:54:58.147555 27427 net.cpp:165] Memory required for data: 216559628
I1022 15:54:58.147558 27427 layer_factory.hpp:77] Creating layer res4f_branch2c
I1022 15:54:58.147569 27427 net.cpp:100] Creating Layer res4f_branch2c
I1022 15:54:58.147572 27427 net.cpp:444] res4f_branch2c <- res4f_branch2b
I1022 15:54:58.147579 27427 net.cpp:418] res4f_branch2c -> res4f_branch2c
I1022 15:54:58.151515 27427 net.cpp:150] Setting up res4f_branch2c
I1022 15:54:58.151528 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.151531 27427 net.cpp:165] Memory required for data: 217362444
I1022 15:54:58.151537 27427 layer_factory.hpp:77] Creating layer bn4f_branch2c
I1022 15:54:58.151546 27427 net.cpp:100] Creating Layer bn4f_branch2c
I1022 15:54:58.151551 27427 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I1022 15:54:58.151557 27427 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I1022 15:54:58.151975 27427 net.cpp:150] Setting up bn4f_branch2c
I1022 15:54:58.151983 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.151986 27427 net.cpp:165] Memory required for data: 218165260
I1022 15:54:58.152014 27427 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1022 15:54:58.152021 27427 net.cpp:100] Creating Layer scale4f_branch2c
I1022 15:54:58.152025 27427 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I1022 15:54:58.152029 27427 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I1022 15:54:58.152098 27427 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1022 15:54:58.152336 27427 net.cpp:150] Setting up scale4f_branch2c
I1022 15:54:58.152343 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.152346 27427 net.cpp:165] Memory required for data: 218968076
I1022 15:54:58.152351 27427 layer_factory.hpp:77] Creating layer res4f
I1022 15:54:58.152361 27427 net.cpp:100] Creating Layer res4f
I1022 15:54:58.152365 27427 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I1022 15:54:58.152369 27427 net.cpp:444] res4f <- res4f_branch2c
I1022 15:54:58.152374 27427 net.cpp:418] res4f -> res4f
I1022 15:54:58.152420 27427 net.cpp:150] Setting up res4f
I1022 15:54:58.152426 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.152429 27427 net.cpp:165] Memory required for data: 219770892
I1022 15:54:58.152432 27427 layer_factory.hpp:77] Creating layer res4f_relu
I1022 15:54:58.152437 27427 net.cpp:100] Creating Layer res4f_relu
I1022 15:54:58.152441 27427 net.cpp:444] res4f_relu <- res4f
I1022 15:54:58.152447 27427 net.cpp:405] res4f_relu -> res4f (in-place)
I1022 15:54:58.153439 27427 net.cpp:150] Setting up res4f_relu
I1022 15:54:58.153451 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.153455 27427 net.cpp:165] Memory required for data: 220573708
I1022 15:54:58.153458 27427 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I1022 15:54:58.153465 27427 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I1022 15:54:58.153468 27427 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I1022 15:54:58.153476 27427 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I1022 15:54:58.153483 27427 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I1022 15:54:58.153491 27427 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I1022 15:54:58.153604 27427 net.cpp:150] Setting up res4f_res4f_relu_0_split
I1022 15:54:58.153612 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.153617 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.153620 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.153623 27427 net.cpp:165] Memory required for data: 222982156
I1022 15:54:58.153626 27427 layer_factory.hpp:77] Creating layer res5a_branch1
I1022 15:54:58.153636 27427 net.cpp:100] Creating Layer res5a_branch1
I1022 15:54:58.153641 27427 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I1022 15:54:58.153650 27427 net.cpp:418] res5a_branch1 -> res5a_branch1
I1022 15:54:58.166720 27427 net.cpp:150] Setting up res5a_branch1
I1022 15:54:58.166736 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.166740 27427 net.cpp:165] Memory required for data: 223383564
I1022 15:54:58.166746 27427 layer_factory.hpp:77] Creating layer bn5a_branch1
I1022 15:54:58.166754 27427 net.cpp:100] Creating Layer bn5a_branch1
I1022 15:54:58.166757 27427 net.cpp:444] bn5a_branch1 <- res5a_branch1
I1022 15:54:58.166765 27427 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I1022 15:54:58.167259 27427 net.cpp:150] Setting up bn5a_branch1
I1022 15:54:58.167268 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.167271 27427 net.cpp:165] Memory required for data: 223784972
I1022 15:54:58.167279 27427 layer_factory.hpp:77] Creating layer scale5a_branch1
I1022 15:54:58.167286 27427 net.cpp:100] Creating Layer scale5a_branch1
I1022 15:54:58.167289 27427 net.cpp:444] scale5a_branch1 <- res5a_branch1
I1022 15:54:58.167294 27427 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I1022 15:54:58.167367 27427 layer_factory.hpp:77] Creating layer scale5a_branch1
I1022 15:54:58.167614 27427 net.cpp:150] Setting up scale5a_branch1
I1022 15:54:58.167623 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.167625 27427 net.cpp:165] Memory required for data: 224186380
I1022 15:54:58.167631 27427 layer_factory.hpp:77] Creating layer res5a_branch2a
I1022 15:54:58.167641 27427 net.cpp:100] Creating Layer res5a_branch2a
I1022 15:54:58.167647 27427 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I1022 15:54:58.167654 27427 net.cpp:418] res5a_branch2a -> res5a_branch2a
I1022 15:54:58.172510 27427 net.cpp:150] Setting up res5a_branch2a
I1022 15:54:58.172524 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.172528 27427 net.cpp:165] Memory required for data: 224286732
I1022 15:54:58.172533 27427 layer_factory.hpp:77] Creating layer bn5a_branch2a
I1022 15:54:58.172543 27427 net.cpp:100] Creating Layer bn5a_branch2a
I1022 15:54:58.172546 27427 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I1022 15:54:58.172554 27427 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I1022 15:54:58.173000 27427 net.cpp:150] Setting up bn5a_branch2a
I1022 15:54:58.173008 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.173012 27427 net.cpp:165] Memory required for data: 224387084
I1022 15:54:58.173019 27427 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1022 15:54:58.173027 27427 net.cpp:100] Creating Layer scale5a_branch2a
I1022 15:54:58.173030 27427 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I1022 15:54:58.173038 27427 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I1022 15:54:58.173107 27427 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1022 15:54:58.173346 27427 net.cpp:150] Setting up scale5a_branch2a
I1022 15:54:58.173353 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.173357 27427 net.cpp:165] Memory required for data: 224487436
I1022 15:54:58.173362 27427 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I1022 15:54:58.173370 27427 net.cpp:100] Creating Layer res5a_branch2a_relu
I1022 15:54:58.173373 27427 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I1022 15:54:58.173378 27427 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I1022 15:54:58.173624 27427 net.cpp:150] Setting up res5a_branch2a_relu
I1022 15:54:58.173632 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.173635 27427 net.cpp:165] Memory required for data: 224587788
I1022 15:54:58.173638 27427 layer_factory.hpp:77] Creating layer res5a_branch2b
I1022 15:54:58.173648 27427 net.cpp:100] Creating Layer res5a_branch2b
I1022 15:54:58.173653 27427 net.cpp:444] res5a_branch2b <- res5a_branch2a
I1022 15:54:58.173658 27427 net.cpp:418] res5a_branch2b -> res5a_branch2b
I1022 15:54:58.189404 27427 net.cpp:150] Setting up res5a_branch2b
I1022 15:54:58.189419 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.189424 27427 net.cpp:165] Memory required for data: 224688140
I1022 15:54:58.189429 27427 layer_factory.hpp:77] Creating layer bn5a_branch2b
I1022 15:54:58.189438 27427 net.cpp:100] Creating Layer bn5a_branch2b
I1022 15:54:58.189442 27427 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I1022 15:54:58.189450 27427 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I1022 15:54:58.189877 27427 net.cpp:150] Setting up bn5a_branch2b
I1022 15:54:58.189887 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.189888 27427 net.cpp:165] Memory required for data: 224788492
I1022 15:54:58.189895 27427 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1022 15:54:58.189901 27427 net.cpp:100] Creating Layer scale5a_branch2b
I1022 15:54:58.189905 27427 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I1022 15:54:58.189911 27427 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I1022 15:54:58.189983 27427 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1022 15:54:58.190223 27427 net.cpp:150] Setting up scale5a_branch2b
I1022 15:54:58.190232 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.190234 27427 net.cpp:165] Memory required for data: 224888844
I1022 15:54:58.190240 27427 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I1022 15:54:58.190246 27427 net.cpp:100] Creating Layer res5a_branch2b_relu
I1022 15:54:58.190251 27427 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I1022 15:54:58.190256 27427 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I1022 15:54:58.190511 27427 net.cpp:150] Setting up res5a_branch2b_relu
I1022 15:54:58.190521 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.190524 27427 net.cpp:165] Memory required for data: 224989196
I1022 15:54:58.190527 27427 layer_factory.hpp:77] Creating layer res5a_branch2c
I1022 15:54:58.190538 27427 net.cpp:100] Creating Layer res5a_branch2c
I1022 15:54:58.190541 27427 net.cpp:444] res5a_branch2c <- res5a_branch2b
I1022 15:54:58.190549 27427 net.cpp:418] res5a_branch2c -> res5a_branch2c
I1022 15:54:58.195916 27427 net.cpp:150] Setting up res5a_branch2c
I1022 15:54:58.195930 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.195933 27427 net.cpp:165] Memory required for data: 225390604
I1022 15:54:58.195945 27427 layer_factory.hpp:77] Creating layer bn5a_branch2c
I1022 15:54:58.195955 27427 net.cpp:100] Creating Layer bn5a_branch2c
I1022 15:54:58.195960 27427 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I1022 15:54:58.195964 27427 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I1022 15:54:58.196408 27427 net.cpp:150] Setting up bn5a_branch2c
I1022 15:54:58.196415 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.196419 27427 net.cpp:165] Memory required for data: 225792012
I1022 15:54:58.196434 27427 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1022 15:54:58.196444 27427 net.cpp:100] Creating Layer scale5a_branch2c
I1022 15:54:58.196447 27427 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I1022 15:54:58.196452 27427 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I1022 15:54:58.196525 27427 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1022 15:54:58.196787 27427 net.cpp:150] Setting up scale5a_branch2c
I1022 15:54:58.196795 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.196799 27427 net.cpp:165] Memory required for data: 226193420
I1022 15:54:58.196805 27427 layer_factory.hpp:77] Creating layer res5a
I1022 15:54:58.196812 27427 net.cpp:100] Creating Layer res5a
I1022 15:54:58.196815 27427 net.cpp:444] res5a <- res5a_branch1
I1022 15:54:58.196820 27427 net.cpp:444] res5a <- res5a_branch2c
I1022 15:54:58.196825 27427 net.cpp:418] res5a -> res5a
I1022 15:54:58.196867 27427 net.cpp:150] Setting up res5a
I1022 15:54:58.196874 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.196878 27427 net.cpp:165] Memory required for data: 226594828
I1022 15:54:58.196882 27427 layer_factory.hpp:77] Creating layer res5a_relu
I1022 15:54:58.196888 27427 net.cpp:100] Creating Layer res5a_relu
I1022 15:54:58.196892 27427 net.cpp:444] res5a_relu <- res5a
I1022 15:54:58.196897 27427 net.cpp:405] res5a_relu -> res5a (in-place)
I1022 15:54:58.197897 27427 net.cpp:150] Setting up res5a_relu
I1022 15:54:58.197911 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.197913 27427 net.cpp:165] Memory required for data: 226996236
I1022 15:54:58.197917 27427 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I1022 15:54:58.197928 27427 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I1022 15:54:58.197932 27427 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I1022 15:54:58.197939 27427 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I1022 15:54:58.197948 27427 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I1022 15:54:58.198036 27427 net.cpp:150] Setting up res5a_res5a_relu_0_split
I1022 15:54:58.198045 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.198048 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.198051 27427 net.cpp:165] Memory required for data: 227799052
I1022 15:54:58.198055 27427 layer_factory.hpp:77] Creating layer res5b_branch2a
I1022 15:54:58.198065 27427 net.cpp:100] Creating Layer res5b_branch2a
I1022 15:54:58.198067 27427 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I1022 15:54:58.198074 27427 net.cpp:418] res5b_branch2a -> res5b_branch2a
I1022 15:54:58.206974 27427 net.cpp:150] Setting up res5b_branch2a
I1022 15:54:58.206988 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.206992 27427 net.cpp:165] Memory required for data: 227899404
I1022 15:54:58.207005 27427 layer_factory.hpp:77] Creating layer bn5b_branch2a
I1022 15:54:58.207015 27427 net.cpp:100] Creating Layer bn5b_branch2a
I1022 15:54:58.207018 27427 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I1022 15:54:58.207024 27427 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I1022 15:54:58.207476 27427 net.cpp:150] Setting up bn5b_branch2a
I1022 15:54:58.207484 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.207489 27427 net.cpp:165] Memory required for data: 227999756
I1022 15:54:58.207501 27427 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1022 15:54:58.207509 27427 net.cpp:100] Creating Layer scale5b_branch2a
I1022 15:54:58.207514 27427 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I1022 15:54:58.207517 27427 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I1022 15:54:58.207589 27427 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1022 15:54:58.207829 27427 net.cpp:150] Setting up scale5b_branch2a
I1022 15:54:58.207837 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.207840 27427 net.cpp:165] Memory required for data: 228100108
I1022 15:54:58.207846 27427 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I1022 15:54:58.207854 27427 net.cpp:100] Creating Layer res5b_branch2a_relu
I1022 15:54:58.207857 27427 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I1022 15:54:58.207862 27427 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I1022 15:54:58.208104 27427 net.cpp:150] Setting up res5b_branch2a_relu
I1022 15:54:58.208114 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.208117 27427 net.cpp:165] Memory required for data: 228200460
I1022 15:54:58.208120 27427 layer_factory.hpp:77] Creating layer res5b_branch2b
I1022 15:54:58.208130 27427 net.cpp:100] Creating Layer res5b_branch2b
I1022 15:54:58.208135 27427 net.cpp:444] res5b_branch2b <- res5b_branch2a
I1022 15:54:58.208143 27427 net.cpp:418] res5b_branch2b -> res5b_branch2b
I1022 15:54:58.218284 27427 net.cpp:150] Setting up res5b_branch2b
I1022 15:54:58.218302 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.218315 27427 net.cpp:165] Memory required for data: 228300812
I1022 15:54:58.218322 27427 layer_factory.hpp:77] Creating layer bn5b_branch2b
I1022 15:54:58.218330 27427 net.cpp:100] Creating Layer bn5b_branch2b
I1022 15:54:58.218334 27427 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I1022 15:54:58.218341 27427 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I1022 15:54:58.218773 27427 net.cpp:150] Setting up bn5b_branch2b
I1022 15:54:58.218782 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.218786 27427 net.cpp:165] Memory required for data: 228401164
I1022 15:54:58.218792 27427 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1022 15:54:58.218801 27427 net.cpp:100] Creating Layer scale5b_branch2b
I1022 15:54:58.218803 27427 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I1022 15:54:58.218811 27427 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I1022 15:54:58.218880 27427 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1022 15:54:58.219123 27427 net.cpp:150] Setting up scale5b_branch2b
I1022 15:54:58.219131 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.219135 27427 net.cpp:165] Memory required for data: 228501516
I1022 15:54:58.219141 27427 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I1022 15:54:58.219147 27427 net.cpp:100] Creating Layer res5b_branch2b_relu
I1022 15:54:58.219151 27427 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I1022 15:54:58.219156 27427 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I1022 15:54:58.219414 27427 net.cpp:150] Setting up res5b_branch2b_relu
I1022 15:54:58.219424 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.219426 27427 net.cpp:165] Memory required for data: 228601868
I1022 15:54:58.219429 27427 layer_factory.hpp:77] Creating layer res5b_branch2c
I1022 15:54:58.219439 27427 net.cpp:100] Creating Layer res5b_branch2c
I1022 15:54:58.219442 27427 net.cpp:444] res5b_branch2c <- res5b_branch2b
I1022 15:54:58.219449 27427 net.cpp:418] res5b_branch2c -> res5b_branch2c
I1022 15:54:58.224913 27427 net.cpp:150] Setting up res5b_branch2c
I1022 15:54:58.224927 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.224931 27427 net.cpp:165] Memory required for data: 229003276
I1022 15:54:58.224944 27427 layer_factory.hpp:77] Creating layer bn5b_branch2c
I1022 15:54:58.224964 27427 net.cpp:100] Creating Layer bn5b_branch2c
I1022 15:54:58.224972 27427 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I1022 15:54:58.224977 27427 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I1022 15:54:58.225430 27427 net.cpp:150] Setting up bn5b_branch2c
I1022 15:54:58.225437 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.225440 27427 net.cpp:165] Memory required for data: 229404684
I1022 15:54:58.225456 27427 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1022 15:54:58.225462 27427 net.cpp:100] Creating Layer scale5b_branch2c
I1022 15:54:58.225466 27427 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I1022 15:54:58.225472 27427 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I1022 15:54:58.225544 27427 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1022 15:54:58.225797 27427 net.cpp:150] Setting up scale5b_branch2c
I1022 15:54:58.225805 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.225807 27427 net.cpp:165] Memory required for data: 229806092
I1022 15:54:58.225813 27427 layer_factory.hpp:77] Creating layer res5b
I1022 15:54:58.225821 27427 net.cpp:100] Creating Layer res5b
I1022 15:54:58.225826 27427 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I1022 15:54:58.225829 27427 net.cpp:444] res5b <- res5b_branch2c
I1022 15:54:58.225836 27427 net.cpp:418] res5b -> res5b
I1022 15:54:58.225881 27427 net.cpp:150] Setting up res5b
I1022 15:54:58.225888 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.225891 27427 net.cpp:165] Memory required for data: 230207500
I1022 15:54:58.225894 27427 layer_factory.hpp:77] Creating layer res5b_relu
I1022 15:54:58.225900 27427 net.cpp:100] Creating Layer res5b_relu
I1022 15:54:58.225903 27427 net.cpp:444] res5b_relu <- res5b
I1022 15:54:58.225909 27427 net.cpp:405] res5b_relu -> res5b (in-place)
I1022 15:54:58.226945 27427 net.cpp:150] Setting up res5b_relu
I1022 15:54:58.226969 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.226984 27427 net.cpp:165] Memory required for data: 230608908
I1022 15:54:58.226987 27427 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I1022 15:54:58.226994 27427 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I1022 15:54:58.226997 27427 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I1022 15:54:58.227005 27427 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I1022 15:54:58.227015 27427 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I1022 15:54:58.227105 27427 net.cpp:150] Setting up res5b_res5b_relu_0_split
I1022 15:54:58.227113 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.227118 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.227120 27427 net.cpp:165] Memory required for data: 231411724
I1022 15:54:58.227123 27427 layer_factory.hpp:77] Creating layer res5c_branch2a
I1022 15:54:58.227133 27427 net.cpp:100] Creating Layer res5c_branch2a
I1022 15:54:58.227138 27427 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I1022 15:54:58.227144 27427 net.cpp:418] res5c_branch2a -> res5c_branch2a
I1022 15:54:58.232596 27427 net.cpp:150] Setting up res5c_branch2a
I1022 15:54:58.232630 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.232633 27427 net.cpp:165] Memory required for data: 231512076
I1022 15:54:58.232650 27427 layer_factory.hpp:77] Creating layer bn5c_branch2a
I1022 15:54:58.232658 27427 net.cpp:100] Creating Layer bn5c_branch2a
I1022 15:54:58.232672 27427 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I1022 15:54:58.232679 27427 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I1022 15:54:58.233135 27427 net.cpp:150] Setting up bn5c_branch2a
I1022 15:54:58.233144 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.233146 27427 net.cpp:165] Memory required for data: 231612428
I1022 15:54:58.233165 27427 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1022 15:54:58.233172 27427 net.cpp:100] Creating Layer scale5c_branch2a
I1022 15:54:58.233175 27427 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I1022 15:54:58.233182 27427 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I1022 15:54:58.233253 27427 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1022 15:54:58.233500 27427 net.cpp:150] Setting up scale5c_branch2a
I1022 15:54:58.233508 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.233511 27427 net.cpp:165] Memory required for data: 231712780
I1022 15:54:58.233517 27427 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I1022 15:54:58.233525 27427 net.cpp:100] Creating Layer res5c_branch2a_relu
I1022 15:54:58.233527 27427 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I1022 15:54:58.233532 27427 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I1022 15:54:58.233774 27427 net.cpp:150] Setting up res5c_branch2a_relu
I1022 15:54:58.233783 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.233786 27427 net.cpp:165] Memory required for data: 231813132
I1022 15:54:58.233789 27427 layer_factory.hpp:77] Creating layer res5c_branch2b
I1022 15:54:58.233800 27427 net.cpp:100] Creating Layer res5c_branch2b
I1022 15:54:58.233805 27427 net.cpp:444] res5c_branch2b <- res5c_branch2a
I1022 15:54:58.233810 27427 net.cpp:418] res5c_branch2b -> res5c_branch2b
I1022 15:54:58.240731 27427 net.cpp:150] Setting up res5c_branch2b
I1022 15:54:58.240744 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.240747 27427 net.cpp:165] Memory required for data: 231913484
I1022 15:54:58.240762 27427 layer_factory.hpp:77] Creating layer bn5c_branch2b
I1022 15:54:58.240772 27427 net.cpp:100] Creating Layer bn5c_branch2b
I1022 15:54:58.240775 27427 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I1022 15:54:58.240780 27427 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I1022 15:54:58.241261 27427 net.cpp:150] Setting up bn5c_branch2b
I1022 15:54:58.241268 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.241271 27427 net.cpp:165] Memory required for data: 232013836
I1022 15:54:58.241288 27427 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1022 15:54:58.241297 27427 net.cpp:100] Creating Layer scale5c_branch2b
I1022 15:54:58.241300 27427 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I1022 15:54:58.241305 27427 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I1022 15:54:58.241377 27427 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1022 15:54:58.241623 27427 net.cpp:150] Setting up scale5c_branch2b
I1022 15:54:58.241631 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.241634 27427 net.cpp:165] Memory required for data: 232114188
I1022 15:54:58.241639 27427 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I1022 15:54:58.241645 27427 net.cpp:100] Creating Layer res5c_branch2b_relu
I1022 15:54:58.241650 27427 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I1022 15:54:58.241657 27427 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I1022 15:54:58.241925 27427 net.cpp:150] Setting up res5c_branch2b_relu
I1022 15:54:58.241935 27427 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 15:54:58.241945 27427 net.cpp:165] Memory required for data: 232214540
I1022 15:54:58.241948 27427 layer_factory.hpp:77] Creating layer res5c_branch2c
I1022 15:54:58.241968 27427 net.cpp:100] Creating Layer res5c_branch2c
I1022 15:54:58.241972 27427 net.cpp:444] res5c_branch2c <- res5c_branch2b
I1022 15:54:58.241979 27427 net.cpp:418] res5c_branch2c -> res5c_branch2c
I1022 15:54:58.248414 27427 net.cpp:150] Setting up res5c_branch2c
I1022 15:54:58.248428 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.248431 27427 net.cpp:165] Memory required for data: 232615948
I1022 15:54:58.248445 27427 layer_factory.hpp:77] Creating layer bn5c_branch2c
I1022 15:54:58.248455 27427 net.cpp:100] Creating Layer bn5c_branch2c
I1022 15:54:58.248458 27427 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I1022 15:54:58.248466 27427 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I1022 15:54:58.248965 27427 net.cpp:150] Setting up bn5c_branch2c
I1022 15:54:58.248973 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.248976 27427 net.cpp:165] Memory required for data: 233017356
I1022 15:54:58.248996 27427 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1022 15:54:58.249003 27427 net.cpp:100] Creating Layer scale5c_branch2c
I1022 15:54:58.249006 27427 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I1022 15:54:58.249014 27427 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I1022 15:54:58.249096 27427 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1022 15:54:58.249348 27427 net.cpp:150] Setting up scale5c_branch2c
I1022 15:54:58.249356 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.249359 27427 net.cpp:165] Memory required for data: 233418764
I1022 15:54:58.249366 27427 layer_factory.hpp:77] Creating layer res5c
I1022 15:54:58.249373 27427 net.cpp:100] Creating Layer res5c
I1022 15:54:58.249377 27427 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I1022 15:54:58.249382 27427 net.cpp:444] res5c <- res5c_branch2c
I1022 15:54:58.249387 27427 net.cpp:418] res5c -> res5c
I1022 15:54:58.249431 27427 net.cpp:150] Setting up res5c
I1022 15:54:58.249439 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.249441 27427 net.cpp:165] Memory required for data: 233820172
I1022 15:54:58.249444 27427 layer_factory.hpp:77] Creating layer res5c_relu
I1022 15:54:58.249449 27427 net.cpp:100] Creating Layer res5c_relu
I1022 15:54:58.249452 27427 net.cpp:444] res5c_relu <- res5c
I1022 15:54:58.249459 27427 net.cpp:405] res5c_relu -> res5c (in-place)
I1022 15:54:58.249707 27427 net.cpp:150] Setting up res5c_relu
I1022 15:54:58.249717 27427 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 15:54:58.249720 27427 net.cpp:165] Memory required for data: 234221580
I1022 15:54:58.249723 27427 layer_factory.hpp:77] Creating layer upP4
I1022 15:54:58.249733 27427 net.cpp:100] Creating Layer upP4
I1022 15:54:58.249738 27427 net.cpp:444] upP4 <- res5c
I1022 15:54:58.249745 27427 net.cpp:418] upP4 -> upP4
I1022 15:54:58.251775 27427 net.cpp:150] Setting up upP4
I1022 15:54:58.251781 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.251785 27427 net.cpp:165] Memory required for data: 234622988
I1022 15:54:58.251791 27427 layer_factory.hpp:77] Creating layer newC4
I1022 15:54:58.251808 27427 net.cpp:100] Creating Layer newC4
I1022 15:54:58.251811 27427 net.cpp:444] newC4 <- res4f_res4f_relu_0_split_2
I1022 15:54:58.251819 27427 net.cpp:418] newC4 -> c4
I1022 15:54:58.261940 27427 net.cpp:150] Setting up newC4
I1022 15:54:58.261955 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.261958 27427 net.cpp:165] Memory required for data: 235024396
I1022 15:54:58.261976 27427 layer_factory.hpp:77] Creating layer eltwise_bnc4_bnp4
I1022 15:54:58.261982 27427 net.cpp:100] Creating Layer eltwise_bnc4_bnp4
I1022 15:54:58.261986 27427 net.cpp:444] eltwise_bnc4_bnp4 <- c4
I1022 15:54:58.261992 27427 net.cpp:444] eltwise_bnc4_bnp4 <- upP4
I1022 15:54:58.262001 27427 net.cpp:418] eltwise_bnc4_bnp4 -> skip_eltwise1
I1022 15:54:58.262068 27427 net.cpp:150] Setting up eltwise_bnc4_bnp4
I1022 15:54:58.262076 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.262079 27427 net.cpp:165] Memory required for data: 235425804
I1022 15:54:58.262084 27427 layer_factory.hpp:77] Creating layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 15:54:58.262089 27427 net.cpp:100] Creating Layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 15:54:58.262092 27427 net.cpp:444] skip_eltwise1_eltwise_bnc4_bnp4_0_split <- skip_eltwise1
I1022 15:54:58.262097 27427 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1022 15:54:58.262106 27427 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1022 15:54:58.262187 27427 net.cpp:150] Setting up skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 15:54:58.262194 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.262199 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.262202 27427 net.cpp:165] Memory required for data: 236228620
I1022 15:54:58.262205 27427 layer_factory.hpp:77] Creating layer bnp4_conv
I1022 15:54:58.262215 27427 net.cpp:100] Creating Layer bnp4_conv
I1022 15:54:58.262220 27427 net.cpp:444] bnp4_conv <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1022 15:54:58.262228 27427 net.cpp:418] bnp4_conv -> bnp4_conv
I1022 15:54:58.267680 27427 net.cpp:150] Setting up bnp4_conv
I1022 15:54:58.267694 27427 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:54:58.267707 27427 net.cpp:165] Memory required for data: 236328972
I1022 15:54:58.267714 27427 layer_factory.hpp:77] Creating layer bnp4_bn
I1022 15:54:58.267720 27427 net.cpp:100] Creating Layer bnp4_bn
I1022 15:54:58.267724 27427 net.cpp:444] bnp4_bn <- bnp4_conv
I1022 15:54:58.267731 27427 net.cpp:405] bnp4_bn -> bnp4_conv (in-place)
I1022 15:54:58.268182 27427 net.cpp:150] Setting up bnp4_bn
I1022 15:54:58.268189 27427 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:54:58.268191 27427 net.cpp:165] Memory required for data: 236429324
I1022 15:54:58.268208 27427 layer_factory.hpp:77] Creating layer bnp4_scale
I1022 15:54:58.268216 27427 net.cpp:100] Creating Layer bnp4_scale
I1022 15:54:58.268220 27427 net.cpp:444] bnp4_scale <- bnp4_conv
I1022 15:54:58.268227 27427 net.cpp:405] bnp4_scale -> bnp4_conv (in-place)
I1022 15:54:58.268303 27427 layer_factory.hpp:77] Creating layer bnp4_scale
I1022 15:54:58.268543 27427 net.cpp:150] Setting up bnp4_scale
I1022 15:54:58.268549 27427 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:54:58.268553 27427 net.cpp:165] Memory required for data: 236529676
I1022 15:54:58.268558 27427 layer_factory.hpp:77] Creating layer bnp4_ReLU
I1022 15:54:58.268566 27427 net.cpp:100] Creating Layer bnp4_ReLU
I1022 15:54:58.268569 27427 net.cpp:444] bnp4_ReLU <- bnp4_conv
I1022 15:54:58.268576 27427 net.cpp:405] bnp4_ReLU -> bnp4_conv (in-place)
I1022 15:54:58.269646 27427 net.cpp:150] Setting up bnp4_ReLU
I1022 15:54:58.269660 27427 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:54:58.269673 27427 net.cpp:165] Memory required for data: 236630028
I1022 15:54:58.269676 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_conv
I1022 15:54:58.269688 27427 net.cpp:100] Creating Layer bn_eltwise_1_1_conv
I1022 15:54:58.269693 27427 net.cpp:444] bn_eltwise_1_1_conv <- bnp4_conv
I1022 15:54:58.269702 27427 net.cpp:418] bn_eltwise_1_1_conv -> bn_eltwise_1_1_conv
I1022 15:54:58.274209 27427 net.cpp:150] Setting up bn_eltwise_1_1_conv
I1022 15:54:58.274224 27427 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:54:58.274235 27427 net.cpp:165] Memory required for data: 236730380
I1022 15:54:58.274245 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_bn
I1022 15:54:58.274252 27427 net.cpp:100] Creating Layer bn_eltwise_1_1_bn
I1022 15:54:58.274256 27427 net.cpp:444] bn_eltwise_1_1_bn <- bn_eltwise_1_1_conv
I1022 15:54:58.274262 27427 net.cpp:405] bn_eltwise_1_1_bn -> bn_eltwise_1_1_conv (in-place)
I1022 15:54:58.274691 27427 net.cpp:150] Setting up bn_eltwise_1_1_bn
I1022 15:54:58.274700 27427 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:54:58.274703 27427 net.cpp:165] Memory required for data: 236830732
I1022 15:54:58.274720 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1022 15:54:58.274727 27427 net.cpp:100] Creating Layer bn_eltwise_1_1_scale
I1022 15:54:58.274730 27427 net.cpp:444] bn_eltwise_1_1_scale <- bn_eltwise_1_1_conv
I1022 15:54:58.274736 27427 net.cpp:405] bn_eltwise_1_1_scale -> bn_eltwise_1_1_conv (in-place)
I1022 15:54:58.274808 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1022 15:54:58.275048 27427 net.cpp:150] Setting up bn_eltwise_1_1_scale
I1022 15:54:58.275055 27427 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:54:58.275058 27427 net.cpp:165] Memory required for data: 236931084
I1022 15:54:58.275064 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_ReLU
I1022 15:54:58.275074 27427 net.cpp:100] Creating Layer bn_eltwise_1_1_ReLU
I1022 15:54:58.275077 27427 net.cpp:444] bn_eltwise_1_1_ReLU <- bn_eltwise_1_1_conv
I1022 15:54:58.275081 27427 net.cpp:405] bn_eltwise_1_1_ReLU -> bn_eltwise_1_1_conv (in-place)
I1022 15:54:58.275338 27427 net.cpp:150] Setting up bn_eltwise_1_1_ReLU
I1022 15:54:58.275346 27427 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 15:54:58.275349 27427 net.cpp:165] Memory required for data: 237031436
I1022 15:54:58.275353 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_conv
I1022 15:54:58.275368 27427 net.cpp:100] Creating Layer bn_eltwise_1_2_conv
I1022 15:54:58.275373 27427 net.cpp:444] bn_eltwise_1_2_conv <- bn_eltwise_1_1_conv
I1022 15:54:58.275379 27427 net.cpp:418] bn_eltwise_1_2_conv -> bn_eltwise_1_2_conv
I1022 15:54:58.278179 27427 net.cpp:150] Setting up bn_eltwise_1_2_conv
I1022 15:54:58.278193 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.278195 27427 net.cpp:165] Memory required for data: 237432844
I1022 15:54:58.278210 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_bn
I1022 15:54:58.278219 27427 net.cpp:100] Creating Layer bn_eltwise_1_2_bn
I1022 15:54:58.278223 27427 net.cpp:444] bn_eltwise_1_2_bn <- bn_eltwise_1_2_conv
I1022 15:54:58.278230 27427 net.cpp:405] bn_eltwise_1_2_bn -> bn_eltwise_1_2_conv (in-place)
I1022 15:54:58.278681 27427 net.cpp:150] Setting up bn_eltwise_1_2_bn
I1022 15:54:58.278689 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.278692 27427 net.cpp:165] Memory required for data: 237834252
I1022 15:54:58.278708 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1022 15:54:58.278730 27427 net.cpp:100] Creating Layer bn_eltwise_1_2_scale
I1022 15:54:58.278734 27427 net.cpp:444] bn_eltwise_1_2_scale <- bn_eltwise_1_2_conv
I1022 15:54:58.278739 27427 net.cpp:405] bn_eltwise_1_2_scale -> bn_eltwise_1_2_conv (in-place)
I1022 15:54:58.278806 27427 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1022 15:54:58.279062 27427 net.cpp:150] Setting up bn_eltwise_1_2_scale
I1022 15:54:58.279069 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.279073 27427 net.cpp:165] Memory required for data: 238235660
I1022 15:54:58.279079 27427 layer_factory.hpp:77] Creating layer p3
I1022 15:54:58.279088 27427 net.cpp:100] Creating Layer p3
I1022 15:54:58.279091 27427 net.cpp:444] p3 <- bn_eltwise_1_2_conv
I1022 15:54:58.279096 27427 net.cpp:444] p3 <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1022 15:54:58.279103 27427 net.cpp:418] p3 -> p3
I1022 15:54:58.279151 27427 net.cpp:150] Setting up p3
I1022 15:54:58.279160 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.279162 27427 net.cpp:165] Memory required for data: 238637068
I1022 15:54:58.279165 27427 layer_factory.hpp:77] Creating layer p3_relu
I1022 15:54:58.279172 27427 net.cpp:100] Creating Layer p3_relu
I1022 15:54:58.279178 27427 net.cpp:444] p3_relu <- p3
I1022 15:54:58.279183 27427 net.cpp:405] p3_relu -> p3 (in-place)
I1022 15:54:58.279423 27427 net.cpp:150] Setting up p3_relu
I1022 15:54:58.279433 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.279435 27427 net.cpp:165] Memory required for data: 239038476
I1022 15:54:58.279438 27427 layer_factory.hpp:77] Creating layer p3_p3_relu_0_split
I1022 15:54:58.279448 27427 net.cpp:100] Creating Layer p3_p3_relu_0_split
I1022 15:54:58.279450 27427 net.cpp:444] p3_p3_relu_0_split <- p3
I1022 15:54:58.279458 27427 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_0
I1022 15:54:58.279465 27427 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_1
I1022 15:54:58.279472 27427 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_2
I1022 15:54:58.279585 27427 net.cpp:150] Setting up p3_p3_relu_0_split
I1022 15:54:58.279592 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.279597 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.279600 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.279603 27427 net.cpp:165] Memory required for data: 240242700
I1022 15:54:58.279606 27427 layer_factory.hpp:77] Creating layer newC3
I1022 15:54:58.279619 27427 net.cpp:100] Creating Layer newC3
I1022 15:54:58.279624 27427 net.cpp:444] newC3 <- res3d_res3d_relu_0_split_2
I1022 15:54:58.279631 27427 net.cpp:418] newC3 -> c3
I1022 15:54:58.290639 27427 net.cpp:150] Setting up newC3
I1022 15:54:58.290683 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.290688 27427 net.cpp:165] Memory required for data: 241848332
I1022 15:54:58.290699 27427 layer_factory.hpp:77] Creating layer upP3
I1022 15:54:58.290716 27427 net.cpp:100] Creating Layer upP3
I1022 15:54:58.290722 27427 net.cpp:444] upP3 <- p3_p3_relu_0_split_0
I1022 15:54:58.290732 27427 net.cpp:418] upP3 -> upP3
I1022 15:54:58.291620 27427 net.cpp:150] Setting up upP3
I1022 15:54:58.291628 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.291631 27427 net.cpp:165] Memory required for data: 243453964
I1022 15:54:58.291644 27427 layer_factory.hpp:77] Creating layer eltwise_bnc3_bnp3
I1022 15:54:58.291652 27427 net.cpp:100] Creating Layer eltwise_bnc3_bnp3
I1022 15:54:58.291656 27427 net.cpp:444] eltwise_bnc3_bnp3 <- c3
I1022 15:54:58.291661 27427 net.cpp:444] eltwise_bnc3_bnp3 <- upP3
I1022 15:54:58.291671 27427 net.cpp:418] eltwise_bnc3_bnp3 -> skip_eltwise2
I1022 15:54:58.291719 27427 net.cpp:150] Setting up eltwise_bnc3_bnp3
I1022 15:54:58.291726 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.291730 27427 net.cpp:165] Memory required for data: 245059596
I1022 15:54:58.291733 27427 layer_factory.hpp:77] Creating layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 15:54:58.291741 27427 net.cpp:100] Creating Layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 15:54:58.291744 27427 net.cpp:444] skip_eltwise2_eltwise_bnc3_bnp3_0_split <- skip_eltwise2
I1022 15:54:58.291750 27427 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1022 15:54:58.291759 27427 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1022 15:54:58.291836 27427 net.cpp:150] Setting up skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 15:54:58.291841 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.291846 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.291848 27427 net.cpp:165] Memory required for data: 248270860
I1022 15:54:58.291851 27427 layer_factory.hpp:77] Creating layer bnp3_conv
I1022 15:54:58.291864 27427 net.cpp:100] Creating Layer bnp3_conv
I1022 15:54:58.291870 27427 net.cpp:444] bnp3_conv <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1022 15:54:58.291875 27427 net.cpp:418] bnp3_conv -> bnp3_conv
I1022 15:54:58.294813 27427 net.cpp:150] Setting up bnp3_conv
I1022 15:54:58.294826 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.294831 27427 net.cpp:165] Memory required for data: 248672268
I1022 15:54:58.294844 27427 layer_factory.hpp:77] Creating layer bnp3_bn
I1022 15:54:58.294853 27427 net.cpp:100] Creating Layer bnp3_bn
I1022 15:54:58.294857 27427 net.cpp:444] bnp3_bn <- bnp3_conv
I1022 15:54:58.294865 27427 net.cpp:405] bnp3_bn -> bnp3_conv (in-place)
I1022 15:54:58.295333 27427 net.cpp:150] Setting up bnp3_bn
I1022 15:54:58.295343 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.295346 27427 net.cpp:165] Memory required for data: 249073676
I1022 15:54:58.295362 27427 layer_factory.hpp:77] Creating layer bnp3_scale
I1022 15:54:58.295370 27427 net.cpp:100] Creating Layer bnp3_scale
I1022 15:54:58.295373 27427 net.cpp:444] bnp3_scale <- bnp3_conv
I1022 15:54:58.295379 27427 net.cpp:405] bnp3_scale -> bnp3_conv (in-place)
I1022 15:54:58.295464 27427 layer_factory.hpp:77] Creating layer bnp3_scale
I1022 15:54:58.295730 27427 net.cpp:150] Setting up bnp3_scale
I1022 15:54:58.295738 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.295742 27427 net.cpp:165] Memory required for data: 249475084
I1022 15:54:58.295748 27427 layer_factory.hpp:77] Creating layer bnp3_ReLU
I1022 15:54:58.295753 27427 net.cpp:100] Creating Layer bnp3_ReLU
I1022 15:54:58.295758 27427 net.cpp:444] bnp3_ReLU <- bnp3_conv
I1022 15:54:58.295761 27427 net.cpp:405] bnp3_ReLU -> bnp3_conv (in-place)
I1022 15:54:58.296813 27427 net.cpp:150] Setting up bnp3_ReLU
I1022 15:54:58.296825 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.296828 27427 net.cpp:165] Memory required for data: 249876492
I1022 15:54:58.296839 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_conv
I1022 15:54:58.296850 27427 net.cpp:100] Creating Layer bn_eltwise_2_1_conv
I1022 15:54:58.296854 27427 net.cpp:444] bn_eltwise_2_1_conv <- bnp3_conv
I1022 15:54:58.296864 27427 net.cpp:418] bn_eltwise_2_1_conv -> bn_eltwise_2_1_conv
I1022 15:54:58.304719 27427 net.cpp:150] Setting up bn_eltwise_2_1_conv
I1022 15:54:58.304733 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.304738 27427 net.cpp:165] Memory required for data: 250277900
I1022 15:54:58.304750 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_bn
I1022 15:54:58.304759 27427 net.cpp:100] Creating Layer bn_eltwise_2_1_bn
I1022 15:54:58.304764 27427 net.cpp:444] bn_eltwise_2_1_bn <- bn_eltwise_2_1_conv
I1022 15:54:58.304781 27427 net.cpp:405] bn_eltwise_2_1_bn -> bn_eltwise_2_1_conv (in-place)
I1022 15:54:58.305274 27427 net.cpp:150] Setting up bn_eltwise_2_1_bn
I1022 15:54:58.305284 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.305286 27427 net.cpp:165] Memory required for data: 250679308
I1022 15:54:58.305301 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1022 15:54:58.305310 27427 net.cpp:100] Creating Layer bn_eltwise_2_1_scale
I1022 15:54:58.305313 27427 net.cpp:444] bn_eltwise_2_1_scale <- bn_eltwise_2_1_conv
I1022 15:54:58.305320 27427 net.cpp:405] bn_eltwise_2_1_scale -> bn_eltwise_2_1_conv (in-place)
I1022 15:54:58.305398 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1022 15:54:58.305654 27427 net.cpp:150] Setting up bn_eltwise_2_1_scale
I1022 15:54:58.305662 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.305665 27427 net.cpp:165] Memory required for data: 251080716
I1022 15:54:58.305672 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_ReLU
I1022 15:54:58.305677 27427 net.cpp:100] Creating Layer bn_eltwise_2_1_ReLU
I1022 15:54:58.305681 27427 net.cpp:444] bn_eltwise_2_1_ReLU <- bn_eltwise_2_1_conv
I1022 15:54:58.305686 27427 net.cpp:405] bn_eltwise_2_1_ReLU -> bn_eltwise_2_1_conv (in-place)
I1022 15:54:58.305948 27427 net.cpp:150] Setting up bn_eltwise_2_1_ReLU
I1022 15:54:58.305958 27427 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 15:54:58.305960 27427 net.cpp:165] Memory required for data: 251482124
I1022 15:54:58.305963 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_conv
I1022 15:54:58.305974 27427 net.cpp:100] Creating Layer bn_eltwise_2_2_conv
I1022 15:54:58.305979 27427 net.cpp:444] bn_eltwise_2_2_conv <- bn_eltwise_2_1_conv
I1022 15:54:58.305987 27427 net.cpp:418] bn_eltwise_2_2_conv -> bn_eltwise_2_2_conv
I1022 15:54:58.308782 27427 net.cpp:150] Setting up bn_eltwise_2_2_conv
I1022 15:54:58.308795 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.308799 27427 net.cpp:165] Memory required for data: 253087756
I1022 15:54:58.308804 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_bn
I1022 15:54:58.308818 27427 net.cpp:100] Creating Layer bn_eltwise_2_2_bn
I1022 15:54:58.308821 27427 net.cpp:444] bn_eltwise_2_2_bn <- bn_eltwise_2_2_conv
I1022 15:54:58.308830 27427 net.cpp:405] bn_eltwise_2_2_bn -> bn_eltwise_2_2_conv (in-place)
I1022 15:54:58.309293 27427 net.cpp:150] Setting up bn_eltwise_2_2_bn
I1022 15:54:58.309300 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.309303 27427 net.cpp:165] Memory required for data: 254693388
I1022 15:54:58.309319 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1022 15:54:58.309326 27427 net.cpp:100] Creating Layer bn_eltwise_2_2_scale
I1022 15:54:58.309330 27427 net.cpp:444] bn_eltwise_2_2_scale <- bn_eltwise_2_2_conv
I1022 15:54:58.309336 27427 net.cpp:405] bn_eltwise_2_2_scale -> bn_eltwise_2_2_conv (in-place)
I1022 15:54:58.309422 27427 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1022 15:54:58.309676 27427 net.cpp:150] Setting up bn_eltwise_2_2_scale
I1022 15:54:58.309684 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.309687 27427 net.cpp:165] Memory required for data: 256299020
I1022 15:54:58.309693 27427 layer_factory.hpp:77] Creating layer p2
I1022 15:54:58.309700 27427 net.cpp:100] Creating Layer p2
I1022 15:54:58.309705 27427 net.cpp:444] p2 <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1022 15:54:58.309710 27427 net.cpp:444] p2 <- bn_eltwise_2_2_conv
I1022 15:54:58.309715 27427 net.cpp:418] p2 -> p2
I1022 15:54:58.309762 27427 net.cpp:150] Setting up p2
I1022 15:54:58.309770 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.309773 27427 net.cpp:165] Memory required for data: 257904652
I1022 15:54:58.309777 27427 layer_factory.hpp:77] Creating layer p2_relu
I1022 15:54:58.309782 27427 net.cpp:100] Creating Layer p2_relu
I1022 15:54:58.309784 27427 net.cpp:444] p2_relu <- p2
I1022 15:54:58.309789 27427 net.cpp:405] p2_relu -> p2 (in-place)
I1022 15:54:58.310043 27427 net.cpp:150] Setting up p2_relu
I1022 15:54:58.310055 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.310057 27427 net.cpp:165] Memory required for data: 259510284
I1022 15:54:58.310060 27427 layer_factory.hpp:77] Creating layer p2_p2_relu_0_split
I1022 15:54:58.310065 27427 net.cpp:100] Creating Layer p2_p2_relu_0_split
I1022 15:54:58.310070 27427 net.cpp:444] p2_p2_relu_0_split <- p2
I1022 15:54:58.310077 27427 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_0
I1022 15:54:58.310084 27427 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_1
I1022 15:54:58.310178 27427 net.cpp:150] Setting up p2_p2_relu_0_split
I1022 15:54:58.310185 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.310190 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.310195 27427 net.cpp:165] Memory required for data: 262721548
I1022 15:54:58.310199 27427 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p2
I1022 15:54:58.310207 27427 net.cpp:100] Creating Layer rpn_conv/3x3_p2
I1022 15:54:58.310212 27427 net.cpp:444] rpn_conv/3x3_p2 <- p2_p2_relu_0_split_0
I1022 15:54:58.310220 27427 net.cpp:418] rpn_conv/3x3_p2 -> rpn/output_p2
I1022 15:54:58.344461 27427 net.cpp:150] Setting up rpn_conv/3x3_p2
I1022 15:54:58.344477 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.344481 27427 net.cpp:165] Memory required for data: 264327180
I1022 15:54:58.344493 27427 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p2
I1022 15:54:58.344503 27427 net.cpp:100] Creating Layer rpn_relu/3x3_p2
I1022 15:54:58.344507 27427 net.cpp:444] rpn_relu/3x3_p2 <- rpn/output_p2
I1022 15:54:58.344514 27427 net.cpp:405] rpn_relu/3x3_p2 -> rpn/output_p2 (in-place)
I1022 15:54:58.347779 27427 net.cpp:150] Setting up rpn_relu/3x3_p2
I1022 15:54:58.347793 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.347796 27427 net.cpp:165] Memory required for data: 265932812
I1022 15:54:58.347800 27427 layer_factory.hpp:77] Creating layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 15:54:58.347812 27427 net.cpp:100] Creating Layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 15:54:58.347816 27427 net.cpp:444] rpn/output_p2_rpn_relu/3x3_p2_0_split <- rpn/output_p2
I1022 15:54:58.347824 27427 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1022 15:54:58.347832 27427 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1022 15:54:58.347929 27427 net.cpp:150] Setting up rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 15:54:58.347937 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.347942 27427 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 15:54:58.347945 27427 net.cpp:165] Memory required for data: 269144076
I1022 15:54:58.347949 27427 layer_factory.hpp:77] Creating layer rpn_cls_score_p2
I1022 15:54:58.347962 27427 net.cpp:100] Creating Layer rpn_cls_score_p2
I1022 15:54:58.347967 27427 net.cpp:444] rpn_cls_score_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1022 15:54:58.347975 27427 net.cpp:418] rpn_cls_score_p2 -> rpn_cls_score_p2
I1022 15:54:58.351104 27427 net.cpp:150] Setting up rpn_cls_score_p2
I1022 15:54:58.351119 27427 net.cpp:157] Top shape: 1 22 28 28 (17248)
I1022 15:54:58.351122 27427 net.cpp:165] Memory required for data: 269213068
I1022 15:54:58.351136 27427 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p2
I1022 15:54:58.351148 27427 net.cpp:100] Creating Layer rpn_bbox_pred_p2
I1022 15:54:58.351152 27427 net.cpp:444] rpn_bbox_pred_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1022 15:54:58.351161 27427 net.cpp:418] rpn_bbox_pred_p2 -> rpn_bbox_pred_p2
I1022 15:54:58.353602 27427 net.cpp:150] Setting up rpn_bbox_pred_p2
I1022 15:54:58.353615 27427 net.cpp:157] Top shape: 1 44 28 28 (34496)
I1022 15:54:58.353618 27427 net.cpp:165] Memory required for data: 269351052
I1022 15:54:58.353628 27427 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p2
I1022 15:54:58.353638 27427 net.cpp:100] Creating Layer rpn_cls_score_reshape_p2
I1022 15:54:58.353642 27427 net.cpp:444] rpn_cls_score_reshape_p2 <- rpn_cls_score_p2
I1022 15:54:58.353649 27427 net.cpp:418] rpn_cls_score_reshape_p2 -> rpn_cls_score_reshape_p2
I1022 15:54:58.353709 27427 net.cpp:150] Setting up rpn_cls_score_reshape_p2
I1022 15:54:58.353718 27427 net.cpp:157] Top shape: 1 2 308 28 (17248)
I1022 15:54:58.353721 27427 net.cpp:165] Memory required for data: 269420044
I1022 15:54:58.353724 27427 layer_factory.hpp:77] Creating layer rpn_cls_prob_p2
I1022 15:54:58.353736 27427 net.cpp:100] Creating Layer rpn_cls_prob_p2
I1022 15:54:58.353742 27427 net.cpp:444] rpn_cls_prob_p2 <- rpn_cls_score_reshape_p2
I1022 15:54:58.353749 27427 net.cpp:418] rpn_cls_prob_p2 -> rpn_cls_prob_p2
I1022 15:54:58.354182 27427 net.cpp:150] Setting up rpn_cls_prob_p2
I1022 15:54:58.354192 27427 net.cpp:157] Top shape: 1 2 308 28 (17248)
I1022 15:54:58.354195 27427 net.cpp:165] Memory required for data: 269489036
I1022 15:54:58.354207 27427 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p2
I1022 15:54:58.354216 27427 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p2
I1022 15:54:58.354220 27427 net.cpp:444] rpn_cls_prob_reshape_p2 <- rpn_cls_prob_p2
I1022 15:54:58.354226 27427 net.cpp:418] rpn_cls_prob_reshape_p2 -> rpn_cls_prob_reshape_p2
I1022 15:54:58.354279 27427 net.cpp:150] Setting up rpn_cls_prob_reshape_p2
I1022 15:54:58.354285 27427 net.cpp:157] Top shape: 1 22 28 28 (17248)
I1022 15:54:58.354287 27427 net.cpp:165] Memory required for data: 269558028
I1022 15:54:58.354291 27427 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p3
I1022 15:54:58.354302 27427 net.cpp:100] Creating Layer rpn_conv/3x3_p3
I1022 15:54:58.354308 27427 net.cpp:444] rpn_conv/3x3_p3 <- p3_p3_relu_0_split_1
I1022 15:54:58.354316 27427 net.cpp:418] rpn_conv/3x3_p3 -> rpn/output_p3
I1022 15:54:58.389348 27427 net.cpp:150] Setting up rpn_conv/3x3_p3
I1022 15:54:58.389364 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.389376 27427 net.cpp:165] Memory required for data: 269959436
I1022 15:54:58.389384 27427 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p3
I1022 15:54:58.389391 27427 net.cpp:100] Creating Layer rpn_relu/3x3_p3
I1022 15:54:58.389398 27427 net.cpp:444] rpn_relu/3x3_p3 <- rpn/output_p3
I1022 15:54:58.389405 27427 net.cpp:405] rpn_relu/3x3_p3 -> rpn/output_p3 (in-place)
I1022 15:54:58.389670 27427 net.cpp:150] Setting up rpn_relu/3x3_p3
I1022 15:54:58.389680 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.389683 27427 net.cpp:165] Memory required for data: 270360844
I1022 15:54:58.389688 27427 layer_factory.hpp:77] Creating layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 15:54:58.389695 27427 net.cpp:100] Creating Layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 15:54:58.389701 27427 net.cpp:444] rpn/output_p3_rpn_relu/3x3_p3_0_split <- rpn/output_p3
I1022 15:54:58.389708 27427 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1022 15:54:58.389714 27427 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1022 15:54:58.389825 27427 net.cpp:150] Setting up rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 15:54:58.389832 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.389837 27427 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 15:54:58.389839 27427 net.cpp:165] Memory required for data: 271163660
I1022 15:54:58.389842 27427 layer_factory.hpp:77] Creating layer rpn_cls_score_p3
I1022 15:54:58.389856 27427 net.cpp:100] Creating Layer rpn_cls_score_p3
I1022 15:54:58.389861 27427 net.cpp:444] rpn_cls_score_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1022 15:54:58.389868 27427 net.cpp:418] rpn_cls_score_p3 -> rpn_cls_score_p3
I1022 15:54:58.392220 27427 net.cpp:150] Setting up rpn_cls_score_p3
I1022 15:54:58.392235 27427 net.cpp:157] Top shape: 1 22 14 14 (4312)
I1022 15:54:58.392248 27427 net.cpp:165] Memory required for data: 271180908
I1022 15:54:58.392256 27427 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p3
I1022 15:54:58.392267 27427 net.cpp:100] Creating Layer rpn_bbox_pred_p3
I1022 15:54:58.392271 27427 net.cpp:444] rpn_bbox_pred_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1022 15:54:58.392280 27427 net.cpp:418] rpn_bbox_pred_p3 -> rpn_bbox_pred_p3
I1022 15:54:58.394781 27427 net.cpp:150] Setting up rpn_bbox_pred_p3
I1022 15:54:58.394795 27427 net.cpp:157] Top shape: 1 44 14 14 (8624)
I1022 15:54:58.394798 27427 net.cpp:165] Memory required for data: 271215404
I1022 15:54:58.394814 27427 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p3
I1022 15:54:58.394820 27427 net.cpp:100] Creating Layer rpn_cls_score_reshape_p3
I1022 15:54:58.394824 27427 net.cpp:444] rpn_cls_score_reshape_p3 <- rpn_cls_score_p3
I1022 15:54:58.394834 27427 net.cpp:418] rpn_cls_score_reshape_p3 -> rpn_cls_score_reshape_p3
I1022 15:54:58.394892 27427 net.cpp:150] Setting up rpn_cls_score_reshape_p3
I1022 15:54:58.394901 27427 net.cpp:157] Top shape: 1 2 154 14 (4312)
I1022 15:54:58.394903 27427 net.cpp:165] Memory required for data: 271232652
I1022 15:54:58.394906 27427 layer_factory.hpp:77] Creating layer rpn_cls_prob_p3
I1022 15:54:58.394914 27427 net.cpp:100] Creating Layer rpn_cls_prob_p3
I1022 15:54:58.394918 27427 net.cpp:444] rpn_cls_prob_p3 <- rpn_cls_score_reshape_p3
I1022 15:54:58.394923 27427 net.cpp:418] rpn_cls_prob_p3 -> rpn_cls_prob_p3
I1022 15:54:58.395326 27427 net.cpp:150] Setting up rpn_cls_prob_p3
I1022 15:54:58.395335 27427 net.cpp:157] Top shape: 1 2 154 14 (4312)
I1022 15:54:58.395339 27427 net.cpp:165] Memory required for data: 271249900
I1022 15:54:58.395351 27427 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p3
I1022 15:54:58.395359 27427 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p3
I1022 15:54:58.395364 27427 net.cpp:444] rpn_cls_prob_reshape_p3 <- rpn_cls_prob_p3
I1022 15:54:58.395370 27427 net.cpp:418] rpn_cls_prob_reshape_p3 -> rpn_cls_prob_reshape_p3
I1022 15:54:58.395421 27427 net.cpp:150] Setting up rpn_cls_prob_reshape_p3
I1022 15:54:58.395431 27427 net.cpp:157] Top shape: 1 22 14 14 (4312)
I1022 15:54:58.395433 27427 net.cpp:165] Memory required for data: 271267148
I1022 15:54:58.395437 27427 layer_factory.hpp:77] Creating layer proposal
I1022 15:54:58.397231 27427 net.cpp:100] Creating Layer proposal
I1022 15:54:58.397243 27427 net.cpp:444] proposal <- im_info
I1022 15:54:58.397258 27427 net.cpp:444] proposal <- rpn_bbox_pred_p2
I1022 15:54:58.397264 27427 net.cpp:444] proposal <- rpn_bbox_pred_p3
I1022 15:54:58.397267 27427 net.cpp:444] proposal <- rpn_cls_prob_reshape_p2
I1022 15:54:58.397271 27427 net.cpp:444] proposal <- rpn_cls_prob_reshape_p3
I1022 15:54:58.397277 27427 net.cpp:418] proposal -> rpn_rois_p2
I1022 15:54:58.397285 27427 net.cpp:418] proposal -> rpn_rois_p3
I1022 15:54:58.398841 27427 net.cpp:150] Setting up proposal
I1022 15:54:58.398854 27427 net.cpp:157] Top shape: 1 5 (5)
I1022 15:54:58.398859 27427 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 15:54:58.398869 27427 net.cpp:165] Memory required for data: 271267172
I1022 15:54:58.398871 27427 layer_factory.hpp:77] Creating layer rpn_rois_p2_proposal_0_split
I1022 15:54:58.398878 27427 net.cpp:100] Creating Layer rpn_rois_p2_proposal_0_split
I1022 15:54:58.398882 27427 net.cpp:444] rpn_rois_p2_proposal_0_split <- rpn_rois_p2
I1022 15:54:58.398890 27427 net.cpp:418] rpn_rois_p2_proposal_0_split -> rpn_rois_p2_proposal_0_split_0
I1022 15:54:58.398897 27427 net.cpp:418] rpn_rois_p2_proposal_0_split -> rpn_rois_p2_proposal_0_split_1
I1022 15:54:58.398979 27427 net.cpp:150] Setting up rpn_rois_p2_proposal_0_split
I1022 15:54:58.398988 27427 net.cpp:157] Top shape: 1 5 (5)
I1022 15:54:58.398991 27427 net.cpp:157] Top shape: 1 5 (5)
I1022 15:54:58.398993 27427 net.cpp:165] Memory required for data: 271267212
I1022 15:54:58.398998 27427 layer_factory.hpp:77] Creating layer rpn_rois_p3_proposal_1_split
I1022 15:54:58.399003 27427 net.cpp:100] Creating Layer rpn_rois_p3_proposal_1_split
I1022 15:54:58.399006 27427 net.cpp:444] rpn_rois_p3_proposal_1_split <- rpn_rois_p3
I1022 15:54:58.399013 27427 net.cpp:418] rpn_rois_p3_proposal_1_split -> rpn_rois_p3_proposal_1_split_0
I1022 15:54:58.399019 27427 net.cpp:418] rpn_rois_p3_proposal_1_split -> rpn_rois_p3_proposal_1_split_1
I1022 15:54:58.399096 27427 net.cpp:150] Setting up rpn_rois_p3_proposal_1_split
I1022 15:54:58.399102 27427 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 15:54:58.399106 27427 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 15:54:58.399109 27427 net.cpp:165] Memory required for data: 271267220
I1022 15:54:58.399112 27427 layer_factory.hpp:77] Creating layer conv_new_p2
I1022 15:54:58.399122 27427 net.cpp:100] Creating Layer conv_new_p2
I1022 15:54:58.399127 27427 net.cpp:444] conv_new_p2 <- p2_p2_relu_0_split_1
I1022 15:54:58.399133 27427 net.cpp:418] conv_new_p2 -> conv_new_p2
I1022 15:54:58.408423 27427 net.cpp:150] Setting up conv_new_p2
I1022 15:54:58.408434 27427 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 15:54:58.408437 27427 net.cpp:165] Memory required for data: 274478484
I1022 15:54:58.408457 27427 layer_factory.hpp:77] Creating layer conv_new_p2_relu
I1022 15:54:58.408462 27427 net.cpp:100] Creating Layer conv_new_p2_relu
I1022 15:54:58.408464 27427 net.cpp:444] conv_new_p2_relu <- conv_new_p2
I1022 15:54:58.408470 27427 net.cpp:405] conv_new_p2_relu -> conv_new_p2 (in-place)
I1022 15:54:58.409397 27427 net.cpp:150] Setting up conv_new_p2_relu
I1022 15:54:58.409407 27427 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 15:54:58.409425 27427 net.cpp:165] Memory required for data: 277689748
I1022 15:54:58.409427 27427 layer_factory.hpp:77] Creating layer conv_new_p2_conv_new_p2_relu_0_split
I1022 15:54:58.409435 27427 net.cpp:100] Creating Layer conv_new_p2_conv_new_p2_relu_0_split
I1022 15:54:58.409437 27427 net.cpp:444] conv_new_p2_conv_new_p2_relu_0_split <- conv_new_p2
I1022 15:54:58.409441 27427 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_0
I1022 15:54:58.409447 27427 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_1
I1022 15:54:58.409525 27427 net.cpp:150] Setting up conv_new_p2_conv_new_p2_relu_0_split
I1022 15:54:58.409533 27427 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 15:54:58.409535 27427 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 15:54:58.409538 27427 net.cpp:165] Memory required for data: 284112276
I1022 15:54:58.409539 27427 layer_factory.hpp:77] Creating layer rfcn_cls_p2
I1022 15:54:58.409550 27427 net.cpp:100] Creating Layer rfcn_cls_p2
I1022 15:54:58.409554 27427 net.cpp:444] rfcn_cls_p2 <- conv_new_p2_conv_new_p2_relu_0_split_0
I1022 15:54:58.409559 27427 net.cpp:418] rfcn_cls_p2 -> rfcn_cls_p2
I1022 15:54:58.412055 27427 net.cpp:150] Setting up rfcn_cls_p2
I1022 15:54:58.412065 27427 net.cpp:157] Top shape: 1 98 28 28 (76832)
I1022 15:54:58.412066 27427 net.cpp:165] Memory required for data: 284419604
I1022 15:54:58.412087 27427 layer_factory.hpp:77] Creating layer rfcn_bbox_p2
I1022 15:54:58.412096 27427 net.cpp:100] Creating Layer rfcn_bbox_p2
I1022 15:54:58.412101 27427 net.cpp:444] rfcn_bbox_p2 <- conv_new_p2_conv_new_p2_relu_0_split_1
I1022 15:54:58.412107 27427 net.cpp:418] rfcn_bbox_p2 -> rfcn_bbox_p2
I1022 15:54:58.418699 27427 net.cpp:150] Setting up rfcn_bbox_p2
I1022 15:54:58.418709 27427 net.cpp:157] Top shape: 1 392 28 28 (307328)
I1022 15:54:58.418726 27427 net.cpp:165] Memory required for data: 285648916
I1022 15:54:58.418732 27427 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p2
I1022 15:54:58.418738 27427 net.cpp:100] Creating Layer psroipooled_cls_rois_p2
I1022 15:54:58.418742 27427 net.cpp:444] psroipooled_cls_rois_p2 <- rfcn_cls_p2
I1022 15:54:58.418746 27427 net.cpp:444] psroipooled_cls_rois_p2 <- rpn_rois_p2_proposal_0_split_0
I1022 15:54:58.418752 27427 net.cpp:418] psroipooled_cls_rois_p2 -> psroipooled_cls_rois_p2
I1022 15:54:58.418759 27427 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1022 15:54:58.418843 27427 net.cpp:150] Setting up psroipooled_cls_rois_p2
I1022 15:54:58.418850 27427 net.cpp:157] Top shape: 1 2 7 7 (98)
I1022 15:54:58.418853 27427 net.cpp:165] Memory required for data: 285649308
I1022 15:54:58.418854 27427 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p2
I1022 15:54:58.418860 27427 net.cpp:100] Creating Layer ave_cls_score_rois_p2
I1022 15:54:58.418865 27427 net.cpp:444] ave_cls_score_rois_p2 <- psroipooled_cls_rois_p2
I1022 15:54:58.418871 27427 net.cpp:418] ave_cls_score_rois_p2 -> cls_score_p2
I1022 15:54:58.419108 27427 net.cpp:150] Setting up ave_cls_score_rois_p2
I1022 15:54:58.419116 27427 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 15:54:58.419119 27427 net.cpp:165] Memory required for data: 285649316
I1022 15:54:58.419121 27427 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p2
I1022 15:54:58.419128 27427 net.cpp:100] Creating Layer psroipooled_loc_rois_p2
I1022 15:54:58.419132 27427 net.cpp:444] psroipooled_loc_rois_p2 <- rfcn_bbox_p2
I1022 15:54:58.419137 27427 net.cpp:444] psroipooled_loc_rois_p2 <- rpn_rois_p2_proposal_0_split_1
I1022 15:54:58.419142 27427 net.cpp:418] psroipooled_loc_rois_p2 -> psroipooled_loc_rois_p2
I1022 15:54:58.419147 27427 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1022 15:54:58.419217 27427 net.cpp:150] Setting up psroipooled_loc_rois_p2
I1022 15:54:58.419224 27427 net.cpp:157] Top shape: 1 8 7 7 (392)
I1022 15:54:58.419225 27427 net.cpp:165] Memory required for data: 285650884
I1022 15:54:58.419227 27427 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p2
I1022 15:54:58.419234 27427 net.cpp:100] Creating Layer ave_bbox_pred_rois_p2
I1022 15:54:58.419239 27427 net.cpp:444] ave_bbox_pred_rois_p2 <- psroipooled_loc_rois_p2
I1022 15:54:58.419242 27427 net.cpp:418] ave_bbox_pred_rois_p2 -> bbox_pred_pre_p2
I1022 15:54:58.419461 27427 net.cpp:150] Setting up ave_bbox_pred_rois_p2
I1022 15:54:58.419468 27427 net.cpp:157] Top shape: 1 8 1 1 (8)
I1022 15:54:58.419471 27427 net.cpp:165] Memory required for data: 285650916
I1022 15:54:58.419474 27427 layer_factory.hpp:77] Creating layer conv_new_p3
I1022 15:54:58.419484 27427 net.cpp:100] Creating Layer conv_new_p3
I1022 15:54:58.419489 27427 net.cpp:444] conv_new_p3 <- p3_p3_relu_0_split_2
I1022 15:54:58.419493 27427 net.cpp:418] conv_new_p3 -> conv_new_p3
I1022 15:54:58.431608 27427 net.cpp:150] Setting up conv_new_p3
I1022 15:54:58.431620 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.431638 27427 net.cpp:165] Memory required for data: 286453732
I1022 15:54:58.431643 27427 layer_factory.hpp:77] Creating layer conv_new_p3_relu
I1022 15:54:58.431650 27427 net.cpp:100] Creating Layer conv_new_p3_relu
I1022 15:54:58.431653 27427 net.cpp:444] conv_new_p3_relu <- conv_new_p3
I1022 15:54:58.431658 27427 net.cpp:405] conv_new_p3_relu -> conv_new_p3 (in-place)
I1022 15:54:58.432499 27427 net.cpp:150] Setting up conv_new_p3_relu
I1022 15:54:58.432510 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.432528 27427 net.cpp:165] Memory required for data: 287256548
I1022 15:54:58.432530 27427 layer_factory.hpp:77] Creating layer conv_new_p3_conv_new_p3_relu_0_split
I1022 15:54:58.432536 27427 net.cpp:100] Creating Layer conv_new_p3_conv_new_p3_relu_0_split
I1022 15:54:58.432538 27427 net.cpp:444] conv_new_p3_conv_new_p3_relu_0_split <- conv_new_p3
I1022 15:54:58.432545 27427 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_0
I1022 15:54:58.432551 27427 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_1
I1022 15:54:58.432679 27427 net.cpp:150] Setting up conv_new_p3_conv_new_p3_relu_0_split
I1022 15:54:58.432687 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.432690 27427 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 15:54:58.432693 27427 net.cpp:165] Memory required for data: 288862180
I1022 15:54:58.432696 27427 layer_factory.hpp:77] Creating layer rfcn_cls_p3
I1022 15:54:58.432705 27427 net.cpp:100] Creating Layer rfcn_cls_p3
I1022 15:54:58.432710 27427 net.cpp:444] rfcn_cls_p3 <- conv_new_p3_conv_new_p3_relu_0_split_0
I1022 15:54:58.432718 27427 net.cpp:418] rfcn_cls_p3 -> rfcn_cls_p3
I1022 15:54:58.435215 27427 net.cpp:150] Setting up rfcn_cls_p3
I1022 15:54:58.435225 27427 net.cpp:157] Top shape: 1 98 14 14 (19208)
I1022 15:54:58.435242 27427 net.cpp:165] Memory required for data: 288939012
I1022 15:54:58.435248 27427 layer_factory.hpp:77] Creating layer rfcn_bbox_p3
I1022 15:54:58.435258 27427 net.cpp:100] Creating Layer rfcn_bbox_p3
I1022 15:54:58.435261 27427 net.cpp:444] rfcn_bbox_p3 <- conv_new_p3_conv_new_p3_relu_0_split_1
I1022 15:54:58.435268 27427 net.cpp:418] rfcn_bbox_p3 -> rfcn_bbox_p3
I1022 15:54:58.441826 27427 net.cpp:150] Setting up rfcn_bbox_p3
I1022 15:54:58.441836 27427 net.cpp:157] Top shape: 1 392 14 14 (76832)
I1022 15:54:58.441838 27427 net.cpp:165] Memory required for data: 289246340
I1022 15:54:58.441859 27427 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p3
I1022 15:54:58.441864 27427 net.cpp:100] Creating Layer psroipooled_cls_rois_p3
I1022 15:54:58.441867 27427 net.cpp:444] psroipooled_cls_rois_p3 <- rfcn_cls_p3
I1022 15:54:58.441871 27427 net.cpp:444] psroipooled_cls_rois_p3 <- rpn_rois_p3_proposal_1_split_0
I1022 15:54:58.441879 27427 net.cpp:418] psroipooled_cls_rois_p3 -> psroipooled_cls_rois_p3
I1022 15:54:58.441885 27427 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1022 15:54:58.441962 27427 net.cpp:150] Setting up psroipooled_cls_rois_p3
I1022 15:54:58.441969 27427 net.cpp:157] Top shape: 1 2 7 7 (98)
I1022 15:54:58.441972 27427 net.cpp:165] Memory required for data: 289246732
I1022 15:54:58.441974 27427 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p3
I1022 15:54:58.441980 27427 net.cpp:100] Creating Layer ave_cls_score_rois_p3
I1022 15:54:58.441985 27427 net.cpp:444] ave_cls_score_rois_p3 <- psroipooled_cls_rois_p3
I1022 15:54:58.441990 27427 net.cpp:418] ave_cls_score_rois_p3 -> cls_score_p3
I1022 15:54:58.442225 27427 net.cpp:150] Setting up ave_cls_score_rois_p3
I1022 15:54:58.442234 27427 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 15:54:58.442235 27427 net.cpp:165] Memory required for data: 289246740
I1022 15:54:58.442239 27427 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p3
I1022 15:54:58.442245 27427 net.cpp:100] Creating Layer psroipooled_loc_rois_p3
I1022 15:54:58.442250 27427 net.cpp:444] psroipooled_loc_rois_p3 <- rfcn_bbox_p3
I1022 15:54:58.442253 27427 net.cpp:444] psroipooled_loc_rois_p3 <- rpn_rois_p3_proposal_1_split_1
I1022 15:54:58.442257 27427 net.cpp:418] psroipooled_loc_rois_p3 -> psroipooled_loc_rois_p3
I1022 15:54:58.442262 27427 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1022 15:54:58.442335 27427 net.cpp:150] Setting up psroipooled_loc_rois_p3
I1022 15:54:58.442340 27427 net.cpp:157] Top shape: 1 8 7 7 (392)
I1022 15:54:58.442342 27427 net.cpp:165] Memory required for data: 289248308
I1022 15:54:58.442345 27427 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p3
I1022 15:54:58.442351 27427 net.cpp:100] Creating Layer ave_bbox_pred_rois_p3
I1022 15:54:58.442358 27427 net.cpp:444] ave_bbox_pred_rois_p3 <- psroipooled_loc_rois_p3
I1022 15:54:58.442361 27427 net.cpp:418] ave_bbox_pred_rois_p3 -> bbox_pred_pre_p3
I1022 15:54:58.442582 27427 net.cpp:150] Setting up ave_bbox_pred_rois_p3
I1022 15:54:58.442590 27427 net.cpp:157] Top shape: 1 8 1 1 (8)
I1022 15:54:58.442592 27427 net.cpp:165] Memory required for data: 289248340
I1022 15:54:58.442595 27427 layer_factory.hpp:77] Creating layer cls_prob_pre_p2
I1022 15:54:58.442601 27427 net.cpp:100] Creating Layer cls_prob_pre_p2
I1022 15:54:58.442606 27427 net.cpp:444] cls_prob_pre_p2 <- cls_score_p2
I1022 15:54:58.442610 27427 net.cpp:418] cls_prob_pre_p2 -> cls_prob_pre_p2
I1022 15:54:58.443527 27427 net.cpp:150] Setting up cls_prob_pre_p2
I1022 15:54:58.443537 27427 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 15:54:58.443554 27427 net.cpp:165] Memory required for data: 289248348
I1022 15:54:58.443557 27427 layer_factory.hpp:77] Creating layer cls_prob_pre_p3
I1022 15:54:58.443562 27427 net.cpp:100] Creating Layer cls_prob_pre_p3
I1022 15:54:58.443565 27427 net.cpp:444] cls_prob_pre_p3 <- cls_score_p3
I1022 15:54:58.443572 27427 net.cpp:418] cls_prob_pre_p3 -> cls_prob_pre_p3
I1022 15:54:58.443894 27427 net.cpp:150] Setting up cls_prob_pre_p3
I1022 15:54:58.443902 27427 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 15:54:58.443903 27427 net.cpp:165] Memory required for data: 289248356
I1022 15:54:58.443922 27427 layer_factory.hpp:77] Creating layer cls_prob_reshape_p2
I1022 15:54:58.443928 27427 net.cpp:100] Creating Layer cls_prob_reshape_p2
I1022 15:54:58.443930 27427 net.cpp:444] cls_prob_reshape_p2 <- cls_prob_pre_p2
I1022 15:54:58.443934 27427 net.cpp:418] cls_prob_reshape_p2 -> cls_prob_p2
I1022 15:54:58.443979 27427 net.cpp:150] Setting up cls_prob_reshape_p2
I1022 15:54:58.443985 27427 net.cpp:157] Top shape: 1 2 (2)
I1022 15:54:58.443987 27427 net.cpp:165] Memory required for data: 289248364
I1022 15:54:58.443990 27427 layer_factory.hpp:77] Creating layer cls_prob_reshape_p3
I1022 15:54:58.443994 27427 net.cpp:100] Creating Layer cls_prob_reshape_p3
I1022 15:54:58.443996 27427 net.cpp:444] cls_prob_reshape_p3 <- cls_prob_pre_p3
I1022 15:54:58.444002 27427 net.cpp:418] cls_prob_reshape_p3 -> cls_prob_p3
I1022 15:54:58.444041 27427 net.cpp:150] Setting up cls_prob_reshape_p3
I1022 15:54:58.444046 27427 net.cpp:157] Top shape: 1 2 (2)
I1022 15:54:58.444048 27427 net.cpp:165] Memory required for data: 289248372
I1022 15:54:58.444051 27427 layer_factory.hpp:77] Creating layer bbox_pred_reshape_p2
I1022 15:54:58.444056 27427 net.cpp:100] Creating Layer bbox_pred_reshape_p2
I1022 15:54:58.444059 27427 net.cpp:444] bbox_pred_reshape_p2 <- bbox_pred_pre_p2
I1022 15:54:58.444063 27427 net.cpp:418] bbox_pred_reshape_p2 -> bbox_pred_p2
I1022 15:54:58.444102 27427 net.cpp:150] Setting up bbox_pred_reshape_p2
I1022 15:54:58.444108 27427 net.cpp:157] Top shape: 1 8 (8)
I1022 15:54:58.444109 27427 net.cpp:165] Memory required for data: 289248404
I1022 15:54:58.444111 27427 layer_factory.hpp:77] Creating layer bbox_pred_reshape_p3
I1022 15:54:58.444115 27427 net.cpp:100] Creating Layer bbox_pred_reshape_p3
I1022 15:54:58.444118 27427 net.cpp:444] bbox_pred_reshape_p3 <- bbox_pred_pre_p3
I1022 15:54:58.444123 27427 net.cpp:418] bbox_pred_reshape_p3 -> bbox_pred_p3
I1022 15:54:58.444159 27427 net.cpp:150] Setting up bbox_pred_reshape_p3
I1022 15:54:58.444164 27427 net.cpp:157] Top shape: 1 8 (8)
I1022 15:54:58.444166 27427 net.cpp:165] Memory required for data: 289248436
I1022 15:54:58.444169 27427 net.cpp:228] bbox_pred_reshape_p3 does not need backward computation.
I1022 15:54:58.444171 27427 net.cpp:228] bbox_pred_reshape_p2 does not need backward computation.
I1022 15:54:58.444175 27427 net.cpp:228] cls_prob_reshape_p3 does not need backward computation.
I1022 15:54:58.444176 27427 net.cpp:228] cls_prob_reshape_p2 does not need backward computation.
I1022 15:54:58.444180 27427 net.cpp:228] cls_prob_pre_p3 does not need backward computation.
I1022 15:54:58.444181 27427 net.cpp:228] cls_prob_pre_p2 does not need backward computation.
I1022 15:54:58.444183 27427 net.cpp:228] ave_bbox_pred_rois_p3 does not need backward computation.
I1022 15:54:58.444186 27427 net.cpp:228] psroipooled_loc_rois_p3 does not need backward computation.
I1022 15:54:58.444190 27427 net.cpp:228] ave_cls_score_rois_p3 does not need backward computation.
I1022 15:54:58.444191 27427 net.cpp:228] psroipooled_cls_rois_p3 does not need backward computation.
I1022 15:54:58.444195 27427 net.cpp:228] rfcn_bbox_p3 does not need backward computation.
I1022 15:54:58.444197 27427 net.cpp:228] rfcn_cls_p3 does not need backward computation.
I1022 15:54:58.444200 27427 net.cpp:228] conv_new_p3_conv_new_p3_relu_0_split does not need backward computation.
I1022 15:54:58.444203 27427 net.cpp:228] conv_new_p3_relu does not need backward computation.
I1022 15:54:58.444205 27427 net.cpp:228] conv_new_p3 does not need backward computation.
I1022 15:54:58.444207 27427 net.cpp:228] ave_bbox_pred_rois_p2 does not need backward computation.
I1022 15:54:58.444211 27427 net.cpp:228] psroipooled_loc_rois_p2 does not need backward computation.
I1022 15:54:58.444216 27427 net.cpp:228] ave_cls_score_rois_p2 does not need backward computation.
I1022 15:54:58.444217 27427 net.cpp:228] psroipooled_cls_rois_p2 does not need backward computation.
I1022 15:54:58.444221 27427 net.cpp:228] rfcn_bbox_p2 does not need backward computation.
I1022 15:54:58.444223 27427 net.cpp:228] rfcn_cls_p2 does not need backward computation.
I1022 15:54:58.444226 27427 net.cpp:228] conv_new_p2_conv_new_p2_relu_0_split does not need backward computation.
I1022 15:54:58.444228 27427 net.cpp:228] conv_new_p2_relu does not need backward computation.
I1022 15:54:58.444231 27427 net.cpp:228] conv_new_p2 does not need backward computation.
I1022 15:54:58.444233 27427 net.cpp:228] rpn_rois_p3_proposal_1_split does not need backward computation.
I1022 15:54:58.444236 27427 net.cpp:228] rpn_rois_p2_proposal_0_split does not need backward computation.
I1022 15:54:58.444238 27427 net.cpp:228] proposal does not need backward computation.
I1022 15:54:58.444243 27427 net.cpp:228] rpn_cls_prob_reshape_p3 does not need backward computation.
I1022 15:54:58.444247 27427 net.cpp:228] rpn_cls_prob_p3 does not need backward computation.
I1022 15:54:58.444248 27427 net.cpp:228] rpn_cls_score_reshape_p3 does not need backward computation.
I1022 15:54:58.444252 27427 net.cpp:228] rpn_bbox_pred_p3 does not need backward computation.
I1022 15:54:58.444255 27427 net.cpp:228] rpn_cls_score_p3 does not need backward computation.
I1022 15:54:58.444258 27427 net.cpp:228] rpn/output_p3_rpn_relu/3x3_p3_0_split does not need backward computation.
I1022 15:54:58.444262 27427 net.cpp:228] rpn_relu/3x3_p3 does not need backward computation.
I1022 15:54:58.444263 27427 net.cpp:228] rpn_conv/3x3_p3 does not need backward computation.
I1022 15:54:58.444267 27427 net.cpp:228] rpn_cls_prob_reshape_p2 does not need backward computation.
I1022 15:54:58.444270 27427 net.cpp:228] rpn_cls_prob_p2 does not need backward computation.
I1022 15:54:58.444273 27427 net.cpp:228] rpn_cls_score_reshape_p2 does not need backward computation.
I1022 15:54:58.444277 27427 net.cpp:228] rpn_bbox_pred_p2 does not need backward computation.
I1022 15:54:58.444280 27427 net.cpp:228] rpn_cls_score_p2 does not need backward computation.
I1022 15:54:58.444283 27427 net.cpp:228] rpn/output_p2_rpn_relu/3x3_p2_0_split does not need backward computation.
I1022 15:54:58.444285 27427 net.cpp:228] rpn_relu/3x3_p2 does not need backward computation.
I1022 15:54:58.444288 27427 net.cpp:228] rpn_conv/3x3_p2 does not need backward computation.
I1022 15:54:58.444291 27427 net.cpp:228] p2_p2_relu_0_split does not need backward computation.
I1022 15:54:58.444294 27427 net.cpp:228] p2_relu does not need backward computation.
I1022 15:54:58.444298 27427 net.cpp:228] p2 does not need backward computation.
I1022 15:54:58.444301 27427 net.cpp:228] bn_eltwise_2_2_scale does not need backward computation.
I1022 15:54:58.444304 27427 net.cpp:228] bn_eltwise_2_2_bn does not need backward computation.
I1022 15:54:58.444306 27427 net.cpp:228] bn_eltwise_2_2_conv does not need backward computation.
I1022 15:54:58.444309 27427 net.cpp:228] bn_eltwise_2_1_ReLU does not need backward computation.
I1022 15:54:58.444313 27427 net.cpp:228] bn_eltwise_2_1_scale does not need backward computation.
I1022 15:54:58.444314 27427 net.cpp:228] bn_eltwise_2_1_bn does not need backward computation.
I1022 15:54:58.444317 27427 net.cpp:228] bn_eltwise_2_1_conv does not need backward computation.
I1022 15:54:58.444319 27427 net.cpp:228] bnp3_ReLU does not need backward computation.
I1022 15:54:58.444322 27427 net.cpp:228] bnp3_scale does not need backward computation.
I1022 15:54:58.444325 27427 net.cpp:228] bnp3_bn does not need backward computation.
I1022 15:54:58.444327 27427 net.cpp:228] bnp3_conv does not need backward computation.
I1022 15:54:58.444330 27427 net.cpp:228] skip_eltwise2_eltwise_bnc3_bnp3_0_split does not need backward computation.
I1022 15:54:58.444334 27427 net.cpp:228] eltwise_bnc3_bnp3 does not need backward computation.
I1022 15:54:58.444337 27427 net.cpp:228] upP3 does not need backward computation.
I1022 15:54:58.444342 27427 net.cpp:228] newC3 does not need backward computation.
I1022 15:54:58.444345 27427 net.cpp:228] p3_p3_relu_0_split does not need backward computation.
I1022 15:54:58.444350 27427 net.cpp:228] p3_relu does not need backward computation.
I1022 15:54:58.444352 27427 net.cpp:228] p3 does not need backward computation.
I1022 15:54:58.444355 27427 net.cpp:228] bn_eltwise_1_2_scale does not need backward computation.
I1022 15:54:58.444358 27427 net.cpp:228] bn_eltwise_1_2_bn does not need backward computation.
I1022 15:54:58.444360 27427 net.cpp:228] bn_eltwise_1_2_conv does not need backward computation.
I1022 15:54:58.444363 27427 net.cpp:228] bn_eltwise_1_1_ReLU does not need backward computation.
I1022 15:54:58.444366 27427 net.cpp:228] bn_eltwise_1_1_scale does not need backward computation.
I1022 15:54:58.444368 27427 net.cpp:228] bn_eltwise_1_1_bn does not need backward computation.
I1022 15:54:58.444371 27427 net.cpp:228] bn_eltwise_1_1_conv does not need backward computation.
I1022 15:54:58.444375 27427 net.cpp:228] bnp4_ReLU does not need backward computation.
I1022 15:54:58.444376 27427 net.cpp:228] bnp4_scale does not need backward computation.
I1022 15:54:58.444380 27427 net.cpp:228] bnp4_bn does not need backward computation.
I1022 15:54:58.444381 27427 net.cpp:228] bnp4_conv does not need backward computation.
I1022 15:54:58.444384 27427 net.cpp:228] skip_eltwise1_eltwise_bnc4_bnp4_0_split does not need backward computation.
I1022 15:54:58.444387 27427 net.cpp:228] eltwise_bnc4_bnp4 does not need backward computation.
I1022 15:54:58.444391 27427 net.cpp:228] newC4 does not need backward computation.
I1022 15:54:58.444393 27427 net.cpp:228] upP4 does not need backward computation.
I1022 15:54:58.444396 27427 net.cpp:228] res5c_relu does not need backward computation.
I1022 15:54:58.444399 27427 net.cpp:228] res5c does not need backward computation.
I1022 15:54:58.444402 27427 net.cpp:228] scale5c_branch2c does not need backward computation.
I1022 15:54:58.444406 27427 net.cpp:228] bn5c_branch2c does not need backward computation.
I1022 15:54:58.444408 27427 net.cpp:228] res5c_branch2c does not need backward computation.
I1022 15:54:58.444411 27427 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I1022 15:54:58.444413 27427 net.cpp:228] scale5c_branch2b does not need backward computation.
I1022 15:54:58.444416 27427 net.cpp:228] bn5c_branch2b does not need backward computation.
I1022 15:54:58.444419 27427 net.cpp:228] res5c_branch2b does not need backward computation.
I1022 15:54:58.444422 27427 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I1022 15:54:58.444424 27427 net.cpp:228] scale5c_branch2a does not need backward computation.
I1022 15:54:58.444427 27427 net.cpp:228] bn5c_branch2a does not need backward computation.
I1022 15:54:58.444429 27427 net.cpp:228] res5c_branch2a does not need backward computation.
I1022 15:54:58.444433 27427 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I1022 15:54:58.444437 27427 net.cpp:228] res5b_relu does not need backward computation.
I1022 15:54:58.444438 27427 net.cpp:228] res5b does not need backward computation.
I1022 15:54:58.444443 27427 net.cpp:228] scale5b_branch2c does not need backward computation.
I1022 15:54:58.444447 27427 net.cpp:228] bn5b_branch2c does not need backward computation.
I1022 15:54:58.444448 27427 net.cpp:228] res5b_branch2c does not need backward computation.
I1022 15:54:58.444452 27427 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I1022 15:54:58.444455 27427 net.cpp:228] scale5b_branch2b does not need backward computation.
I1022 15:54:58.444458 27427 net.cpp:228] bn5b_branch2b does not need backward computation.
I1022 15:54:58.444459 27427 net.cpp:228] res5b_branch2b does not need backward computation.
I1022 15:54:58.444463 27427 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I1022 15:54:58.444465 27427 net.cpp:228] scale5b_branch2a does not need backward computation.
I1022 15:54:58.444468 27427 net.cpp:228] bn5b_branch2a does not need backward computation.
I1022 15:54:58.444469 27427 net.cpp:228] res5b_branch2a does not need backward computation.
I1022 15:54:58.444473 27427 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I1022 15:54:58.444476 27427 net.cpp:228] res5a_relu does not need backward computation.
I1022 15:54:58.444479 27427 net.cpp:228] res5a does not need backward computation.
I1022 15:54:58.444483 27427 net.cpp:228] scale5a_branch2c does not need backward computation.
I1022 15:54:58.444485 27427 net.cpp:228] bn5a_branch2c does not need backward computation.
I1022 15:54:58.444489 27427 net.cpp:228] res5a_branch2c does not need backward computation.
I1022 15:54:58.444490 27427 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I1022 15:54:58.444494 27427 net.cpp:228] scale5a_branch2b does not need backward computation.
I1022 15:54:58.444495 27427 net.cpp:228] bn5a_branch2b does not need backward computation.
I1022 15:54:58.444499 27427 net.cpp:228] res5a_branch2b does not need backward computation.
I1022 15:54:58.444501 27427 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I1022 15:54:58.444504 27427 net.cpp:228] scale5a_branch2a does not need backward computation.
I1022 15:54:58.444506 27427 net.cpp:228] bn5a_branch2a does not need backward computation.
I1022 15:54:58.444509 27427 net.cpp:228] res5a_branch2a does not need backward computation.
I1022 15:54:58.444512 27427 net.cpp:228] scale5a_branch1 does not need backward computation.
I1022 15:54:58.444514 27427 net.cpp:228] bn5a_branch1 does not need backward computation.
I1022 15:54:58.444517 27427 net.cpp:228] res5a_branch1 does not need backward computation.
I1022 15:54:58.444520 27427 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I1022 15:54:58.444523 27427 net.cpp:228] res4f_relu does not need backward computation.
I1022 15:54:58.444526 27427 net.cpp:228] res4f does not need backward computation.
I1022 15:54:58.444530 27427 net.cpp:228] scale4f_branch2c does not need backward computation.
I1022 15:54:58.444532 27427 net.cpp:228] bn4f_branch2c does not need backward computation.
I1022 15:54:58.444535 27427 net.cpp:228] res4f_branch2c does not need backward computation.
I1022 15:54:58.444538 27427 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I1022 15:54:58.444541 27427 net.cpp:228] scale4f_branch2b does not need backward computation.
I1022 15:54:58.444545 27427 net.cpp:228] bn4f_branch2b does not need backward computation.
I1022 15:54:58.444546 27427 net.cpp:228] res4f_branch2b does not need backward computation.
I1022 15:54:58.444550 27427 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I1022 15:54:58.444552 27427 net.cpp:228] scale4f_branch2a does not need backward computation.
I1022 15:54:58.444555 27427 net.cpp:228] bn4f_branch2a does not need backward computation.
I1022 15:54:58.444557 27427 net.cpp:228] res4f_branch2a does not need backward computation.
I1022 15:54:58.444561 27427 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I1022 15:54:58.444563 27427 net.cpp:228] res4e_relu does not need backward computation.
I1022 15:54:58.444566 27427 net.cpp:228] res4e does not need backward computation.
I1022 15:54:58.444571 27427 net.cpp:228] scale4e_branch2c does not need backward computation.
I1022 15:54:58.444573 27427 net.cpp:228] bn4e_branch2c does not need backward computation.
I1022 15:54:58.444576 27427 net.cpp:228] res4e_branch2c does not need backward computation.
I1022 15:54:58.444578 27427 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I1022 15:54:58.444581 27427 net.cpp:228] scale4e_branch2b does not need backward computation.
I1022 15:54:58.444583 27427 net.cpp:228] bn4e_branch2b does not need backward computation.
I1022 15:54:58.444586 27427 net.cpp:228] res4e_branch2b does not need backward computation.
I1022 15:54:58.444588 27427 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I1022 15:54:58.444591 27427 net.cpp:228] scale4e_branch2a does not need backward computation.
I1022 15:54:58.444593 27427 net.cpp:228] bn4e_branch2a does not need backward computation.
I1022 15:54:58.444597 27427 net.cpp:228] res4e_branch2a does not need backward computation.
I1022 15:54:58.444602 27427 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I1022 15:54:58.444604 27427 net.cpp:228] res4d_relu does not need backward computation.
I1022 15:54:58.444607 27427 net.cpp:228] res4d does not need backward computation.
I1022 15:54:58.444634 27427 net.cpp:228] scale4d_branch2c does not need backward computation.
I1022 15:54:58.444638 27427 net.cpp:228] bn4d_branch2c does not need backward computation.
I1022 15:54:58.444656 27427 net.cpp:228] res4d_branch2c does not need backward computation.
I1022 15:54:58.444658 27427 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I1022 15:54:58.444661 27427 net.cpp:228] scale4d_branch2b does not need backward computation.
I1022 15:54:58.444664 27427 net.cpp:228] bn4d_branch2b does not need backward computation.
I1022 15:54:58.444666 27427 net.cpp:228] res4d_branch2b does not need backward computation.
I1022 15:54:58.444669 27427 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I1022 15:54:58.444672 27427 net.cpp:228] scale4d_branch2a does not need backward computation.
I1022 15:54:58.444675 27427 net.cpp:228] bn4d_branch2a does not need backward computation.
I1022 15:54:58.444677 27427 net.cpp:228] res4d_branch2a does not need backward computation.
I1022 15:54:58.444681 27427 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I1022 15:54:58.444684 27427 net.cpp:228] res4c_relu does not need backward computation.
I1022 15:54:58.444687 27427 net.cpp:228] res4c does not need backward computation.
I1022 15:54:58.444690 27427 net.cpp:228] scale4c_branch2c does not need backward computation.
I1022 15:54:58.444694 27427 net.cpp:228] bn4c_branch2c does not need backward computation.
I1022 15:54:58.444696 27427 net.cpp:228] res4c_branch2c does not need backward computation.
I1022 15:54:58.444699 27427 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I1022 15:54:58.444701 27427 net.cpp:228] scale4c_branch2b does not need backward computation.
I1022 15:54:58.444705 27427 net.cpp:228] bn4c_branch2b does not need backward computation.
I1022 15:54:58.444706 27427 net.cpp:228] res4c_branch2b does not need backward computation.
I1022 15:54:58.444710 27427 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I1022 15:54:58.444712 27427 net.cpp:228] scale4c_branch2a does not need backward computation.
I1022 15:54:58.444715 27427 net.cpp:228] bn4c_branch2a does not need backward computation.
I1022 15:54:58.444717 27427 net.cpp:228] res4c_branch2a does not need backward computation.
I1022 15:54:58.444720 27427 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I1022 15:54:58.444723 27427 net.cpp:228] res4b_relu does not need backward computation.
I1022 15:54:58.444727 27427 net.cpp:228] res4b does not need backward computation.
I1022 15:54:58.444730 27427 net.cpp:228] scale4b_branch2c does not need backward computation.
I1022 15:54:58.444733 27427 net.cpp:228] bn4b_branch2c does not need backward computation.
I1022 15:54:58.444736 27427 net.cpp:228] res4b_branch2c does not need backward computation.
I1022 15:54:58.444738 27427 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I1022 15:54:58.444741 27427 net.cpp:228] scale4b_branch2b does not need backward computation.
I1022 15:54:58.444743 27427 net.cpp:228] bn4b_branch2b does not need backward computation.
I1022 15:54:58.444746 27427 net.cpp:228] res4b_branch2b does not need backward computation.
I1022 15:54:58.444748 27427 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I1022 15:54:58.444752 27427 net.cpp:228] scale4b_branch2a does not need backward computation.
I1022 15:54:58.444756 27427 net.cpp:228] bn4b_branch2a does not need backward computation.
I1022 15:54:58.444757 27427 net.cpp:228] res4b_branch2a does not need backward computation.
I1022 15:54:58.444761 27427 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I1022 15:54:58.444764 27427 net.cpp:228] res4a_relu does not need backward computation.
I1022 15:54:58.444767 27427 net.cpp:228] res4a does not need backward computation.
I1022 15:54:58.444777 27427 net.cpp:228] scale4a_branch2c does not need backward computation.
I1022 15:54:58.444782 27427 net.cpp:228] bn4a_branch2c does not need backward computation.
I1022 15:54:58.444785 27427 net.cpp:228] res4a_branch2c does not need backward computation.
I1022 15:54:58.444787 27427 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I1022 15:54:58.444790 27427 net.cpp:228] scale4a_branch2b does not need backward computation.
I1022 15:54:58.444793 27427 net.cpp:228] bn4a_branch2b does not need backward computation.
I1022 15:54:58.444797 27427 net.cpp:228] res4a_branch2b does not need backward computation.
I1022 15:54:58.444799 27427 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I1022 15:54:58.444802 27427 net.cpp:228] scale4a_branch2a does not need backward computation.
I1022 15:54:58.444804 27427 net.cpp:228] bn4a_branch2a does not need backward computation.
I1022 15:54:58.444808 27427 net.cpp:228] res4a_branch2a does not need backward computation.
I1022 15:54:58.444810 27427 net.cpp:228] scale4a_branch1 does not need backward computation.
I1022 15:54:58.444813 27427 net.cpp:228] bn4a_branch1 does not need backward computation.
I1022 15:54:58.444815 27427 net.cpp:228] res4a_branch1 does not need backward computation.
I1022 15:54:58.444819 27427 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I1022 15:54:58.444823 27427 net.cpp:228] res3d_relu does not need backward computation.
I1022 15:54:58.444825 27427 net.cpp:228] res3d does not need backward computation.
I1022 15:54:58.444829 27427 net.cpp:228] scale3d_branch2c does not need backward computation.
I1022 15:54:58.444833 27427 net.cpp:228] bn3d_branch2c does not need backward computation.
I1022 15:54:58.444834 27427 net.cpp:228] res3d_branch2c does not need backward computation.
I1022 15:54:58.444838 27427 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I1022 15:54:58.444840 27427 net.cpp:228] scale3d_branch2b does not need backward computation.
I1022 15:54:58.444844 27427 net.cpp:228] bn3d_branch2b does not need backward computation.
I1022 15:54:58.444846 27427 net.cpp:228] res3d_branch2b does not need backward computation.
I1022 15:54:58.444849 27427 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I1022 15:54:58.444851 27427 net.cpp:228] scale3d_branch2a does not need backward computation.
I1022 15:54:58.444854 27427 net.cpp:228] bn3d_branch2a does not need backward computation.
I1022 15:54:58.444857 27427 net.cpp:228] res3d_branch2a does not need backward computation.
I1022 15:54:58.444860 27427 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I1022 15:54:58.444864 27427 net.cpp:228] res3c_relu does not need backward computation.
I1022 15:54:58.444866 27427 net.cpp:228] res3c does not need backward computation.
I1022 15:54:58.444870 27427 net.cpp:228] scale3c_branch2c does not need backward computation.
I1022 15:54:58.444872 27427 net.cpp:228] bn3c_branch2c does not need backward computation.
I1022 15:54:58.444875 27427 net.cpp:228] res3c_branch2c does not need backward computation.
I1022 15:54:58.444877 27427 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I1022 15:54:58.444881 27427 net.cpp:228] scale3c_branch2b does not need backward computation.
I1022 15:54:58.444883 27427 net.cpp:228] bn3c_branch2b does not need backward computation.
I1022 15:54:58.444886 27427 net.cpp:228] res3c_branch2b does not need backward computation.
I1022 15:54:58.444888 27427 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I1022 15:54:58.444891 27427 net.cpp:228] scale3c_branch2a does not need backward computation.
I1022 15:54:58.444895 27427 net.cpp:228] bn3c_branch2a does not need backward computation.
I1022 15:54:58.444896 27427 net.cpp:228] res3c_branch2a does not need backward computation.
I1022 15:54:58.444900 27427 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I1022 15:54:58.444903 27427 net.cpp:228] res3b_relu does not need backward computation.
I1022 15:54:58.444906 27427 net.cpp:228] res3b does not need backward computation.
I1022 15:54:58.444910 27427 net.cpp:228] scale3b_branch2c does not need backward computation.
I1022 15:54:58.444912 27427 net.cpp:228] bn3b_branch2c does not need backward computation.
I1022 15:54:58.444916 27427 net.cpp:228] res3b_branch2c does not need backward computation.
I1022 15:54:58.444936 27427 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I1022 15:54:58.444938 27427 net.cpp:228] scale3b_branch2b does not need backward computation.
I1022 15:54:58.444941 27427 net.cpp:228] bn3b_branch2b does not need backward computation.
I1022 15:54:58.444943 27427 net.cpp:228] res3b_branch2b does not need backward computation.
I1022 15:54:58.444962 27427 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I1022 15:54:58.444963 27427 net.cpp:228] scale3b_branch2a does not need backward computation.
I1022 15:54:58.444967 27427 net.cpp:228] bn3b_branch2a does not need backward computation.
I1022 15:54:58.444969 27427 net.cpp:228] res3b_branch2a does not need backward computation.
I1022 15:54:58.444974 27427 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I1022 15:54:58.444977 27427 net.cpp:228] res3a_relu does not need backward computation.
I1022 15:54:58.444980 27427 net.cpp:228] res3a does not need backward computation.
I1022 15:54:58.444983 27427 net.cpp:228] scale3a_branch2c does not need backward computation.
I1022 15:54:58.444986 27427 net.cpp:228] bn3a_branch2c does not need backward computation.
I1022 15:54:58.444989 27427 net.cpp:228] res3a_branch2c does not need backward computation.
I1022 15:54:58.444991 27427 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I1022 15:54:58.444995 27427 net.cpp:228] scale3a_branch2b does not need backward computation.
I1022 15:54:58.444998 27427 net.cpp:228] bn3a_branch2b does not need backward computation.
I1022 15:54:58.445000 27427 net.cpp:228] res3a_branch2b does not need backward computation.
I1022 15:54:58.445003 27427 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I1022 15:54:58.445006 27427 net.cpp:228] scale3a_branch2a does not need backward computation.
I1022 15:54:58.445008 27427 net.cpp:228] bn3a_branch2a does not need backward computation.
I1022 15:54:58.445010 27427 net.cpp:228] res3a_branch2a does not need backward computation.
I1022 15:54:58.445014 27427 net.cpp:228] scale3a_branch1 does not need backward computation.
I1022 15:54:58.445017 27427 net.cpp:228] bn3a_branch1 does not need backward computation.
I1022 15:54:58.445020 27427 net.cpp:228] res3a_branch1 does not need backward computation.
I1022 15:54:58.445022 27427 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I1022 15:54:58.445025 27427 net.cpp:228] res2c_relu does not need backward computation.
I1022 15:54:58.445029 27427 net.cpp:228] res2c does not need backward computation.
I1022 15:54:58.445032 27427 net.cpp:228] scale2c_branch2c does not need backward computation.
I1022 15:54:58.445035 27427 net.cpp:228] bn2c_branch2c does not need backward computation.
I1022 15:54:58.445037 27427 net.cpp:228] res2c_branch2c does not need backward computation.
I1022 15:54:58.445040 27427 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I1022 15:54:58.445044 27427 net.cpp:228] scale2c_branch2b does not need backward computation.
I1022 15:54:58.445062 27427 net.cpp:228] bn2c_branch2b does not need backward computation.
I1022 15:54:58.445065 27427 net.cpp:228] res2c_branch2b does not need backward computation.
I1022 15:54:58.445068 27427 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I1022 15:54:58.445070 27427 net.cpp:228] scale2c_branch2a does not need backward computation.
I1022 15:54:58.445072 27427 net.cpp:228] bn2c_branch2a does not need backward computation.
I1022 15:54:58.445075 27427 net.cpp:228] res2c_branch2a does not need backward computation.
I1022 15:54:58.445078 27427 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I1022 15:54:58.445081 27427 net.cpp:228] res2b_relu does not need backward computation.
I1022 15:54:58.445083 27427 net.cpp:228] res2b does not need backward computation.
I1022 15:54:58.445087 27427 net.cpp:228] scale2b_branch2c does not need backward computation.
I1022 15:54:58.445091 27427 net.cpp:228] bn2b_branch2c does not need backward computation.
I1022 15:54:58.445092 27427 net.cpp:228] res2b_branch2c does not need backward computation.
I1022 15:54:58.445096 27427 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I1022 15:54:58.445098 27427 net.cpp:228] scale2b_branch2b does not need backward computation.
I1022 15:54:58.445101 27427 net.cpp:228] bn2b_branch2b does not need backward computation.
I1022 15:54:58.445104 27427 net.cpp:228] res2b_branch2b does not need backward computation.
I1022 15:54:58.445106 27427 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I1022 15:54:58.445109 27427 net.cpp:228] scale2b_branch2a does not need backward computation.
I1022 15:54:58.445112 27427 net.cpp:228] bn2b_branch2a does not need backward computation.
I1022 15:54:58.445114 27427 net.cpp:228] res2b_branch2a does not need backward computation.
I1022 15:54:58.445117 27427 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I1022 15:54:58.445120 27427 net.cpp:228] res2a_relu does not need backward computation.
I1022 15:54:58.445123 27427 net.cpp:228] res2a does not need backward computation.
I1022 15:54:58.445127 27427 net.cpp:228] scale2a_branch2c does not need backward computation.
I1022 15:54:58.445129 27427 net.cpp:228] bn2a_branch2c does not need backward computation.
I1022 15:54:58.445132 27427 net.cpp:228] res2a_branch2c does not need backward computation.
I1022 15:54:58.445135 27427 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I1022 15:54:58.445137 27427 net.cpp:228] scale2a_branch2b does not need backward computation.
I1022 15:54:58.445140 27427 net.cpp:228] bn2a_branch2b does not need backward computation.
I1022 15:54:58.445143 27427 net.cpp:228] res2a_branch2b does not need backward computation.
I1022 15:54:58.445145 27427 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I1022 15:54:58.445148 27427 net.cpp:228] scale2a_branch2a does not need backward computation.
I1022 15:54:58.445150 27427 net.cpp:228] bn2a_branch2a does not need backward computation.
I1022 15:54:58.445153 27427 net.cpp:228] res2a_branch2a does not need backward computation.
I1022 15:54:58.445156 27427 net.cpp:228] scale2a_branch1 does not need backward computation.
I1022 15:54:58.445159 27427 net.cpp:228] bn2a_branch1 does not need backward computation.
I1022 15:54:58.445161 27427 net.cpp:228] res2a_branch1 does not need backward computation.
I1022 15:54:58.445164 27427 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I1022 15:54:58.445168 27427 net.cpp:228] pool1 does not need backward computation.
I1022 15:54:58.445170 27427 net.cpp:228] conv1_relu does not need backward computation.
I1022 15:54:58.445173 27427 net.cpp:228] scale_conv1 does not need backward computation.
I1022 15:54:58.445176 27427 net.cpp:228] bn_conv1 does not need backward computation.
I1022 15:54:58.445178 27427 net.cpp:228] conv1 does not need backward computation.
I1022 15:54:58.445181 27427 net.cpp:228] input does not need backward computation.
I1022 15:54:58.445184 27427 net.cpp:270] This network produces output bbox_pred_p2
I1022 15:54:58.445188 27427 net.cpp:270] This network produces output bbox_pred_p3
I1022 15:54:58.445190 27427 net.cpp:270] This network produces output cls_prob_p2
I1022 15:54:58.445192 27427 net.cpp:270] This network produces output cls_prob_p3
I1022 15:54:58.445335 27427 net.cpp:283] Network initialization done.
I1022 15:54:58.535724 27427 net.cpp:771] Ignoring source layer input-data
I1022 15:54:58.535746 27427 net.cpp:771] Ignoring source layer data_input-data_0_split
I1022 15:54:58.535748 27427 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I1022 15:54:58.535751 27427 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I1022 15:54:58.535753 27427 net.cpp:774] Copying source layer conv1
I1022 15:54:58.535773 27427 net.cpp:774] Copying source layer bn_conv1
I1022 15:54:58.535784 27427 net.cpp:774] Copying source layer scale_conv1
I1022 15:54:58.535787 27427 net.cpp:774] Copying source layer conv1_relu
I1022 15:54:58.535789 27427 net.cpp:774] Copying source layer pool1
I1022 15:54:58.535792 27427 net.cpp:774] Copying source layer pool1_pool1_0_split
I1022 15:54:58.535794 27427 net.cpp:774] Copying source layer res2a_branch1
I1022 15:54:58.535817 27427 net.cpp:774] Copying source layer bn2a_branch1
I1022 15:54:58.535825 27427 net.cpp:774] Copying source layer scale2a_branch1
I1022 15:54:58.535830 27427 net.cpp:774] Copying source layer res2a_branch2a
I1022 15:54:58.535840 27427 net.cpp:774] Copying source layer bn2a_branch2a
I1022 15:54:58.535845 27427 net.cpp:774] Copying source layer scale2a_branch2a
I1022 15:54:58.535848 27427 net.cpp:774] Copying source layer res2a_branch2a_relu
I1022 15:54:58.535851 27427 net.cpp:774] Copying source layer res2a_branch2b
I1022 15:54:58.535892 27427 net.cpp:774] Copying source layer bn2a_branch2b
I1022 15:54:58.535898 27427 net.cpp:774] Copying source layer scale2a_branch2b
I1022 15:54:58.535902 27427 net.cpp:774] Copying source layer res2a_branch2b_relu
I1022 15:54:58.535907 27427 net.cpp:774] Copying source layer res2a_branch2c
I1022 15:54:58.535929 27427 net.cpp:774] Copying source layer bn2a_branch2c
I1022 15:54:58.535938 27427 net.cpp:774] Copying source layer scale2a_branch2c
I1022 15:54:58.535943 27427 net.cpp:774] Copying source layer res2a
I1022 15:54:58.535945 27427 net.cpp:774] Copying source layer res2a_relu
I1022 15:54:58.535948 27427 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I1022 15:54:58.535949 27427 net.cpp:774] Copying source layer res2b_branch2a
I1022 15:54:58.535974 27427 net.cpp:774] Copying source layer bn2b_branch2a
I1022 15:54:58.535979 27427 net.cpp:774] Copying source layer scale2b_branch2a
I1022 15:54:58.535984 27427 net.cpp:774] Copying source layer res2b_branch2a_relu
I1022 15:54:58.535985 27427 net.cpp:774] Copying source layer res2b_branch2b
I1022 15:54:58.536026 27427 net.cpp:774] Copying source layer bn2b_branch2b
I1022 15:54:58.536033 27427 net.cpp:774] Copying source layer scale2b_branch2b
I1022 15:54:58.536036 27427 net.cpp:774] Copying source layer res2b_branch2b_relu
I1022 15:54:58.536039 27427 net.cpp:774] Copying source layer res2b_branch2c
I1022 15:54:58.536062 27427 net.cpp:774] Copying source layer bn2b_branch2c
I1022 15:54:58.536068 27427 net.cpp:774] Copying source layer scale2b_branch2c
I1022 15:54:58.536072 27427 net.cpp:774] Copying source layer res2b
I1022 15:54:58.536075 27427 net.cpp:774] Copying source layer res2b_relu
I1022 15:54:58.536078 27427 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I1022 15:54:58.536080 27427 net.cpp:774] Copying source layer res2c_branch2a
I1022 15:54:58.536104 27427 net.cpp:774] Copying source layer bn2c_branch2a
I1022 15:54:58.536110 27427 net.cpp:774] Copying source layer scale2c_branch2a
I1022 15:54:58.536114 27427 net.cpp:774] Copying source layer res2c_branch2a_relu
I1022 15:54:58.536116 27427 net.cpp:774] Copying source layer res2c_branch2b
I1022 15:54:58.536155 27427 net.cpp:774] Copying source layer bn2c_branch2b
I1022 15:54:58.536162 27427 net.cpp:774] Copying source layer scale2c_branch2b
I1022 15:54:58.536166 27427 net.cpp:774] Copying source layer res2c_branch2b_relu
I1022 15:54:58.536168 27427 net.cpp:774] Copying source layer res2c_branch2c
I1022 15:54:58.536191 27427 net.cpp:774] Copying source layer bn2c_branch2c
I1022 15:54:58.536197 27427 net.cpp:774] Copying source layer scale2c_branch2c
I1022 15:54:58.536202 27427 net.cpp:774] Copying source layer res2c
I1022 15:54:58.536206 27427 net.cpp:774] Copying source layer res2c_relu
I1022 15:54:58.536207 27427 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I1022 15:54:58.536209 27427 net.cpp:774] Copying source layer res3a_branch1
I1022 15:54:58.536322 27427 net.cpp:774] Copying source layer bn3a_branch1
I1022 15:54:58.536330 27427 net.cpp:774] Copying source layer scale3a_branch1
I1022 15:54:58.536336 27427 net.cpp:774] Copying source layer res3a_branch2a
I1022 15:54:58.536376 27427 net.cpp:774] Copying source layer bn3a_branch2a
I1022 15:54:58.536384 27427 net.cpp:774] Copying source layer scale3a_branch2a
I1022 15:54:58.536388 27427 net.cpp:774] Copying source layer res3a_branch2a_relu
I1022 15:54:58.536391 27427 net.cpp:774] Copying source layer res3a_branch2b
I1022 15:54:58.536518 27427 net.cpp:774] Copying source layer bn3a_branch2b
I1022 15:54:58.536525 27427 net.cpp:774] Copying source layer scale3a_branch2b
I1022 15:54:58.536530 27427 net.cpp:774] Copying source layer res3a_branch2b_relu
I1022 15:54:58.536532 27427 net.cpp:774] Copying source layer res3a_branch2c
I1022 15:54:58.536597 27427 net.cpp:774] Copying source layer bn3a_branch2c
I1022 15:54:58.536605 27427 net.cpp:774] Copying source layer scale3a_branch2c
I1022 15:54:58.536634 27427 net.cpp:774] Copying source layer res3a
I1022 15:54:58.536638 27427 net.cpp:774] Copying source layer res3a_relu
I1022 15:54:58.536640 27427 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I1022 15:54:58.536659 27427 net.cpp:774] Copying source layer res3b_branch2a
I1022 15:54:58.536725 27427 net.cpp:774] Copying source layer bn3b_branch2a
I1022 15:54:58.536733 27427 net.cpp:774] Copying source layer scale3b_branch2a
I1022 15:54:58.536737 27427 net.cpp:774] Copying source layer res3b_branch2a_relu
I1022 15:54:58.536739 27427 net.cpp:774] Copying source layer res3b_branch2b
I1022 15:54:58.536873 27427 net.cpp:774] Copying source layer bn3b_branch2b
I1022 15:54:58.536880 27427 net.cpp:774] Copying source layer scale3b_branch2b
I1022 15:54:58.536885 27427 net.cpp:774] Copying source layer res3b_branch2b_relu
I1022 15:54:58.536887 27427 net.cpp:774] Copying source layer res3b_branch2c
I1022 15:54:58.536968 27427 net.cpp:774] Copying source layer bn3b_branch2c
I1022 15:54:58.536978 27427 net.cpp:774] Copying source layer scale3b_branch2c
I1022 15:54:58.536983 27427 net.cpp:774] Copying source layer res3b
I1022 15:54:58.536984 27427 net.cpp:774] Copying source layer res3b_relu
I1022 15:54:58.536988 27427 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I1022 15:54:58.536989 27427 net.cpp:774] Copying source layer res3c_branch2a
I1022 15:54:58.537051 27427 net.cpp:774] Copying source layer bn3c_branch2a
I1022 15:54:58.537058 27427 net.cpp:774] Copying source layer scale3c_branch2a
I1022 15:54:58.537062 27427 net.cpp:774] Copying source layer res3c_branch2a_relu
I1022 15:54:58.537065 27427 net.cpp:774] Copying source layer res3c_branch2b
I1022 15:54:58.537207 27427 net.cpp:774] Copying source layer bn3c_branch2b
I1022 15:54:58.537214 27427 net.cpp:774] Copying source layer scale3c_branch2b
I1022 15:54:58.537219 27427 net.cpp:774] Copying source layer res3c_branch2b_relu
I1022 15:54:58.537221 27427 net.cpp:774] Copying source layer res3c_branch2c
I1022 15:54:58.537286 27427 net.cpp:774] Copying source layer bn3c_branch2c
I1022 15:54:58.537294 27427 net.cpp:774] Copying source layer scale3c_branch2c
I1022 15:54:58.537299 27427 net.cpp:774] Copying source layer res3c
I1022 15:54:58.537302 27427 net.cpp:774] Copying source layer res3c_relu
I1022 15:54:58.537304 27427 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I1022 15:54:58.537307 27427 net.cpp:774] Copying source layer res3d_branch2a
I1022 15:54:58.537371 27427 net.cpp:774] Copying source layer bn3d_branch2a
I1022 15:54:58.537377 27427 net.cpp:774] Copying source layer scale3d_branch2a
I1022 15:54:58.537382 27427 net.cpp:774] Copying source layer res3d_branch2a_relu
I1022 15:54:58.537384 27427 net.cpp:774] Copying source layer res3d_branch2b
I1022 15:54:58.537511 27427 net.cpp:774] Copying source layer bn3d_branch2b
I1022 15:54:58.537518 27427 net.cpp:774] Copying source layer scale3d_branch2b
I1022 15:54:58.537523 27427 net.cpp:774] Copying source layer res3d_branch2b_relu
I1022 15:54:58.537525 27427 net.cpp:774] Copying source layer res3d_branch2c
I1022 15:54:58.537587 27427 net.cpp:774] Copying source layer bn3d_branch2c
I1022 15:54:58.537595 27427 net.cpp:774] Copying source layer scale3d_branch2c
I1022 15:54:58.537600 27427 net.cpp:774] Copying source layer res3d
I1022 15:54:58.537603 27427 net.cpp:774] Copying source layer res3d_relu
I1022 15:54:58.537607 27427 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I1022 15:54:58.537609 27427 net.cpp:774] Copying source layer res4a_branch1
I1022 15:54:58.538071 27427 net.cpp:774] Copying source layer bn4a_branch1
I1022 15:54:58.538080 27427 net.cpp:774] Copying source layer scale4a_branch1
I1022 15:54:58.538101 27427 net.cpp:774] Copying source layer res4a_branch2a
I1022 15:54:58.538218 27427 net.cpp:774] Copying source layer bn4a_branch2a
I1022 15:54:58.538225 27427 net.cpp:774] Copying source layer scale4a_branch2a
I1022 15:54:58.538229 27427 net.cpp:774] Copying source layer res4a_branch2a_relu
I1022 15:54:58.538233 27427 net.cpp:774] Copying source layer res4a_branch2b
I1022 15:54:58.538722 27427 net.cpp:774] Copying source layer bn4a_branch2b
I1022 15:54:58.538729 27427 net.cpp:774] Copying source layer scale4a_branch2b
I1022 15:54:58.538748 27427 net.cpp:774] Copying source layer res4a_branch2b_relu
I1022 15:54:58.538751 27427 net.cpp:774] Copying source layer res4a_branch2c
I1022 15:54:58.538977 27427 net.cpp:774] Copying source layer bn4a_branch2c
I1022 15:54:58.538986 27427 net.cpp:774] Copying source layer scale4a_branch2c
I1022 15:54:58.538991 27427 net.cpp:774] Copying source layer res4a
I1022 15:54:58.538995 27427 net.cpp:774] Copying source layer res4a_relu
I1022 15:54:58.538997 27427 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I1022 15:54:58.539000 27427 net.cpp:774] Copying source layer res4b_branch2a
I1022 15:54:58.539222 27427 net.cpp:774] Copying source layer bn4b_branch2a
I1022 15:54:58.539230 27427 net.cpp:774] Copying source layer scale4b_branch2a
I1022 15:54:58.539234 27427 net.cpp:774] Copying source layer res4b_branch2a_relu
I1022 15:54:58.539237 27427 net.cpp:774] Copying source layer res4b_branch2b
I1022 15:54:58.539721 27427 net.cpp:774] Copying source layer bn4b_branch2b
I1022 15:54:58.539728 27427 net.cpp:774] Copying source layer scale4b_branch2b
I1022 15:54:58.539747 27427 net.cpp:774] Copying source layer res4b_branch2b_relu
I1022 15:54:58.539749 27427 net.cpp:774] Copying source layer res4b_branch2c
I1022 15:54:58.539974 27427 net.cpp:774] Copying source layer bn4b_branch2c
I1022 15:54:58.539984 27427 net.cpp:774] Copying source layer scale4b_branch2c
I1022 15:54:58.539989 27427 net.cpp:774] Copying source layer res4b
I1022 15:54:58.539993 27427 net.cpp:774] Copying source layer res4b_relu
I1022 15:54:58.539994 27427 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I1022 15:54:58.539997 27427 net.cpp:774] Copying source layer res4c_branch2a
I1022 15:54:58.540215 27427 net.cpp:774] Copying source layer bn4c_branch2a
I1022 15:54:58.540222 27427 net.cpp:774] Copying source layer scale4c_branch2a
I1022 15:54:58.540227 27427 net.cpp:774] Copying source layer res4c_branch2a_relu
I1022 15:54:58.540230 27427 net.cpp:774] Copying source layer res4c_branch2b
I1022 15:54:58.540776 27427 net.cpp:774] Copying source layer bn4c_branch2b
I1022 15:54:58.540786 27427 net.cpp:774] Copying source layer scale4c_branch2b
I1022 15:54:58.540802 27427 net.cpp:774] Copying source layer res4c_branch2b_relu
I1022 15:54:58.540804 27427 net.cpp:774] Copying source layer res4c_branch2c
I1022 15:54:58.541044 27427 net.cpp:774] Copying source layer bn4c_branch2c
I1022 15:54:58.541054 27427 net.cpp:774] Copying source layer scale4c_branch2c
I1022 15:54:58.541060 27427 net.cpp:774] Copying source layer res4c
I1022 15:54:58.541064 27427 net.cpp:774] Copying source layer res4c_relu
I1022 15:54:58.541067 27427 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I1022 15:54:58.541070 27427 net.cpp:774] Copying source layer res4d_branch2a
I1022 15:54:58.541307 27427 net.cpp:774] Copying source layer bn4d_branch2a
I1022 15:54:58.541316 27427 net.cpp:774] Copying source layer scale4d_branch2a
I1022 15:54:58.541321 27427 net.cpp:774] Copying source layer res4d_branch2a_relu
I1022 15:54:58.541323 27427 net.cpp:774] Copying source layer res4d_branch2b
I1022 15:54:58.541812 27427 net.cpp:774] Copying source layer bn4d_branch2b
I1022 15:54:58.541821 27427 net.cpp:774] Copying source layer scale4d_branch2b
I1022 15:54:58.541837 27427 net.cpp:774] Copying source layer res4d_branch2b_relu
I1022 15:54:58.541841 27427 net.cpp:774] Copying source layer res4d_branch2c
I1022 15:54:58.542063 27427 net.cpp:774] Copying source layer bn4d_branch2c
I1022 15:54:58.542074 27427 net.cpp:774] Copying source layer scale4d_branch2c
I1022 15:54:58.542080 27427 net.cpp:774] Copying source layer res4d
I1022 15:54:58.542084 27427 net.cpp:774] Copying source layer res4d_relu
I1022 15:54:58.542086 27427 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I1022 15:54:58.542089 27427 net.cpp:774] Copying source layer res4e_branch2a
I1022 15:54:58.542309 27427 net.cpp:774] Copying source layer bn4e_branch2a
I1022 15:54:58.542317 27427 net.cpp:774] Copying source layer scale4e_branch2a
I1022 15:54:58.542321 27427 net.cpp:774] Copying source layer res4e_branch2a_relu
I1022 15:54:58.542325 27427 net.cpp:774] Copying source layer res4e_branch2b
I1022 15:54:58.542826 27427 net.cpp:774] Copying source layer bn4e_branch2b
I1022 15:54:58.542834 27427 net.cpp:774] Copying source layer scale4e_branch2b
I1022 15:54:58.542850 27427 net.cpp:774] Copying source layer res4e_branch2b_relu
I1022 15:54:58.542852 27427 net.cpp:774] Copying source layer res4e_branch2c
I1022 15:54:58.543077 27427 net.cpp:774] Copying source layer bn4e_branch2c
I1022 15:54:58.543087 27427 net.cpp:774] Copying source layer scale4e_branch2c
I1022 15:54:58.543095 27427 net.cpp:774] Copying source layer res4e
I1022 15:54:58.543099 27427 net.cpp:774] Copying source layer res4e_relu
I1022 15:54:58.543102 27427 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I1022 15:54:58.543104 27427 net.cpp:774] Copying source layer res4f_branch2a
I1022 15:54:58.543329 27427 net.cpp:774] Copying source layer bn4f_branch2a
I1022 15:54:58.543336 27427 net.cpp:774] Copying source layer scale4f_branch2a
I1022 15:54:58.543342 27427 net.cpp:774] Copying source layer res4f_branch2a_relu
I1022 15:54:58.543344 27427 net.cpp:774] Copying source layer res4f_branch2b
I1022 15:54:58.543848 27427 net.cpp:774] Copying source layer bn4f_branch2b
I1022 15:54:58.543867 27427 net.cpp:774] Copying source layer scale4f_branch2b
I1022 15:54:58.543872 27427 net.cpp:774] Copying source layer res4f_branch2b_relu
I1022 15:54:58.543875 27427 net.cpp:774] Copying source layer res4f_branch2c
I1022 15:54:58.544101 27427 net.cpp:774] Copying source layer bn4f_branch2c
I1022 15:54:58.544111 27427 net.cpp:774] Copying source layer scale4f_branch2c
I1022 15:54:58.544117 27427 net.cpp:774] Copying source layer res4f
I1022 15:54:58.544122 27427 net.cpp:774] Copying source layer res4f_relu
I1022 15:54:58.544126 27427 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I1022 15:54:58.544128 27427 net.cpp:774] Copying source layer res5a_branch1
I1022 15:54:58.546020 27427 net.cpp:774] Copying source layer bn5a_branch1
I1022 15:54:58.546049 27427 net.cpp:774] Copying source layer scale5a_branch1
I1022 15:54:58.546059 27427 net.cpp:774] Copying source layer res5a_branch2a
I1022 15:54:58.546514 27427 net.cpp:774] Copying source layer bn5a_branch2a
I1022 15:54:58.546540 27427 net.cpp:774] Copying source layer scale5a_branch2a
I1022 15:54:58.546546 27427 net.cpp:774] Copying source layer res5a_branch2a_relu
I1022 15:54:58.546548 27427 net.cpp:774] Copying source layer res5a_branch2b
I1022 15:54:58.548558 27427 net.cpp:774] Copying source layer bn5a_branch2b
I1022 15:54:58.548590 27427 net.cpp:774] Copying source layer scale5a_branch2b
I1022 15:54:58.548597 27427 net.cpp:774] Copying source layer res5a_branch2b_relu
I1022 15:54:58.548599 27427 net.cpp:774] Copying source layer res5a_branch2c
I1022 15:54:58.549578 27427 net.cpp:774] Copying source layer bn5a_branch2c
I1022 15:54:58.549612 27427 net.cpp:774] Copying source layer scale5a_branch2c
I1022 15:54:58.549621 27427 net.cpp:774] Copying source layer res5a
I1022 15:54:58.549623 27427 net.cpp:774] Copying source layer res5a_relu
I1022 15:54:58.549628 27427 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I1022 15:54:58.549630 27427 net.cpp:774] Copying source layer res5b_branch2a
I1022 15:54:58.550508 27427 net.cpp:774] Copying source layer bn5b_branch2a
I1022 15:54:58.550516 27427 net.cpp:774] Copying source layer scale5b_branch2a
I1022 15:54:58.550539 27427 net.cpp:774] Copying source layer res5b_branch2a_relu
I1022 15:54:58.550541 27427 net.cpp:774] Copying source layer res5b_branch2b
I1022 15:54:58.552484 27427 net.cpp:774] Copying source layer bn5b_branch2b
I1022 15:54:58.552515 27427 net.cpp:774] Copying source layer scale5b_branch2b
I1022 15:54:58.552522 27427 net.cpp:774] Copying source layer res5b_branch2b_relu
I1022 15:54:58.552525 27427 net.cpp:774] Copying source layer res5b_branch2c
I1022 15:54:58.553467 27427 net.cpp:774] Copying source layer bn5b_branch2c
I1022 15:54:58.553495 27427 net.cpp:774] Copying source layer scale5b_branch2c
I1022 15:54:58.553505 27427 net.cpp:774] Copying source layer res5b
I1022 15:54:58.553508 27427 net.cpp:774] Copying source layer res5b_relu
I1022 15:54:58.553512 27427 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I1022 15:54:58.553515 27427 net.cpp:774] Copying source layer res5c_branch2a
I1022 15:54:58.554373 27427 net.cpp:774] Copying source layer bn5c_branch2a
I1022 15:54:58.554381 27427 net.cpp:774] Copying source layer scale5c_branch2a
I1022 15:54:58.554402 27427 net.cpp:774] Copying source layer res5c_branch2a_relu
I1022 15:54:58.554405 27427 net.cpp:774] Copying source layer res5c_branch2b
I1022 15:54:58.556303 27427 net.cpp:774] Copying source layer bn5c_branch2b
I1022 15:54:58.556329 27427 net.cpp:774] Copying source layer scale5c_branch2b
I1022 15:54:58.556335 27427 net.cpp:774] Copying source layer res5c_branch2b_relu
I1022 15:54:58.556339 27427 net.cpp:774] Copying source layer res5c_branch2c
I1022 15:54:58.557317 27427 net.cpp:774] Copying source layer bn5c_branch2c
I1022 15:54:58.557348 27427 net.cpp:774] Copying source layer scale5c_branch2c
I1022 15:54:58.557356 27427 net.cpp:774] Copying source layer res5c
I1022 15:54:58.557360 27427 net.cpp:774] Copying source layer res5c_relu
I1022 15:54:58.557363 27427 net.cpp:774] Copying source layer upP4
I1022 15:54:58.557397 27427 net.cpp:774] Copying source layer newC4
I1022 15:54:58.557844 27427 net.cpp:774] Copying source layer eltwise_bnc4_bnp4
I1022 15:54:58.557849 27427 net.cpp:774] Copying source layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 15:54:58.557852 27427 net.cpp:774] Copying source layer bnp4_conv
I1022 15:54:58.557929 27427 net.cpp:774] Copying source layer bnp4_bn
I1022 15:54:58.557935 27427 net.cpp:774] Copying source layer bnp4_scale
I1022 15:54:58.557940 27427 net.cpp:774] Copying source layer bnp4_ReLU
I1022 15:54:58.557945 27427 net.cpp:774] Copying source layer bn_eltwise_1_1_conv
I1022 15:54:58.558073 27427 net.cpp:774] Copying source layer bn_eltwise_1_1_bn
I1022 15:54:58.558079 27427 net.cpp:774] Copying source layer bn_eltwise_1_1_scale
I1022 15:54:58.558084 27427 net.cpp:774] Copying source layer bn_eltwise_1_1_ReLU
I1022 15:54:58.558087 27427 net.cpp:774] Copying source layer bn_eltwise_1_2_conv
I1022 15:54:58.558151 27427 net.cpp:774] Copying source layer bn_eltwise_1_2_bn
I1022 15:54:58.558158 27427 net.cpp:774] Copying source layer bn_eltwise_1_2_scale
I1022 15:54:58.558163 27427 net.cpp:774] Copying source layer p3
I1022 15:54:58.558166 27427 net.cpp:774] Copying source layer p3_relu
I1022 15:54:58.558169 27427 net.cpp:774] Copying source layer p3_p3_relu_0_split
I1022 15:54:58.558172 27427 net.cpp:774] Copying source layer newC3
I1022 15:54:58.558389 27427 net.cpp:774] Copying source layer upP3
I1022 15:54:58.558405 27427 net.cpp:774] Copying source layer eltwise_bnc3_bnp3
I1022 15:54:58.558409 27427 net.cpp:774] Copying source layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 15:54:58.558413 27427 net.cpp:774] Copying source layer bnp3_conv
I1022 15:54:58.558475 27427 net.cpp:774] Copying source layer bnp3_bn
I1022 15:54:58.558482 27427 net.cpp:774] Copying source layer bnp3_scale
I1022 15:54:58.558486 27427 net.cpp:774] Copying source layer bnp3_ReLU
I1022 15:54:58.558490 27427 net.cpp:774] Copying source layer bn_eltwise_2_1_conv
I1022 15:54:58.558620 27427 net.cpp:774] Copying source layer bn_eltwise_2_1_bn
I1022 15:54:58.558629 27427 net.cpp:774] Copying source layer bn_eltwise_2_1_scale
I1022 15:54:58.558632 27427 net.cpp:774] Copying source layer bn_eltwise_2_1_ReLU
I1022 15:54:58.558635 27427 net.cpp:774] Copying source layer bn_eltwise_2_2_conv
I1022 15:54:58.558696 27427 net.cpp:774] Copying source layer bn_eltwise_2_2_bn
I1022 15:54:58.558703 27427 net.cpp:774] Copying source layer bn_eltwise_2_2_scale
I1022 15:54:58.558708 27427 net.cpp:774] Copying source layer p2
I1022 15:54:58.558712 27427 net.cpp:774] Copying source layer p2_relu
I1022 15:54:58.558713 27427 net.cpp:774] Copying source layer p2_p2_relu_0_split
I1022 15:54:58.558717 27427 net.cpp:774] Copying source layer rpn_conv/3x3_p2
I1022 15:54:58.560600 27427 net.cpp:774] Copying source layer rpn_relu/3x3_p2
I1022 15:54:58.560636 27427 net.cpp:774] Copying source layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 15:54:58.560642 27427 net.cpp:774] Copying source layer rpn_cls_score_p2
I1022 15:54:58.560669 27427 net.cpp:771] Ignoring source layer rpn_cls_score_p2_rpn_cls_score_p2_0_split
I1022 15:54:58.560673 27427 net.cpp:774] Copying source layer rpn_bbox_pred_p2
I1022 15:54:58.560698 27427 net.cpp:771] Ignoring source layer rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split
I1022 15:54:58.560704 27427 net.cpp:774] Copying source layer rpn_cls_score_reshape_p2
I1022 15:54:58.560708 27427 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split
I1022 15:54:58.560710 27427 net.cpp:774] Copying source layer rpn_cls_prob_p2
I1022 15:54:58.560712 27427 net.cpp:774] Copying source layer rpn_cls_prob_reshape_p2
I1022 15:54:58.560715 27427 net.cpp:774] Copying source layer rpn_conv/3x3_p3
I1022 15:54:58.562695 27427 net.cpp:774] Copying source layer rpn_relu/3x3_p3
I1022 15:54:58.562711 27427 net.cpp:774] Copying source layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 15:54:58.562728 27427 net.cpp:774] Copying source layer rpn_cls_score_p3
I1022 15:54:58.562748 27427 net.cpp:771] Ignoring source layer rpn_cls_score_p3_rpn_cls_score_p3_0_split
I1022 15:54:58.562752 27427 net.cpp:774] Copying source layer rpn_bbox_pred_p3
I1022 15:54:58.562778 27427 net.cpp:771] Ignoring source layer rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split
I1022 15:54:58.562785 27427 net.cpp:774] Copying source layer rpn_cls_score_reshape_p3
I1022 15:54:58.562788 27427 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split
I1022 15:54:58.562790 27427 net.cpp:774] Copying source layer rpn_cls_prob_p3
I1022 15:54:58.562793 27427 net.cpp:774] Copying source layer rpn_cls_prob_reshape_p3
I1022 15:54:58.562795 27427 net.cpp:771] Ignoring source layer rpn-data
I1022 15:54:58.562798 27427 net.cpp:771] Ignoring source layer rpn_loss_cls_p2
I1022 15:54:58.562803 27427 net.cpp:771] Ignoring source layer rpn_loss_bbox_p2
I1022 15:54:58.562805 27427 net.cpp:771] Ignoring source layer rpn_loss_cls_p3
I1022 15:54:58.562808 27427 net.cpp:771] Ignoring source layer rpn_loss_bbox_p3
I1022 15:54:58.562810 27427 net.cpp:774] Copying source layer proposal
I1022 15:54:58.562813 27427 net.cpp:771] Ignoring source layer roi-data
I1022 15:54:58.562816 27427 net.cpp:771] Ignoring source layer rois_p2_roi-data_0_split
I1022 15:54:58.562819 27427 net.cpp:771] Ignoring source layer rois_p3_roi-data_1_split
I1022 15:54:58.562821 27427 net.cpp:771] Ignoring source layer labels_p2_roi-data_2_split
I1022 15:54:58.562824 27427 net.cpp:771] Ignoring source layer labels_p3_roi-data_3_split
I1022 15:54:58.562825 27427 net.cpp:771] Ignoring source layer bbox_targets_p2_roi-data_4_split
I1022 15:54:58.562829 27427 net.cpp:771] Ignoring source layer bbox_targets_p3_roi-data_5_split
I1022 15:54:58.562830 27427 net.cpp:771] Ignoring source layer bbox_inside_weights_p2_roi-data_6_split
I1022 15:54:58.562834 27427 net.cpp:771] Ignoring source layer bbox_inside_weights_p3_roi-data_7_split
I1022 15:54:58.562836 27427 net.cpp:774] Copying source layer conv_new_p2
I1022 15:54:58.563302 27427 net.cpp:774] Copying source layer conv_new_p2_relu
I1022 15:54:58.563308 27427 net.cpp:774] Copying source layer conv_new_p2_conv_new_p2_relu_0_split
I1022 15:54:58.563310 27427 net.cpp:774] Copying source layer rfcn_cls_p2
I1022 15:54:58.563421 27427 net.cpp:774] Copying source layer rfcn_bbox_p2
I1022 15:54:58.563771 27427 net.cpp:774] Copying source layer psroipooled_cls_rois_p2
I1022 15:54:58.563776 27427 net.cpp:774] Copying source layer ave_cls_score_rois_p2
I1022 15:54:58.563778 27427 net.cpp:771] Ignoring source layer cls_score_p2_ave_cls_score_rois_p2_0_split
I1022 15:54:58.563791 27427 net.cpp:774] Copying source layer psroipooled_loc_rois_p2
I1022 15:54:58.563793 27427 net.cpp:774] Copying source layer ave_bbox_pred_rois_p2
I1022 15:54:58.563796 27427 net.cpp:771] Ignoring source layer bbox_pred_p2_ave_bbox_pred_rois_p2_0_split
I1022 15:54:58.563802 27427 net.cpp:771] Ignoring source layer per_roi_loss_cls_p2
I1022 15:54:58.563804 27427 net.cpp:771] Ignoring source layer per_roi_loss_bbox_p2
I1022 15:54:58.563807 27427 net.cpp:771] Ignoring source layer per_roi_loss_p2
I1022 15:54:58.563809 27427 net.cpp:771] Ignoring source layer annotator_detector_p2
I1022 15:54:58.563812 27427 net.cpp:771] Ignoring source layer labels_ohem_p2_annotator_detector_p2_0_split
I1022 15:54:58.563814 27427 net.cpp:774] Copying source layer conv_new_p3
I1022 15:54:58.564270 27427 net.cpp:774] Copying source layer conv_new_p3_relu
I1022 15:54:58.564275 27427 net.cpp:774] Copying source layer conv_new_p3_conv_new_p3_relu_0_split
I1022 15:54:58.564276 27427 net.cpp:774] Copying source layer rfcn_cls_p3
I1022 15:54:58.564381 27427 net.cpp:774] Copying source layer rfcn_bbox_p3
I1022 15:54:58.564761 27427 net.cpp:774] Copying source layer psroipooled_cls_rois_p3
I1022 15:54:58.564767 27427 net.cpp:774] Copying source layer ave_cls_score_rois_p3
I1022 15:54:58.564770 27427 net.cpp:771] Ignoring source layer cls_score_p3_ave_cls_score_rois_p3_0_split
I1022 15:54:58.564783 27427 net.cpp:774] Copying source layer psroipooled_loc_rois_p3
I1022 15:54:58.564785 27427 net.cpp:774] Copying source layer ave_bbox_pred_rois_p3
I1022 15:54:58.564788 27427 net.cpp:771] Ignoring source layer bbox_pred_p3_ave_bbox_pred_rois_p3_0_split
I1022 15:54:58.564791 27427 net.cpp:771] Ignoring source layer per_roi_loss_cls_p3
I1022 15:54:58.564795 27427 net.cpp:771] Ignoring source layer per_roi_loss_bbox_p3
I1022 15:54:58.564797 27427 net.cpp:771] Ignoring source layer per_roi_loss_p3
I1022 15:54:58.564805 27427 net.cpp:771] Ignoring source layer annotator_detector_p3
I1022 15:54:58.564807 27427 net.cpp:771] Ignoring source layer labels_ohem_p3_annotator_detector_p3_0_split
I1022 15:54:58.564810 27427 net.cpp:771] Ignoring source layer loss_p2
I1022 15:54:58.564812 27427 net.cpp:771] Ignoring source layer loss_p3
I1022 15:54:58.564815 27427 net.cpp:771] Ignoring source layer accuarcy_p2
I1022 15:54:58.564818 27427 net.cpp:771] Ignoring source layer accuarcy_p3
I1022 15:54:58.564821 27427 net.cpp:771] Ignoring source layer loss_bbox_p2
I1022 15:54:58.564823 27427 net.cpp:771] Ignoring source layer loss_bbox_p3
I1022 15:54:58.564826 27427 net.cpp:771] Ignoring source layer silence
im_detect: 1/4024 1.137s 0.000s
im_detect: 2/4024 0.683s 0.000s
im_detect: 3/4024 0.527s 0.000s
im_detect: 4/4024 0.449s 0.000s
im_detect: 5/4024 0.400s 0.000s
im_detect: 6/4024 0.371s 0.000s
im_detect: 7/4024 0.352s 0.001s
im_detect: 8/4024 0.336s 0.001s
im_detect: 9/4024 0.323s 0.000s
im_detect: 10/4024 0.313s 0.001s
im_detect: 11/4024 0.305s 0.001s
im_detect: 12/4024 0.298s 0.001s
im_detect: 13/4024 0.293s 0.001s
im_detect: 14/4024 0.287s 0.001s
im_detect: 15/4024 0.283s 0.001s
im_detect: 16/4024 0.281s 0.001s
im_detect: 17/4024 0.278s 0.001s
im_detect: 18/4024 0.276s 0.001s
im_detect: 19/4024 0.274s 0.001s
im_detect: 20/4024 0.272s 0.001s
im_detect: 21/4024 0.270s 0.001s
im_detect: 22/4024 0.268s 0.001s
im_detect: 23/4024 0.266s 0.001s
im_detect: 24/4024 0.264s 0.001s
im_detect: 25/4024 0.262s 0.001s
im_detect: 26/4024 0.261s 0.001s
im_detect: 27/4024 0.260s 0.001s
im_detect: 28/4024 0.259s 0.001s
im_detect: 29/4024 0.257s 0.001s
im_detect: 30/4024 0.255s 0.001s
im_detect: 31/4024 0.255s 0.001s
im_detect: 32/4024 0.254s 0.001s
im_detect: 33/4024 0.253s 0.001s
im_detect: 34/4024 0.253s 0.001s
im_detect: 35/4024 0.252s 0.001s
im_detect: 36/4024 0.252s 0.001s
im_detect: 37/4024 0.251s 0.001s
im_detect: 38/4024 0.250s 0.001s
im_detect: 39/4024 0.249s 0.001s
im_detect: 40/4024 0.248s 0.001s
im_detect: 41/4024 0.247s 0.001s
im_detect: 42/4024 0.246s 0.001s
im_detect: 43/4024 0.245s 0.001s
im_detect: 44/4024 0.245s 0.001s
im_detect: 45/4024 0.244s 0.001s
im_detect: 46/4024 0.244s 0.001s
im_detect: 47/4024 0.244s 0.001s
im_detect: 48/4024 0.244s 0.001s
im_detect: 49/4024 0.243s 0.001s
im_detect: 50/4024 0.243s 0.001s
im_detect: 51/4024 0.243s 0.001s
im_detect: 52/4024 0.242s 0.001s
im_detect: 53/4024 0.242s 0.001s
im_detect: 54/4024 0.241s 0.001s
im_detect: 55/4024 0.241s 0.001s
im_detect: 56/4024 0.241s 0.001s
im_detect: 57/4024 0.241s 0.001s
im_detect: 58/4024 0.240s 0.001s
im_detect: 59/4024 0.240s 0.001s
im_detect: 60/4024 0.240s 0.001s
im_detect: 61/4024 0.240s 0.001s
im_detect: 62/4024 0.239s 0.001s
im_detect: 63/4024 0.239s 0.001s
im_detect: 64/4024 0.239s 0.001s
im_detect: 65/4024 0.239s 0.001s
im_detect: 66/4024 0.238s 0.001s
im_detect: 67/4024 0.238s 0.001s
im_detect: 68/4024 0.238s 0.001s
im_detect: 69/4024 0.238s 0.001s
im_detect: 70/4024 0.238s 0.001s
im_detect: 71/4024 0.238s 0.001s
im_detect: 72/4024 0.238s 0.001s
im_detect: 73/4024 0.237s 0.001s
im_detect: 74/4024 0.237s 0.001s
im_detect: 75/4024 0.237s 0.001s
im_detect: 76/4024 0.237s 0.001s
im_detect: 77/4024 0.237s 0.001s
im_detect: 78/4024 0.237s 0.001s
im_detect: 79/4024 0.237s 0.001s
im_detect: 80/4024 0.236s 0.001s
im_detect: 81/4024 0.236s 0.001s
im_detect: 82/4024 0.236s 0.001s
im_detect: 83/4024 0.236s 0.001s
im_detect: 84/4024 0.236s 0.001s
im_detect: 85/4024 0.236s 0.001s
im_detect: 86/4024 0.236s 0.001s
im_detect: 87/4024 0.236s 0.001s
im_detect: 88/4024 0.235s 0.001s
im_detect: 89/4024 0.235s 0.001s
im_detect: 90/4024 0.235s 0.001s
im_detect: 91/4024 0.235s 0.001s
im_detect: 92/4024 0.235s 0.001s
im_detect: 93/4024 0.235s 0.001s
im_detect: 94/4024 0.234s 0.001s
im_detect: 95/4024 0.234s 0.001s
im_detect: 96/4024 0.234s 0.001s
im_detect: 97/4024 0.234s 0.001s
im_detect: 98/4024 0.234s 0.001s
im_detect: 99/4024 0.234s 0.001s
im_detect: 100/4024 0.234s 0.001s
im_detect: 101/4024 0.234s 0.001s
im_detect: 102/4024 0.234s 0.001s
im_detect: 103/4024 0.234s 0.001s
im_detect: 104/4024 0.234s 0.001s
im_detect: 105/4024 0.234s 0.001s
im_detect: 106/4024 0.234s 0.001s
im_detect: 107/4024 0.233s 0.001s
im_detect: 108/4024 0.233s 0.001s
im_detect: 109/4024 0.233s 0.001s
im_detect: 110/4024 0.233s 0.001s
im_detect: 111/4024 0.234s 0.001s
im_detect: 112/4024 0.233s 0.001s
im_detect: 113/4024 0.233s 0.001s
im_detect: 114/4024 0.233s 0.001s
im_detect: 115/4024 0.233s 0.001s
im_detect: 116/4024 0.233s 0.001s
im_detect: 117/4024 0.232s 0.001s
im_detect: 118/4024 0.232s 0.001s
im_detect: 119/4024 0.232s 0.001s
im_detect: 120/4024 0.232s 0.001s
im_detect: 121/4024 0.232s 0.001s
im_detect: 122/4024 0.232s 0.001s
im_detect: 123/4024 0.232s 0.001s
im_detect: 124/4024 0.232s 0.001s
im_detect: 125/4024 0.232s 0.001s
im_detect: 126/4024 0.232s 0.001s
im_detect: 127/4024 0.231s 0.001s
im_detect: 128/4024 0.231s 0.001s
im_detect: 129/4024 0.231s 0.001s
im_detect: 130/4024 0.231s 0.001s
im_detect: 131/4024 0.231s 0.001s
im_detect: 132/4024 0.231s 0.001s
im_detect: 133/4024 0.231s 0.001s
im_detect: 134/4024 0.231s 0.001s
im_detect: 135/4024 0.231s 0.001s
im_detect: 136/4024 0.231s 0.001s
im_detect: 137/4024 0.231s 0.001s
im_detect: 138/4024 0.231s 0.001s
im_detect: 139/4024 0.231s 0.001s
im_detect: 140/4024 0.231s 0.001s
im_detect: 141/4024 0.231s 0.001s
im_detect: 142/4024 0.231s 0.001s
im_detect: 143/4024 0.231s 0.001s
im_detect: 144/4024 0.231s 0.001s
im_detect: 145/4024 0.231s 0.001s
im_detect: 146/4024 0.231s 0.001s
im_detect: 147/4024 0.230s 0.001s
im_detect: 148/4024 0.230s 0.001s
im_detect: 149/4024 0.230s 0.001s
im_detect: 150/4024 0.230s 0.001s
im_detect: 151/4024 0.230s 0.001s
im_detect: 152/4024 0.231s 0.001s
im_detect: 153/4024 0.230s 0.001s
im_detect: 154/4024 0.231s 0.001s
im_detect: 155/4024 0.230s 0.001s
im_detect: 156/4024 0.231s 0.001s
im_detect: 157/4024 0.231s 0.001s
im_detect: 158/4024 0.231s 0.001s
im_detect: 159/4024 0.231s 0.001s
im_detect: 160/4024 0.231s 0.001s
im_detect: 161/4024 0.231s 0.001s
im_detect: 162/4024 0.231s 0.001s
im_detect: 163/4024 0.231s 0.001s
im_detect: 164/4024 0.231s 0.001s
im_detect: 165/4024 0.231s 0.001s
im_detect: 166/4024 0.230s 0.001s
im_detect: 167/4024 0.231s 0.001s
im_detect: 168/4024 0.230s 0.001s
im_detect: 169/4024 0.230s 0.001s
im_detect: 170/4024 0.230s 0.001s
im_detect: 171/4024 0.230s 0.001s
im_detect: 172/4024 0.230s 0.001s
im_detect: 173/4024 0.230s 0.001s
im_detect: 174/4024 0.230s 0.001s
im_detect: 175/4024 0.230s 0.001s
im_detect: 176/4024 0.230s 0.001s
im_detect: 177/4024 0.230s 0.001s
im_detect: 178/4024 0.230s 0.001s
im_detect: 179/4024 0.230s 0.001s
im_detect: 180/4024 0.230s 0.001s
im_detect: 181/4024 0.230s 0.001s
im_detect: 182/4024 0.230s 0.001s
im_detect: 183/4024 0.230s 0.001s
im_detect: 184/4024 0.230s 0.001s
im_detect: 185/4024 0.230s 0.001s
im_detect: 186/4024 0.230s 0.001s
im_detect: 187/4024 0.230s 0.001s
im_detect: 188/4024 0.230s 0.001s
im_detect: 189/4024 0.230s 0.001s
im_detect: 190/4024 0.230s 0.001s
im_detect: 191/4024 0.230s 0.001s
im_detect: 192/4024 0.230s 0.001s
im_detect: 193/4024 0.230s 0.001s
im_detect: 194/4024 0.230s 0.001s
im_detect: 195/4024 0.230s 0.001s
im_detect: 196/4024 0.230s 0.001s
im_detect: 197/4024 0.230s 0.001s
im_detect: 198/4024 0.230s 0.001s
im_detect: 199/4024 0.230s 0.001s
im_detect: 200/4024 0.230s 0.001s
im_detect: 201/4024 0.230s 0.001s
im_detect: 202/4024 0.230s 0.001s
im_detect: 203/4024 0.230s 0.001s
im_detect: 204/4024 0.230s 0.001s
im_detect: 205/4024 0.230s 0.001s
im_detect: 206/4024 0.230s 0.001s
im_detect: 207/4024 0.230s 0.001s
im_detect: 208/4024 0.230s 0.001s
im_detect: 209/4024 0.230s 0.001s
im_detect: 210/4024 0.230s 0.001s
im_detect: 211/4024 0.230s 0.001s
im_detect: 212/4024 0.230s 0.001s
im_detect: 213/4024 0.230s 0.001s
im_detect: 214/4024 0.230s 0.001s
im_detect: 215/4024 0.230s 0.001s
im_detect: 216/4024 0.230s 0.001s
im_detect: 217/4024 0.230s 0.001s
im_detect: 218/4024 0.230s 0.001s
im_detect: 219/4024 0.230s 0.001s
im_detect: 220/4024 0.230s 0.001s
im_detect: 221/4024 0.230s 0.001s
im_detect: 222/4024 0.230s 0.001s
im_detect: 223/4024 0.230s 0.001s
im_detect: 224/4024 0.230s 0.001s
im_detect: 225/4024 0.229s 0.001s
im_detect: 226/4024 0.229s 0.001s
im_detect: 227/4024 0.230s 0.001s
im_detect: 228/4024 0.230s 0.001s
im_detect: 229/4024 0.230s 0.001s
im_detect: 230/4024 0.230s 0.001s
im_detect: 231/4024 0.229s 0.001s
im_detect: 232/4024 0.230s 0.001s
im_detect: 233/4024 0.230s 0.001s
im_detect: 234/4024 0.230s 0.001s
im_detect: 235/4024 0.230s 0.001s
im_detect: 236/4024 0.230s 0.001s
im_detect: 237/4024 0.230s 0.001s
im_detect: 238/4024 0.230s 0.001s
im_detect: 239/4024 0.230s 0.001s
im_detect: 240/4024 0.230s 0.001s
im_detect: 241/4024 0.230s 0.001s
im_detect: 242/4024 0.230s 0.001s
im_detect: 243/4024 0.229s 0.001s
im_detect: 244/4024 0.229s 0.001s
im_detect: 245/4024 0.229s 0.001s
im_detect: 246/4024 0.229s 0.001s
im_detect: 247/4024 0.229s 0.001s
im_detect: 248/4024 0.229s 0.001s
im_detect: 249/4024 0.229s 0.001s
im_detect: 250/4024 0.229s 0.001s
im_detect: 251/4024 0.229s 0.001s
im_detect: 252/4024 0.229s 0.001s
im_detect: 253/4024 0.229s 0.001s
im_detect: 254/4024 0.229s 0.001s
im_detect: 255/4024 0.229s 0.001s
im_detect: 256/4024 0.229s 0.001s
im_detect: 257/4024 0.229s 0.001s
im_detect: 258/4024 0.229s 0.001s
im_detect: 259/4024 0.229s 0.001s
im_detect: 260/4024 0.229s 0.001s
im_detect: 261/4024 0.229s 0.001s
im_detect: 262/4024 0.229s 0.001s
im_detect: 263/4024 0.229s 0.001s
im_detect: 264/4024 0.229s 0.001s
im_detect: 265/4024 0.229s 0.001s
im_detect: 266/4024 0.229s 0.001s
im_detect: 267/4024 0.229s 0.001s
im_detect: 268/4024 0.229s 0.001s
im_detect: 269/4024 0.229s 0.001s
im_detect: 270/4024 0.229s 0.001s
im_detect: 271/4024 0.229s 0.001s
im_detect: 272/4024 0.229s 0.001s
im_detect: 273/4024 0.229s 0.001s
im_detect: 274/4024 0.229s 0.001s
im_detect: 275/4024 0.229s 0.001s
im_detect: 276/4024 0.229s 0.001s
im_detect: 277/4024 0.229s 0.001s
im_detect: 278/4024 0.229s 0.001s
im_detect: 279/4024 0.229s 0.001s
im_detect: 280/4024 0.229s 0.001s
im_detect: 281/4024 0.229s 0.001s
im_detect: 282/4024 0.229s 0.001s
im_detect: 283/4024 0.229s 0.001s
im_detect: 284/4024 0.229s 0.001s
im_detect: 285/4024 0.229s 0.001s
im_detect: 286/4024 0.229s 0.001s
im_detect: 287/4024 0.229s 0.001s
im_detect: 288/4024 0.229s 0.001s
im_detect: 289/4024 0.229s 0.001s
im_detect: 290/4024 0.229s 0.001s
im_detect: 291/4024 0.229s 0.001s
im_detect: 292/4024 0.229s 0.001s
im_detect: 293/4024 0.229s 0.001s
im_detect: 294/4024 0.229s 0.001s
im_detect: 295/4024 0.229s 0.001s
im_detect: 296/4024 0.229s 0.001s
im_detect: 297/4024 0.229s 0.001s
im_detect: 298/4024 0.229s 0.001s
im_detect: 299/4024 0.229s 0.001s
im_detect: 300/4024 0.229s 0.001s
im_detect: 301/4024 0.229s 0.001s
im_detect: 302/4024 0.229s 0.001s
im_detect: 303/4024 0.229s 0.001s
im_detect: 304/4024 0.229s 0.001s
im_detect: 305/4024 0.229s 0.001s
im_detect: 306/4024 0.229s 0.001s
im_detect: 307/4024 0.229s 0.001s
im_detect: 308/4024 0.229s 0.001s
im_detect: 309/4024 0.229s 0.001s
im_detect: 310/4024 0.229s 0.001s
im_detect: 311/4024 0.229s 0.001s
im_detect: 312/4024 0.229s 0.001s
im_detect: 313/4024 0.229s 0.001s
im_detect: 314/4024 0.229s 0.001s
im_detect: 315/4024 0.229s 0.001s
im_detect: 316/4024 0.229s 0.001s
im_detect: 317/4024 0.229s 0.001s
im_detect: 318/4024 0.229s 0.001s
im_detect: 319/4024 0.229s 0.001s
im_detect: 320/4024 0.229s 0.001s
im_detect: 321/4024 0.229s 0.001s
im_detect: 322/4024 0.229s 0.001s
im_detect: 323/4024 0.229s 0.001s
im_detect: 324/4024 0.229s 0.001s
im_detect: 325/4024 0.229s 0.001s
im_detect: 326/4024 0.229s 0.001s
im_detect: 327/4024 0.229s 0.001s
im_detect: 328/4024 0.229s 0.001s
im_detect: 329/4024 0.229s 0.001s
im_detect: 330/4024 0.229s 0.001s
im_detect: 331/4024 0.229s 0.001s
im_detect: 332/4024 0.229s 0.001s
im_detect: 333/4024 0.229s 0.001s
im_detect: 334/4024 0.229s 0.001s
im_detect: 335/4024 0.229s 0.001s
im_detect: 336/4024 0.229s 0.001s
im_detect: 337/4024 0.229s 0.001s
im_detect: 338/4024 0.229s 0.001s
im_detect: 339/4024 0.229s 0.001s
im_detect: 340/4024 0.229s 0.001s
im_detect: 341/4024 0.229s 0.001s
im_detect: 342/4024 0.229s 0.001s
im_detect: 343/4024 0.229s 0.001s
im_detect: 344/4024 0.229s 0.001s
im_detect: 345/4024 0.229s 0.001s
im_detect: 346/4024 0.229s 0.001s
im_detect: 347/4024 0.229s 0.001s
im_detect: 348/4024 0.229s 0.001s
im_detect: 349/4024 0.229s 0.001s
im_detect: 350/4024 0.229s 0.001s
im_detect: 351/4024 0.229s 0.001s
im_detect: 352/4024 0.229s 0.001s
im_detect: 353/4024 0.229s 0.001s
im_detect: 354/4024 0.229s 0.001s
im_detect: 355/4024 0.229s 0.001s
im_detect: 356/4024 0.228s 0.001s
im_detect: 357/4024 0.228s 0.001s
im_detect: 358/4024 0.228s 0.001s
im_detect: 359/4024 0.228s 0.001s
im_detect: 360/4024 0.229s 0.001s
im_detect: 361/4024 0.229s 0.001s
im_detect: 362/4024 0.228s 0.001s
im_detect: 363/4024 0.228s 0.001s
im_detect: 364/4024 0.228s 0.001s
im_detect: 365/4024 0.229s 0.001s
im_detect: 366/4024 0.229s 0.001s
im_detect: 367/4024 0.228s 0.001s
im_detect: 368/4024 0.228s 0.001s
im_detect: 369/4024 0.229s 0.001s
im_detect: 370/4024 0.229s 0.001s
im_detect: 371/4024 0.228s 0.001s
im_detect: 372/4024 0.228s 0.001s
im_detect: 373/4024 0.228s 0.001s
im_detect: 374/4024 0.228s 0.001s
im_detect: 375/4024 0.228s 0.001s
im_detect: 376/4024 0.228s 0.001s
im_detect: 377/4024 0.228s 0.001s
im_detect: 378/4024 0.228s 0.001s
im_detect: 379/4024 0.228s 0.001s
im_detect: 380/4024 0.228s 0.001s
im_detect: 381/4024 0.228s 0.001s
im_detect: 382/4024 0.228s 0.001s
im_detect: 383/4024 0.228s 0.001s
im_detect: 384/4024 0.228s 0.001s
im_detect: 385/4024 0.228s 0.001s
im_detect: 386/4024 0.228s 0.001s
im_detect: 387/4024 0.228s 0.001s
im_detect: 388/4024 0.228s 0.001s
im_detect: 389/4024 0.228s 0.001s
im_detect: 390/4024 0.228s 0.001s
im_detect: 391/4024 0.228s 0.001s
im_detect: 392/4024 0.228s 0.001s
im_detect: 393/4024 0.228s 0.001s
im_detect: 394/4024 0.228s 0.001s
im_detect: 395/4024 0.228s 0.001s
im_detect: 396/4024 0.228s 0.001s
im_detect: 397/4024 0.228s 0.001s
im_detect: 398/4024 0.228s 0.001s
im_detect: 399/4024 0.228s 0.001s
im_detect: 400/4024 0.228s 0.001s
im_detect: 401/4024 0.228s 0.001s
im_detect: 402/4024 0.228s 0.001s
im_detect: 403/4024 0.228s 0.001s
im_detect: 404/4024 0.228s 0.001s
im_detect: 405/4024 0.228s 0.001s
im_detect: 406/4024 0.228s 0.001s
im_detect: 407/4024 0.227s 0.001s
im_detect: 408/4024 0.227s 0.001s
im_detect: 409/4024 0.227s 0.001s
im_detect: 410/4024 0.227s 0.001s
im_detect: 411/4024 0.227s 0.001s
im_detect: 412/4024 0.227s 0.001s
im_detect: 413/4024 0.227s 0.001s
im_detect: 414/4024 0.227s 0.001s
im_detect: 415/4024 0.227s 0.001s
im_detect: 416/4024 0.227s 0.001s
im_detect: 417/4024 0.227s 0.001s
im_detect: 418/4024 0.227s 0.001s
im_detect: 419/4024 0.227s 0.001s
im_detect: 420/4024 0.227s 0.001s
im_detect: 421/4024 0.227s 0.001s
im_detect: 422/4024 0.227s 0.001s
im_detect: 423/4024 0.227s 0.001s
im_detect: 424/4024 0.227s 0.001s
im_detect: 425/4024 0.227s 0.001s
im_detect: 426/4024 0.227s 0.001s
im_detect: 427/4024 0.227s 0.001s
im_detect: 428/4024 0.227s 0.001s
im_detect: 429/4024 0.227s 0.001s
im_detect: 430/4024 0.227s 0.001s
im_detect: 431/4024 0.227s 0.001s
im_detect: 432/4024 0.227s 0.001s
im_detect: 433/4024 0.227s 0.001s
im_detect: 434/4024 0.227s 0.001s
im_detect: 435/4024 0.227s 0.001s
im_detect: 436/4024 0.227s 0.001s
im_detect: 437/4024 0.227s 0.001s
im_detect: 438/4024 0.227s 0.001s
im_detect: 439/4024 0.227s 0.001s
im_detect: 440/4024 0.227s 0.001s
im_detect: 441/4024 0.227s 0.001s
im_detect: 442/4024 0.227s 0.001s
im_detect: 443/4024 0.227s 0.001s
im_detect: 444/4024 0.227s 0.001s
im_detect: 445/4024 0.227s 0.001s
im_detect: 446/4024 0.227s 0.001s
im_detect: 447/4024 0.227s 0.001s
im_detect: 448/4024 0.227s 0.001s
im_detect: 449/4024 0.227s 0.001s
im_detect: 450/4024 0.227s 0.001s
im_detect: 451/4024 0.227s 0.001s
im_detect: 452/4024 0.227s 0.001s
im_detect: 453/4024 0.227s 0.001s
im_detect: 454/4024 0.227s 0.001s
im_detect: 455/4024 0.227s 0.001s
im_detect: 456/4024 0.227s 0.001s
im_detect: 457/4024 0.227s 0.001s
im_detect: 458/4024 0.227s 0.001s
im_detect: 459/4024 0.227s 0.001s
im_detect: 460/4024 0.227s 0.001s
im_detect: 461/4024 0.227s 0.001s
im_detect: 462/4024 0.227s 0.001s
im_detect: 463/4024 0.227s 0.001s
im_detect: 464/4024 0.227s 0.001s
im_detect: 465/4024 0.227s 0.001s
im_detect: 466/4024 0.227s 0.001s
im_detect: 467/4024 0.227s 0.001s
im_detect: 468/4024 0.227s 0.001s
im_detect: 469/4024 0.227s 0.001s
im_detect: 470/4024 0.227s 0.001s
im_detect: 471/4024 0.227s 0.001s
im_detect: 472/4024 0.227s 0.001s
im_detect: 473/4024 0.227s 0.001s
im_detect: 474/4024 0.227s 0.001s
im_detect: 475/4024 0.227s 0.001s
im_detect: 476/4024 0.227s 0.001s
im_detect: 477/4024 0.227s 0.001s
im_detect: 478/4024 0.227s 0.001s
im_detect: 479/4024 0.227s 0.001s
im_detect: 480/4024 0.227s 0.001s
im_detect: 481/4024 0.227s 0.001s
im_detect: 482/4024 0.227s 0.001s
im_detect: 483/4024 0.227s 0.001s
im_detect: 484/4024 0.227s 0.001s
im_detect: 485/4024 0.227s 0.001s
im_detect: 486/4024 0.227s 0.001s
im_detect: 487/4024 0.227s 0.001s
im_detect: 488/4024 0.227s 0.001s
im_detect: 489/4024 0.227s 0.001s
im_detect: 490/4024 0.227s 0.001s
im_detect: 491/4024 0.227s 0.001s
im_detect: 492/4024 0.227s 0.001s
im_detect: 493/4024 0.227s 0.001s
im_detect: 494/4024 0.227s 0.001s
im_detect: 495/4024 0.227s 0.001s
im_detect: 496/4024 0.227s 0.001s
im_detect: 497/4024 0.227s 0.001s
im_detect: 498/4024 0.227s 0.001s
im_detect: 499/4024 0.227s 0.001s
im_detect: 500/4024 0.227s 0.001s
im_detect: 501/4024 0.227s 0.001s
im_detect: 502/4024 0.227s 0.001s
im_detect: 503/4024 0.227s 0.001s
im_detect: 504/4024 0.227s 0.001s
im_detect: 505/4024 0.227s 0.001s
im_detect: 506/4024 0.227s 0.001s
im_detect: 507/4024 0.227s 0.001s
im_detect: 508/4024 0.227s 0.001s
im_detect: 509/4024 0.227s 0.001s
im_detect: 510/4024 0.227s 0.001s
im_detect: 511/4024 0.227s 0.001s
im_detect: 512/4024 0.227s 0.001s
im_detect: 513/4024 0.227s 0.001s
im_detect: 514/4024 0.227s 0.001s
im_detect: 515/4024 0.227s 0.001s
im_detect: 516/4024 0.227s 0.001s
im_detect: 517/4024 0.227s 0.001s
im_detect: 518/4024 0.227s 0.001s
im_detect: 519/4024 0.227s 0.001s
im_detect: 520/4024 0.227s 0.001s
im_detect: 521/4024 0.227s 0.001s
im_detect: 522/4024 0.227s 0.001s
im_detect: 523/4024 0.227s 0.001s
im_detect: 524/4024 0.227s 0.001s
im_detect: 525/4024 0.227s 0.001s
im_detect: 526/4024 0.227s 0.001s
im_detect: 527/4024 0.227s 0.001s
im_detect: 528/4024 0.227s 0.001s
im_detect: 529/4024 0.227s 0.001s
im_detect: 530/4024 0.227s 0.001s
im_detect: 531/4024 0.228s 0.001s
im_detect: 532/4024 0.228s 0.001s
im_detect: 533/4024 0.228s 0.001s
im_detect: 534/4024 0.228s 0.001s
im_detect: 535/4024 0.228s 0.001s
im_detect: 536/4024 0.227s 0.001s
im_detect: 537/4024 0.228s 0.001s
im_detect: 538/4024 0.228s 0.001s
im_detect: 539/4024 0.228s 0.001s
im_detect: 540/4024 0.228s 0.001s
im_detect: 541/4024 0.228s 0.001s
im_detect: 542/4024 0.228s 0.001s
im_detect: 543/4024 0.228s 0.001s
im_detect: 544/4024 0.228s 0.001s
im_detect: 545/4024 0.228s 0.001s
im_detect: 546/4024 0.228s 0.001s
im_detect: 547/4024 0.228s 0.001s
im_detect: 548/4024 0.228s 0.001s
im_detect: 549/4024 0.227s 0.001s
im_detect: 550/4024 0.227s 0.001s
im_detect: 551/4024 0.227s 0.001s
im_detect: 552/4024 0.228s 0.001s
im_detect: 553/4024 0.227s 0.001s
im_detect: 554/4024 0.228s 0.001s
im_detect: 555/4024 0.228s 0.001s
im_detect: 556/4024 0.228s 0.001s
im_detect: 557/4024 0.228s 0.001s
im_detect: 558/4024 0.228s 0.001s
im_detect: 559/4024 0.228s 0.001s
im_detect: 560/4024 0.228s 0.001s
im_detect: 561/4024 0.228s 0.001s
im_detect: 562/4024 0.228s 0.001s
im_detect: 563/4024 0.228s 0.001s
im_detect: 564/4024 0.228s 0.001s
im_detect: 565/4024 0.227s 0.001s
im_detect: 566/4024 0.227s 0.001s
im_detect: 567/4024 0.227s 0.001s
im_detect: 568/4024 0.227s 0.001s
im_detect: 569/4024 0.228s 0.001s
im_detect: 570/4024 0.227s 0.001s
im_detect: 571/4024 0.227s 0.001s
im_detect: 572/4024 0.227s 0.001s
im_detect: 573/4024 0.227s 0.001s
im_detect: 574/4024 0.227s 0.001s
im_detect: 575/4024 0.227s 0.001s
im_detect: 576/4024 0.227s 0.001s
im_detect: 577/4024 0.227s 0.001s
im_detect: 578/4024 0.227s 0.001s
im_detect: 579/4024 0.227s 0.001s
im_detect: 580/4024 0.227s 0.001s
im_detect: 581/4024 0.227s 0.001s
im_detect: 582/4024 0.227s 0.001s
im_detect: 583/4024 0.227s 0.001s
im_detect: 584/4024 0.227s 0.001s
im_detect: 585/4024 0.227s 0.001s
im_detect: 586/4024 0.227s 0.001s
im_detect: 587/4024 0.227s 0.001s
im_detect: 588/4024 0.227s 0.001s
im_detect: 589/4024 0.227s 0.001s
im_detect: 590/4024 0.227s 0.001s
im_detect: 591/4024 0.227s 0.001s
im_detect: 592/4024 0.227s 0.001s
im_detect: 593/4024 0.227s 0.001s
im_detect: 594/4024 0.227s 0.001s
im_detect: 595/4024 0.227s 0.001s
im_detect: 596/4024 0.227s 0.001s
im_detect: 597/4024 0.227s 0.001s
im_detect: 598/4024 0.227s 0.001s
im_detect: 599/4024 0.227s 0.001s
im_detect: 600/4024 0.227s 0.001s
im_detect: 601/4024 0.227s 0.001s
im_detect: 602/4024 0.227s 0.001s
im_detect: 603/4024 0.227s 0.001s
im_detect: 604/4024 0.227s 0.001s
im_detect: 605/4024 0.227s 0.001s
im_detect: 606/4024 0.227s 0.001s
im_detect: 607/4024 0.227s 0.001s
im_detect: 608/4024 0.227s 0.001s
im_detect: 609/4024 0.227s 0.001s
im_detect: 610/4024 0.227s 0.001s
im_detect: 611/4024 0.227s 0.001s
im_detect: 612/4024 0.227s 0.001s
im_detect: 613/4024 0.227s 0.001s
im_detect: 614/4024 0.227s 0.001s
im_detect: 615/4024 0.227s 0.001s
im_detect: 616/4024 0.227s 0.001s
im_detect: 617/4024 0.227s 0.001s
im_detect: 618/4024 0.227s 0.001s
im_detect: 619/4024 0.227s 0.001s
im_detect: 620/4024 0.227s 0.001s
im_detect: 621/4024 0.227s 0.001s
im_detect: 622/4024 0.227s 0.001s
im_detect: 623/4024 0.227s 0.001s
im_detect: 624/4024 0.227s 0.001s
im_detect: 625/4024 0.227s 0.001s
im_detect: 626/4024 0.227s 0.001s
im_detect: 627/4024 0.227s 0.001s
im_detect: 628/4024 0.227s 0.001s
im_detect: 629/4024 0.227s 0.001s
im_detect: 630/4024 0.226s 0.001s
im_detect: 631/4024 0.226s 0.001s
im_detect: 632/4024 0.226s 0.001s
im_detect: 633/4024 0.226s 0.001s
im_detect: 634/4024 0.226s 0.001s
im_detect: 635/4024 0.226s 0.001s
im_detect: 636/4024 0.227s 0.001s
im_detect: 637/4024 0.226s 0.001s
im_detect: 638/4024 0.226s 0.001s
im_detect: 639/4024 0.226s 0.001s
im_detect: 640/4024 0.226s 0.001s
im_detect: 641/4024 0.226s 0.001s
im_detect: 642/4024 0.226s 0.001s
im_detect: 643/4024 0.226s 0.001s
im_detect: 644/4024 0.226s 0.001s
im_detect: 645/4024 0.226s 0.001s
im_detect: 646/4024 0.226s 0.001s
im_detect: 647/4024 0.226s 0.001s
im_detect: 648/4024 0.226s 0.001s
im_detect: 649/4024 0.226s 0.001s
im_detect: 650/4024 0.226s 0.001s
im_detect: 651/4024 0.226s 0.001s
im_detect: 652/4024 0.226s 0.001s
im_detect: 653/4024 0.226s 0.001s
im_detect: 654/4024 0.226s 0.001s
im_detect: 655/4024 0.226s 0.001s
im_detect: 656/4024 0.226s 0.001s
im_detect: 657/4024 0.226s 0.001s
im_detect: 658/4024 0.226s 0.001s
im_detect: 659/4024 0.226s 0.001s
im_detect: 660/4024 0.226s 0.001s
im_detect: 661/4024 0.226s 0.001s
im_detect: 662/4024 0.226s 0.001s
im_detect: 663/4024 0.226s 0.001s
im_detect: 664/4024 0.226s 0.001s
im_detect: 665/4024 0.226s 0.001s
im_detect: 666/4024 0.226s 0.001s
im_detect: 667/4024 0.226s 0.001s
im_detect: 668/4024 0.226s 0.001s
im_detect: 669/4024 0.226s 0.001s
im_detect: 670/4024 0.226s 0.001s
im_detect: 671/4024 0.226s 0.001s
im_detect: 672/4024 0.226s 0.001s
im_detect: 673/4024 0.226s 0.001s
im_detect: 674/4024 0.226s 0.001s
im_detect: 675/4024 0.226s 0.001s
im_detect: 676/4024 0.226s 0.001s
im_detect: 677/4024 0.226s 0.001s
im_detect: 678/4024 0.226s 0.001s
im_detect: 679/4024 0.226s 0.001s
im_detect: 680/4024 0.226s 0.001s
im_detect: 681/4024 0.226s 0.001s
im_detect: 682/4024 0.226s 0.001s
im_detect: 683/4024 0.226s 0.001s
im_detect: 684/4024 0.226s 0.001s
im_detect: 685/4024 0.226s 0.001s
im_detect: 686/4024 0.226s 0.001s
im_detect: 687/4024 0.226s 0.001s
im_detect: 688/4024 0.226s 0.001s
im_detect: 689/4024 0.226s 0.001s
im_detect: 690/4024 0.226s 0.001s
im_detect: 691/4024 0.226s 0.001s
im_detect: 692/4024 0.226s 0.001s
im_detect: 693/4024 0.226s 0.001s
im_detect: 694/4024 0.226s 0.001s
im_detect: 695/4024 0.226s 0.001s
im_detect: 696/4024 0.226s 0.001s
im_detect: 697/4024 0.226s 0.001s
im_detect: 698/4024 0.226s 0.001s
im_detect: 699/4024 0.226s 0.001s
im_detect: 700/4024 0.226s 0.001s
im_detect: 701/4024 0.226s 0.001s
im_detect: 702/4024 0.226s 0.001s
im_detect: 703/4024 0.226s 0.001s
im_detect: 704/4024 0.226s 0.001s
im_detect: 705/4024 0.226s 0.001s
im_detect: 706/4024 0.226s 0.001s
im_detect: 707/4024 0.226s 0.001s
im_detect: 708/4024 0.226s 0.001s
im_detect: 709/4024 0.226s 0.001s
im_detect: 710/4024 0.226s 0.001s
im_detect: 711/4024 0.226s 0.001s
im_detect: 712/4024 0.226s 0.001s
im_detect: 713/4024 0.226s 0.001s
im_detect: 714/4024 0.226s 0.001s
im_detect: 715/4024 0.226s 0.001s
im_detect: 716/4024 0.226s 0.001s
im_detect: 717/4024 0.226s 0.001s
im_detect: 718/4024 0.225s 0.001s
im_detect: 719/4024 0.225s 0.001s
im_detect: 720/4024 0.225s 0.001s
im_detect: 721/4024 0.225s 0.001s
im_detect: 722/4024 0.225s 0.001s
im_detect: 723/4024 0.225s 0.001s
im_detect: 724/4024 0.225s 0.001s
im_detect: 725/4024 0.225s 0.001s
im_detect: 726/4024 0.225s 0.001s
im_detect: 727/4024 0.225s 0.001s
im_detect: 728/4024 0.225s 0.001s
im_detect: 729/4024 0.225s 0.001s
im_detect: 730/4024 0.225s 0.001s
im_detect: 731/4024 0.225s 0.001s
im_detect: 732/4024 0.225s 0.001s
im_detect: 733/4024 0.225s 0.001s
im_detect: 734/4024 0.225s 0.001s
im_detect: 735/4024 0.225s 0.001s
im_detect: 736/4024 0.225s 0.001s
im_detect: 737/4024 0.225s 0.001s
im_detect: 738/4024 0.225s 0.001s
im_detect: 739/4024 0.225s 0.001s
im_detect: 740/4024 0.225s 0.001s
im_detect: 741/4024 0.225s 0.001s
im_detect: 742/4024 0.225s 0.001s
im_detect: 743/4024 0.225s 0.001s
im_detect: 744/4024 0.225s 0.001s
im_detect: 745/4024 0.225s 0.001s
im_detect: 746/4024 0.225s 0.001s
im_detect: 747/4024 0.225s 0.001s
im_detect: 748/4024 0.225s 0.001s
im_detect: 749/4024 0.225s 0.001s
im_detect: 750/4024 0.225s 0.001s
im_detect: 751/4024 0.225s 0.001s
im_detect: 752/4024 0.225s 0.001s
im_detect: 753/4024 0.225s 0.001s
im_detect: 754/4024 0.225s 0.001s
im_detect: 755/4024 0.225s 0.001s
im_detect: 756/4024 0.225s 0.001s
im_detect: 757/4024 0.225s 0.001s
im_detect: 758/4024 0.225s 0.001s
im_detect: 759/4024 0.225s 0.001s
im_detect: 760/4024 0.225s 0.001s
im_detect: 761/4024 0.225s 0.001s
im_detect: 762/4024 0.225s 0.001s
im_detect: 763/4024 0.225s 0.001s
im_detect: 764/4024 0.225s 0.001s
im_detect: 765/4024 0.225s 0.001s
im_detect: 766/4024 0.225s 0.001s
im_detect: 767/4024 0.225s 0.001s
im_detect: 768/4024 0.225s 0.001s
im_detect: 769/4024 0.225s 0.001s
im_detect: 770/4024 0.225s 0.001s
im_detect: 771/4024 0.225s 0.001s
im_detect: 772/4024 0.225s 0.001s
im_detect: 773/4024 0.225s 0.001s
im_detect: 774/4024 0.225s 0.001s
im_detect: 775/4024 0.225s 0.001s
im_detect: 776/4024 0.225s 0.001s
im_detect: 777/4024 0.225s 0.001s
im_detect: 778/4024 0.225s 0.001s
im_detect: 779/4024 0.225s 0.001s
im_detect: 780/4024 0.225s 0.001s
im_detect: 781/4024 0.225s 0.001s
im_detect: 782/4024 0.225s 0.001s
im_detect: 783/4024 0.225s 0.001s
im_detect: 784/4024 0.225s 0.001s
im_detect: 785/4024 0.225s 0.001s
im_detect: 786/4024 0.225s 0.001s
im_detect: 787/4024 0.225s 0.001s
im_detect: 788/4024 0.225s 0.001s
im_detect: 789/4024 0.225s 0.001s
im_detect: 790/4024 0.225s 0.001s
im_detect: 791/4024 0.225s 0.001s
im_detect: 792/4024 0.225s 0.001s
im_detect: 793/4024 0.225s 0.001s
im_detect: 794/4024 0.225s 0.001s
im_detect: 795/4024 0.225s 0.001s
im_detect: 796/4024 0.225s 0.001s
im_detect: 797/4024 0.225s 0.001s
im_detect: 798/4024 0.225s 0.001s
im_detect: 799/4024 0.225s 0.001s
im_detect: 800/4024 0.225s 0.001s
im_detect: 801/4024 0.225s 0.001s
im_detect: 802/4024 0.225s 0.001s
im_detect: 803/4024 0.225s 0.001s
im_detect: 804/4024 0.225s 0.001s
im_detect: 805/4024 0.225s 0.001s
im_detect: 806/4024 0.225s 0.001s
im_detect: 807/4024 0.225s 0.001s
im_detect: 808/4024 0.225s 0.001s
im_detect: 809/4024 0.225s 0.001s
im_detect: 810/4024 0.225s 0.001s
im_detect: 811/4024 0.225s 0.001s
im_detect: 812/4024 0.225s 0.001s
im_detect: 813/4024 0.225s 0.001s
im_detect: 814/4024 0.225s 0.001s
im_detect: 815/4024 0.225s 0.001s
im_detect: 816/4024 0.225s 0.001s
im_detect: 817/4024 0.225s 0.001s
im_detect: 818/4024 0.225s 0.001s
im_detect: 819/4024 0.225s 0.001s
im_detect: 820/4024 0.224s 0.001s
im_detect: 821/4024 0.224s 0.001s
im_detect: 822/4024 0.224s 0.001s
im_detect: 823/4024 0.224s 0.001s
im_detect: 824/4024 0.224s 0.001s
im_detect: 825/4024 0.224s 0.001s
im_detect: 826/4024 0.224s 0.001s
im_detect: 827/4024 0.224s 0.001s
im_detect: 828/4024 0.224s 0.001s
im_detect: 829/4024 0.224s 0.001s
im_detect: 830/4024 0.224s 0.001s
im_detect: 831/4024 0.224s 0.001s
im_detect: 832/4024 0.224s 0.001s
im_detect: 833/4024 0.224s 0.001s
im_detect: 834/4024 0.224s 0.001s
im_detect: 835/4024 0.224s 0.001s
im_detect: 836/4024 0.224s 0.001s
im_detect: 837/4024 0.224s 0.001s
im_detect: 838/4024 0.224s 0.001s
im_detect: 839/4024 0.224s 0.001s
im_detect: 840/4024 0.224s 0.001s
im_detect: 841/4024 0.224s 0.001s
im_detect: 842/4024 0.224s 0.001s
im_detect: 843/4024 0.224s 0.001s
im_detect: 844/4024 0.224s 0.001s
im_detect: 845/4024 0.224s 0.001s
im_detect: 846/4024 0.224s 0.001s
im_detect: 847/4024 0.224s 0.001s
im_detect: 848/4024 0.224s 0.001s
im_detect: 849/4024 0.224s 0.001s
im_detect: 850/4024 0.224s 0.001s
im_detect: 851/4024 0.224s 0.001s
im_detect: 852/4024 0.224s 0.001s
im_detect: 853/4024 0.224s 0.001s
im_detect: 854/4024 0.224s 0.001s
im_detect: 855/4024 0.224s 0.001s
im_detect: 856/4024 0.224s 0.001s
im_detect: 857/4024 0.224s 0.001s
im_detect: 858/4024 0.224s 0.001s
im_detect: 859/4024 0.224s 0.001s
im_detect: 860/4024 0.224s 0.001s
im_detect: 861/4024 0.224s 0.001s
im_detect: 862/4024 0.224s 0.001s
im_detect: 863/4024 0.224s 0.001s
im_detect: 864/4024 0.224s 0.001s
im_detect: 865/4024 0.224s 0.001s
im_detect: 866/4024 0.224s 0.001s
im_detect: 867/4024 0.224s 0.001s
im_detect: 868/4024 0.224s 0.001s
im_detect: 869/4024 0.224s 0.001s
im_detect: 870/4024 0.224s 0.001s
im_detect: 871/4024 0.224s 0.001s
im_detect: 872/4024 0.224s 0.001s
im_detect: 873/4024 0.224s 0.001s
im_detect: 874/4024 0.224s 0.001s
im_detect: 875/4024 0.224s 0.001s
im_detect: 876/4024 0.224s 0.001s
im_detect: 877/4024 0.224s 0.001s
im_detect: 878/4024 0.224s 0.001s
im_detect: 879/4024 0.224s 0.001s
im_detect: 880/4024 0.224s 0.001s
im_detect: 881/4024 0.224s 0.001s
im_detect: 882/4024 0.224s 0.001s
im_detect: 883/4024 0.224s 0.001s
im_detect: 884/4024 0.224s 0.001s
im_detect: 885/4024 0.224s 0.001s
im_detect: 886/4024 0.224s 0.001s
im_detect: 887/4024 0.224s 0.001s
im_detect: 888/4024 0.224s 0.001s
im_detect: 889/4024 0.224s 0.001s
im_detect: 890/4024 0.224s 0.001s
im_detect: 891/4024 0.224s 0.001s
im_detect: 892/4024 0.224s 0.001s
im_detect: 893/4024 0.224s 0.001s
im_detect: 894/4024 0.224s 0.001s
im_detect: 895/4024 0.224s 0.001s
im_detect: 896/4024 0.224s 0.001s
im_detect: 897/4024 0.224s 0.001s
im_detect: 898/4024 0.224s 0.001s
im_detect: 899/4024 0.224s 0.001s
im_detect: 900/4024 0.224s 0.001s
im_detect: 901/4024 0.224s 0.001s
im_detect: 902/4024 0.224s 0.001s
im_detect: 903/4024 0.224s 0.001s
im_detect: 904/4024 0.224s 0.001s
im_detect: 905/4024 0.224s 0.001s
im_detect: 906/4024 0.224s 0.001s
im_detect: 907/4024 0.224s 0.001s
im_detect: 908/4024 0.224s 0.001s
im_detect: 909/4024 0.224s 0.001s
im_detect: 910/4024 0.224s 0.001s
im_detect: 911/4024 0.224s 0.001s
im_detect: 912/4024 0.224s 0.001s
im_detect: 913/4024 0.224s 0.001s
im_detect: 914/4024 0.224s 0.001s
im_detect: 915/4024 0.224s 0.001s
im_detect: 916/4024 0.224s 0.001s
im_detect: 917/4024 0.224s 0.001s
im_detect: 918/4024 0.224s 0.001s
im_detect: 919/4024 0.224s 0.001s
im_detect: 920/4024 0.224s 0.001s
im_detect: 921/4024 0.224s 0.001s
im_detect: 922/4024 0.224s 0.001s
im_detect: 923/4024 0.224s 0.001s
im_detect: 924/4024 0.224s 0.001s
im_detect: 925/4024 0.224s 0.001s
im_detect: 926/4024 0.224s 0.001s
im_detect: 927/4024 0.224s 0.001s
im_detect: 928/4024 0.224s 0.001s
im_detect: 929/4024 0.224s 0.001s
im_detect: 930/4024 0.224s 0.001s
im_detect: 931/4024 0.224s 0.001s
im_detect: 932/4024 0.224s 0.001s
im_detect: 933/4024 0.224s 0.001s
im_detect: 934/4024 0.224s 0.001s
im_detect: 935/4024 0.224s 0.001s
im_detect: 936/4024 0.224s 0.001s
im_detect: 937/4024 0.224s 0.001s
im_detect: 938/4024 0.224s 0.001s
im_detect: 939/4024 0.224s 0.001s
im_detect: 940/4024 0.224s 0.001s
im_detect: 941/4024 0.224s 0.001s
im_detect: 942/4024 0.224s 0.001s
im_detect: 943/4024 0.224s 0.001s
im_detect: 944/4024 0.224s 0.001s
im_detect: 945/4024 0.224s 0.001s
im_detect: 946/4024 0.224s 0.001s
im_detect: 947/4024 0.224s 0.001s
im_detect: 948/4024 0.224s 0.001s
im_detect: 949/4024 0.224s 0.001s
im_detect: 950/4024 0.224s 0.001s
im_detect: 951/4024 0.224s 0.001s
im_detect: 952/4024 0.224s 0.001s
im_detect: 953/4024 0.224s 0.001s
im_detect: 954/4024 0.224s 0.001s
im_detect: 955/4024 0.224s 0.001s
im_detect: 956/4024 0.224s 0.001s
im_detect: 957/4024 0.224s 0.001s
im_detect: 958/4024 0.224s 0.001s
im_detect: 959/4024 0.224s 0.001s
im_detect: 960/4024 0.224s 0.001s
im_detect: 961/4024 0.224s 0.001s
im_detect: 962/4024 0.224s 0.001s
im_detect: 963/4024 0.224s 0.001s
im_detect: 964/4024 0.224s 0.001s
im_detect: 965/4024 0.224s 0.001s
im_detect: 966/4024 0.224s 0.001s
im_detect: 967/4024 0.224s 0.001s
im_detect: 968/4024 0.224s 0.001s
im_detect: 969/4024 0.224s 0.001s
im_detect: 970/4024 0.224s 0.001s
im_detect: 971/4024 0.224s 0.001s
im_detect: 972/4024 0.224s 0.001s
im_detect: 973/4024 0.224s 0.001s
im_detect: 974/4024 0.223s 0.001s
im_detect: 975/4024 0.223s 0.001s
im_detect: 976/4024 0.223s 0.001s
im_detect: 977/4024 0.223s 0.001s
im_detect: 978/4024 0.223s 0.001s
im_detect: 979/4024 0.224s 0.001s
im_detect: 980/4024 0.224s 0.001s
im_detect: 981/4024 0.224s 0.001s
im_detect: 982/4024 0.224s 0.001s
im_detect: 983/4024 0.224s 0.001s
im_detect: 984/4024 0.224s 0.001s
im_detect: 985/4024 0.223s 0.001s
im_detect: 986/4024 0.224s 0.001s
im_detect: 987/4024 0.223s 0.001s
im_detect: 988/4024 0.223s 0.001s
im_detect: 989/4024 0.223s 0.001s
im_detect: 990/4024 0.223s 0.001s
im_detect: 991/4024 0.223s 0.001s
im_detect: 992/4024 0.223s 0.001s
im_detect: 993/4024 0.223s 0.001s
im_detect: 994/4024 0.223s 0.001s
im_detect: 995/4024 0.223s 0.001s
im_detect: 996/4024 0.223s 0.001s
im_detect: 997/4024 0.223s 0.001s
im_detect: 998/4024 0.223s 0.001s
im_detect: 999/4024 0.223s 0.001s
im_detect: 1000/4024 0.223s 0.001s
im_detect: 1001/4024 0.223s 0.001s
im_detect: 1002/4024 0.223s 0.001s
im_detect: 1003/4024 0.223s 0.001s
im_detect: 1004/4024 0.223s 0.001s
im_detect: 1005/4024 0.223s 0.001s
im_detect: 1006/4024 0.223s 0.001s
im_detect: 1007/4024 0.223s 0.001s
im_detect: 1008/4024 0.223s 0.001s
im_detect: 1009/4024 0.223s 0.001s
im_detect: 1010/4024 0.223s 0.001s
im_detect: 1011/4024 0.223s 0.001s
im_detect: 1012/4024 0.223s 0.001s
im_detect: 1013/4024 0.223s 0.001s
im_detect: 1014/4024 0.223s 0.001s
im_detect: 1015/4024 0.223s 0.001s
im_detect: 1016/4024 0.223s 0.001s
im_detect: 1017/4024 0.223s 0.001s
im_detect: 1018/4024 0.223s 0.001s
im_detect: 1019/4024 0.223s 0.001s
im_detect: 1020/4024 0.223s 0.001s
im_detect: 1021/4024 0.223s 0.001s
im_detect: 1022/4024 0.223s 0.001s
im_detect: 1023/4024 0.223s 0.001s
im_detect: 1024/4024 0.223s 0.001s
im_detect: 1025/4024 0.223s 0.001s
im_detect: 1026/4024 0.223s 0.001s
im_detect: 1027/4024 0.223s 0.001s
im_detect: 1028/4024 0.223s 0.001s
im_detect: 1029/4024 0.223s 0.001s
im_detect: 1030/4024 0.223s 0.001s
im_detect: 1031/4024 0.223s 0.001s
im_detect: 1032/4024 0.223s 0.001s
im_detect: 1033/4024 0.223s 0.001s
im_detect: 1034/4024 0.223s 0.001s
im_detect: 1035/4024 0.223s 0.001s
im_detect: 1036/4024 0.223s 0.001s
im_detect: 1037/4024 0.223s 0.001s
im_detect: 1038/4024 0.223s 0.001s
im_detect: 1039/4024 0.223s 0.001s
im_detect: 1040/4024 0.223s 0.001s
im_detect: 1041/4024 0.223s 0.001s
im_detect: 1042/4024 0.223s 0.001s
im_detect: 1043/4024 0.223s 0.001s
im_detect: 1044/4024 0.223s 0.001s
im_detect: 1045/4024 0.223s 0.001s
im_detect: 1046/4024 0.223s 0.001s
im_detect: 1047/4024 0.223s 0.001s
im_detect: 1048/4024 0.223s 0.001s
im_detect: 1049/4024 0.223s 0.001s
im_detect: 1050/4024 0.223s 0.001s
im_detect: 1051/4024 0.223s 0.001s
im_detect: 1052/4024 0.223s 0.001s
im_detect: 1053/4024 0.223s 0.001s
im_detect: 1054/4024 0.223s 0.001s
im_detect: 1055/4024 0.223s 0.001s
im_detect: 1056/4024 0.223s 0.001s
im_detect: 1057/4024 0.223s 0.001s
im_detect: 1058/4024 0.223s 0.001s
im_detect: 1059/4024 0.223s 0.001s
im_detect: 1060/4024 0.223s 0.001s
im_detect: 1061/4024 0.223s 0.001s
im_detect: 1062/4024 0.223s 0.001s
im_detect: 1063/4024 0.223s 0.001s
im_detect: 1064/4024 0.223s 0.001s
im_detect: 1065/4024 0.223s 0.001s
im_detect: 1066/4024 0.223s 0.001s
im_detect: 1067/4024 0.223s 0.001s
im_detect: 1068/4024 0.223s 0.001s
im_detect: 1069/4024 0.223s 0.001s
im_detect: 1070/4024 0.223s 0.001s
im_detect: 1071/4024 0.223s 0.001s
im_detect: 1072/4024 0.223s 0.001s
im_detect: 1073/4024 0.223s 0.001s
im_detect: 1074/4024 0.223s 0.001s
im_detect: 1075/4024 0.223s 0.001s
im_detect: 1076/4024 0.223s 0.001s
im_detect: 1077/4024 0.223s 0.001s
im_detect: 1078/4024 0.223s 0.001s
im_detect: 1079/4024 0.223s 0.001s
im_detect: 1080/4024 0.223s 0.001s
im_detect: 1081/4024 0.223s 0.001s
im_detect: 1082/4024 0.223s 0.001s
im_detect: 1083/4024 0.223s 0.001s
im_detect: 1084/4024 0.223s 0.001s
im_detect: 1085/4024 0.223s 0.001s
im_detect: 1086/4024 0.223s 0.001s
im_detect: 1087/4024 0.223s 0.001s
im_detect: 1088/4024 0.223s 0.001s
im_detect: 1089/4024 0.223s 0.001s
im_detect: 1090/4024 0.223s 0.001s
im_detect: 1091/4024 0.223s 0.001s
im_detect: 1092/4024 0.223s 0.001s
im_detect: 1093/4024 0.223s 0.001s
im_detect: 1094/4024 0.223s 0.001s
im_detect: 1095/4024 0.223s 0.001s
im_detect: 1096/4024 0.223s 0.001s
im_detect: 1097/4024 0.223s 0.001s
im_detect: 1098/4024 0.223s 0.001s
im_detect: 1099/4024 0.223s 0.001s
im_detect: 1100/4024 0.223s 0.001s
im_detect: 1101/4024 0.223s 0.001s
im_detect: 1102/4024 0.223s 0.001s
im_detect: 1103/4024 0.223s 0.001s
im_detect: 1104/4024 0.223s 0.001s
im_detect: 1105/4024 0.223s 0.001s
im_detect: 1106/4024 0.223s 0.001s
im_detect: 1107/4024 0.223s 0.001s
im_detect: 1108/4024 0.223s 0.001s
im_detect: 1109/4024 0.223s 0.001s
im_detect: 1110/4024 0.223s 0.001s
im_detect: 1111/4024 0.223s 0.001s
im_detect: 1112/4024 0.223s 0.001s
im_detect: 1113/4024 0.223s 0.001s
im_detect: 1114/4024 0.223s 0.001s
im_detect: 1115/4024 0.223s 0.001s
im_detect: 1116/4024 0.223s 0.001s
im_detect: 1117/4024 0.223s 0.001s
im_detect: 1118/4024 0.223s 0.001s
im_detect: 1119/4024 0.223s 0.001s
im_detect: 1120/4024 0.223s 0.001s
im_detect: 1121/4024 0.223s 0.001s
im_detect: 1122/4024 0.223s 0.001s
im_detect: 1123/4024 0.223s 0.001s
im_detect: 1124/4024 0.223s 0.001s
im_detect: 1125/4024 0.223s 0.001s
im_detect: 1126/4024 0.223s 0.001s
im_detect: 1127/4024 0.223s 0.001s
im_detect: 1128/4024 0.223s 0.001s
im_detect: 1129/4024 0.223s 0.001s
im_detect: 1130/4024 0.223s 0.001s
im_detect: 1131/4024 0.223s 0.001s
im_detect: 1132/4024 0.223s 0.001s
im_detect: 1133/4024 0.223s 0.001s
im_detect: 1134/4024 0.223s 0.001s
im_detect: 1135/4024 0.223s 0.001s
im_detect: 1136/4024 0.223s 0.001s
im_detect: 1137/4024 0.223s 0.001s
im_detect: 1138/4024 0.223s 0.001s
im_detect: 1139/4024 0.223s 0.001s
im_detect: 1140/4024 0.223s 0.001s
im_detect: 1141/4024 0.223s 0.001s
im_detect: 1142/4024 0.223s 0.001s
im_detect: 1143/4024 0.223s 0.001s
im_detect: 1144/4024 0.223s 0.001s
im_detect: 1145/4024 0.223s 0.001s
im_detect: 1146/4024 0.223s 0.001s
im_detect: 1147/4024 0.223s 0.001s
im_detect: 1148/4024 0.223s 0.001s
im_detect: 1149/4024 0.223s 0.001s
im_detect: 1150/4024 0.223s 0.001s
im_detect: 1151/4024 0.223s 0.001s
im_detect: 1152/4024 0.223s 0.001s
im_detect: 1153/4024 0.223s 0.001s
im_detect: 1154/4024 0.223s 0.001s
im_detect: 1155/4024 0.223s 0.001s
im_detect: 1156/4024 0.223s 0.001s
im_detect: 1157/4024 0.223s 0.001s
im_detect: 1158/4024 0.223s 0.001s
im_detect: 1159/4024 0.223s 0.001s
im_detect: 1160/4024 0.223s 0.001s
im_detect: 1161/4024 0.223s 0.001s
im_detect: 1162/4024 0.223s 0.001s
im_detect: 1163/4024 0.223s 0.001s
im_detect: 1164/4024 0.223s 0.001s
im_detect: 1165/4024 0.223s 0.001s
im_detect: 1166/4024 0.223s 0.001s
im_detect: 1167/4024 0.223s 0.001s
im_detect: 1168/4024 0.223s 0.001s
im_detect: 1169/4024 0.223s 0.001s
im_detect: 1170/4024 0.223s 0.001s
im_detect: 1171/4024 0.223s 0.001s
im_detect: 1172/4024 0.223s 0.001s
im_detect: 1173/4024 0.223s 0.001s
im_detect: 1174/4024 0.223s 0.001s
im_detect: 1175/4024 0.223s 0.001s
im_detect: 1176/4024 0.223s 0.001s
im_detect: 1177/4024 0.223s 0.001s
im_detect: 1178/4024 0.223s 0.001s
im_detect: 1179/4024 0.223s 0.001s
im_detect: 1180/4024 0.223s 0.001s
im_detect: 1181/4024 0.223s 0.001s
im_detect: 1182/4024 0.223s 0.001s
im_detect: 1183/4024 0.223s 0.001s
im_detect: 1184/4024 0.223s 0.001s
im_detect: 1185/4024 0.223s 0.001s
im_detect: 1186/4024 0.223s 0.001s
im_detect: 1187/4024 0.223s 0.001s
im_detect: 1188/4024 0.223s 0.001s
im_detect: 1189/4024 0.223s 0.001s
im_detect: 1190/4024 0.223s 0.001s
im_detect: 1191/4024 0.223s 0.001s
im_detect: 1192/4024 0.223s 0.001s
im_detect: 1193/4024 0.223s 0.001s
im_detect: 1194/4024 0.223s 0.001s
im_detect: 1195/4024 0.223s 0.001s
im_detect: 1196/4024 0.223s 0.001s
im_detect: 1197/4024 0.223s 0.001s
im_detect: 1198/4024 0.223s 0.001s
im_detect: 1199/4024 0.223s 0.001s
im_detect: 1200/4024 0.223s 0.001s
im_detect: 1201/4024 0.223s 0.001s
im_detect: 1202/4024 0.223s 0.001s
im_detect: 1203/4024 0.223s 0.001s
im_detect: 1204/4024 0.223s 0.001s
im_detect: 1205/4024 0.223s 0.001s
im_detect: 1206/4024 0.223s 0.001s
im_detect: 1207/4024 0.223s 0.001s
im_detect: 1208/4024 0.223s 0.001s
im_detect: 1209/4024 0.223s 0.001s
im_detect: 1210/4024 0.223s 0.001s
im_detect: 1211/4024 0.223s 0.001s
im_detect: 1212/4024 0.223s 0.001s
im_detect: 1213/4024 0.223s 0.001s
im_detect: 1214/4024 0.223s 0.001s
im_detect: 1215/4024 0.223s 0.001s
im_detect: 1216/4024 0.223s 0.001s
im_detect: 1217/4024 0.223s 0.001s
im_detect: 1218/4024 0.223s 0.001s
im_detect: 1219/4024 0.223s 0.001s
im_detect: 1220/4024 0.223s 0.001s
im_detect: 1221/4024 0.223s 0.001s
im_detect: 1222/4024 0.223s 0.001s
im_detect: 1223/4024 0.223s 0.001s
im_detect: 1224/4024 0.223s 0.001s
im_detect: 1225/4024 0.223s 0.001s
im_detect: 1226/4024 0.223s 0.001s
im_detect: 1227/4024 0.223s 0.001s
im_detect: 1228/4024 0.223s 0.001s
im_detect: 1229/4024 0.223s 0.001s
im_detect: 1230/4024 0.223s 0.001s
im_detect: 1231/4024 0.223s 0.001s
im_detect: 1232/4024 0.223s 0.001s
im_detect: 1233/4024 0.223s 0.001s
im_detect: 1234/4024 0.223s 0.001s
im_detect: 1235/4024 0.223s 0.001s
im_detect: 1236/4024 0.223s 0.001s
im_detect: 1237/4024 0.223s 0.001s
im_detect: 1238/4024 0.223s 0.001s
im_detect: 1239/4024 0.223s 0.001s
im_detect: 1240/4024 0.223s 0.001s
im_detect: 1241/4024 0.223s 0.001s
im_detect: 1242/4024 0.223s 0.001s
im_detect: 1243/4024 0.223s 0.001s
im_detect: 1244/4024 0.223s 0.001s
im_detect: 1245/4024 0.223s 0.001s
im_detect: 1246/4024 0.223s 0.001s
im_detect: 1247/4024 0.223s 0.001s
im_detect: 1248/4024 0.223s 0.001s
im_detect: 1249/4024 0.223s 0.001s
im_detect: 1250/4024 0.223s 0.001s
im_detect: 1251/4024 0.223s 0.001s
im_detect: 1252/4024 0.223s 0.001s
im_detect: 1253/4024 0.223s 0.001s
im_detect: 1254/4024 0.223s 0.001s
im_detect: 1255/4024 0.223s 0.001s
im_detect: 1256/4024 0.223s 0.001s
im_detect: 1257/4024 0.223s 0.001s
im_detect: 1258/4024 0.223s 0.001s
im_detect: 1259/4024 0.223s 0.001s
im_detect: 1260/4024 0.223s 0.001s
im_detect: 1261/4024 0.223s 0.001s
im_detect: 1262/4024 0.223s 0.001s
im_detect: 1263/4024 0.223s 0.001s
im_detect: 1264/4024 0.223s 0.001s
im_detect: 1265/4024 0.223s 0.001s
im_detect: 1266/4024 0.223s 0.001s
im_detect: 1267/4024 0.223s 0.001s
im_detect: 1268/4024 0.223s 0.001s
im_detect: 1269/4024 0.223s 0.001s
im_detect: 1270/4024 0.223s 0.001s
im_detect: 1271/4024 0.223s 0.001s
im_detect: 1272/4024 0.223s 0.001s
im_detect: 1273/4024 0.223s 0.001s
im_detect: 1274/4024 0.223s 0.001s
im_detect: 1275/4024 0.223s 0.001s
im_detect: 1276/4024 0.223s 0.001s
im_detect: 1277/4024 0.223s 0.001s
im_detect: 1278/4024 0.223s 0.001s
im_detect: 1279/4024 0.223s 0.001s
im_detect: 1280/4024 0.223s 0.001s
im_detect: 1281/4024 0.223s 0.001s
im_detect: 1282/4024 0.223s 0.001s
im_detect: 1283/4024 0.223s 0.001s
im_detect: 1284/4024 0.223s 0.001s
im_detect: 1285/4024 0.223s 0.001s
im_detect: 1286/4024 0.223s 0.001s
im_detect: 1287/4024 0.223s 0.001s
im_detect: 1288/4024 0.223s 0.001s
im_detect: 1289/4024 0.223s 0.001s
im_detect: 1290/4024 0.223s 0.001s
im_detect: 1291/4024 0.223s 0.001s
im_detect: 1292/4024 0.223s 0.001s
im_detect: 1293/4024 0.223s 0.001s
im_detect: 1294/4024 0.223s 0.001s
im_detect: 1295/4024 0.223s 0.001s
im_detect: 1296/4024 0.223s 0.001s
im_detect: 1297/4024 0.223s 0.001s
im_detect: 1298/4024 0.223s 0.001s
im_detect: 1299/4024 0.223s 0.001s
im_detect: 1300/4024 0.223s 0.001s
im_detect: 1301/4024 0.223s 0.001s
im_detect: 1302/4024 0.223s 0.001s
im_detect: 1303/4024 0.223s 0.001s
im_detect: 1304/4024 0.223s 0.001s
im_detect: 1305/4024 0.223s 0.001s
im_detect: 1306/4024 0.223s 0.001s
im_detect: 1307/4024 0.223s 0.001s
im_detect: 1308/4024 0.223s 0.001s
im_detect: 1309/4024 0.223s 0.001s
im_detect: 1310/4024 0.223s 0.001s
im_detect: 1311/4024 0.223s 0.001s
im_detect: 1312/4024 0.223s 0.001s
im_detect: 1313/4024 0.223s 0.001s
im_detect: 1314/4024 0.223s 0.001s
im_detect: 1315/4024 0.223s 0.001s
im_detect: 1316/4024 0.223s 0.001s
im_detect: 1317/4024 0.223s 0.001s
im_detect: 1318/4024 0.223s 0.001s
im_detect: 1319/4024 0.223s 0.001s
im_detect: 1320/4024 0.223s 0.001s
im_detect: 1321/4024 0.223s 0.001s
im_detect: 1322/4024 0.223s 0.001s
im_detect: 1323/4024 0.223s 0.001s
im_detect: 1324/4024 0.223s 0.001s
im_detect: 1325/4024 0.223s 0.001s
im_detect: 1326/4024 0.223s 0.001s
im_detect: 1327/4024 0.223s 0.001s
im_detect: 1328/4024 0.223s 0.001s
im_detect: 1329/4024 0.223s 0.001s
im_detect: 1330/4024 0.223s 0.001s
im_detect: 1331/4024 0.223s 0.001s
im_detect: 1332/4024 0.223s 0.001s
im_detect: 1333/4024 0.223s 0.001s
im_detect: 1334/4024 0.223s 0.001s
im_detect: 1335/4024 0.223s 0.001s
im_detect: 1336/4024 0.223s 0.001s
im_detect: 1337/4024 0.223s 0.001s
im_detect: 1338/4024 0.223s 0.001s
im_detect: 1339/4024 0.223s 0.001s
im_detect: 1340/4024 0.223s 0.001s
im_detect: 1341/4024 0.223s 0.001s
im_detect: 1342/4024 0.223s 0.001s
im_detect: 1343/4024 0.223s 0.001s
im_detect: 1344/4024 0.223s 0.001s
im_detect: 1345/4024 0.223s 0.001s
im_detect: 1346/4024 0.223s 0.001s
im_detect: 1347/4024 0.223s 0.001s
im_detect: 1348/4024 0.223s 0.001s
im_detect: 1349/4024 0.223s 0.001s
im_detect: 1350/4024 0.223s 0.001s
im_detect: 1351/4024 0.223s 0.001s
im_detect: 1352/4024 0.223s 0.001s
im_detect: 1353/4024 0.223s 0.001s
im_detect: 1354/4024 0.223s 0.001s
im_detect: 1355/4024 0.223s 0.001s
im_detect: 1356/4024 0.223s 0.001s
im_detect: 1357/4024 0.223s 0.001s
im_detect: 1358/4024 0.223s 0.001s
im_detect: 1359/4024 0.223s 0.001s
im_detect: 1360/4024 0.223s 0.001s
im_detect: 1361/4024 0.223s 0.001s
im_detect: 1362/4024 0.223s 0.001s
im_detect: 1363/4024 0.223s 0.001s
im_detect: 1364/4024 0.223s 0.001s
im_detect: 1365/4024 0.223s 0.001s
im_detect: 1366/4024 0.223s 0.001s
im_detect: 1367/4024 0.223s 0.001s
im_detect: 1368/4024 0.223s 0.001s
im_detect: 1369/4024 0.223s 0.001s
im_detect: 1370/4024 0.223s 0.001s
im_detect: 1371/4024 0.223s 0.001s
im_detect: 1372/4024 0.223s 0.001s
im_detect: 1373/4024 0.223s 0.001s
im_detect: 1374/4024 0.223s 0.001s
im_detect: 1375/4024 0.223s 0.001s
im_detect: 1376/4024 0.223s 0.001s
im_detect: 1377/4024 0.223s 0.001s
im_detect: 1378/4024 0.223s 0.001s
im_detect: 1379/4024 0.223s 0.001s
im_detect: 1380/4024 0.223s 0.001s
im_detect: 1381/4024 0.223s 0.001s
im_detect: 1382/4024 0.223s 0.001s
im_detect: 1383/4024 0.223s 0.001s
im_detect: 1384/4024 0.223s 0.001s
im_detect: 1385/4024 0.223s 0.001s
im_detect: 1386/4024 0.223s 0.001s
im_detect: 1387/4024 0.223s 0.001s
im_detect: 1388/4024 0.223s 0.001s
im_detect: 1389/4024 0.223s 0.001s
im_detect: 1390/4024 0.223s 0.001s
im_detect: 1391/4024 0.223s 0.001s
im_detect: 1392/4024 0.223s 0.001s
im_detect: 1393/4024 0.223s 0.001s
im_detect: 1394/4024 0.223s 0.001s
im_detect: 1395/4024 0.223s 0.001s
im_detect: 1396/4024 0.223s 0.001s
im_detect: 1397/4024 0.223s 0.001s
im_detect: 1398/4024 0.223s 0.001s
im_detect: 1399/4024 0.223s 0.001s
im_detect: 1400/4024 0.223s 0.001s
im_detect: 1401/4024 0.223s 0.001s
im_detect: 1402/4024 0.223s 0.001s
im_detect: 1403/4024 0.223s 0.001s
im_detect: 1404/4024 0.223s 0.001s
im_detect: 1405/4024 0.223s 0.001s
im_detect: 1406/4024 0.223s 0.001s
im_detect: 1407/4024 0.223s 0.001s
im_detect: 1408/4024 0.223s 0.001s
im_detect: 1409/4024 0.223s 0.001s
im_detect: 1410/4024 0.223s 0.001s
im_detect: 1411/4024 0.223s 0.001s
im_detect: 1412/4024 0.223s 0.001s
im_detect: 1413/4024 0.223s 0.001s
im_detect: 1414/4024 0.223s 0.001s
im_detect: 1415/4024 0.223s 0.001s
im_detect: 1416/4024 0.223s 0.001s
im_detect: 1417/4024 0.223s 0.001s
im_detect: 1418/4024 0.223s 0.001s
im_detect: 1419/4024 0.223s 0.001s
im_detect: 1420/4024 0.223s 0.001s
im_detect: 1421/4024 0.223s 0.001s
im_detect: 1422/4024 0.223s 0.001s
im_detect: 1423/4024 0.223s 0.001s
im_detect: 1424/4024 0.223s 0.001s
im_detect: 1425/4024 0.223s 0.001s
im_detect: 1426/4024 0.223s 0.001s
im_detect: 1427/4024 0.223s 0.001s
im_detect: 1428/4024 0.223s 0.001s
im_detect: 1429/4024 0.223s 0.001s
im_detect: 1430/4024 0.223s 0.001s
im_detect: 1431/4024 0.223s 0.001s
im_detect: 1432/4024 0.223s 0.001s
im_detect: 1433/4024 0.223s 0.001s
im_detect: 1434/4024 0.223s 0.001s
im_detect: 1435/4024 0.223s 0.001s
im_detect: 1436/4024 0.223s 0.001s
im_detect: 1437/4024 0.223s 0.001s
im_detect: 1438/4024 0.223s 0.001s
im_detect: 1439/4024 0.224s 0.001s
im_detect: 1440/4024 0.224s 0.001s
im_detect: 1441/4024 0.224s 0.001s
im_detect: 1442/4024 0.224s 0.001s
im_detect: 1443/4024 0.224s 0.001s
im_detect: 1444/4024 0.224s 0.001s
im_detect: 1445/4024 0.224s 0.001s
im_detect: 1446/4024 0.224s 0.001s
im_detect: 1447/4024 0.224s 0.001s
im_detect: 1448/4024 0.224s 0.001s
im_detect: 1449/4024 0.224s 0.001s
im_detect: 1450/4024 0.224s 0.001s
im_detect: 1451/4024 0.224s 0.001s
im_detect: 1452/4024 0.224s 0.001s
im_detect: 1453/4024 0.224s 0.001s
im_detect: 1454/4024 0.224s 0.001s
im_detect: 1455/4024 0.224s 0.001s
im_detect: 1456/4024 0.224s 0.001s
im_detect: 1457/4024 0.224s 0.001s
im_detect: 1458/4024 0.224s 0.001s
im_detect: 1459/4024 0.224s 0.001s
im_detect: 1460/4024 0.224s 0.001s
im_detect: 1461/4024 0.224s 0.001s
im_detect: 1462/4024 0.224s 0.001s
im_detect: 1463/4024 0.224s 0.001s
im_detect: 1464/4024 0.224s 0.001s
im_detect: 1465/4024 0.224s 0.001s
im_detect: 1466/4024 0.224s 0.001s
im_detect: 1467/4024 0.224s 0.001s
im_detect: 1468/4024 0.224s 0.001s
im_detect: 1469/4024 0.224s 0.001s
im_detect: 1470/4024 0.224s 0.001s
im_detect: 1471/4024 0.224s 0.001s
im_detect: 1472/4024 0.224s 0.001s
im_detect: 1473/4024 0.224s 0.001s
im_detect: 1474/4024 0.224s 0.001s
im_detect: 1475/4024 0.224s 0.001s
im_detect: 1476/4024 0.224s 0.001s
im_detect: 1477/4024 0.224s 0.001s
im_detect: 1478/4024 0.224s 0.001s
im_detect: 1479/4024 0.224s 0.001s
im_detect: 1480/4024 0.224s 0.001s
im_detect: 1481/4024 0.224s 0.001s
im_detect: 1482/4024 0.224s 0.001s
im_detect: 1483/4024 0.224s 0.001s
im_detect: 1484/4024 0.224s 0.001s
im_detect: 1485/4024 0.224s 0.001s
im_detect: 1486/4024 0.224s 0.001s
im_detect: 1487/4024 0.224s 0.001s
im_detect: 1488/4024 0.224s 0.001s
im_detect: 1489/4024 0.224s 0.001s
im_detect: 1490/4024 0.224s 0.001s
im_detect: 1491/4024 0.224s 0.001s
im_detect: 1492/4024 0.224s 0.001s
im_detect: 1493/4024 0.224s 0.001s
im_detect: 1494/4024 0.224s 0.001s
im_detect: 1495/4024 0.224s 0.001s
im_detect: 1496/4024 0.224s 0.001s
im_detect: 1497/4024 0.224s 0.001s
im_detect: 1498/4024 0.224s 0.001s
im_detect: 1499/4024 0.224s 0.001s
im_detect: 1500/4024 0.224s 0.001s
im_detect: 1501/4024 0.224s 0.001s
im_detect: 1502/4024 0.224s 0.001s
im_detect: 1503/4024 0.224s 0.001s
im_detect: 1504/4024 0.224s 0.001s
im_detect: 1505/4024 0.224s 0.001s
im_detect: 1506/4024 0.224s 0.001s
im_detect: 1507/4024 0.224s 0.001s
im_detect: 1508/4024 0.224s 0.001s
im_detect: 1509/4024 0.224s 0.001s
im_detect: 1510/4024 0.224s 0.001s
im_detect: 1511/4024 0.224s 0.001s
im_detect: 1512/4024 0.224s 0.001s
im_detect: 1513/4024 0.224s 0.001s
im_detect: 1514/4024 0.224s 0.001s
im_detect: 1515/4024 0.224s 0.001s
im_detect: 1516/4024 0.224s 0.001s
im_detect: 1517/4024 0.224s 0.001s
im_detect: 1518/4024 0.224s 0.001s
im_detect: 1519/4024 0.224s 0.001s
im_detect: 1520/4024 0.224s 0.001s
im_detect: 1521/4024 0.224s 0.001s
im_detect: 1522/4024 0.224s 0.001s
im_detect: 1523/4024 0.224s 0.001s
im_detect: 1524/4024 0.224s 0.001s
im_detect: 1525/4024 0.224s 0.001s
im_detect: 1526/4024 0.224s 0.001s
im_detect: 1527/4024 0.224s 0.001s
im_detect: 1528/4024 0.224s 0.001s
im_detect: 1529/4024 0.224s 0.001s
im_detect: 1530/4024 0.224s 0.001s
im_detect: 1531/4024 0.224s 0.001s
im_detect: 1532/4024 0.224s 0.001s
im_detect: 1533/4024 0.224s 0.001s
im_detect: 1534/4024 0.224s 0.001s
im_detect: 1535/4024 0.224s 0.001s
im_detect: 1536/4024 0.224s 0.001s
im_detect: 1537/4024 0.224s 0.001s
im_detect: 1538/4024 0.224s 0.001s
im_detect: 1539/4024 0.224s 0.001s
im_detect: 1540/4024 0.224s 0.001s
im_detect: 1541/4024 0.224s 0.001s
im_detect: 1542/4024 0.224s 0.001s
im_detect: 1543/4024 0.224s 0.001s
im_detect: 1544/4024 0.224s 0.001s
im_detect: 1545/4024 0.224s 0.001s
im_detect: 1546/4024 0.224s 0.001s
im_detect: 1547/4024 0.224s 0.001s
im_detect: 1548/4024 0.224s 0.001s
im_detect: 1549/4024 0.224s 0.001s
im_detect: 1550/4024 0.224s 0.001s
im_detect: 1551/4024 0.224s 0.001s
im_detect: 1552/4024 0.224s 0.001s
im_detect: 1553/4024 0.224s 0.001s
im_detect: 1554/4024 0.224s 0.001s
im_detect: 1555/4024 0.224s 0.001s
im_detect: 1556/4024 0.224s 0.001s
im_detect: 1557/4024 0.224s 0.001s
im_detect: 1558/4024 0.224s 0.001s
im_detect: 1559/4024 0.224s 0.001s
im_detect: 1560/4024 0.224s 0.001s
im_detect: 1561/4024 0.224s 0.001s
im_detect: 1562/4024 0.224s 0.001s
im_detect: 1563/4024 0.224s 0.001s
im_detect: 1564/4024 0.224s 0.001s
im_detect: 1565/4024 0.224s 0.001s
im_detect: 1566/4024 0.224s 0.001s
im_detect: 1567/4024 0.224s 0.001s
im_detect: 1568/4024 0.224s 0.001s
im_detect: 1569/4024 0.224s 0.001s
im_detect: 1570/4024 0.224s 0.001s
im_detect: 1571/4024 0.224s 0.001s
im_detect: 1572/4024 0.224s 0.001s
im_detect: 1573/4024 0.224s 0.001s
im_detect: 1574/4024 0.224s 0.001s
im_detect: 1575/4024 0.224s 0.001s
im_detect: 1576/4024 0.224s 0.001s
im_detect: 1577/4024 0.224s 0.001s
im_detect: 1578/4024 0.224s 0.001s
im_detect: 1579/4024 0.224s 0.001s
im_detect: 1580/4024 0.224s 0.001s
im_detect: 1581/4024 0.224s 0.001s
im_detect: 1582/4024 0.224s 0.001s
im_detect: 1583/4024 0.224s 0.001s
im_detect: 1584/4024 0.224s 0.001s
im_detect: 1585/4024 0.224s 0.001s
im_detect: 1586/4024 0.224s 0.001s
im_detect: 1587/4024 0.224s 0.001s
im_detect: 1588/4024 0.224s 0.001s
im_detect: 1589/4024 0.224s 0.001s
im_detect: 1590/4024 0.224s 0.001s
im_detect: 1591/4024 0.224s 0.001s
im_detect: 1592/4024 0.224s 0.001s
im_detect: 1593/4024 0.224s 0.001s
im_detect: 1594/4024 0.224s 0.001s
im_detect: 1595/4024 0.224s 0.001s
im_detect: 1596/4024 0.224s 0.001s
im_detect: 1597/4024 0.224s 0.001s
im_detect: 1598/4024 0.224s 0.001s
im_detect: 1599/4024 0.224s 0.001s
im_detect: 1600/4024 0.224s 0.001s
im_detect: 1601/4024 0.224s 0.001s
im_detect: 1602/4024 0.224s 0.001s
im_detect: 1603/4024 0.224s 0.001s
im_detect: 1604/4024 0.224s 0.001s
im_detect: 1605/4024 0.224s 0.001s
im_detect: 1606/4024 0.224s 0.001s
im_detect: 1607/4024 0.224s 0.001s
im_detect: 1608/4024 0.224s 0.001s
im_detect: 1609/4024 0.224s 0.001s
im_detect: 1610/4024 0.224s 0.001s
im_detect: 1611/4024 0.224s 0.001s
im_detect: 1612/4024 0.224s 0.001s
im_detect: 1613/4024 0.224s 0.001s
im_detect: 1614/4024 0.224s 0.001s
im_detect: 1615/4024 0.224s 0.001s
im_detect: 1616/4024 0.224s 0.001s
im_detect: 1617/4024 0.224s 0.001s
im_detect: 1618/4024 0.224s 0.001s
im_detect: 1619/4024 0.224s 0.001s
im_detect: 1620/4024 0.224s 0.001s
im_detect: 1621/4024 0.224s 0.001s
im_detect: 1622/4024 0.224s 0.001s
im_detect: 1623/4024 0.224s 0.001s
im_detect: 1624/4024 0.224s 0.001s
im_detect: 1625/4024 0.224s 0.001s
im_detect: 1626/4024 0.224s 0.001s
im_detect: 1627/4024 0.224s 0.001s
im_detect: 1628/4024 0.224s 0.001s
im_detect: 1629/4024 0.224s 0.001s
im_detect: 1630/4024 0.224s 0.001s
im_detect: 1631/4024 0.224s 0.001s
im_detect: 1632/4024 0.224s 0.001s
im_detect: 1633/4024 0.224s 0.001s
im_detect: 1634/4024 0.224s 0.001s
im_detect: 1635/4024 0.224s 0.001s
im_detect: 1636/4024 0.224s 0.001s
im_detect: 1637/4024 0.224s 0.001s
im_detect: 1638/4024 0.224s 0.001s
im_detect: 1639/4024 0.224s 0.001s
im_detect: 1640/4024 0.224s 0.001s
im_detect: 1641/4024 0.224s 0.001s
im_detect: 1642/4024 0.224s 0.001s
im_detect: 1643/4024 0.224s 0.001s
im_detect: 1644/4024 0.224s 0.001s
im_detect: 1645/4024 0.224s 0.001s
im_detect: 1646/4024 0.224s 0.001s
im_detect: 1647/4024 0.224s 0.001s
im_detect: 1648/4024 0.224s 0.001s
im_detect: 1649/4024 0.224s 0.001s
im_detect: 1650/4024 0.224s 0.001s
im_detect: 1651/4024 0.224s 0.001s
im_detect: 1652/4024 0.224s 0.001s
im_detect: 1653/4024 0.224s 0.001s
im_detect: 1654/4024 0.224s 0.001s
im_detect: 1655/4024 0.224s 0.001s
im_detect: 1656/4024 0.224s 0.001s
im_detect: 1657/4024 0.224s 0.001s
im_detect: 1658/4024 0.224s 0.001s
im_detect: 1659/4024 0.224s 0.001s
im_detect: 1660/4024 0.224s 0.001s
im_detect: 1661/4024 0.224s 0.001s
im_detect: 1662/4024 0.224s 0.001s
im_detect: 1663/4024 0.224s 0.001s
im_detect: 1664/4024 0.224s 0.001s
im_detect: 1665/4024 0.224s 0.001s
im_detect: 1666/4024 0.224s 0.001s
im_detect: 1667/4024 0.224s 0.001s
im_detect: 1668/4024 0.224s 0.001s
im_detect: 1669/4024 0.224s 0.001s
im_detect: 1670/4024 0.224s 0.001s
im_detect: 1671/4024 0.224s 0.001s
im_detect: 1672/4024 0.224s 0.001s
im_detect: 1673/4024 0.224s 0.001s
im_detect: 1674/4024 0.224s 0.001s
im_detect: 1675/4024 0.224s 0.001s
im_detect: 1676/4024 0.224s 0.001s
im_detect: 1677/4024 0.224s 0.001s
im_detect: 1678/4024 0.224s 0.001s
im_detect: 1679/4024 0.224s 0.001s
im_detect: 1680/4024 0.224s 0.001s
im_detect: 1681/4024 0.224s 0.001s
im_detect: 1682/4024 0.224s 0.001s
im_detect: 1683/4024 0.224s 0.001s
im_detect: 1684/4024 0.224s 0.001s
im_detect: 1685/4024 0.224s 0.001s
im_detect: 1686/4024 0.224s 0.001s
im_detect: 1687/4024 0.224s 0.001s
im_detect: 1688/4024 0.224s 0.001s
im_detect: 1689/4024 0.224s 0.001s
im_detect: 1690/4024 0.224s 0.001s
im_detect: 1691/4024 0.224s 0.001s
im_detect: 1692/4024 0.224s 0.001s
im_detect: 1693/4024 0.224s 0.001s
im_detect: 1694/4024 0.224s 0.001s
im_detect: 1695/4024 0.224s 0.001s
im_detect: 1696/4024 0.224s 0.001s
im_detect: 1697/4024 0.224s 0.001s
im_detect: 1698/4024 0.224s 0.001s
im_detect: 1699/4024 0.224s 0.001s
im_detect: 1700/4024 0.224s 0.001s
im_detect: 1701/4024 0.224s 0.001s
im_detect: 1702/4024 0.224s 0.001s
im_detect: 1703/4024 0.224s 0.001s
im_detect: 1704/4024 0.224s 0.001s
im_detect: 1705/4024 0.224s 0.001s
im_detect: 1706/4024 0.224s 0.001s
im_detect: 1707/4024 0.224s 0.001s
im_detect: 1708/4024 0.224s 0.001s
im_detect: 1709/4024 0.224s 0.001s
im_detect: 1710/4024 0.224s 0.001s
im_detect: 1711/4024 0.224s 0.001s
im_detect: 1712/4024 0.224s 0.001s
im_detect: 1713/4024 0.224s 0.001s
im_detect: 1714/4024 0.224s 0.001s
im_detect: 1715/4024 0.224s 0.001s
im_detect: 1716/4024 0.224s 0.001s
im_detect: 1717/4024 0.224s 0.001s
im_detect: 1718/4024 0.224s 0.001s
im_detect: 1719/4024 0.224s 0.001s
im_detect: 1720/4024 0.224s 0.001s
im_detect: 1721/4024 0.224s 0.001s
im_detect: 1722/4024 0.224s 0.001s
im_detect: 1723/4024 0.224s 0.001s
im_detect: 1724/4024 0.224s 0.001s
im_detect: 1725/4024 0.224s 0.001s
im_detect: 1726/4024 0.224s 0.001s
im_detect: 1727/4024 0.224s 0.001s
im_detect: 1728/4024 0.224s 0.001s
im_detect: 1729/4024 0.224s 0.001s
im_detect: 1730/4024 0.224s 0.001s
im_detect: 1731/4024 0.224s 0.001s
im_detect: 1732/4024 0.224s 0.001s
im_detect: 1733/4024 0.224s 0.001s
im_detect: 1734/4024 0.224s 0.001s
im_detect: 1735/4024 0.224s 0.001s
im_detect: 1736/4024 0.224s 0.001s
im_detect: 1737/4024 0.224s 0.001s
im_detect: 1738/4024 0.224s 0.001s
im_detect: 1739/4024 0.224s 0.001s
im_detect: 1740/4024 0.224s 0.001s
im_detect: 1741/4024 0.224s 0.001s
im_detect: 1742/4024 0.224s 0.001s
im_detect: 1743/4024 0.224s 0.001s
im_detect: 1744/4024 0.224s 0.001s
im_detect: 1745/4024 0.224s 0.001s
im_detect: 1746/4024 0.224s 0.001s
im_detect: 1747/4024 0.224s 0.001s
im_detect: 1748/4024 0.224s 0.001s
im_detect: 1749/4024 0.224s 0.001s
im_detect: 1750/4024 0.224s 0.001s
im_detect: 1751/4024 0.224s 0.001s
im_detect: 1752/4024 0.224s 0.001s
im_detect: 1753/4024 0.224s 0.001s
im_detect: 1754/4024 0.224s 0.001s
im_detect: 1755/4024 0.224s 0.001s
im_detect: 1756/4024 0.224s 0.001s
im_detect: 1757/4024 0.224s 0.001s
im_detect: 1758/4024 0.224s 0.001s
im_detect: 1759/4024 0.224s 0.001s
im_detect: 1760/4024 0.224s 0.001s
im_detect: 1761/4024 0.224s 0.001s
im_detect: 1762/4024 0.224s 0.001s
im_detect: 1763/4024 0.224s 0.001s
im_detect: 1764/4024 0.224s 0.001s
im_detect: 1765/4024 0.224s 0.001s
im_detect: 1766/4024 0.224s 0.001s
im_detect: 1767/4024 0.224s 0.001s
im_detect: 1768/4024 0.224s 0.001s
im_detect: 1769/4024 0.224s 0.001s
im_detect: 1770/4024 0.224s 0.001s
im_detect: 1771/4024 0.224s 0.001s
im_detect: 1772/4024 0.224s 0.001s
im_detect: 1773/4024 0.224s 0.001s
im_detect: 1774/4024 0.224s 0.001s
im_detect: 1775/4024 0.224s 0.001s
im_detect: 1776/4024 0.224s 0.001s
im_detect: 1777/4024 0.224s 0.001s
im_detect: 1778/4024 0.224s 0.001s
im_detect: 1779/4024 0.224s 0.001s
im_detect: 1780/4024 0.224s 0.001s
im_detect: 1781/4024 0.224s 0.001s
im_detect: 1782/4024 0.224s 0.001s
im_detect: 1783/4024 0.224s 0.001s
im_detect: 1784/4024 0.224s 0.001s
im_detect: 1785/4024 0.224s 0.001s
im_detect: 1786/4024 0.224s 0.001s
im_detect: 1787/4024 0.224s 0.001s
im_detect: 1788/4024 0.224s 0.001s
im_detect: 1789/4024 0.224s 0.001s
im_detect: 1790/4024 0.224s 0.001s
im_detect: 1791/4024 0.224s 0.001s
im_detect: 1792/4024 0.224s 0.001s
im_detect: 1793/4024 0.224s 0.001s
im_detect: 1794/4024 0.224s 0.001s
im_detect: 1795/4024 0.224s 0.001s
im_detect: 1796/4024 0.224s 0.001s
im_detect: 1797/4024 0.224s 0.001s
im_detect: 1798/4024 0.224s 0.001s
im_detect: 1799/4024 0.224s 0.001s
im_detect: 1800/4024 0.224s 0.001s
im_detect: 1801/4024 0.224s 0.001s
im_detect: 1802/4024 0.224s 0.001s
im_detect: 1803/4024 0.224s 0.001s
im_detect: 1804/4024 0.224s 0.001s
im_detect: 1805/4024 0.224s 0.001s
im_detect: 1806/4024 0.224s 0.001s
im_detect: 1807/4024 0.224s 0.001s
im_detect: 1808/4024 0.224s 0.001s
im_detect: 1809/4024 0.224s 0.001s
im_detect: 1810/4024 0.224s 0.001s
im_detect: 1811/4024 0.224s 0.001s
im_detect: 1812/4024 0.224s 0.001s
im_detect: 1813/4024 0.224s 0.001s
im_detect: 1814/4024 0.224s 0.001s
im_detect: 1815/4024 0.224s 0.001s
im_detect: 1816/4024 0.224s 0.001s
im_detect: 1817/4024 0.224s 0.001s
im_detect: 1818/4024 0.224s 0.001s
im_detect: 1819/4024 0.224s 0.001s
im_detect: 1820/4024 0.224s 0.001s
im_detect: 1821/4024 0.224s 0.001s
im_detect: 1822/4024 0.224s 0.001s
im_detect: 1823/4024 0.224s 0.001s
im_detect: 1824/4024 0.224s 0.001s
im_detect: 1825/4024 0.224s 0.001s
im_detect: 1826/4024 0.224s 0.001s
im_detect: 1827/4024 0.224s 0.001s
im_detect: 1828/4024 0.224s 0.001s
im_detect: 1829/4024 0.224s 0.001s
im_detect: 1830/4024 0.224s 0.001s
im_detect: 1831/4024 0.224s 0.001s
im_detect: 1832/4024 0.224s 0.001s
im_detect: 1833/4024 0.224s 0.001s
im_detect: 1834/4024 0.224s 0.001s
im_detect: 1835/4024 0.224s 0.001s
im_detect: 1836/4024 0.224s 0.001s
im_detect: 1837/4024 0.224s 0.001s
im_detect: 1838/4024 0.224s 0.001s
im_detect: 1839/4024 0.224s 0.001s
im_detect: 1840/4024 0.224s 0.001s
im_detect: 1841/4024 0.224s 0.001s
im_detect: 1842/4024 0.224s 0.001s
im_detect: 1843/4024 0.224s 0.001s
im_detect: 1844/4024 0.224s 0.001s
im_detect: 1845/4024 0.224s 0.001s
im_detect: 1846/4024 0.224s 0.001s
im_detect: 1847/4024 0.224s 0.001s
im_detect: 1848/4024 0.224s 0.001s
im_detect: 1849/4024 0.224s 0.001s
im_detect: 1850/4024 0.224s 0.001s
im_detect: 1851/4024 0.224s 0.001s
im_detect: 1852/4024 0.224s 0.001s
im_detect: 1853/4024 0.224s 0.001s
im_detect: 1854/4024 0.224s 0.001s
im_detect: 1855/4024 0.224s 0.001s
im_detect: 1856/4024 0.224s 0.001s
im_detect: 1857/4024 0.224s 0.001s
im_detect: 1858/4024 0.224s 0.001s
im_detect: 1859/4024 0.224s 0.001s
im_detect: 1860/4024 0.224s 0.001s
im_detect: 1861/4024 0.224s 0.001s
im_detect: 1862/4024 0.224s 0.001s
im_detect: 1863/4024 0.224s 0.001s
im_detect: 1864/4024 0.224s 0.001s
im_detect: 1865/4024 0.224s 0.001s
im_detect: 1866/4024 0.224s 0.001s
im_detect: 1867/4024 0.224s 0.001s
im_detect: 1868/4024 0.224s 0.001s
im_detect: 1869/4024 0.224s 0.001s
im_detect: 1870/4024 0.224s 0.001s
im_detect: 1871/4024 0.224s 0.001s
im_detect: 1872/4024 0.224s 0.001s
im_detect: 1873/4024 0.224s 0.001s
im_detect: 1874/4024 0.224s 0.001s
im_detect: 1875/4024 0.224s 0.001s
im_detect: 1876/4024 0.224s 0.001s
im_detect: 1877/4024 0.224s 0.001s
im_detect: 1878/4024 0.224s 0.001s
im_detect: 1879/4024 0.224s 0.001s
im_detect: 1880/4024 0.224s 0.001s
im_detect: 1881/4024 0.224s 0.001s
im_detect: 1882/4024 0.224s 0.001s
im_detect: 1883/4024 0.224s 0.001s
im_detect: 1884/4024 0.224s 0.001s
im_detect: 1885/4024 0.224s 0.001s
im_detect: 1886/4024 0.224s 0.001s
im_detect: 1887/4024 0.224s 0.001s
im_detect: 1888/4024 0.224s 0.001s
im_detect: 1889/4024 0.224s 0.001s
im_detect: 1890/4024 0.224s 0.001s
im_detect: 1891/4024 0.224s 0.001s
im_detect: 1892/4024 0.224s 0.001s
im_detect: 1893/4024 0.224s 0.001s
im_detect: 1894/4024 0.224s 0.001s
im_detect: 1895/4024 0.224s 0.001s
im_detect: 1896/4024 0.224s 0.001s
im_detect: 1897/4024 0.224s 0.001s
im_detect: 1898/4024 0.224s 0.001s
im_detect: 1899/4024 0.224s 0.001s
im_detect: 1900/4024 0.224s 0.001s
im_detect: 1901/4024 0.224s 0.001s
im_detect: 1902/4024 0.224s 0.001s
im_detect: 1903/4024 0.224s 0.001s
im_detect: 1904/4024 0.224s 0.001s
im_detect: 1905/4024 0.224s 0.001s
im_detect: 1906/4024 0.224s 0.001s
im_detect: 1907/4024 0.224s 0.001s
im_detect: 1908/4024 0.224s 0.001s
im_detect: 1909/4024 0.224s 0.001s
im_detect: 1910/4024 0.224s 0.001s
im_detect: 1911/4024 0.224s 0.001s
im_detect: 1912/4024 0.224s 0.001s
im_detect: 1913/4024 0.224s 0.001s
im_detect: 1914/4024 0.224s 0.001s
im_detect: 1915/4024 0.224s 0.001s
im_detect: 1916/4024 0.224s 0.001s
im_detect: 1917/4024 0.224s 0.001s
im_detect: 1918/4024 0.224s 0.001s
im_detect: 1919/4024 0.224s 0.001s
im_detect: 1920/4024 0.224s 0.001s
im_detect: 1921/4024 0.224s 0.001s
im_detect: 1922/4024 0.224s 0.001s
im_detect: 1923/4024 0.224s 0.001s
im_detect: 1924/4024 0.224s 0.001s
im_detect: 1925/4024 0.224s 0.001s
im_detect: 1926/4024 0.224s 0.001s
im_detect: 1927/4024 0.224s 0.001s
im_detect: 1928/4024 0.224s 0.001s
im_detect: 1929/4024 0.224s 0.001s
im_detect: 1930/4024 0.224s 0.001s
im_detect: 1931/4024 0.224s 0.001s
im_detect: 1932/4024 0.224s 0.001s
im_detect: 1933/4024 0.224s 0.001s
im_detect: 1934/4024 0.223s 0.001s
im_detect: 1935/4024 0.223s 0.001s
im_detect: 1936/4024 0.223s 0.001s
im_detect: 1937/4024 0.223s 0.001s
im_detect: 1938/4024 0.223s 0.001s
im_detect: 1939/4024 0.223s 0.001s
im_detect: 1940/4024 0.223s 0.001s
im_detect: 1941/4024 0.223s 0.001s
im_detect: 1942/4024 0.223s 0.001s
im_detect: 1943/4024 0.223s 0.001s
im_detect: 1944/4024 0.223s 0.001s
im_detect: 1945/4024 0.223s 0.001s
im_detect: 1946/4024 0.223s 0.001s
im_detect: 1947/4024 0.223s 0.001s
im_detect: 1948/4024 0.223s 0.001s
im_detect: 1949/4024 0.223s 0.001s
im_detect: 1950/4024 0.223s 0.001s
im_detect: 1951/4024 0.223s 0.001s
im_detect: 1952/4024 0.223s 0.001s
im_detect: 1953/4024 0.223s 0.001s
im_detect: 1954/4024 0.223s 0.001s
im_detect: 1955/4024 0.223s 0.001s
im_detect: 1956/4024 0.223s 0.001s
im_detect: 1957/4024 0.223s 0.001s
im_detect: 1958/4024 0.223s 0.001s
im_detect: 1959/4024 0.223s 0.001s
im_detect: 1960/4024 0.223s 0.001s
im_detect: 1961/4024 0.223s 0.001s
im_detect: 1962/4024 0.223s 0.001s
im_detect: 1963/4024 0.223s 0.001s
im_detect: 1964/4024 0.223s 0.001s
im_detect: 1965/4024 0.223s 0.001s
im_detect: 1966/4024 0.223s 0.001s
im_detect: 1967/4024 0.223s 0.001s
im_detect: 1968/4024 0.223s 0.001s
im_detect: 1969/4024 0.223s 0.001s
im_detect: 1970/4024 0.223s 0.001s
im_detect: 1971/4024 0.223s 0.001s
im_detect: 1972/4024 0.223s 0.001s
im_detect: 1973/4024 0.223s 0.001s
im_detect: 1974/4024 0.223s 0.001s
im_detect: 1975/4024 0.223s 0.001s
im_detect: 1976/4024 0.223s 0.001s
im_detect: 1977/4024 0.223s 0.001s
im_detect: 1978/4024 0.223s 0.001s
im_detect: 1979/4024 0.223s 0.001s
im_detect: 1980/4024 0.223s 0.001s
im_detect: 1981/4024 0.223s 0.001s
im_detect: 1982/4024 0.223s 0.001s
im_detect: 1983/4024 0.223s 0.001s
im_detect: 1984/4024 0.223s 0.001s
im_detect: 1985/4024 0.223s 0.001s
im_detect: 1986/4024 0.223s 0.001s
im_detect: 1987/4024 0.223s 0.001s
im_detect: 1988/4024 0.223s 0.001s
im_detect: 1989/4024 0.223s 0.001s
im_detect: 1990/4024 0.223s 0.001s
im_detect: 1991/4024 0.223s 0.001s
im_detect: 1992/4024 0.223s 0.001s
im_detect: 1993/4024 0.223s 0.001s
im_detect: 1994/4024 0.223s 0.001s
im_detect: 1995/4024 0.223s 0.001s
im_detect: 1996/4024 0.223s 0.001s
im_detect: 1997/4024 0.223s 0.001s
im_detect: 1998/4024 0.223s 0.001s
im_detect: 1999/4024 0.223s 0.001s
im_detect: 2000/4024 0.223s 0.001s
im_detect: 2001/4024 0.223s 0.001s
im_detect: 2002/4024 0.223s 0.001s
im_detect: 2003/4024 0.223s 0.001s
im_detect: 2004/4024 0.223s 0.001s
im_detect: 2005/4024 0.223s 0.001s
im_detect: 2006/4024 0.223s 0.001s
im_detect: 2007/4024 0.223s 0.001s
im_detect: 2008/4024 0.223s 0.001s
im_detect: 2009/4024 0.223s 0.001s
im_detect: 2010/4024 0.223s 0.001s
im_detect: 2011/4024 0.223s 0.001s
im_detect: 2012/4024 0.223s 0.001s
im_detect: 2013/4024 0.223s 0.001s
im_detect: 2014/4024 0.223s 0.001s
im_detect: 2015/4024 0.223s 0.001s
im_detect: 2016/4024 0.223s 0.001s
im_detect: 2017/4024 0.223s 0.001s
im_detect: 2018/4024 0.223s 0.001s
im_detect: 2019/4024 0.223s 0.001s
im_detect: 2020/4024 0.223s 0.001s
im_detect: 2021/4024 0.223s 0.001s
im_detect: 2022/4024 0.223s 0.001s
im_detect: 2023/4024 0.223s 0.001s
im_detect: 2024/4024 0.223s 0.001s
im_detect: 2025/4024 0.223s 0.001s
im_detect: 2026/4024 0.223s 0.001s
im_detect: 2027/4024 0.223s 0.001s
im_detect: 2028/4024 0.223s 0.001s
im_detect: 2029/4024 0.223s 0.001s
im_detect: 2030/4024 0.223s 0.001s
im_detect: 2031/4024 0.223s 0.001s
im_detect: 2032/4024 0.223s 0.001s
im_detect: 2033/4024 0.223s 0.001s
im_detect: 2034/4024 0.223s 0.001s
im_detect: 2035/4024 0.223s 0.001s
im_detect: 2036/4024 0.223s 0.001s
im_detect: 2037/4024 0.223s 0.001s
im_detect: 2038/4024 0.223s 0.001s
im_detect: 2039/4024 0.223s 0.001s
im_detect: 2040/4024 0.223s 0.001s
im_detect: 2041/4024 0.223s 0.001s
im_detect: 2042/4024 0.223s 0.001s
im_detect: 2043/4024 0.223s 0.001s
im_detect: 2044/4024 0.223s 0.001s
im_detect: 2045/4024 0.223s 0.001s
im_detect: 2046/4024 0.223s 0.001s
im_detect: 2047/4024 0.223s 0.001s
im_detect: 2048/4024 0.223s 0.001s
im_detect: 2049/4024 0.223s 0.001s
im_detect: 2050/4024 0.223s 0.001s
im_detect: 2051/4024 0.223s 0.001s
im_detect: 2052/4024 0.223s 0.001s
im_detect: 2053/4024 0.223s 0.001s
im_detect: 2054/4024 0.223s 0.001s
im_detect: 2055/4024 0.223s 0.001s
im_detect: 2056/4024 0.223s 0.001s
im_detect: 2057/4024 0.223s 0.001s
im_detect: 2058/4024 0.223s 0.001s
im_detect: 2059/4024 0.223s 0.001s
im_detect: 2060/4024 0.223s 0.001s
im_detect: 2061/4024 0.223s 0.001s
im_detect: 2062/4024 0.223s 0.001s
im_detect: 2063/4024 0.223s 0.001s
im_detect: 2064/4024 0.223s 0.001s
im_detect: 2065/4024 0.223s 0.001s
im_detect: 2066/4024 0.223s 0.001s
im_detect: 2067/4024 0.223s 0.001s
im_detect: 2068/4024 0.223s 0.001s
im_detect: 2069/4024 0.223s 0.001s
im_detect: 2070/4024 0.223s 0.001s
im_detect: 2071/4024 0.223s 0.001s
im_detect: 2072/4024 0.223s 0.001s
im_detect: 2073/4024 0.223s 0.001s
im_detect: 2074/4024 0.223s 0.001s
im_detect: 2075/4024 0.223s 0.001s
im_detect: 2076/4024 0.223s 0.001s
im_detect: 2077/4024 0.223s 0.001s
im_detect: 2078/4024 0.223s 0.001s
im_detect: 2079/4024 0.223s 0.001s
im_detect: 2080/4024 0.223s 0.001s
im_detect: 2081/4024 0.223s 0.001s
im_detect: 2082/4024 0.223s 0.001s
im_detect: 2083/4024 0.223s 0.001s
im_detect: 2084/4024 0.223s 0.001s
im_detect: 2085/4024 0.223s 0.001s
im_detect: 2086/4024 0.223s 0.001s
im_detect: 2087/4024 0.223s 0.001s
im_detect: 2088/4024 0.223s 0.001s
im_detect: 2089/4024 0.223s 0.001s
im_detect: 2090/4024 0.223s 0.001s
im_detect: 2091/4024 0.223s 0.001s
im_detect: 2092/4024 0.223s 0.001s
im_detect: 2093/4024 0.223s 0.001s
im_detect: 2094/4024 0.223s 0.001s
im_detect: 2095/4024 0.223s 0.001s
im_detect: 2096/4024 0.223s 0.001s
im_detect: 2097/4024 0.223s 0.001s
im_detect: 2098/4024 0.223s 0.001s
im_detect: 2099/4024 0.223s 0.001s
im_detect: 2100/4024 0.223s 0.001s
im_detect: 2101/4024 0.223s 0.001s
im_detect: 2102/4024 0.223s 0.001s
im_detect: 2103/4024 0.223s 0.001s
im_detect: 2104/4024 0.223s 0.001s
im_detect: 2105/4024 0.223s 0.001s
im_detect: 2106/4024 0.223s 0.001s
im_detect: 2107/4024 0.223s 0.001s
im_detect: 2108/4024 0.223s 0.001s
im_detect: 2109/4024 0.223s 0.001s
im_detect: 2110/4024 0.223s 0.001s
im_detect: 2111/4024 0.223s 0.001s
im_detect: 2112/4024 0.223s 0.001s
im_detect: 2113/4024 0.223s 0.001s
im_detect: 2114/4024 0.223s 0.001s
im_detect: 2115/4024 0.223s 0.001s
im_detect: 2116/4024 0.223s 0.001s
im_detect: 2117/4024 0.223s 0.001s
im_detect: 2118/4024 0.223s 0.001s
im_detect: 2119/4024 0.223s 0.001s
im_detect: 2120/4024 0.223s 0.001s
im_detect: 2121/4024 0.223s 0.001s
im_detect: 2122/4024 0.223s 0.001s
im_detect: 2123/4024 0.223s 0.001s
im_detect: 2124/4024 0.223s 0.001s
im_detect: 2125/4024 0.223s 0.001s
im_detect: 2126/4024 0.223s 0.001s
im_detect: 2127/4024 0.223s 0.001s
im_detect: 2128/4024 0.223s 0.001s
im_detect: 2129/4024 0.223s 0.001s
im_detect: 2130/4024 0.223s 0.001s
im_detect: 2131/4024 0.223s 0.001s
im_detect: 2132/4024 0.223s 0.001s
im_detect: 2133/4024 0.223s 0.001s
im_detect: 2134/4024 0.223s 0.001s
im_detect: 2135/4024 0.223s 0.001s
im_detect: 2136/4024 0.223s 0.001s
im_detect: 2137/4024 0.223s 0.001s
im_detect: 2138/4024 0.223s 0.001s
im_detect: 2139/4024 0.223s 0.001s
im_detect: 2140/4024 0.223s 0.001s
im_detect: 2141/4024 0.223s 0.001s
im_detect: 2142/4024 0.223s 0.001s
im_detect: 2143/4024 0.223s 0.001s
im_detect: 2144/4024 0.223s 0.001s
im_detect: 2145/4024 0.223s 0.001s
im_detect: 2146/4024 0.223s 0.001s
im_detect: 2147/4024 0.223s 0.001s
im_detect: 2148/4024 0.223s 0.001s
im_detect: 2149/4024 0.223s 0.001s
im_detect: 2150/4024 0.223s 0.001s
im_detect: 2151/4024 0.223s 0.001s
im_detect: 2152/4024 0.223s 0.001s
im_detect: 2153/4024 0.223s 0.001s
im_detect: 2154/4024 0.223s 0.001s
im_detect: 2155/4024 0.223s 0.001s
im_detect: 2156/4024 0.223s 0.001s
im_detect: 2157/4024 0.223s 0.001s
im_detect: 2158/4024 0.223s 0.001s
im_detect: 2159/4024 0.223s 0.001s
im_detect: 2160/4024 0.223s 0.001s
im_detect: 2161/4024 0.223s 0.001s
im_detect: 2162/4024 0.223s 0.001s
im_detect: 2163/4024 0.223s 0.001s
im_detect: 2164/4024 0.223s 0.001s
im_detect: 2165/4024 0.223s 0.001s
im_detect: 2166/4024 0.223s 0.001s
im_detect: 2167/4024 0.223s 0.001s
im_detect: 2168/4024 0.223s 0.001s
im_detect: 2169/4024 0.223s 0.001s
im_detect: 2170/4024 0.223s 0.001s
im_detect: 2171/4024 0.223s 0.001s
im_detect: 2172/4024 0.223s 0.001s
im_detect: 2173/4024 0.223s 0.001s
im_detect: 2174/4024 0.223s 0.001s
im_detect: 2175/4024 0.223s 0.001s
im_detect: 2176/4024 0.223s 0.001s
im_detect: 2177/4024 0.223s 0.001s
im_detect: 2178/4024 0.223s 0.001s
im_detect: 2179/4024 0.223s 0.001s
im_detect: 2180/4024 0.223s 0.001s
im_detect: 2181/4024 0.223s 0.001s
im_detect: 2182/4024 0.223s 0.001s
im_detect: 2183/4024 0.223s 0.001s
im_detect: 2184/4024 0.223s 0.001s
im_detect: 2185/4024 0.223s 0.001s
im_detect: 2186/4024 0.223s 0.001s
im_detect: 2187/4024 0.223s 0.001s
im_detect: 2188/4024 0.223s 0.001s
im_detect: 2189/4024 0.223s 0.001s
im_detect: 2190/4024 0.223s 0.001s
im_detect: 2191/4024 0.223s 0.001s
im_detect: 2192/4024 0.223s 0.001s
im_detect: 2193/4024 0.223s 0.001s
im_detect: 2194/4024 0.223s 0.001s
im_detect: 2195/4024 0.223s 0.001s
im_detect: 2196/4024 0.223s 0.001s
im_detect: 2197/4024 0.223s 0.001s
im_detect: 2198/4024 0.223s 0.001s
im_detect: 2199/4024 0.223s 0.001s
im_detect: 2200/4024 0.223s 0.001s
im_detect: 2201/4024 0.223s 0.001s
im_detect: 2202/4024 0.223s 0.001s
im_detect: 2203/4024 0.223s 0.001s
im_detect: 2204/4024 0.223s 0.001s
im_detect: 2205/4024 0.223s 0.001s
im_detect: 2206/4024 0.223s 0.001s
im_detect: 2207/4024 0.223s 0.001s
im_detect: 2208/4024 0.223s 0.001s
im_detect: 2209/4024 0.223s 0.001s
im_detect: 2210/4024 0.223s 0.001s
im_detect: 2211/4024 0.223s 0.001s
im_detect: 2212/4024 0.223s 0.001s
im_detect: 2213/4024 0.223s 0.001s
im_detect: 2214/4024 0.223s 0.001s
im_detect: 2215/4024 0.223s 0.001s
im_detect: 2216/4024 0.223s 0.001s
im_detect: 2217/4024 0.223s 0.001s
im_detect: 2218/4024 0.223s 0.001s
im_detect: 2219/4024 0.223s 0.001s
im_detect: 2220/4024 0.223s 0.001s
im_detect: 2221/4024 0.223s 0.001s
im_detect: 2222/4024 0.223s 0.001s
im_detect: 2223/4024 0.223s 0.001s
im_detect: 2224/4024 0.223s 0.001s
im_detect: 2225/4024 0.223s 0.001s
im_detect: 2226/4024 0.223s 0.001s
im_detect: 2227/4024 0.223s 0.001s
im_detect: 2228/4024 0.223s 0.001s
im_detect: 2229/4024 0.223s 0.001s
im_detect: 2230/4024 0.223s 0.001s
im_detect: 2231/4024 0.223s 0.001s
im_detect: 2232/4024 0.223s 0.001s
im_detect: 2233/4024 0.223s 0.001s
im_detect: 2234/4024 0.223s 0.001s
im_detect: 2235/4024 0.223s 0.001s
im_detect: 2236/4024 0.223s 0.001s
im_detect: 2237/4024 0.223s 0.001s
im_detect: 2238/4024 0.223s 0.001s
im_detect: 2239/4024 0.223s 0.001s
im_detect: 2240/4024 0.223s 0.001s
im_detect: 2241/4024 0.223s 0.001s
im_detect: 2242/4024 0.223s 0.001s
im_detect: 2243/4024 0.223s 0.001s
im_detect: 2244/4024 0.223s 0.001s
im_detect: 2245/4024 0.223s 0.001s
im_detect: 2246/4024 0.223s 0.001s
im_detect: 2247/4024 0.223s 0.001s
im_detect: 2248/4024 0.223s 0.001s
im_detect: 2249/4024 0.223s 0.001s
im_detect: 2250/4024 0.223s 0.001s
im_detect: 2251/4024 0.223s 0.001s
im_detect: 2252/4024 0.223s 0.001s
im_detect: 2253/4024 0.223s 0.001s
im_detect: 2254/4024 0.223s 0.001s
im_detect: 2255/4024 0.223s 0.001s
im_detect: 2256/4024 0.223s 0.001s
im_detect: 2257/4024 0.223s 0.001s
im_detect: 2258/4024 0.223s 0.001s
im_detect: 2259/4024 0.223s 0.001s
im_detect: 2260/4024 0.223s 0.001s
im_detect: 2261/4024 0.223s 0.001s
im_detect: 2262/4024 0.223s 0.001s
im_detect: 2263/4024 0.223s 0.001s
im_detect: 2264/4024 0.223s 0.001s
im_detect: 2265/4024 0.223s 0.001s
im_detect: 2266/4024 0.223s 0.001s
im_detect: 2267/4024 0.223s 0.001s
im_detect: 2268/4024 0.223s 0.001s
im_detect: 2269/4024 0.223s 0.001s
im_detect: 2270/4024 0.223s 0.001s
im_detect: 2271/4024 0.223s 0.001s
im_detect: 2272/4024 0.223s 0.001s
im_detect: 2273/4024 0.223s 0.001s
im_detect: 2274/4024 0.223s 0.001s
im_detect: 2275/4024 0.223s 0.001s
im_detect: 2276/4024 0.223s 0.001s
im_detect: 2277/4024 0.223s 0.001s
im_detect: 2278/4024 0.223s 0.001s
im_detect: 2279/4024 0.223s 0.001s
im_detect: 2280/4024 0.223s 0.001s
im_detect: 2281/4024 0.223s 0.001s
im_detect: 2282/4024 0.223s 0.001s
im_detect: 2283/4024 0.223s 0.001s
im_detect: 2284/4024 0.223s 0.001s
im_detect: 2285/4024 0.223s 0.001s
im_detect: 2286/4024 0.223s 0.001s
im_detect: 2287/4024 0.223s 0.001s
im_detect: 2288/4024 0.223s 0.001s
im_detect: 2289/4024 0.223s 0.001s
im_detect: 2290/4024 0.223s 0.001s
im_detect: 2291/4024 0.223s 0.001s
im_detect: 2292/4024 0.223s 0.001s
im_detect: 2293/4024 0.223s 0.001s
im_detect: 2294/4024 0.223s 0.001s
im_detect: 2295/4024 0.223s 0.001s
im_detect: 2296/4024 0.223s 0.001s
im_detect: 2297/4024 0.223s 0.001s
im_detect: 2298/4024 0.223s 0.001s
im_detect: 2299/4024 0.223s 0.001s
im_detect: 2300/4024 0.223s 0.001s
im_detect: 2301/4024 0.223s 0.001s
im_detect: 2302/4024 0.223s 0.001s
im_detect: 2303/4024 0.223s 0.001s
im_detect: 2304/4024 0.223s 0.001s
im_detect: 2305/4024 0.223s 0.001s
im_detect: 2306/4024 0.223s 0.001s
im_detect: 2307/4024 0.223s 0.001s
im_detect: 2308/4024 0.223s 0.001s
im_detect: 2309/4024 0.223s 0.001s
im_detect: 2310/4024 0.223s 0.001s
im_detect: 2311/4024 0.223s 0.001s
im_detect: 2312/4024 0.223s 0.001s
im_detect: 2313/4024 0.223s 0.001s
im_detect: 2314/4024 0.223s 0.001s
im_detect: 2315/4024 0.223s 0.001s
im_detect: 2316/4024 0.223s 0.001s
im_detect: 2317/4024 0.223s 0.001s
im_detect: 2318/4024 0.223s 0.001s
im_detect: 2319/4024 0.223s 0.001s
im_detect: 2320/4024 0.223s 0.001s
im_detect: 2321/4024 0.223s 0.001s
im_detect: 2322/4024 0.223s 0.001s
im_detect: 2323/4024 0.223s 0.001s
im_detect: 2324/4024 0.223s 0.001s
im_detect: 2325/4024 0.223s 0.001s
im_detect: 2326/4024 0.223s 0.001s
im_detect: 2327/4024 0.223s 0.001s
im_detect: 2328/4024 0.223s 0.001s
im_detect: 2329/4024 0.223s 0.001s
im_detect: 2330/4024 0.223s 0.001s
im_detect: 2331/4024 0.223s 0.001s
im_detect: 2332/4024 0.223s 0.001s
im_detect: 2333/4024 0.223s 0.001s
im_detect: 2334/4024 0.223s 0.001s
im_detect: 2335/4024 0.223s 0.001s
im_detect: 2336/4024 0.223s 0.001s
im_detect: 2337/4024 0.223s 0.001s
im_detect: 2338/4024 0.223s 0.001s
im_detect: 2339/4024 0.223s 0.001s
im_detect: 2340/4024 0.223s 0.001s
im_detect: 2341/4024 0.223s 0.001s
im_detect: 2342/4024 0.223s 0.001s
im_detect: 2343/4024 0.223s 0.001s
im_detect: 2344/4024 0.223s 0.001s
im_detect: 2345/4024 0.223s 0.001s
im_detect: 2346/4024 0.223s 0.001s
im_detect: 2347/4024 0.223s 0.001s
im_detect: 2348/4024 0.223s 0.001s
im_detect: 2349/4024 0.223s 0.001s
im_detect: 2350/4024 0.223s 0.001s
im_detect: 2351/4024 0.223s 0.001s
im_detect: 2352/4024 0.223s 0.001s
im_detect: 2353/4024 0.223s 0.001s
im_detect: 2354/4024 0.223s 0.001s
im_detect: 2355/4024 0.223s 0.001s
im_detect: 2356/4024 0.223s 0.001s
im_detect: 2357/4024 0.223s 0.001s
im_detect: 2358/4024 0.223s 0.001s
im_detect: 2359/4024 0.223s 0.001s
im_detect: 2360/4024 0.223s 0.001s
im_detect: 2361/4024 0.223s 0.001s
im_detect: 2362/4024 0.223s 0.001s
im_detect: 2363/4024 0.223s 0.001s
im_detect: 2364/4024 0.223s 0.001s
im_detect: 2365/4024 0.223s 0.001s
im_detect: 2366/4024 0.223s 0.001s
im_detect: 2367/4024 0.223s 0.001s
im_detect: 2368/4024 0.223s 0.001s
im_detect: 2369/4024 0.223s 0.001s
im_detect: 2370/4024 0.223s 0.001s
im_detect: 2371/4024 0.223s 0.001s
im_detect: 2372/4024 0.223s 0.001s
im_detect: 2373/4024 0.223s 0.001s
im_detect: 2374/4024 0.223s 0.001s
im_detect: 2375/4024 0.223s 0.001s
im_detect: 2376/4024 0.223s 0.001s
im_detect: 2377/4024 0.223s 0.001s
im_detect: 2378/4024 0.223s 0.001s
im_detect: 2379/4024 0.223s 0.001s
im_detect: 2380/4024 0.223s 0.001s
im_detect: 2381/4024 0.223s 0.001s
im_detect: 2382/4024 0.223s 0.001s
im_detect: 2383/4024 0.223s 0.001s
im_detect: 2384/4024 0.223s 0.001s
im_detect: 2385/4024 0.223s 0.001s
im_detect: 2386/4024 0.223s 0.001s
im_detect: 2387/4024 0.223s 0.001s
im_detect: 2388/4024 0.223s 0.001s
im_detect: 2389/4024 0.223s 0.001s
im_detect: 2390/4024 0.223s 0.001s
im_detect: 2391/4024 0.223s 0.001s
im_detect: 2392/4024 0.223s 0.001s
im_detect: 2393/4024 0.223s 0.001s
im_detect: 2394/4024 0.223s 0.001s
im_detect: 2395/4024 0.223s 0.001s
im_detect: 2396/4024 0.223s 0.001s
im_detect: 2397/4024 0.223s 0.001s
im_detect: 2398/4024 0.223s 0.001s
im_detect: 2399/4024 0.223s 0.001s
im_detect: 2400/4024 0.223s 0.001s
im_detect: 2401/4024 0.223s 0.001s
im_detect: 2402/4024 0.223s 0.001s
im_detect: 2403/4024 0.223s 0.001s
im_detect: 2404/4024 0.223s 0.001s
im_detect: 2405/4024 0.223s 0.001s
im_detect: 2406/4024 0.223s 0.001s
im_detect: 2407/4024 0.223s 0.001s
im_detect: 2408/4024 0.223s 0.001s
im_detect: 2409/4024 0.223s 0.001s
im_detect: 2410/4024 0.223s 0.001s
im_detect: 2411/4024 0.223s 0.001s
im_detect: 2412/4024 0.223s 0.001s
im_detect: 2413/4024 0.223s 0.001s
im_detect: 2414/4024 0.223s 0.001s
im_detect: 2415/4024 0.223s 0.001s
im_detect: 2416/4024 0.223s 0.001s
im_detect: 2417/4024 0.223s 0.001s
im_detect: 2418/4024 0.223s 0.001s
im_detect: 2419/4024 0.223s 0.001s
im_detect: 2420/4024 0.223s 0.001s
im_detect: 2421/4024 0.223s 0.001s
im_detect: 2422/4024 0.223s 0.001s
im_detect: 2423/4024 0.223s 0.001s
im_detect: 2424/4024 0.223s 0.001s
im_detect: 2425/4024 0.223s 0.001s
im_detect: 2426/4024 0.223s 0.001s
im_detect: 2427/4024 0.223s 0.001s
im_detect: 2428/4024 0.223s 0.001s
im_detect: 2429/4024 0.223s 0.001s
im_detect: 2430/4024 0.223s 0.001s
im_detect: 2431/4024 0.223s 0.001s
im_detect: 2432/4024 0.223s 0.001s
im_detect: 2433/4024 0.223s 0.001s
im_detect: 2434/4024 0.223s 0.001s
im_detect: 2435/4024 0.223s 0.001s
im_detect: 2436/4024 0.223s 0.001s
im_detect: 2437/4024 0.223s 0.001s
im_detect: 2438/4024 0.223s 0.001s
im_detect: 2439/4024 0.223s 0.001s
im_detect: 2440/4024 0.223s 0.001s
im_detect: 2441/4024 0.223s 0.001s
im_detect: 2442/4024 0.223s 0.001s
im_detect: 2443/4024 0.223s 0.001s
im_detect: 2444/4024 0.223s 0.001s
im_detect: 2445/4024 0.223s 0.001s
im_detect: 2446/4024 0.223s 0.001s
im_detect: 2447/4024 0.223s 0.001s
im_detect: 2448/4024 0.223s 0.001s
im_detect: 2449/4024 0.223s 0.001s
im_detect: 2450/4024 0.223s 0.001s
im_detect: 2451/4024 0.223s 0.001s
im_detect: 2452/4024 0.223s 0.001s
im_detect: 2453/4024 0.223s 0.001s
im_detect: 2454/4024 0.223s 0.001s
im_detect: 2455/4024 0.223s 0.001s
im_detect: 2456/4024 0.223s 0.001s
im_detect: 2457/4024 0.223s 0.001s
im_detect: 2458/4024 0.223s 0.001s
im_detect: 2459/4024 0.223s 0.001s
im_detect: 2460/4024 0.223s 0.001s
im_detect: 2461/4024 0.223s 0.001s
im_detect: 2462/4024 0.223s 0.001s
im_detect: 2463/4024 0.223s 0.001s
im_detect: 2464/4024 0.223s 0.001s
im_detect: 2465/4024 0.223s 0.001s
im_detect: 2466/4024 0.223s 0.001s
im_detect: 2467/4024 0.223s 0.001s
im_detect: 2468/4024 0.223s 0.001s
im_detect: 2469/4024 0.223s 0.001s
im_detect: 2470/4024 0.223s 0.001s
im_detect: 2471/4024 0.223s 0.001s
im_detect: 2472/4024 0.223s 0.001s
im_detect: 2473/4024 0.223s 0.001s
im_detect: 2474/4024 0.223s 0.001s
im_detect: 2475/4024 0.223s 0.001s
im_detect: 2476/4024 0.223s 0.001s
im_detect: 2477/4024 0.223s 0.001s
im_detect: 2478/4024 0.223s 0.001s
im_detect: 2479/4024 0.223s 0.001s
im_detect: 2480/4024 0.223s 0.001s
im_detect: 2481/4024 0.223s 0.001s
im_detect: 2482/4024 0.223s 0.001s
im_detect: 2483/4024 0.223s 0.001s
im_detect: 2484/4024 0.223s 0.001s
im_detect: 2485/4024 0.223s 0.001s
im_detect: 2486/4024 0.223s 0.001s
im_detect: 2487/4024 0.223s 0.001s
im_detect: 2488/4024 0.223s 0.001s
im_detect: 2489/4024 0.223s 0.001s
im_detect: 2490/4024 0.223s 0.001s
im_detect: 2491/4024 0.223s 0.001s
im_detect: 2492/4024 0.223s 0.001s
im_detect: 2493/4024 0.223s 0.001s
im_detect: 2494/4024 0.223s 0.001s
im_detect: 2495/4024 0.223s 0.001s
im_detect: 2496/4024 0.223s 0.001s
im_detect: 2497/4024 0.223s 0.001s
im_detect: 2498/4024 0.223s 0.001s
im_detect: 2499/4024 0.223s 0.001s
im_detect: 2500/4024 0.223s 0.001s
im_detect: 2501/4024 0.223s 0.001s
im_detect: 2502/4024 0.223s 0.001s
im_detect: 2503/4024 0.223s 0.001s
im_detect: 2504/4024 0.223s 0.001s
im_detect: 2505/4024 0.223s 0.001s
im_detect: 2506/4024 0.223s 0.001s
im_detect: 2507/4024 0.223s 0.001s
im_detect: 2508/4024 0.223s 0.001s
im_detect: 2509/4024 0.223s 0.001s
im_detect: 2510/4024 0.223s 0.001s
im_detect: 2511/4024 0.223s 0.001s
im_detect: 2512/4024 0.223s 0.001s
im_detect: 2513/4024 0.223s 0.001s
im_detect: 2514/4024 0.223s 0.001s
im_detect: 2515/4024 0.223s 0.001s
im_detect: 2516/4024 0.223s 0.001s
im_detect: 2517/4024 0.223s 0.001s
im_detect: 2518/4024 0.223s 0.001s
im_detect: 2519/4024 0.223s 0.001s
im_detect: 2520/4024 0.223s 0.001s
im_detect: 2521/4024 0.223s 0.001s
im_detect: 2522/4024 0.223s 0.001s
im_detect: 2523/4024 0.223s 0.001s
im_detect: 2524/4024 0.223s 0.001s
im_detect: 2525/4024 0.223s 0.001s
im_detect: 2526/4024 0.223s 0.001s
im_detect: 2527/4024 0.223s 0.001s
im_detect: 2528/4024 0.223s 0.001s
im_detect: 2529/4024 0.223s 0.001s
im_detect: 2530/4024 0.223s 0.001s
im_detect: 2531/4024 0.223s 0.001s
im_detect: 2532/4024 0.223s 0.001s
im_detect: 2533/4024 0.223s 0.001s
im_detect: 2534/4024 0.223s 0.001s
im_detect: 2535/4024 0.223s 0.001s
im_detect: 2536/4024 0.223s 0.001s
im_detect: 2537/4024 0.223s 0.001s
im_detect: 2538/4024 0.223s 0.001s
im_detect: 2539/4024 0.223s 0.001s
im_detect: 2540/4024 0.223s 0.001s
im_detect: 2541/4024 0.223s 0.001s
im_detect: 2542/4024 0.223s 0.001s
im_detect: 2543/4024 0.223s 0.001s
im_detect: 2544/4024 0.223s 0.001s
im_detect: 2545/4024 0.223s 0.001s
im_detect: 2546/4024 0.223s 0.001s
im_detect: 2547/4024 0.223s 0.001s
im_detect: 2548/4024 0.223s 0.001s
im_detect: 2549/4024 0.223s 0.001s
im_detect: 2550/4024 0.223s 0.001s
im_detect: 2551/4024 0.223s 0.001s
im_detect: 2552/4024 0.223s 0.001s
im_detect: 2553/4024 0.223s 0.001s
im_detect: 2554/4024 0.223s 0.001s
im_detect: 2555/4024 0.223s 0.001s
im_detect: 2556/4024 0.223s 0.001s
im_detect: 2557/4024 0.223s 0.001s
im_detect: 2558/4024 0.223s 0.001s
im_detect: 2559/4024 0.223s 0.001s
im_detect: 2560/4024 0.223s 0.001s
im_detect: 2561/4024 0.223s 0.001s
im_detect: 2562/4024 0.223s 0.001s
im_detect: 2563/4024 0.223s 0.001s
im_detect: 2564/4024 0.223s 0.001s
im_detect: 2565/4024 0.223s 0.001s
im_detect: 2566/4024 0.223s 0.001s
im_detect: 2567/4024 0.223s 0.001s
im_detect: 2568/4024 0.223s 0.001s
im_detect: 2569/4024 0.223s 0.001s
im_detect: 2570/4024 0.223s 0.001s
im_detect: 2571/4024 0.223s 0.001s
im_detect: 2572/4024 0.223s 0.001s
im_detect: 2573/4024 0.223s 0.001s
im_detect: 2574/4024 0.223s 0.001s
im_detect: 2575/4024 0.223s 0.001s
im_detect: 2576/4024 0.223s 0.001s
im_detect: 2577/4024 0.223s 0.001s
im_detect: 2578/4024 0.223s 0.001s
im_detect: 2579/4024 0.223s 0.001s
im_detect: 2580/4024 0.223s 0.001s
im_detect: 2581/4024 0.223s 0.001s
im_detect: 2582/4024 0.223s 0.001s
im_detect: 2583/4024 0.223s 0.001s
im_detect: 2584/4024 0.223s 0.001s
im_detect: 2585/4024 0.223s 0.001s
im_detect: 2586/4024 0.223s 0.001s
im_detect: 2587/4024 0.223s 0.001s
im_detect: 2588/4024 0.223s 0.001s
im_detect: 2589/4024 0.223s 0.001s
im_detect: 2590/4024 0.223s 0.001s
im_detect: 2591/4024 0.223s 0.001s
im_detect: 2592/4024 0.223s 0.001s
im_detect: 2593/4024 0.223s 0.001s
im_detect: 2594/4024 0.223s 0.001s
im_detect: 2595/4024 0.223s 0.001s
im_detect: 2596/4024 0.223s 0.001s
im_detect: 2597/4024 0.223s 0.001s
im_detect: 2598/4024 0.223s 0.001s
im_detect: 2599/4024 0.223s 0.001s
im_detect: 2600/4024 0.223s 0.001s
im_detect: 2601/4024 0.223s 0.001s
im_detect: 2602/4024 0.223s 0.001s
im_detect: 2603/4024 0.223s 0.001s
im_detect: 2604/4024 0.223s 0.001s
im_detect: 2605/4024 0.223s 0.001s
im_detect: 2606/4024 0.223s 0.001s
im_detect: 2607/4024 0.223s 0.001s
im_detect: 2608/4024 0.223s 0.001s
im_detect: 2609/4024 0.223s 0.001s
im_detect: 2610/4024 0.223s 0.001s
im_detect: 2611/4024 0.223s 0.001s
im_detect: 2612/4024 0.223s 0.001s
im_detect: 2613/4024 0.223s 0.001s
im_detect: 2614/4024 0.223s 0.001s
im_detect: 2615/4024 0.223s 0.001s
im_detect: 2616/4024 0.223s 0.001s
im_detect: 2617/4024 0.223s 0.001s
im_detect: 2618/4024 0.223s 0.001s
im_detect: 2619/4024 0.223s 0.001s
im_detect: 2620/4024 0.223s 0.001s
im_detect: 2621/4024 0.223s 0.001s
im_detect: 2622/4024 0.223s 0.001s
im_detect: 2623/4024 0.223s 0.001s
im_detect: 2624/4024 0.223s 0.001s
im_detect: 2625/4024 0.223s 0.001s
im_detect: 2626/4024 0.223s 0.001s
im_detect: 2627/4024 0.223s 0.001s
im_detect: 2628/4024 0.223s 0.001s
im_detect: 2629/4024 0.223s 0.001s
im_detect: 2630/4024 0.223s 0.001s
im_detect: 2631/4024 0.223s 0.001s
im_detect: 2632/4024 0.223s 0.001s
im_detect: 2633/4024 0.223s 0.001s
im_detect: 2634/4024 0.223s 0.001s
im_detect: 2635/4024 0.223s 0.001s
im_detect: 2636/4024 0.223s 0.001s
im_detect: 2637/4024 0.223s 0.001s
im_detect: 2638/4024 0.223s 0.001s
im_detect: 2639/4024 0.223s 0.001s
im_detect: 2640/4024 0.223s 0.001s
im_detect: 2641/4024 0.223s 0.001s
im_detect: 2642/4024 0.223s 0.001s
im_detect: 2643/4024 0.223s 0.001s
im_detect: 2644/4024 0.223s 0.001s
im_detect: 2645/4024 0.223s 0.001s
im_detect: 2646/4024 0.223s 0.001s
im_detect: 2647/4024 0.223s 0.001s
im_detect: 2648/4024 0.223s 0.001s
im_detect: 2649/4024 0.223s 0.001s
im_detect: 2650/4024 0.223s 0.001s
im_detect: 2651/4024 0.223s 0.001s
im_detect: 2652/4024 0.223s 0.001s
im_detect: 2653/4024 0.223s 0.001s
im_detect: 2654/4024 0.223s 0.001s
im_detect: 2655/4024 0.223s 0.001s
im_detect: 2656/4024 0.223s 0.001s
im_detect: 2657/4024 0.223s 0.001s
im_detect: 2658/4024 0.223s 0.001s
im_detect: 2659/4024 0.223s 0.001s
im_detect: 2660/4024 0.223s 0.001s
im_detect: 2661/4024 0.223s 0.001s
im_detect: 2662/4024 0.223s 0.001s
im_detect: 2663/4024 0.223s 0.001s
im_detect: 2664/4024 0.223s 0.001s
im_detect: 2665/4024 0.223s 0.001s
im_detect: 2666/4024 0.223s 0.001s
im_detect: 2667/4024 0.223s 0.001s
im_detect: 2668/4024 0.223s 0.001s
im_detect: 2669/4024 0.223s 0.001s
im_detect: 2670/4024 0.223s 0.001s
im_detect: 2671/4024 0.223s 0.001s
im_detect: 2672/4024 0.223s 0.001s
im_detect: 2673/4024 0.223s 0.001s
im_detect: 2674/4024 0.223s 0.001s
im_detect: 2675/4024 0.223s 0.001s
im_detect: 2676/4024 0.223s 0.001s
im_detect: 2677/4024 0.223s 0.001s
im_detect: 2678/4024 0.223s 0.001s
im_detect: 2679/4024 0.223s 0.001s
im_detect: 2680/4024 0.223s 0.001s
im_detect: 2681/4024 0.223s 0.001s
im_detect: 2682/4024 0.223s 0.001s
im_detect: 2683/4024 0.223s 0.001s
im_detect: 2684/4024 0.223s 0.001s
im_detect: 2685/4024 0.223s 0.001s
im_detect: 2686/4024 0.223s 0.001s
im_detect: 2687/4024 0.223s 0.001s
im_detect: 2688/4024 0.223s 0.001s
im_detect: 2689/4024 0.223s 0.001s
im_detect: 2690/4024 0.223s 0.001s
im_detect: 2691/4024 0.223s 0.001s
im_detect: 2692/4024 0.223s 0.001s
im_detect: 2693/4024 0.223s 0.001s
im_detect: 2694/4024 0.223s 0.001s
im_detect: 2695/4024 0.223s 0.001s
im_detect: 2696/4024 0.223s 0.001s
im_detect: 2697/4024 0.223s 0.001s
im_detect: 2698/4024 0.223s 0.001s
im_detect: 2699/4024 0.223s 0.001s
im_detect: 2700/4024 0.223s 0.001s
im_detect: 2701/4024 0.223s 0.001s
im_detect: 2702/4024 0.223s 0.001s
im_detect: 2703/4024 0.223s 0.001s
im_detect: 2704/4024 0.223s 0.001s
im_detect: 2705/4024 0.223s 0.001s
im_detect: 2706/4024 0.223s 0.001s
im_detect: 2707/4024 0.223s 0.001s
im_detect: 2708/4024 0.223s 0.001s
im_detect: 2709/4024 0.223s 0.001s
im_detect: 2710/4024 0.223s 0.001s
im_detect: 2711/4024 0.223s 0.001s
im_detect: 2712/4024 0.223s 0.001s
im_detect: 2713/4024 0.223s 0.001s
im_detect: 2714/4024 0.223s 0.001s
im_detect: 2715/4024 0.223s 0.001s
im_detect: 2716/4024 0.223s 0.001s
im_detect: 2717/4024 0.223s 0.001s
im_detect: 2718/4024 0.223s 0.001s
im_detect: 2719/4024 0.224s 0.001s
im_detect: 2720/4024 0.223s 0.001s
im_detect: 2721/4024 0.224s 0.001s
im_detect: 2722/4024 0.224s 0.001s
im_detect: 2723/4024 0.224s 0.001s
im_detect: 2724/4024 0.224s 0.001s
im_detect: 2725/4024 0.224s 0.001s
im_detect: 2726/4024 0.224s 0.001s
im_detect: 2727/4024 0.224s 0.001s
im_detect: 2728/4024 0.224s 0.001s
im_detect: 2729/4024 0.223s 0.001s
im_detect: 2730/4024 0.223s 0.001s
im_detect: 2731/4024 0.223s 0.001s
im_detect: 2732/4024 0.223s 0.001s
im_detect: 2733/4024 0.223s 0.001s
im_detect: 2734/4024 0.223s 0.001s
im_detect: 2735/4024 0.223s 0.001s
im_detect: 2736/4024 0.223s 0.001s
im_detect: 2737/4024 0.224s 0.001s
im_detect: 2738/4024 0.224s 0.001s
im_detect: 2739/4024 0.224s 0.001s
im_detect: 2740/4024 0.224s 0.001s
im_detect: 2741/4024 0.224s 0.001s
im_detect: 2742/4024 0.224s 0.001s
im_detect: 2743/4024 0.224s 0.001s
im_detect: 2744/4024 0.224s 0.001s
im_detect: 2745/4024 0.224s 0.001s
im_detect: 2746/4024 0.224s 0.001s
im_detect: 2747/4024 0.224s 0.001s
im_detect: 2748/4024 0.224s 0.001s
im_detect: 2749/4024 0.224s 0.001s
im_detect: 2750/4024 0.224s 0.001s
im_detect: 2751/4024 0.224s 0.001s
im_detect: 2752/4024 0.224s 0.001s
im_detect: 2753/4024 0.224s 0.001s
im_detect: 2754/4024 0.224s 0.001s
im_detect: 2755/4024 0.224s 0.001s
im_detect: 2756/4024 0.224s 0.001s
im_detect: 2757/4024 0.224s 0.001s
im_detect: 2758/4024 0.224s 0.001s
im_detect: 2759/4024 0.224s 0.001s
im_detect: 2760/4024 0.224s 0.001s
im_detect: 2761/4024 0.224s 0.001s
im_detect: 2762/4024 0.224s 0.001s
im_detect: 2763/4024 0.224s 0.001s
im_detect: 2764/4024 0.224s 0.001s
im_detect: 2765/4024 0.224s 0.001s
im_detect: 2766/4024 0.224s 0.001s
im_detect: 2767/4024 0.224s 0.001s
im_detect: 2768/4024 0.224s 0.001s
im_detect: 2769/4024 0.224s 0.001s
im_detect: 2770/4024 0.224s 0.001s
im_detect: 2771/4024 0.224s 0.001s
im_detect: 2772/4024 0.224s 0.001s
im_detect: 2773/4024 0.224s 0.001s
im_detect: 2774/4024 0.224s 0.001s
im_detect: 2775/4024 0.224s 0.001s
im_detect: 2776/4024 0.224s 0.001s
im_detect: 2777/4024 0.224s 0.001s
im_detect: 2778/4024 0.224s 0.001s
im_detect: 2779/4024 0.224s 0.001s
im_detect: 2780/4024 0.224s 0.001s
im_detect: 2781/4024 0.224s 0.001s
im_detect: 2782/4024 0.224s 0.001s
im_detect: 2783/4024 0.224s 0.001s
im_detect: 2784/4024 0.224s 0.001s
im_detect: 2785/4024 0.224s 0.001s
im_detect: 2786/4024 0.224s 0.001s
im_detect: 2787/4024 0.224s 0.001s
im_detect: 2788/4024 0.224s 0.001s
im_detect: 2789/4024 0.224s 0.001s
im_detect: 2790/4024 0.224s 0.001s
im_detect: 2791/4024 0.224s 0.001s
im_detect: 2792/4024 0.224s 0.001s
im_detect: 2793/4024 0.224s 0.001s
im_detect: 2794/4024 0.224s 0.001s
im_detect: 2795/4024 0.224s 0.001s
im_detect: 2796/4024 0.224s 0.001s
im_detect: 2797/4024 0.224s 0.001s
im_detect: 2798/4024 0.224s 0.001s
im_detect: 2799/4024 0.224s 0.001s
im_detect: 2800/4024 0.224s 0.001s
im_detect: 2801/4024 0.224s 0.001s
im_detect: 2802/4024 0.224s 0.001s
im_detect: 2803/4024 0.224s 0.001s
im_detect: 2804/4024 0.224s 0.001s
im_detect: 2805/4024 0.224s 0.001s
im_detect: 2806/4024 0.224s 0.001s
im_detect: 2807/4024 0.224s 0.001s
im_detect: 2808/4024 0.224s 0.001s
im_detect: 2809/4024 0.224s 0.001s
im_detect: 2810/4024 0.224s 0.001s
im_detect: 2811/4024 0.224s 0.001s
im_detect: 2812/4024 0.224s 0.001s
im_detect: 2813/4024 0.224s 0.001s
im_detect: 2814/4024 0.224s 0.001s
im_detect: 2815/4024 0.224s 0.001s
im_detect: 2816/4024 0.224s 0.001s
im_detect: 2817/4024 0.224s 0.001s
im_detect: 2818/4024 0.224s 0.001s
im_detect: 2819/4024 0.224s 0.001s
im_detect: 2820/4024 0.224s 0.001s
im_detect: 2821/4024 0.224s 0.001s
im_detect: 2822/4024 0.224s 0.001s
im_detect: 2823/4024 0.224s 0.001s
im_detect: 2824/4024 0.224s 0.001s
im_detect: 2825/4024 0.224s 0.001s
im_detect: 2826/4024 0.224s 0.001s
im_detect: 2827/4024 0.224s 0.001s
im_detect: 2828/4024 0.224s 0.001s
im_detect: 2829/4024 0.224s 0.001s
im_detect: 2830/4024 0.224s 0.001s
im_detect: 2831/4024 0.224s 0.001s
im_detect: 2832/4024 0.224s 0.001s
im_detect: 2833/4024 0.224s 0.001s
im_detect: 2834/4024 0.224s 0.001s
im_detect: 2835/4024 0.224s 0.001s
im_detect: 2836/4024 0.224s 0.001s
im_detect: 2837/4024 0.224s 0.001s
im_detect: 2838/4024 0.224s 0.001s
im_detect: 2839/4024 0.224s 0.001s
im_detect: 2840/4024 0.224s 0.001s
im_detect: 2841/4024 0.224s 0.001s
im_detect: 2842/4024 0.224s 0.001s
im_detect: 2843/4024 0.224s 0.001s
im_detect: 2844/4024 0.224s 0.001s
im_detect: 2845/4024 0.224s 0.001s
im_detect: 2846/4024 0.224s 0.001s
im_detect: 2847/4024 0.224s 0.001s
im_detect: 2848/4024 0.224s 0.001s
im_detect: 2849/4024 0.224s 0.001s
im_detect: 2850/4024 0.224s 0.001s
im_detect: 2851/4024 0.224s 0.001s
im_detect: 2852/4024 0.224s 0.001s
im_detect: 2853/4024 0.224s 0.001s
im_detect: 2854/4024 0.224s 0.001s
im_detect: 2855/4024 0.224s 0.001s
im_detect: 2856/4024 0.224s 0.001s
im_detect: 2857/4024 0.224s 0.001s
im_detect: 2858/4024 0.224s 0.001s
im_detect: 2859/4024 0.224s 0.001s
im_detect: 2860/4024 0.224s 0.001s
im_detect: 2861/4024 0.224s 0.001s
im_detect: 2862/4024 0.224s 0.001s
im_detect: 2863/4024 0.224s 0.001s
im_detect: 2864/4024 0.224s 0.001s
im_detect: 2865/4024 0.224s 0.001s
im_detect: 2866/4024 0.224s 0.001s
im_detect: 2867/4024 0.224s 0.001s
im_detect: 2868/4024 0.224s 0.001s
im_detect: 2869/4024 0.224s 0.001s
im_detect: 2870/4024 0.224s 0.001s
im_detect: 2871/4024 0.224s 0.001s
im_detect: 2872/4024 0.224s 0.001s
im_detect: 2873/4024 0.224s 0.001s
im_detect: 2874/4024 0.224s 0.001s
im_detect: 2875/4024 0.224s 0.001s
im_detect: 2876/4024 0.224s 0.001s
im_detect: 2877/4024 0.224s 0.001s
im_detect: 2878/4024 0.224s 0.001s
im_detect: 2879/4024 0.224s 0.001s
im_detect: 2880/4024 0.224s 0.001s
im_detect: 2881/4024 0.224s 0.001s
im_detect: 2882/4024 0.224s 0.001s
im_detect: 2883/4024 0.224s 0.001s
im_detect: 2884/4024 0.224s 0.001s
im_detect: 2885/4024 0.224s 0.001s
im_detect: 2886/4024 0.224s 0.001s
im_detect: 2887/4024 0.224s 0.001s
im_detect: 2888/4024 0.224s 0.001s
im_detect: 2889/4024 0.224s 0.001s
im_detect: 2890/4024 0.224s 0.001s
im_detect: 2891/4024 0.224s 0.001s
im_detect: 2892/4024 0.224s 0.001s
im_detect: 2893/4024 0.224s 0.001s
im_detect: 2894/4024 0.224s 0.001s
im_detect: 2895/4024 0.224s 0.001s
im_detect: 2896/4024 0.224s 0.001s
im_detect: 2897/4024 0.224s 0.001s
im_detect: 2898/4024 0.224s 0.001s
im_detect: 2899/4024 0.224s 0.001s
im_detect: 2900/4024 0.224s 0.001s
im_detect: 2901/4024 0.224s 0.001s
im_detect: 2902/4024 0.224s 0.001s
im_detect: 2903/4024 0.224s 0.001s
im_detect: 2904/4024 0.224s 0.001s
im_detect: 2905/4024 0.224s 0.001s
im_detect: 2906/4024 0.224s 0.001s
im_detect: 2907/4024 0.224s 0.001s
im_detect: 2908/4024 0.224s 0.001s
im_detect: 2909/4024 0.224s 0.001s
im_detect: 2910/4024 0.224s 0.001s
im_detect: 2911/4024 0.224s 0.001s
im_detect: 2912/4024 0.224s 0.001s
im_detect: 2913/4024 0.224s 0.001s
im_detect: 2914/4024 0.224s 0.001s
im_detect: 2915/4024 0.224s 0.001s
im_detect: 2916/4024 0.224s 0.001s
im_detect: 2917/4024 0.224s 0.001s
im_detect: 2918/4024 0.224s 0.001s
im_detect: 2919/4024 0.224s 0.001s
im_detect: 2920/4024 0.224s 0.001s
im_detect: 2921/4024 0.224s 0.001s
im_detect: 2922/4024 0.224s 0.001s
im_detect: 2923/4024 0.224s 0.001s
im_detect: 2924/4024 0.224s 0.001s
im_detect: 2925/4024 0.224s 0.001s
im_detect: 2926/4024 0.224s 0.001s
im_detect: 2927/4024 0.224s 0.001s
im_detect: 2928/4024 0.224s 0.001s
im_detect: 2929/4024 0.224s 0.001s
im_detect: 2930/4024 0.224s 0.001s
im_detect: 2931/4024 0.224s 0.001s
im_detect: 2932/4024 0.224s 0.001s
im_detect: 2933/4024 0.224s 0.001s
im_detect: 2934/4024 0.224s 0.001s
im_detect: 2935/4024 0.224s 0.001s
im_detect: 2936/4024 0.224s 0.001s
im_detect: 2937/4024 0.224s 0.001s
im_detect: 2938/4024 0.224s 0.001s
im_detect: 2939/4024 0.224s 0.001s
im_detect: 2940/4024 0.224s 0.001s
im_detect: 2941/4024 0.224s 0.001s
im_detect: 2942/4024 0.224s 0.001s
im_detect: 2943/4024 0.224s 0.001s
im_detect: 2944/4024 0.224s 0.001s
im_detect: 2945/4024 0.224s 0.001s
im_detect: 2946/4024 0.224s 0.001s
im_detect: 2947/4024 0.224s 0.001s
im_detect: 2948/4024 0.224s 0.001s
im_detect: 2949/4024 0.224s 0.001s
im_detect: 2950/4024 0.224s 0.001s
im_detect: 2951/4024 0.224s 0.001s
im_detect: 2952/4024 0.224s 0.001s
im_detect: 2953/4024 0.224s 0.001s
im_detect: 2954/4024 0.224s 0.001s
im_detect: 2955/4024 0.224s 0.001s
im_detect: 2956/4024 0.224s 0.001s
im_detect: 2957/4024 0.224s 0.001s
im_detect: 2958/4024 0.224s 0.001s
im_detect: 2959/4024 0.224s 0.001s
im_detect: 2960/4024 0.224s 0.001s
im_detect: 2961/4024 0.224s 0.001s
im_detect: 2962/4024 0.224s 0.001s
im_detect: 2963/4024 0.224s 0.001s
im_detect: 2964/4024 0.224s 0.001s
im_detect: 2965/4024 0.224s 0.001s
im_detect: 2966/4024 0.224s 0.001s
im_detect: 2967/4024 0.224s 0.001s
im_detect: 2968/4024 0.224s 0.001s
im_detect: 2969/4024 0.224s 0.001s
im_detect: 2970/4024 0.224s 0.001s
im_detect: 2971/4024 0.224s 0.001s
im_detect: 2972/4024 0.224s 0.001s
im_detect: 2973/4024 0.224s 0.001s
im_detect: 2974/4024 0.224s 0.001s
im_detect: 2975/4024 0.224s 0.001s
im_detect: 2976/4024 0.224s 0.001s
im_detect: 2977/4024 0.224s 0.001s
im_detect: 2978/4024 0.224s 0.001s
im_detect: 2979/4024 0.224s 0.001s
im_detect: 2980/4024 0.224s 0.001s
im_detect: 2981/4024 0.224s 0.001s
im_detect: 2982/4024 0.224s 0.001s
im_detect: 2983/4024 0.224s 0.001s
im_detect: 2984/4024 0.224s 0.001s
im_detect: 2985/4024 0.224s 0.001s
im_detect: 2986/4024 0.224s 0.001s
im_detect: 2987/4024 0.224s 0.001s
im_detect: 2988/4024 0.224s 0.001s
im_detect: 2989/4024 0.224s 0.001s
im_detect: 2990/4024 0.224s 0.001s
im_detect: 2991/4024 0.224s 0.001s
im_detect: 2992/4024 0.224s 0.001s
im_detect: 2993/4024 0.224s 0.001s
im_detect: 2994/4024 0.224s 0.001s
im_detect: 2995/4024 0.224s 0.001s
im_detect: 2996/4024 0.224s 0.001s
im_detect: 2997/4024 0.224s 0.001s
im_detect: 2998/4024 0.224s 0.001s
im_detect: 2999/4024 0.224s 0.001s
im_detect: 3000/4024 0.224s 0.001s
im_detect: 3001/4024 0.224s 0.001s
im_detect: 3002/4024 0.224s 0.001s
im_detect: 3003/4024 0.224s 0.001s
im_detect: 3004/4024 0.224s 0.001s
im_detect: 3005/4024 0.224s 0.001s
im_detect: 3006/4024 0.224s 0.001s
im_detect: 3007/4024 0.224s 0.001s
im_detect: 3008/4024 0.224s 0.001s
im_detect: 3009/4024 0.224s 0.001s
im_detect: 3010/4024 0.224s 0.001s
im_detect: 3011/4024 0.224s 0.001s
im_detect: 3012/4024 0.224s 0.001s
im_detect: 3013/4024 0.224s 0.001s
im_detect: 3014/4024 0.224s 0.001s
im_detect: 3015/4024 0.224s 0.001s
im_detect: 3016/4024 0.224s 0.001s
im_detect: 3017/4024 0.224s 0.001s
im_detect: 3018/4024 0.224s 0.001s
im_detect: 3019/4024 0.224s 0.001s
im_detect: 3020/4024 0.224s 0.001s
im_detect: 3021/4024 0.224s 0.001s
im_detect: 3022/4024 0.224s 0.001s
im_detect: 3023/4024 0.224s 0.001s
im_detect: 3024/4024 0.224s 0.001s
im_detect: 3025/4024 0.224s 0.001s
im_detect: 3026/4024 0.224s 0.001s
im_detect: 3027/4024 0.224s 0.001s
im_detect: 3028/4024 0.224s 0.001s
im_detect: 3029/4024 0.224s 0.001s
im_detect: 3030/4024 0.224s 0.001s
im_detect: 3031/4024 0.224s 0.001s
im_detect: 3032/4024 0.224s 0.001s
im_detect: 3033/4024 0.224s 0.001s
im_detect: 3034/4024 0.224s 0.001s
im_detect: 3035/4024 0.224s 0.001s
im_detect: 3036/4024 0.224s 0.001s
im_detect: 3037/4024 0.224s 0.001s
im_detect: 3038/4024 0.224s 0.001s
im_detect: 3039/4024 0.224s 0.001s
im_detect: 3040/4024 0.224s 0.001s
im_detect: 3041/4024 0.224s 0.001s
im_detect: 3042/4024 0.224s 0.001s
im_detect: 3043/4024 0.224s 0.001s
im_detect: 3044/4024 0.224s 0.001s
im_detect: 3045/4024 0.224s 0.001s
im_detect: 3046/4024 0.224s 0.001s
im_detect: 3047/4024 0.224s 0.001s
im_detect: 3048/4024 0.224s 0.001s
im_detect: 3049/4024 0.224s 0.001s
im_detect: 3050/4024 0.224s 0.001s
im_detect: 3051/4024 0.224s 0.001s
im_detect: 3052/4024 0.224s 0.001s
im_detect: 3053/4024 0.224s 0.001s
im_detect: 3054/4024 0.224s 0.001s
im_detect: 3055/4024 0.224s 0.001s
im_detect: 3056/4024 0.224s 0.001s
im_detect: 3057/4024 0.224s 0.001s
im_detect: 3058/4024 0.224s 0.001s
im_detect: 3059/4024 0.224s 0.001s
im_detect: 3060/4024 0.224s 0.001s
im_detect: 3061/4024 0.224s 0.001s
im_detect: 3062/4024 0.224s 0.001s
im_detect: 3063/4024 0.224s 0.001s
im_detect: 3064/4024 0.224s 0.001s
im_detect: 3065/4024 0.224s 0.001s
im_detect: 3066/4024 0.224s 0.001s
im_detect: 3067/4024 0.224s 0.001s
im_detect: 3068/4024 0.224s 0.001s
im_detect: 3069/4024 0.224s 0.001s
im_detect: 3070/4024 0.224s 0.001s
im_detect: 3071/4024 0.224s 0.001s
im_detect: 3072/4024 0.224s 0.001s
im_detect: 3073/4024 0.224s 0.001s
im_detect: 3074/4024 0.224s 0.001s
im_detect: 3075/4024 0.224s 0.001s
im_detect: 3076/4024 0.224s 0.001s
im_detect: 3077/4024 0.224s 0.001s
im_detect: 3078/4024 0.224s 0.001s
im_detect: 3079/4024 0.224s 0.001s
im_detect: 3080/4024 0.224s 0.001s
im_detect: 3081/4024 0.224s 0.001s
im_detect: 3082/4024 0.224s 0.001s
im_detect: 3083/4024 0.224s 0.001s
im_detect: 3084/4024 0.224s 0.001s
im_detect: 3085/4024 0.224s 0.001s
im_detect: 3086/4024 0.224s 0.001s
im_detect: 3087/4024 0.224s 0.001s
im_detect: 3088/4024 0.224s 0.001s
im_detect: 3089/4024 0.224s 0.001s
im_detect: 3090/4024 0.224s 0.001s
im_detect: 3091/4024 0.224s 0.001s
im_detect: 3092/4024 0.224s 0.001s
im_detect: 3093/4024 0.224s 0.001s
im_detect: 3094/4024 0.224s 0.001s
im_detect: 3095/4024 0.224s 0.001s
im_detect: 3096/4024 0.224s 0.001s
im_detect: 3097/4024 0.224s 0.001s
im_detect: 3098/4024 0.224s 0.001s
im_detect: 3099/4024 0.224s 0.001s
im_detect: 3100/4024 0.224s 0.001s
im_detect: 3101/4024 0.224s 0.001s
im_detect: 3102/4024 0.224s 0.001s
im_detect: 3103/4024 0.224s 0.001s
im_detect: 3104/4024 0.224s 0.001s
im_detect: 3105/4024 0.224s 0.001s
im_detect: 3106/4024 0.224s 0.001s
im_detect: 3107/4024 0.224s 0.001s
im_detect: 3108/4024 0.224s 0.001s
im_detect: 3109/4024 0.224s 0.001s
im_detect: 3110/4024 0.224s 0.001s
im_detect: 3111/4024 0.224s 0.001s
im_detect: 3112/4024 0.224s 0.001s
im_detect: 3113/4024 0.224s 0.001s
im_detect: 3114/4024 0.224s 0.001s
im_detect: 3115/4024 0.224s 0.001s
im_detect: 3116/4024 0.224s 0.001s
im_detect: 3117/4024 0.224s 0.001s
im_detect: 3118/4024 0.224s 0.001s
im_detect: 3119/4024 0.224s 0.001s
im_detect: 3120/4024 0.224s 0.001s
im_detect: 3121/4024 0.224s 0.001s
im_detect: 3122/4024 0.224s 0.001s
im_detect: 3123/4024 0.224s 0.001s
im_detect: 3124/4024 0.224s 0.001s
im_detect: 3125/4024 0.224s 0.001s
im_detect: 3126/4024 0.224s 0.001s
im_detect: 3127/4024 0.224s 0.001s
im_detect: 3128/4024 0.224s 0.001s
im_detect: 3129/4024 0.224s 0.001s
im_detect: 3130/4024 0.224s 0.001s
im_detect: 3131/4024 0.224s 0.001s
im_detect: 3132/4024 0.224s 0.001s
im_detect: 3133/4024 0.224s 0.001s
im_detect: 3134/4024 0.224s 0.001s
im_detect: 3135/4024 0.224s 0.001s
im_detect: 3136/4024 0.224s 0.001s
im_detect: 3137/4024 0.224s 0.001s
im_detect: 3138/4024 0.224s 0.001s
im_detect: 3139/4024 0.224s 0.001s
im_detect: 3140/4024 0.224s 0.001s
im_detect: 3141/4024 0.224s 0.001s
im_detect: 3142/4024 0.224s 0.001s
im_detect: 3143/4024 0.224s 0.001s
im_detect: 3144/4024 0.224s 0.001s
im_detect: 3145/4024 0.224s 0.001s
im_detect: 3146/4024 0.224s 0.001s
im_detect: 3147/4024 0.224s 0.001s
im_detect: 3148/4024 0.224s 0.001s
im_detect: 3149/4024 0.224s 0.001s
im_detect: 3150/4024 0.224s 0.001s
im_detect: 3151/4024 0.224s 0.001s
im_detect: 3152/4024 0.224s 0.001s
im_detect: 3153/4024 0.224s 0.001s
im_detect: 3154/4024 0.224s 0.001s
im_detect: 3155/4024 0.224s 0.001s
im_detect: 3156/4024 0.224s 0.001s
im_detect: 3157/4024 0.224s 0.001s
im_detect: 3158/4024 0.224s 0.001s
im_detect: 3159/4024 0.224s 0.001s
im_detect: 3160/4024 0.224s 0.001s
im_detect: 3161/4024 0.224s 0.001s
im_detect: 3162/4024 0.224s 0.001s
im_detect: 3163/4024 0.224s 0.001s
im_detect: 3164/4024 0.224s 0.001s
im_detect: 3165/4024 0.224s 0.001s
im_detect: 3166/4024 0.224s 0.001s
im_detect: 3167/4024 0.224s 0.001s
im_detect: 3168/4024 0.224s 0.001s
im_detect: 3169/4024 0.224s 0.001s
im_detect: 3170/4024 0.224s 0.001s
im_detect: 3171/4024 0.224s 0.001s
im_detect: 3172/4024 0.224s 0.001s
im_detect: 3173/4024 0.224s 0.001s
im_detect: 3174/4024 0.224s 0.001s
im_detect: 3175/4024 0.224s 0.001s
im_detect: 3176/4024 0.224s 0.001s
im_detect: 3177/4024 0.224s 0.001s
im_detect: 3178/4024 0.224s 0.001s
im_detect: 3179/4024 0.224s 0.001s
im_detect: 3180/4024 0.224s 0.001s
im_detect: 3181/4024 0.224s 0.001s
im_detect: 3182/4024 0.224s 0.001s
im_detect: 3183/4024 0.224s 0.001s
im_detect: 3184/4024 0.224s 0.001s
im_detect: 3185/4024 0.224s 0.001s
im_detect: 3186/4024 0.224s 0.001s
im_detect: 3187/4024 0.224s 0.001s
im_detect: 3188/4024 0.224s 0.001s
im_detect: 3189/4024 0.224s 0.001s
im_detect: 3190/4024 0.224s 0.001s
im_detect: 3191/4024 0.224s 0.001s
im_detect: 3192/4024 0.224s 0.001s
im_detect: 3193/4024 0.224s 0.001s
im_detect: 3194/4024 0.224s 0.001s
im_detect: 3195/4024 0.224s 0.001s
im_detect: 3196/4024 0.224s 0.001s
im_detect: 3197/4024 0.224s 0.001s
im_detect: 3198/4024 0.224s 0.001s
im_detect: 3199/4024 0.224s 0.001s
im_detect: 3200/4024 0.224s 0.001s
im_detect: 3201/4024 0.224s 0.001s
im_detect: 3202/4024 0.224s 0.001s
im_detect: 3203/4024 0.224s 0.001s
im_detect: 3204/4024 0.224s 0.001s
im_detect: 3205/4024 0.224s 0.001s
im_detect: 3206/4024 0.224s 0.001s
im_detect: 3207/4024 0.224s 0.001s
im_detect: 3208/4024 0.224s 0.001s
im_detect: 3209/4024 0.224s 0.001s
im_detect: 3210/4024 0.224s 0.001s
im_detect: 3211/4024 0.224s 0.001s
im_detect: 3212/4024 0.224s 0.001s
im_detect: 3213/4024 0.224s 0.001s
im_detect: 3214/4024 0.224s 0.001s
im_detect: 3215/4024 0.224s 0.001s
im_detect: 3216/4024 0.224s 0.001s
im_detect: 3217/4024 0.224s 0.001s
im_detect: 3218/4024 0.224s 0.001s
im_detect: 3219/4024 0.224s 0.001s
im_detect: 3220/4024 0.224s 0.001s
im_detect: 3221/4024 0.224s 0.001s
im_detect: 3222/4024 0.224s 0.001s
im_detect: 3223/4024 0.224s 0.001s
im_detect: 3224/4024 0.224s 0.001s
im_detect: 3225/4024 0.224s 0.001s
im_detect: 3226/4024 0.224s 0.001s
im_detect: 3227/4024 0.224s 0.001s
im_detect: 3228/4024 0.224s 0.001s
im_detect: 3229/4024 0.224s 0.001s
im_detect: 3230/4024 0.224s 0.001s
im_detect: 3231/4024 0.224s 0.001s
im_detect: 3232/4024 0.224s 0.001s
im_detect: 3233/4024 0.224s 0.001s
im_detect: 3234/4024 0.224s 0.001s
im_detect: 3235/4024 0.224s 0.001s
im_detect: 3236/4024 0.224s 0.001s
im_detect: 3237/4024 0.224s 0.001s
im_detect: 3238/4024 0.224s 0.001s
im_detect: 3239/4024 0.224s 0.001s
im_detect: 3240/4024 0.224s 0.001s
im_detect: 3241/4024 0.224s 0.001s
im_detect: 3242/4024 0.224s 0.001s
im_detect: 3243/4024 0.224s 0.001s
im_detect: 3244/4024 0.224s 0.001s
im_detect: 3245/4024 0.224s 0.001s
im_detect: 3246/4024 0.224s 0.001s
im_detect: 3247/4024 0.224s 0.001s
im_detect: 3248/4024 0.224s 0.001s
im_detect: 3249/4024 0.224s 0.001s
im_detect: 3250/4024 0.224s 0.001s
im_detect: 3251/4024 0.224s 0.001s
im_detect: 3252/4024 0.224s 0.001s
im_detect: 3253/4024 0.224s 0.001s
im_detect: 3254/4024 0.224s 0.001s
im_detect: 3255/4024 0.224s 0.001s
im_detect: 3256/4024 0.224s 0.001s
im_detect: 3257/4024 0.224s 0.001s
im_detect: 3258/4024 0.224s 0.001s
im_detect: 3259/4024 0.224s 0.001s
im_detect: 3260/4024 0.224s 0.001s
im_detect: 3261/4024 0.224s 0.001s
im_detect: 3262/4024 0.224s 0.001s
im_detect: 3263/4024 0.224s 0.001s
im_detect: 3264/4024 0.224s 0.001s
im_detect: 3265/4024 0.224s 0.001s
im_detect: 3266/4024 0.224s 0.001s
im_detect: 3267/4024 0.224s 0.001s
im_detect: 3268/4024 0.224s 0.001s
im_detect: 3269/4024 0.224s 0.001s
im_detect: 3270/4024 0.224s 0.001s
im_detect: 3271/4024 0.224s 0.001s
im_detect: 3272/4024 0.224s 0.001s
im_detect: 3273/4024 0.224s 0.001s
im_detect: 3274/4024 0.224s 0.001s
im_detect: 3275/4024 0.224s 0.001s
im_detect: 3276/4024 0.224s 0.001s
im_detect: 3277/4024 0.224s 0.001s
im_detect: 3278/4024 0.224s 0.001s
im_detect: 3279/4024 0.224s 0.001s
im_detect: 3280/4024 0.224s 0.001s
im_detect: 3281/4024 0.224s 0.001s
im_detect: 3282/4024 0.224s 0.001s
im_detect: 3283/4024 0.224s 0.001s
im_detect: 3284/4024 0.224s 0.001s
im_detect: 3285/4024 0.224s 0.001s
im_detect: 3286/4024 0.224s 0.001s
im_detect: 3287/4024 0.224s 0.001s
im_detect: 3288/4024 0.224s 0.001s
im_detect: 3289/4024 0.224s 0.001s
im_detect: 3290/4024 0.224s 0.001s
im_detect: 3291/4024 0.224s 0.001s
im_detect: 3292/4024 0.224s 0.001s
im_detect: 3293/4024 0.224s 0.001s
im_detect: 3294/4024 0.224s 0.001s
im_detect: 3295/4024 0.224s 0.001s
im_detect: 3296/4024 0.224s 0.001s
im_detect: 3297/4024 0.224s 0.001s
im_detect: 3298/4024 0.224s 0.001s
im_detect: 3299/4024 0.224s 0.001s
im_detect: 3300/4024 0.224s 0.001s
im_detect: 3301/4024 0.224s 0.001s
im_detect: 3302/4024 0.224s 0.001s
im_detect: 3303/4024 0.224s 0.001s
im_detect: 3304/4024 0.224s 0.001s
im_detect: 3305/4024 0.224s 0.001s
im_detect: 3306/4024 0.224s 0.001s
im_detect: 3307/4024 0.224s 0.001s
im_detect: 3308/4024 0.224s 0.001s
im_detect: 3309/4024 0.224s 0.001s
im_detect: 3310/4024 0.224s 0.001s
im_detect: 3311/4024 0.224s 0.001s
im_detect: 3312/4024 0.224s 0.001s
im_detect: 3313/4024 0.224s 0.001s
im_detect: 3314/4024 0.224s 0.001s
im_detect: 3315/4024 0.224s 0.001s
im_detect: 3316/4024 0.224s 0.001s
im_detect: 3317/4024 0.224s 0.001s
im_detect: 3318/4024 0.224s 0.001s
im_detect: 3319/4024 0.224s 0.001s
im_detect: 3320/4024 0.224s 0.001s
im_detect: 3321/4024 0.224s 0.001s
im_detect: 3322/4024 0.224s 0.001s
im_detect: 3323/4024 0.224s 0.001s
im_detect: 3324/4024 0.224s 0.001s
im_detect: 3325/4024 0.224s 0.001s
im_detect: 3326/4024 0.224s 0.001s
im_detect: 3327/4024 0.224s 0.001s
im_detect: 3328/4024 0.224s 0.001s
im_detect: 3329/4024 0.224s 0.001s
im_detect: 3330/4024 0.224s 0.001s
im_detect: 3331/4024 0.224s 0.001s
im_detect: 3332/4024 0.224s 0.001s
im_detect: 3333/4024 0.224s 0.001s
im_detect: 3334/4024 0.224s 0.001s
im_detect: 3335/4024 0.224s 0.001s
im_detect: 3336/4024 0.224s 0.001s
im_detect: 3337/4024 0.224s 0.001s
im_detect: 3338/4024 0.224s 0.001s
im_detect: 3339/4024 0.224s 0.001s
im_detect: 3340/4024 0.224s 0.001s
im_detect: 3341/4024 0.224s 0.001s
im_detect: 3342/4024 0.224s 0.001s
im_detect: 3343/4024 0.224s 0.001s
im_detect: 3344/4024 0.224s 0.001s
im_detect: 3345/4024 0.224s 0.001s
im_detect: 3346/4024 0.224s 0.001s
im_detect: 3347/4024 0.224s 0.001s
im_detect: 3348/4024 0.224s 0.001s
im_detect: 3349/4024 0.224s 0.001s
im_detect: 3350/4024 0.224s 0.001s
im_detect: 3351/4024 0.224s 0.001s
im_detect: 3352/4024 0.224s 0.001s
im_detect: 3353/4024 0.224s 0.001s
im_detect: 3354/4024 0.224s 0.001s
im_detect: 3355/4024 0.224s 0.001s
im_detect: 3356/4024 0.224s 0.001s
im_detect: 3357/4024 0.224s 0.001s
im_detect: 3358/4024 0.224s 0.001s
im_detect: 3359/4024 0.224s 0.001s
im_detect: 3360/4024 0.224s 0.001s
im_detect: 3361/4024 0.224s 0.001s
im_detect: 3362/4024 0.224s 0.001s
im_detect: 3363/4024 0.224s 0.001s
im_detect: 3364/4024 0.224s 0.001s
im_detect: 3365/4024 0.224s 0.001s
im_detect: 3366/4024 0.224s 0.001s
im_detect: 3367/4024 0.224s 0.001s
im_detect: 3368/4024 0.224s 0.001s
im_detect: 3369/4024 0.224s 0.001s
im_detect: 3370/4024 0.224s 0.001s
im_detect: 3371/4024 0.224s 0.001s
im_detect: 3372/4024 0.224s 0.001s
im_detect: 3373/4024 0.224s 0.001s
im_detect: 3374/4024 0.224s 0.001s
im_detect: 3375/4024 0.224s 0.001s
im_detect: 3376/4024 0.224s 0.001s
im_detect: 3377/4024 0.223s 0.001s
im_detect: 3378/4024 0.223s 0.001s
im_detect: 3379/4024 0.223s 0.001s
im_detect: 3380/4024 0.223s 0.001s
im_detect: 3381/4024 0.223s 0.001s
im_detect: 3382/4024 0.223s 0.001s
im_detect: 3383/4024 0.223s 0.001s
im_detect: 3384/4024 0.223s 0.001s
im_detect: 3385/4024 0.223s 0.001s
im_detect: 3386/4024 0.223s 0.001s
im_detect: 3387/4024 0.223s 0.001s
im_detect: 3388/4024 0.223s 0.001s
im_detect: 3389/4024 0.223s 0.001s
im_detect: 3390/4024 0.223s 0.001s
im_detect: 3391/4024 0.223s 0.001s
im_detect: 3392/4024 0.223s 0.001s
im_detect: 3393/4024 0.223s 0.001s
im_detect: 3394/4024 0.223s 0.001s
im_detect: 3395/4024 0.223s 0.001s
im_detect: 3396/4024 0.223s 0.001s
im_detect: 3397/4024 0.223s 0.001s
im_detect: 3398/4024 0.223s 0.001s
im_detect: 3399/4024 0.223s 0.001s
im_detect: 3400/4024 0.223s 0.001s
im_detect: 3401/4024 0.223s 0.001s
im_detect: 3402/4024 0.223s 0.001s
im_detect: 3403/4024 0.223s 0.001s
im_detect: 3404/4024 0.223s 0.001s
im_detect: 3405/4024 0.223s 0.001s
im_detect: 3406/4024 0.223s 0.001s
im_detect: 3407/4024 0.223s 0.001s
im_detect: 3408/4024 0.223s 0.001s
im_detect: 3409/4024 0.223s 0.001s
im_detect: 3410/4024 0.223s 0.001s
im_detect: 3411/4024 0.223s 0.001s
im_detect: 3412/4024 0.223s 0.001s
im_detect: 3413/4024 0.223s 0.001s
im_detect: 3414/4024 0.223s 0.001s
im_detect: 3415/4024 0.223s 0.001s
im_detect: 3416/4024 0.223s 0.001s
im_detect: 3417/4024 0.223s 0.001s
im_detect: 3418/4024 0.223s 0.001s
im_detect: 3419/4024 0.223s 0.001s
im_detect: 3420/4024 0.223s 0.001s
im_detect: 3421/4024 0.223s 0.001s
im_detect: 3422/4024 0.223s 0.001s
im_detect: 3423/4024 0.223s 0.001s
im_detect: 3424/4024 0.223s 0.001s
im_detect: 3425/4024 0.223s 0.001s
im_detect: 3426/4024 0.223s 0.001s
im_detect: 3427/4024 0.223s 0.001s
im_detect: 3428/4024 0.223s 0.001s
im_detect: 3429/4024 0.223s 0.001s
im_detect: 3430/4024 0.223s 0.001s
im_detect: 3431/4024 0.223s 0.001s
im_detect: 3432/4024 0.223s 0.001s
im_detect: 3433/4024 0.223s 0.001s
im_detect: 3434/4024 0.223s 0.001s
im_detect: 3435/4024 0.223s 0.001s
im_detect: 3436/4024 0.223s 0.001s
im_detect: 3437/4024 0.223s 0.001s
im_detect: 3438/4024 0.223s 0.001s
im_detect: 3439/4024 0.223s 0.001s
im_detect: 3440/4024 0.223s 0.001s
im_detect: 3441/4024 0.223s 0.001s
im_detect: 3442/4024 0.223s 0.001s
im_detect: 3443/4024 0.223s 0.001s
im_detect: 3444/4024 0.223s 0.001s
im_detect: 3445/4024 0.223s 0.001s
im_detect: 3446/4024 0.223s 0.001s
im_detect: 3447/4024 0.223s 0.001s
im_detect: 3448/4024 0.223s 0.001s
im_detect: 3449/4024 0.223s 0.001s
im_detect: 3450/4024 0.223s 0.001s
im_detect: 3451/4024 0.223s 0.001s
im_detect: 3452/4024 0.223s 0.001s
im_detect: 3453/4024 0.223s 0.001s
im_detect: 3454/4024 0.223s 0.001s
im_detect: 3455/4024 0.223s 0.001s
im_detect: 3456/4024 0.223s 0.001s
im_detect: 3457/4024 0.223s 0.001s
im_detect: 3458/4024 0.223s 0.001s
im_detect: 3459/4024 0.223s 0.001s
im_detect: 3460/4024 0.223s 0.001s
im_detect: 3461/4024 0.223s 0.001s
im_detect: 3462/4024 0.223s 0.001s
im_detect: 3463/4024 0.223s 0.001s
im_detect: 3464/4024 0.223s 0.001s
im_detect: 3465/4024 0.223s 0.001s
im_detect: 3466/4024 0.223s 0.001s
im_detect: 3467/4024 0.223s 0.001s
im_detect: 3468/4024 0.223s 0.001s
im_detect: 3469/4024 0.223s 0.001s
im_detect: 3470/4024 0.223s 0.001s
im_detect: 3471/4024 0.223s 0.001s
im_detect: 3472/4024 0.223s 0.001s
im_detect: 3473/4024 0.223s 0.001s
im_detect: 3474/4024 0.223s 0.001s
im_detect: 3475/4024 0.223s 0.001s
im_detect: 3476/4024 0.223s 0.001s
im_detect: 3477/4024 0.223s 0.001s
im_detect: 3478/4024 0.223s 0.001s
im_detect: 3479/4024 0.223s 0.001s
im_detect: 3480/4024 0.223s 0.001s
im_detect: 3481/4024 0.223s 0.001s
im_detect: 3482/4024 0.223s 0.001s
im_detect: 3483/4024 0.223s 0.001s
im_detect: 3484/4024 0.223s 0.001s
im_detect: 3485/4024 0.223s 0.001s
im_detect: 3486/4024 0.223s 0.001s
im_detect: 3487/4024 0.223s 0.001s
im_detect: 3488/4024 0.223s 0.001s
im_detect: 3489/4024 0.223s 0.001s
im_detect: 3490/4024 0.223s 0.001s
im_detect: 3491/4024 0.223s 0.001s
im_detect: 3492/4024 0.223s 0.001s
im_detect: 3493/4024 0.223s 0.001s
im_detect: 3494/4024 0.223s 0.001s
im_detect: 3495/4024 0.223s 0.001s
im_detect: 3496/4024 0.223s 0.001s
im_detect: 3497/4024 0.223s 0.001s
im_detect: 3498/4024 0.223s 0.001s
im_detect: 3499/4024 0.223s 0.001s
im_detect: 3500/4024 0.223s 0.001s
im_detect: 3501/4024 0.223s 0.001s
im_detect: 3502/4024 0.223s 0.001s
im_detect: 3503/4024 0.223s 0.001s
im_detect: 3504/4024 0.223s 0.001s
im_detect: 3505/4024 0.223s 0.001s
im_detect: 3506/4024 0.223s 0.001s
im_detect: 3507/4024 0.223s 0.001s
im_detect: 3508/4024 0.223s 0.001s
im_detect: 3509/4024 0.223s 0.001s
im_detect: 3510/4024 0.223s 0.001s
im_detect: 3511/4024 0.223s 0.001s
im_detect: 3512/4024 0.223s 0.001s
im_detect: 3513/4024 0.223s 0.001s
im_detect: 3514/4024 0.223s 0.001s
im_detect: 3515/4024 0.223s 0.001s
im_detect: 3516/4024 0.223s 0.001s
im_detect: 3517/4024 0.223s 0.001s
im_detect: 3518/4024 0.223s 0.001s
im_detect: 3519/4024 0.223s 0.001s
im_detect: 3520/4024 0.223s 0.001s
im_detect: 3521/4024 0.223s 0.001s
im_detect: 3522/4024 0.223s 0.001s
im_detect: 3523/4024 0.223s 0.001s
im_detect: 3524/4024 0.223s 0.001s
im_detect: 3525/4024 0.223s 0.001s
im_detect: 3526/4024 0.223s 0.001s
im_detect: 3527/4024 0.223s 0.001s
im_detect: 3528/4024 0.223s 0.001s
im_detect: 3529/4024 0.223s 0.001s
im_detect: 3530/4024 0.223s 0.001s
im_detect: 3531/4024 0.223s 0.001s
im_detect: 3532/4024 0.223s 0.001s
im_detect: 3533/4024 0.223s 0.001s
im_detect: 3534/4024 0.223s 0.001s
im_detect: 3535/4024 0.223s 0.001s
im_detect: 3536/4024 0.223s 0.001s
im_detect: 3537/4024 0.223s 0.001s
im_detect: 3538/4024 0.223s 0.001s
im_detect: 3539/4024 0.223s 0.001s
im_detect: 3540/4024 0.223s 0.001s
im_detect: 3541/4024 0.223s 0.001s
im_detect: 3542/4024 0.223s 0.001s
im_detect: 3543/4024 0.223s 0.001s
im_detect: 3544/4024 0.223s 0.001s
im_detect: 3545/4024 0.223s 0.001s
im_detect: 3546/4024 0.223s 0.001s
im_detect: 3547/4024 0.223s 0.001s
im_detect: 3548/4024 0.223s 0.001s
im_detect: 3549/4024 0.223s 0.001s
im_detect: 3550/4024 0.223s 0.001s
im_detect: 3551/4024 0.223s 0.001s
im_detect: 3552/4024 0.223s 0.001s
im_detect: 3553/4024 0.223s 0.001s
im_detect: 3554/4024 0.223s 0.001s
im_detect: 3555/4024 0.223s 0.001s
im_detect: 3556/4024 0.223s 0.001s
im_detect: 3557/4024 0.223s 0.001s
im_detect: 3558/4024 0.223s 0.001s
im_detect: 3559/4024 0.223s 0.001s
im_detect: 3560/4024 0.223s 0.001s
im_detect: 3561/4024 0.223s 0.001s
im_detect: 3562/4024 0.223s 0.001s
im_detect: 3563/4024 0.223s 0.001s
im_detect: 3564/4024 0.223s 0.001s
im_detect: 3565/4024 0.223s 0.001s
im_detect: 3566/4024 0.223s 0.001s
im_detect: 3567/4024 0.223s 0.001s
im_detect: 3568/4024 0.223s 0.001s
im_detect: 3569/4024 0.223s 0.001s
im_detect: 3570/4024 0.223s 0.001s
im_detect: 3571/4024 0.223s 0.001s
im_detect: 3572/4024 0.223s 0.001s
im_detect: 3573/4024 0.223s 0.001s
im_detect: 3574/4024 0.223s 0.001s
im_detect: 3575/4024 0.223s 0.001s
im_detect: 3576/4024 0.223s 0.001s
im_detect: 3577/4024 0.223s 0.001s
im_detect: 3578/4024 0.223s 0.001s
im_detect: 3579/4024 0.223s 0.001s
im_detect: 3580/4024 0.223s 0.001s
im_detect: 3581/4024 0.223s 0.001s
im_detect: 3582/4024 0.223s 0.001s
im_detect: 3583/4024 0.223s 0.001s
im_detect: 3584/4024 0.223s 0.001s
im_detect: 3585/4024 0.223s 0.001s
im_detect: 3586/4024 0.223s 0.001s
im_detect: 3587/4024 0.223s 0.001s
im_detect: 3588/4024 0.223s 0.001s
im_detect: 3589/4024 0.223s 0.001s
im_detect: 3590/4024 0.223s 0.001s
im_detect: 3591/4024 0.223s 0.001s
im_detect: 3592/4024 0.223s 0.001s
im_detect: 3593/4024 0.223s 0.001s
im_detect: 3594/4024 0.223s 0.001s
im_detect: 3595/4024 0.223s 0.001s
im_detect: 3596/4024 0.223s 0.001s
im_detect: 3597/4024 0.223s 0.001s
im_detect: 3598/4024 0.223s 0.001s
im_detect: 3599/4024 0.223s 0.001s
im_detect: 3600/4024 0.223s 0.001s
im_detect: 3601/4024 0.223s 0.001s
im_detect: 3602/4024 0.223s 0.001s
im_detect: 3603/4024 0.223s 0.001s
im_detect: 3604/4024 0.223s 0.001s
im_detect: 3605/4024 0.223s 0.001s
im_detect: 3606/4024 0.223s 0.001s
im_detect: 3607/4024 0.223s 0.001s
im_detect: 3608/4024 0.223s 0.001s
im_detect: 3609/4024 0.223s 0.001s
im_detect: 3610/4024 0.223s 0.001s
im_detect: 3611/4024 0.223s 0.001s
im_detect: 3612/4024 0.223s 0.001s
im_detect: 3613/4024 0.223s 0.001s
im_detect: 3614/4024 0.223s 0.001s
im_detect: 3615/4024 0.223s 0.001s
im_detect: 3616/4024 0.223s 0.001s
im_detect: 3617/4024 0.223s 0.001s
im_detect: 3618/4024 0.223s 0.001s
im_detect: 3619/4024 0.223s 0.001s
im_detect: 3620/4024 0.223s 0.001s
im_detect: 3621/4024 0.223s 0.001s
im_detect: 3622/4024 0.223s 0.001s
im_detect: 3623/4024 0.223s 0.001s
im_detect: 3624/4024 0.223s 0.001s
im_detect: 3625/4024 0.223s 0.001s
im_detect: 3626/4024 0.223s 0.001s
im_detect: 3627/4024 0.223s 0.001s
im_detect: 3628/4024 0.223s 0.001s
im_detect: 3629/4024 0.223s 0.001s
im_detect: 3630/4024 0.223s 0.001s
im_detect: 3631/4024 0.223s 0.001s
im_detect: 3632/4024 0.223s 0.001s
im_detect: 3633/4024 0.223s 0.001s
im_detect: 3634/4024 0.223s 0.001s
im_detect: 3635/4024 0.223s 0.001s
im_detect: 3636/4024 0.223s 0.001s
im_detect: 3637/4024 0.223s 0.001s
im_detect: 3638/4024 0.223s 0.001s
im_detect: 3639/4024 0.223s 0.001s
im_detect: 3640/4024 0.223s 0.001s
im_detect: 3641/4024 0.223s 0.001s
im_detect: 3642/4024 0.223s 0.001s
im_detect: 3643/4024 0.223s 0.001s
im_detect: 3644/4024 0.223s 0.001s
im_detect: 3645/4024 0.223s 0.001s
im_detect: 3646/4024 0.223s 0.001s
im_detect: 3647/4024 0.223s 0.001s
im_detect: 3648/4024 0.223s 0.001s
im_detect: 3649/4024 0.223s 0.001s
im_detect: 3650/4024 0.223s 0.001s
im_detect: 3651/4024 0.223s 0.001s
im_detect: 3652/4024 0.223s 0.001s
im_detect: 3653/4024 0.223s 0.001s
im_detect: 3654/4024 0.223s 0.001s
im_detect: 3655/4024 0.223s 0.001s
im_detect: 3656/4024 0.223s 0.001s
im_detect: 3657/4024 0.223s 0.001s
im_detect: 3658/4024 0.223s 0.001s
im_detect: 3659/4024 0.223s 0.001s
im_detect: 3660/4024 0.223s 0.001s
im_detect: 3661/4024 0.223s 0.001s
im_detect: 3662/4024 0.223s 0.001s
im_detect: 3663/4024 0.223s 0.001s
im_detect: 3664/4024 0.223s 0.001s
im_detect: 3665/4024 0.223s 0.001s
im_detect: 3666/4024 0.223s 0.001s
im_detect: 3667/4024 0.223s 0.001s
im_detect: 3668/4024 0.223s 0.001s
im_detect: 3669/4024 0.223s 0.001s
im_detect: 3670/4024 0.223s 0.001s
im_detect: 3671/4024 0.223s 0.001s
im_detect: 3672/4024 0.223s 0.001s
im_detect: 3673/4024 0.223s 0.001s
im_detect: 3674/4024 0.223s 0.001s
im_detect: 3675/4024 0.223s 0.001s
im_detect: 3676/4024 0.223s 0.001s
im_detect: 3677/4024 0.223s 0.001s
im_detect: 3678/4024 0.223s 0.001s
im_detect: 3679/4024 0.223s 0.001s
im_detect: 3680/4024 0.223s 0.001s
im_detect: 3681/4024 0.223s 0.001s
im_detect: 3682/4024 0.223s 0.001s
im_detect: 3683/4024 0.223s 0.001s
im_detect: 3684/4024 0.223s 0.001s
im_detect: 3685/4024 0.223s 0.001s
im_detect: 3686/4024 0.223s 0.001s
im_detect: 3687/4024 0.223s 0.001s
im_detect: 3688/4024 0.223s 0.001s
im_detect: 3689/4024 0.223s 0.001s
im_detect: 3690/4024 0.223s 0.001s
im_detect: 3691/4024 0.223s 0.001s
im_detect: 3692/4024 0.223s 0.001s
im_detect: 3693/4024 0.223s 0.001s
im_detect: 3694/4024 0.223s 0.001s
im_detect: 3695/4024 0.223s 0.001s
im_detect: 3696/4024 0.223s 0.001s
im_detect: 3697/4024 0.223s 0.001s
im_detect: 3698/4024 0.223s 0.001s
im_detect: 3699/4024 0.223s 0.001s
im_detect: 3700/4024 0.223s 0.001s
im_detect: 3701/4024 0.223s 0.001s
im_detect: 3702/4024 0.223s 0.001s
im_detect: 3703/4024 0.223s 0.001s
im_detect: 3704/4024 0.223s 0.001s
im_detect: 3705/4024 0.223s 0.001s
im_detect: 3706/4024 0.223s 0.001s
im_detect: 3707/4024 0.223s 0.001s
im_detect: 3708/4024 0.223s 0.001s
im_detect: 3709/4024 0.223s 0.001s
im_detect: 3710/4024 0.223s 0.001s
im_detect: 3711/4024 0.223s 0.001s
im_detect: 3712/4024 0.223s 0.001s
im_detect: 3713/4024 0.223s 0.001s
im_detect: 3714/4024 0.223s 0.001s
im_detect: 3715/4024 0.223s 0.001s
im_detect: 3716/4024 0.223s 0.001s
im_detect: 3717/4024 0.223s 0.001s
im_detect: 3718/4024 0.223s 0.001s
im_detect: 3719/4024 0.223s 0.001s
im_detect: 3720/4024 0.223s 0.001s
im_detect: 3721/4024 0.223s 0.001s
im_detect: 3722/4024 0.223s 0.001s
im_detect: 3723/4024 0.223s 0.001s
im_detect: 3724/4024 0.223s 0.001s
im_detect: 3725/4024 0.223s 0.001s
im_detect: 3726/4024 0.223s 0.001s
im_detect: 3727/4024 0.223s 0.001s
im_detect: 3728/4024 0.223s 0.001s
im_detect: 3729/4024 0.223s 0.001s
im_detect: 3730/4024 0.223s 0.001s
im_detect: 3731/4024 0.223s 0.001s
im_detect: 3732/4024 0.223s 0.001s
im_detect: 3733/4024 0.223s 0.001s
im_detect: 3734/4024 0.223s 0.001s
im_detect: 3735/4024 0.223s 0.001s
im_detect: 3736/4024 0.223s 0.001s
im_detect: 3737/4024 0.223s 0.001s
im_detect: 3738/4024 0.223s 0.001s
im_detect: 3739/4024 0.223s 0.001s
im_detect: 3740/4024 0.223s 0.001s
im_detect: 3741/4024 0.223s 0.001s
im_detect: 3742/4024 0.223s 0.001s
im_detect: 3743/4024 0.223s 0.001s
im_detect: 3744/4024 0.223s 0.001s
im_detect: 3745/4024 0.223s 0.001s
im_detect: 3746/4024 0.223s 0.001s
im_detect: 3747/4024 0.223s 0.001s
im_detect: 3748/4024 0.223s 0.001s
im_detect: 3749/4024 0.223s 0.001s
im_detect: 3750/4024 0.223s 0.001s
im_detect: 3751/4024 0.223s 0.001s
im_detect: 3752/4024 0.223s 0.001s
im_detect: 3753/4024 0.223s 0.001s
im_detect: 3754/4024 0.223s 0.001s
im_detect: 3755/4024 0.223s 0.001s
im_detect: 3756/4024 0.223s 0.001s
im_detect: 3757/4024 0.223s 0.001s
im_detect: 3758/4024 0.223s 0.001s
im_detect: 3759/4024 0.223s 0.001s
im_detect: 3760/4024 0.223s 0.001s
im_detect: 3761/4024 0.223s 0.001s
im_detect: 3762/4024 0.223s 0.001s
im_detect: 3763/4024 0.223s 0.001s
im_detect: 3764/4024 0.223s 0.001s
im_detect: 3765/4024 0.223s 0.001s
im_detect: 3766/4024 0.223s 0.001s
im_detect: 3767/4024 0.223s 0.001s
im_detect: 3768/4024 0.223s 0.001s
im_detect: 3769/4024 0.223s 0.001s
im_detect: 3770/4024 0.223s 0.001s
im_detect: 3771/4024 0.223s 0.001s
im_detect: 3772/4024 0.223s 0.001s
im_detect: 3773/4024 0.223s 0.001s
im_detect: 3774/4024 0.223s 0.001s
im_detect: 3775/4024 0.223s 0.001s
im_detect: 3776/4024 0.223s 0.001s
im_detect: 3777/4024 0.223s 0.001s
im_detect: 3778/4024 0.223s 0.001s
im_detect: 3779/4024 0.223s 0.001s
im_detect: 3780/4024 0.223s 0.001s
im_detect: 3781/4024 0.223s 0.001s
im_detect: 3782/4024 0.223s 0.001s
im_detect: 3783/4024 0.223s 0.001s
im_detect: 3784/4024 0.223s 0.001s
im_detect: 3785/4024 0.223s 0.001s
im_detect: 3786/4024 0.223s 0.001s
im_detect: 3787/4024 0.223s 0.001s
im_detect: 3788/4024 0.223s 0.001s
im_detect: 3789/4024 0.223s 0.001s
im_detect: 3790/4024 0.223s 0.001s
im_detect: 3791/4024 0.223s 0.001s
im_detect: 3792/4024 0.223s 0.001s
im_detect: 3793/4024 0.223s 0.001s
im_detect: 3794/4024 0.223s 0.001s
im_detect: 3795/4024 0.223s 0.001s
im_detect: 3796/4024 0.223s 0.001s
im_detect: 3797/4024 0.223s 0.001s
im_detect: 3798/4024 0.223s 0.001s
im_detect: 3799/4024 0.223s 0.001s
im_detect: 3800/4024 0.223s 0.001s
im_detect: 3801/4024 0.223s 0.001s
im_detect: 3802/4024 0.223s 0.001s
im_detect: 3803/4024 0.223s 0.001s
im_detect: 3804/4024 0.223s 0.001s
im_detect: 3805/4024 0.223s 0.001s
im_detect: 3806/4024 0.223s 0.001s
im_detect: 3807/4024 0.223s 0.001s
im_detect: 3808/4024 0.223s 0.001s
im_detect: 3809/4024 0.223s 0.001s
im_detect: 3810/4024 0.223s 0.001s
im_detect: 3811/4024 0.223s 0.001s
im_detect: 3812/4024 0.223s 0.001s
im_detect: 3813/4024 0.223s 0.001s
im_detect: 3814/4024 0.223s 0.001s
im_detect: 3815/4024 0.223s 0.001s
im_detect: 3816/4024 0.223s 0.001s
im_detect: 3817/4024 0.223s 0.001s
im_detect: 3818/4024 0.223s 0.001s
im_detect: 3819/4024 0.223s 0.001s
im_detect: 3820/4024 0.223s 0.001s
im_detect: 3821/4024 0.223s 0.001s
im_detect: 3822/4024 0.223s 0.001s
im_detect: 3823/4024 0.223s 0.001s
im_detect: 3824/4024 0.223s 0.001s
im_detect: 3825/4024 0.223s 0.001s
im_detect: 3826/4024 0.223s 0.001s
im_detect: 3827/4024 0.223s 0.001s
im_detect: 3828/4024 0.223s 0.001s
im_detect: 3829/4024 0.223s 0.001s
im_detect: 3830/4024 0.223s 0.001s
im_detect: 3831/4024 0.223s 0.001s
im_detect: 3832/4024 0.223s 0.001s
im_detect: 3833/4024 0.223s 0.001s
im_detect: 3834/4024 0.223s 0.001s
im_detect: 3835/4024 0.223s 0.001s
im_detect: 3836/4024 0.223s 0.001s
im_detect: 3837/4024 0.223s 0.001s
im_detect: 3838/4024 0.223s 0.001s
im_detect: 3839/4024 0.223s 0.001s
im_detect: 3840/4024 0.223s 0.001s
im_detect: 3841/4024 0.223s 0.001s
im_detect: 3842/4024 0.223s 0.001s
im_detect: 3843/4024 0.223s 0.001s
im_detect: 3844/4024 0.223s 0.001s
im_detect: 3845/4024 0.223s 0.001s
im_detect: 3846/4024 0.223s 0.001s
im_detect: 3847/4024 0.223s 0.001s
im_detect: 3848/4024 0.223s 0.001s
im_detect: 3849/4024 0.223s 0.001s
im_detect: 3850/4024 0.223s 0.001s
im_detect: 3851/4024 0.223s 0.001s
im_detect: 3852/4024 0.223s 0.001s
im_detect: 3853/4024 0.223s 0.001s
im_detect: 3854/4024 0.223s 0.001s
im_detect: 3855/4024 0.223s 0.001s
im_detect: 3856/4024 0.223s 0.001s
im_detect: 3857/4024 0.223s 0.001s
im_detect: 3858/4024 0.223s 0.001s
im_detect: 3859/4024 0.223s 0.001s
im_detect: 3860/4024 0.223s 0.001s
im_detect: 3861/4024 0.223s 0.001s
im_detect: 3862/4024 0.223s 0.001s
im_detect: 3863/4024 0.223s 0.001s
im_detect: 3864/4024 0.223s 0.001s
im_detect: 3865/4024 0.223s 0.001s
im_detect: 3866/4024 0.223s 0.001s
im_detect: 3867/4024 0.223s 0.001s
im_detect: 3868/4024 0.223s 0.001s
im_detect: 3869/4024 0.223s 0.001s
im_detect: 3870/4024 0.223s 0.001s
im_detect: 3871/4024 0.223s 0.001s
im_detect: 3872/4024 0.223s 0.001s
im_detect: 3873/4024 0.223s 0.001s
im_detect: 3874/4024 0.223s 0.001s
im_detect: 3875/4024 0.223s 0.001s
im_detect: 3876/4024 0.223s 0.001s
im_detect: 3877/4024 0.223s 0.001s
im_detect: 3878/4024 0.223s 0.001s
im_detect: 3879/4024 0.223s 0.001s
im_detect: 3880/4024 0.223s 0.001s
im_detect: 3881/4024 0.223s 0.001s
im_detect: 3882/4024 0.223s 0.001s
im_detect: 3883/4024 0.223s 0.001s
im_detect: 3884/4024 0.223s 0.001s
im_detect: 3885/4024 0.223s 0.001s
im_detect: 3886/4024 0.223s 0.001s
im_detect: 3887/4024 0.223s 0.001s
im_detect: 3888/4024 0.223s 0.001s
im_detect: 3889/4024 0.223s 0.001s
im_detect: 3890/4024 0.223s 0.001s
im_detect: 3891/4024 0.223s 0.001s
im_detect: 3892/4024 0.223s 0.001s
im_detect: 3893/4024 0.223s 0.001s
im_detect: 3894/4024 0.223s 0.001s
im_detect: 3895/4024 0.223s 0.001s
im_detect: 3896/4024 0.223s 0.001s
im_detect: 3897/4024 0.223s 0.001s
im_detect: 3898/4024 0.223s 0.001s
im_detect: 3899/4024 0.223s 0.001s
im_detect: 3900/4024 0.223s 0.001s
im_detect: 3901/4024 0.223s 0.001s
im_detect: 3902/4024 0.223s 0.001s
im_detect: 3903/4024 0.223s 0.001s
im_detect: 3904/4024 0.223s 0.001s
im_detect: 3905/4024 0.223s 0.001s
im_detect: 3906/4024 0.223s 0.001s
im_detect: 3907/4024 0.224s 0.001s
im_detect: 3908/4024 0.224s 0.001s
im_detect: 3909/4024 0.224s 0.001s
im_detect: 3910/4024 0.224s 0.001s
im_detect: 3911/4024 0.224s 0.001s
im_detect: 3912/4024 0.224s 0.001s
im_detect: 3913/4024 0.224s 0.001s
im_detect: 3914/4024 0.224s 0.001s
im_detect: 3915/4024 0.224s 0.001s
im_detect: 3916/4024 0.224s 0.001s
im_detect: 3917/4024 0.224s 0.001s
im_detect: 3918/4024 0.224s 0.001s
im_detect: 3919/4024 0.224s 0.001s
im_detect: 3920/4024 0.224s 0.001s
im_detect: 3921/4024 0.224s 0.001s
im_detect: 3922/4024 0.224s 0.001s
im_detect: 3923/4024 0.224s 0.001s
im_detect: 3924/4024 0.224s 0.001s
im_detect: 3925/4024 0.224s 0.001s
im_detect: 3926/4024 0.224s 0.001s
im_detect: 3927/4024 0.224s 0.001s
im_detect: 3928/4024 0.224s 0.001s
im_detect: 3929/4024 0.224s 0.001s
im_detect: 3930/4024 0.224s 0.001s
im_detect: 3931/4024 0.224s 0.001s
im_detect: 3932/4024 0.224s 0.001s
im_detect: 3933/4024 0.224s 0.001s
im_detect: 3934/4024 0.224s 0.001s
im_detect: 3935/4024 0.224s 0.001s
im_detect: 3936/4024 0.224s 0.001s
im_detect: 3937/4024 0.224s 0.001s
im_detect: 3938/4024 0.224s 0.001s
im_detect: 3939/4024 0.224s 0.001s
im_detect: 3940/4024 0.224s 0.001s
im_detect: 3941/4024 0.224s 0.001s
im_detect: 3942/4024 0.224s 0.001s
im_detect: 3943/4024 0.224s 0.001s
im_detect: 3944/4024 0.224s 0.001s
im_detect: 3945/4024 0.224s 0.001s
im_detect: 3946/4024 0.224s 0.001s
im_detect: 3947/4024 0.224s 0.001s
im_detect: 3948/4024 0.224s 0.001s
im_detect: 3949/4024 0.224s 0.001s
im_detect: 3950/4024 0.224s 0.001s
im_detect: 3951/4024 0.224s 0.001s
im_detect: 3952/4024 0.224s 0.001s
im_detect: 3953/4024 0.224s 0.001s
im_detect: 3954/4024 0.224s 0.001s
im_detect: 3955/4024 0.224s 0.001s
im_detect: 3956/4024 0.224s 0.001s
im_detect: 3957/4024 0.224s 0.001s
im_detect: 3958/4024 0.224s 0.001s
im_detect: 3959/4024 0.224s 0.001s
im_detect: 3960/4024 0.224s 0.001s
im_detect: 3961/4024 0.224s 0.001s
im_detect: 3962/4024 0.224s 0.001s
im_detect: 3963/4024 0.224s 0.001s
im_detect: 3964/4024 0.224s 0.001s
im_detect: 3965/4024 0.224s 0.001s
im_detect: 3966/4024 0.224s 0.001s
im_detect: 3967/4024 0.224s 0.001s
im_detect: 3968/4024 0.224s 0.001s
im_detect: 3969/4024 0.224s 0.001s
im_detect: 3970/4024 0.224s 0.001s
im_detect: 3971/4024 0.224s 0.001s
im_detect: 3972/4024 0.224s 0.001s
im_detect: 3973/4024 0.224s 0.001s
im_detect: 3974/4024 0.224s 0.001s
im_detect: 3975/4024 0.224s 0.001s
im_detect: 3976/4024 0.224s 0.001s
im_detect: 3977/4024 0.224s 0.001s
im_detect: 3978/4024 0.224s 0.001s
im_detect: 3979/4024 0.224s 0.001s
im_detect: 3980/4024 0.224s 0.001s
im_detect: 3981/4024 0.224s 0.001s
im_detect: 3982/4024 0.224s 0.001s
im_detect: 3983/4024 0.224s 0.001s
im_detect: 3984/4024 0.224s 0.001s
im_detect: 3985/4024 0.224s 0.001s
im_detect: 3986/4024 0.224s 0.001s
im_detect: 3987/4024 0.224s 0.001s
im_detect: 3988/4024 0.224s 0.001s
im_detect: 3989/4024 0.224s 0.001s
im_detect: 3990/4024 0.224s 0.001s
im_detect: 3991/4024 0.224s 0.001s
im_detect: 3992/4024 0.224s 0.001s
im_detect: 3993/4024 0.224s 0.001s
im_detect: 3994/4024 0.224s 0.001s
im_detect: 3995/4024 0.224s 0.001s
im_detect: 3996/4024 0.224s 0.001s
im_detect: 3997/4024 0.224s 0.001s
im_detect: 3998/4024 0.224s 0.001s
im_detect: 3999/4024 0.224s 0.001s
im_detect: 4000/4024 0.224s 0.001s
im_detect: 4001/4024 0.224s 0.001s
im_detect: 4002/4024 0.224s 0.001s
im_detect: 4003/4024 0.224s 0.001s
im_detect: 4004/4024 0.224s 0.001s
im_detect: 4005/4024 0.224s 0.001s
im_detect: 4006/4024 0.224s 0.001s
im_detect: 4007/4024 0.224s 0.001s
im_detect: 4008/4024 0.224s 0.001s
im_detect: 4009/4024 0.224s 0.001s
im_detect: 4010/4024 0.224s 0.001s
im_detect: 4011/4024 0.224s 0.001s
im_detect: 4012/4024 0.224s 0.001s
im_detect: 4013/4024 0.224s 0.001s
im_detect: 4014/4024 0.224s 0.001s
im_detect: 4015/4024 0.224s 0.001s
im_detect: 4016/4024 0.224s 0.001s
im_detect: 4017/4024 0.224s 0.001s
im_detect: 4018/4024 0.224s 0.001s
im_detect: 4019/4024 0.224s 0.001s
im_detect: 4020/4024 0.224s 0.001s
im_detect: 4021/4024 0.224s 0.001s
im_detect: 4022/4024 0.224s 0.001s
im_detect: 4023/4024 0.224s 0.001s
im_detect: 4024/4024 0.224s 0.001s
Evaluating detections
Writing person VOC results file
VOC07 metric? Yes
[      0.       0.       0. ... 1225252. 1225253. 1225254.] [1.000e+00 2.000e+00 3.000e+00 ... 1.637e+03 1.637e+03 1.637e+03] 0.0
/home/neuiva1/sol/10_12/py-R-FCN/tools/../lib/datasets/voc_eval.py:197: RuntimeWarning: divide by zero encountered in divide
  rec = tp / float(npos)
AP for person = 1.0000
Mean AP = 1.0000
~~~~~~~~
Results:
1.000
1.000
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	16m3.321s
user	15m29.080s
sys	1m29.756s
+ ./tools/test_net.py --gpu 3 --def experiments/10_22/model_ohem/multi_test.prototxt --net output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_10000.caffemodel --imdb voc_0712_test --cfg experiments/10_22/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_10000.caffemodel', cfg_file='experiments/10_22/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=3, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/10_22/model_ohem/multi_test.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'DATA_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '10_22/model',
 'GPU_ID': 3,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/models/pascal_voc',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/neuiva1/sol/10_12/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.55,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 20,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 20,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 2000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W1022 16:11:00.101605 27537 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W1022 16:11:00.101675 27537 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W1022 16:11:00.101678 27537 _caffe.cpp:125] Net('experiments/10_22/model_ohem/multi_test.prototxt', 1, weights='output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_10000.caffemodel')
I1022 16:11:00.105315 27537 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/10_22/model_ohem/multi_test.prototxt
I1022 16:11:00.105376 27537 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W1022 16:11:00.105383 27537 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I1022 16:11:00.107518 27537 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b
I1022 16:11:00.108630 27537 layer_factory.hpp:77] Creating layer input
I1022 16:11:00.108642 27537 net.cpp:100] Creating Layer input
I1022 16:11:00.108649 27537 net.cpp:418] input -> data
I1022 16:11:00.108661 27537 net.cpp:418] input -> im_info
I1022 16:11:00.667780 27537 net.cpp:150] Setting up input
I1022 16:11:00.667829 27537 net.cpp:157] Top shape: 1 3 224 224 (150528)
I1022 16:11:00.667836 27537 net.cpp:157] Top shape: 1 3 (3)
I1022 16:11:00.667840 27537 net.cpp:165] Memory required for data: 602124
I1022 16:11:00.667850 27537 layer_factory.hpp:77] Creating layer conv1
I1022 16:11:00.667876 27537 net.cpp:100] Creating Layer conv1
I1022 16:11:00.667894 27537 net.cpp:444] conv1 <- data
I1022 16:11:00.667906 27537 net.cpp:418] conv1 -> conv1
I1022 16:11:01.354939 27537 net.cpp:150] Setting up conv1
I1022 16:11:01.354977 27537 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 16:11:01.354982 27537 net.cpp:165] Memory required for data: 3813388
I1022 16:11:01.355001 27537 layer_factory.hpp:77] Creating layer bn_conv1
I1022 16:11:01.355033 27537 net.cpp:100] Creating Layer bn_conv1
I1022 16:11:01.355038 27537 net.cpp:444] bn_conv1 <- conv1
I1022 16:11:01.355046 27537 net.cpp:405] bn_conv1 -> conv1 (in-place)
I1022 16:11:01.355394 27537 net.cpp:150] Setting up bn_conv1
I1022 16:11:01.355401 27537 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 16:11:01.355404 27537 net.cpp:165] Memory required for data: 7024652
I1022 16:11:01.355423 27537 layer_factory.hpp:77] Creating layer scale_conv1
I1022 16:11:01.355434 27537 net.cpp:100] Creating Layer scale_conv1
I1022 16:11:01.355437 27537 net.cpp:444] scale_conv1 <- conv1
I1022 16:11:01.355443 27537 net.cpp:405] scale_conv1 -> conv1 (in-place)
I1022 16:11:01.355506 27537 layer_factory.hpp:77] Creating layer scale_conv1
I1022 16:11:01.355711 27537 net.cpp:150] Setting up scale_conv1
I1022 16:11:01.355720 27537 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 16:11:01.355723 27537 net.cpp:165] Memory required for data: 10235916
I1022 16:11:01.355731 27537 layer_factory.hpp:77] Creating layer conv1_relu
I1022 16:11:01.355741 27537 net.cpp:100] Creating Layer conv1_relu
I1022 16:11:01.355746 27537 net.cpp:444] conv1_relu <- conv1
I1022 16:11:01.355751 27537 net.cpp:405] conv1_relu -> conv1 (in-place)
I1022 16:11:01.355968 27537 net.cpp:150] Setting up conv1_relu
I1022 16:11:01.355978 27537 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 16:11:01.355980 27537 net.cpp:165] Memory required for data: 13447180
I1022 16:11:01.355983 27537 layer_factory.hpp:77] Creating layer pool1
I1022 16:11:01.355993 27537 net.cpp:100] Creating Layer pool1
I1022 16:11:01.355996 27537 net.cpp:444] pool1 <- conv1
I1022 16:11:01.356001 27537 net.cpp:418] pool1 -> pool1
I1022 16:11:01.356065 27537 net.cpp:150] Setting up pool1
I1022 16:11:01.356073 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.356076 27537 net.cpp:165] Memory required for data: 14249996
I1022 16:11:01.356079 27537 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I1022 16:11:01.356086 27537 net.cpp:100] Creating Layer pool1_pool1_0_split
I1022 16:11:01.356091 27537 net.cpp:444] pool1_pool1_0_split <- pool1
I1022 16:11:01.356096 27537 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1022 16:11:01.356106 27537 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1022 16:11:01.356158 27537 net.cpp:150] Setting up pool1_pool1_0_split
I1022 16:11:01.356165 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.356169 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.356171 27537 net.cpp:165] Memory required for data: 15855628
I1022 16:11:01.356174 27537 layer_factory.hpp:77] Creating layer res2a_branch1
I1022 16:11:01.356186 27537 net.cpp:100] Creating Layer res2a_branch1
I1022 16:11:01.356190 27537 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I1022 16:11:01.356195 27537 net.cpp:418] res2a_branch1 -> res2a_branch1
I1022 16:11:01.357828 27537 net.cpp:150] Setting up res2a_branch1
I1022 16:11:01.357842 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.357846 27537 net.cpp:165] Memory required for data: 19066892
I1022 16:11:01.357851 27537 layer_factory.hpp:77] Creating layer bn2a_branch1
I1022 16:11:01.357861 27537 net.cpp:100] Creating Layer bn2a_branch1
I1022 16:11:01.357864 27537 net.cpp:444] bn2a_branch1 <- res2a_branch1
I1022 16:11:01.357869 27537 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I1022 16:11:01.360085 27537 net.cpp:150] Setting up bn2a_branch1
I1022 16:11:01.360097 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.360100 27537 net.cpp:165] Memory required for data: 22278156
I1022 16:11:01.360111 27537 layer_factory.hpp:77] Creating layer scale2a_branch1
I1022 16:11:01.360119 27537 net.cpp:100] Creating Layer scale2a_branch1
I1022 16:11:01.360122 27537 net.cpp:444] scale2a_branch1 <- res2a_branch1
I1022 16:11:01.360128 27537 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I1022 16:11:01.360188 27537 layer_factory.hpp:77] Creating layer scale2a_branch1
I1022 16:11:01.360365 27537 net.cpp:150] Setting up scale2a_branch1
I1022 16:11:01.360373 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.360378 27537 net.cpp:165] Memory required for data: 25489420
I1022 16:11:01.360383 27537 layer_factory.hpp:77] Creating layer res2a_branch2a
I1022 16:11:01.360393 27537 net.cpp:100] Creating Layer res2a_branch2a
I1022 16:11:01.360397 27537 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I1022 16:11:01.360404 27537 net.cpp:418] res2a_branch2a -> res2a_branch2a
I1022 16:11:01.362025 27537 net.cpp:150] Setting up res2a_branch2a
I1022 16:11:01.362038 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.362041 27537 net.cpp:165] Memory required for data: 26292236
I1022 16:11:01.362047 27537 layer_factory.hpp:77] Creating layer bn2a_branch2a
I1022 16:11:01.362054 27537 net.cpp:100] Creating Layer bn2a_branch2a
I1022 16:11:01.362057 27537 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I1022 16:11:01.362063 27537 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I1022 16:11:01.362376 27537 net.cpp:150] Setting up bn2a_branch2a
I1022 16:11:01.362383 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.362386 27537 net.cpp:165] Memory required for data: 27095052
I1022 16:11:01.362396 27537 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1022 16:11:01.362402 27537 net.cpp:100] Creating Layer scale2a_branch2a
I1022 16:11:01.362406 27537 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I1022 16:11:01.362411 27537 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I1022 16:11:01.362466 27537 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1022 16:11:01.362654 27537 net.cpp:150] Setting up scale2a_branch2a
I1022 16:11:01.362661 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.362664 27537 net.cpp:165] Memory required for data: 27897868
I1022 16:11:01.362670 27537 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I1022 16:11:01.362677 27537 net.cpp:100] Creating Layer res2a_branch2a_relu
I1022 16:11:01.362680 27537 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I1022 16:11:01.362684 27537 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I1022 16:11:01.362897 27537 net.cpp:150] Setting up res2a_branch2a_relu
I1022 16:11:01.362906 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.362910 27537 net.cpp:165] Memory required for data: 28700684
I1022 16:11:01.362913 27537 layer_factory.hpp:77] Creating layer res2a_branch2b
I1022 16:11:01.362921 27537 net.cpp:100] Creating Layer res2a_branch2b
I1022 16:11:01.362926 27537 net.cpp:444] res2a_branch2b <- res2a_branch2a
I1022 16:11:01.362932 27537 net.cpp:418] res2a_branch2b -> res2a_branch2b
I1022 16:11:01.370319 27537 net.cpp:150] Setting up res2a_branch2b
I1022 16:11:01.370334 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.370338 27537 net.cpp:165] Memory required for data: 29503500
I1022 16:11:01.370345 27537 layer_factory.hpp:77] Creating layer bn2a_branch2b
I1022 16:11:01.370352 27537 net.cpp:100] Creating Layer bn2a_branch2b
I1022 16:11:01.370357 27537 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I1022 16:11:01.370362 27537 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I1022 16:11:01.370702 27537 net.cpp:150] Setting up bn2a_branch2b
I1022 16:11:01.370710 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.370713 27537 net.cpp:165] Memory required for data: 30306316
I1022 16:11:01.370720 27537 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1022 16:11:01.370728 27537 net.cpp:100] Creating Layer scale2a_branch2b
I1022 16:11:01.370731 27537 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I1022 16:11:01.370736 27537 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I1022 16:11:01.370795 27537 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1022 16:11:01.370987 27537 net.cpp:150] Setting up scale2a_branch2b
I1022 16:11:01.370995 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.370998 27537 net.cpp:165] Memory required for data: 31109132
I1022 16:11:01.371006 27537 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I1022 16:11:01.371011 27537 net.cpp:100] Creating Layer res2a_branch2b_relu
I1022 16:11:01.371013 27537 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I1022 16:11:01.371017 27537 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I1022 16:11:01.371879 27537 net.cpp:150] Setting up res2a_branch2b_relu
I1022 16:11:01.371891 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.371894 27537 net.cpp:165] Memory required for data: 31911948
I1022 16:11:01.371898 27537 layer_factory.hpp:77] Creating layer res2a_branch2c
I1022 16:11:01.371907 27537 net.cpp:100] Creating Layer res2a_branch2c
I1022 16:11:01.371911 27537 net.cpp:444] res2a_branch2c <- res2a_branch2b
I1022 16:11:01.371917 27537 net.cpp:418] res2a_branch2c -> res2a_branch2c
I1022 16:11:01.373909 27537 net.cpp:150] Setting up res2a_branch2c
I1022 16:11:01.373941 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.373945 27537 net.cpp:165] Memory required for data: 35123212
I1022 16:11:01.373956 27537 layer_factory.hpp:77] Creating layer bn2a_branch2c
I1022 16:11:01.373971 27537 net.cpp:100] Creating Layer bn2a_branch2c
I1022 16:11:01.373977 27537 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I1022 16:11:01.373986 27537 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I1022 16:11:01.374338 27537 net.cpp:150] Setting up bn2a_branch2c
I1022 16:11:01.374346 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.374351 27537 net.cpp:165] Memory required for data: 38334476
I1022 16:11:01.374359 27537 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1022 16:11:01.374368 27537 net.cpp:100] Creating Layer scale2a_branch2c
I1022 16:11:01.374372 27537 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I1022 16:11:01.374377 27537 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I1022 16:11:01.374442 27537 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1022 16:11:01.374639 27537 net.cpp:150] Setting up scale2a_branch2c
I1022 16:11:01.374650 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.374653 27537 net.cpp:165] Memory required for data: 41545740
I1022 16:11:01.374660 27537 layer_factory.hpp:77] Creating layer res2a
I1022 16:11:01.374670 27537 net.cpp:100] Creating Layer res2a
I1022 16:11:01.374673 27537 net.cpp:444] res2a <- res2a_branch1
I1022 16:11:01.374678 27537 net.cpp:444] res2a <- res2a_branch2c
I1022 16:11:01.374685 27537 net.cpp:418] res2a -> res2a
I1022 16:11:01.374729 27537 net.cpp:150] Setting up res2a
I1022 16:11:01.374738 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.374742 27537 net.cpp:165] Memory required for data: 44757004
I1022 16:11:01.374745 27537 layer_factory.hpp:77] Creating layer res2a_relu
I1022 16:11:01.374752 27537 net.cpp:100] Creating Layer res2a_relu
I1022 16:11:01.374755 27537 net.cpp:444] res2a_relu <- res2a
I1022 16:11:01.374763 27537 net.cpp:405] res2a_relu -> res2a (in-place)
I1022 16:11:01.375007 27537 net.cpp:150] Setting up res2a_relu
I1022 16:11:01.375018 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.375021 27537 net.cpp:165] Memory required for data: 47968268
I1022 16:11:01.375025 27537 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I1022 16:11:01.375033 27537 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I1022 16:11:01.375038 27537 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I1022 16:11:01.375046 27537 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I1022 16:11:01.375054 27537 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I1022 16:11:01.375120 27537 net.cpp:150] Setting up res2a_res2a_relu_0_split
I1022 16:11:01.375129 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.375133 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.375136 27537 net.cpp:165] Memory required for data: 54390796
I1022 16:11:01.375139 27537 layer_factory.hpp:77] Creating layer res2b_branch2a
I1022 16:11:01.375151 27537 net.cpp:100] Creating Layer res2b_branch2a
I1022 16:11:01.375157 27537 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I1022 16:11:01.375164 27537 net.cpp:418] res2b_branch2a -> res2b_branch2a
I1022 16:11:01.376932 27537 net.cpp:150] Setting up res2b_branch2a
I1022 16:11:01.376947 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.376950 27537 net.cpp:165] Memory required for data: 55193612
I1022 16:11:01.376957 27537 layer_factory.hpp:77] Creating layer bn2b_branch2a
I1022 16:11:01.376968 27537 net.cpp:100] Creating Layer bn2b_branch2a
I1022 16:11:01.376972 27537 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I1022 16:11:01.376979 27537 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I1022 16:11:01.377661 27537 net.cpp:150] Setting up bn2b_branch2a
I1022 16:11:01.377676 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.377693 27537 net.cpp:165] Memory required for data: 55996428
I1022 16:11:01.377717 27537 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1022 16:11:01.377738 27537 net.cpp:100] Creating Layer scale2b_branch2a
I1022 16:11:01.377748 27537 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I1022 16:11:01.377759 27537 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I1022 16:11:01.377880 27537 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1022 16:11:01.378273 27537 net.cpp:150] Setting up scale2b_branch2a
I1022 16:11:01.378289 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.378294 27537 net.cpp:165] Memory required for data: 56799244
I1022 16:11:01.378306 27537 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I1022 16:11:01.378320 27537 net.cpp:100] Creating Layer res2b_branch2a_relu
I1022 16:11:01.378329 27537 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I1022 16:11:01.378340 27537 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I1022 16:11:01.378777 27537 net.cpp:150] Setting up res2b_branch2a_relu
I1022 16:11:01.378794 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.378799 27537 net.cpp:165] Memory required for data: 57602060
I1022 16:11:01.378806 27537 layer_factory.hpp:77] Creating layer res2b_branch2b
I1022 16:11:01.378823 27537 net.cpp:100] Creating Layer res2b_branch2b
I1022 16:11:01.378831 27537 net.cpp:444] res2b_branch2b <- res2b_branch2a
I1022 16:11:01.378845 27537 net.cpp:418] res2b_branch2b -> res2b_branch2b
I1022 16:11:01.388718 27537 net.cpp:150] Setting up res2b_branch2b
I1022 16:11:01.388770 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.388778 27537 net.cpp:165] Memory required for data: 58404876
I1022 16:11:01.388797 27537 layer_factory.hpp:77] Creating layer bn2b_branch2b
I1022 16:11:01.388823 27537 net.cpp:100] Creating Layer bn2b_branch2b
I1022 16:11:01.388833 27537 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I1022 16:11:01.388849 27537 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I1022 16:11:01.389562 27537 net.cpp:150] Setting up bn2b_branch2b
I1022 16:11:01.389576 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.389582 27537 net.cpp:165] Memory required for data: 59207692
I1022 16:11:01.389598 27537 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1022 16:11:01.389612 27537 net.cpp:100] Creating Layer scale2b_branch2b
I1022 16:11:01.389618 27537 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I1022 16:11:01.389629 27537 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I1022 16:11:01.389753 27537 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1022 16:11:01.390151 27537 net.cpp:150] Setting up scale2b_branch2b
I1022 16:11:01.390166 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.390172 27537 net.cpp:165] Memory required for data: 60010508
I1022 16:11:01.390183 27537 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I1022 16:11:01.390194 27537 net.cpp:100] Creating Layer res2b_branch2b_relu
I1022 16:11:01.390200 27537 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I1022 16:11:01.390209 27537 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I1022 16:11:01.392007 27537 net.cpp:150] Setting up res2b_branch2b_relu
I1022 16:11:01.392030 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.392036 27537 net.cpp:165] Memory required for data: 60813324
I1022 16:11:01.392043 27537 layer_factory.hpp:77] Creating layer res2b_branch2c
I1022 16:11:01.392067 27537 net.cpp:100] Creating Layer res2b_branch2c
I1022 16:11:01.392077 27537 net.cpp:444] res2b_branch2c <- res2b_branch2b
I1022 16:11:01.392089 27537 net.cpp:418] res2b_branch2c -> res2b_branch2c
I1022 16:11:01.396383 27537 net.cpp:150] Setting up res2b_branch2c
I1022 16:11:01.396410 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.396416 27537 net.cpp:165] Memory required for data: 64024588
I1022 16:11:01.396427 27537 layer_factory.hpp:77] Creating layer bn2b_branch2c
I1022 16:11:01.396443 27537 net.cpp:100] Creating Layer bn2b_branch2c
I1022 16:11:01.396457 27537 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I1022 16:11:01.396467 27537 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I1022 16:11:01.397153 27537 net.cpp:150] Setting up bn2b_branch2c
I1022 16:11:01.397167 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.397173 27537 net.cpp:165] Memory required for data: 67235852
I1022 16:11:01.397186 27537 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1022 16:11:01.397200 27537 net.cpp:100] Creating Layer scale2b_branch2c
I1022 16:11:01.397207 27537 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I1022 16:11:01.397214 27537 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I1022 16:11:01.397330 27537 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1022 16:11:01.397678 27537 net.cpp:150] Setting up scale2b_branch2c
I1022 16:11:01.397691 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.397696 27537 net.cpp:165] Memory required for data: 70447116
I1022 16:11:01.397706 27537 layer_factory.hpp:77] Creating layer res2b
I1022 16:11:01.397716 27537 net.cpp:100] Creating Layer res2b
I1022 16:11:01.397724 27537 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I1022 16:11:01.397733 27537 net.cpp:444] res2b <- res2b_branch2c
I1022 16:11:01.397742 27537 net.cpp:418] res2b -> res2b
I1022 16:11:01.397812 27537 net.cpp:150] Setting up res2b
I1022 16:11:01.397825 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.397832 27537 net.cpp:165] Memory required for data: 73658380
I1022 16:11:01.397837 27537 layer_factory.hpp:77] Creating layer res2b_relu
I1022 16:11:01.397846 27537 net.cpp:100] Creating Layer res2b_relu
I1022 16:11:01.397853 27537 net.cpp:444] res2b_relu <- res2b
I1022 16:11:01.397864 27537 net.cpp:405] res2b_relu -> res2b (in-place)
I1022 16:11:01.398288 27537 net.cpp:150] Setting up res2b_relu
I1022 16:11:01.398303 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.398306 27537 net.cpp:165] Memory required for data: 76869644
I1022 16:11:01.398313 27537 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I1022 16:11:01.398325 27537 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I1022 16:11:01.398334 27537 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I1022 16:11:01.398341 27537 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I1022 16:11:01.398360 27537 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I1022 16:11:01.398478 27537 net.cpp:150] Setting up res2b_res2b_relu_0_split
I1022 16:11:01.398489 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.398499 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.398506 27537 net.cpp:165] Memory required for data: 83292172
I1022 16:11:01.398511 27537 layer_factory.hpp:77] Creating layer res2c_branch2a
I1022 16:11:01.398530 27537 net.cpp:100] Creating Layer res2c_branch2a
I1022 16:11:01.398537 27537 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I1022 16:11:01.398546 27537 net.cpp:418] res2c_branch2a -> res2c_branch2a
I1022 16:11:01.401540 27537 net.cpp:150] Setting up res2c_branch2a
I1022 16:11:01.401563 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.401571 27537 net.cpp:165] Memory required for data: 84094988
I1022 16:11:01.401582 27537 layer_factory.hpp:77] Creating layer bn2c_branch2a
I1022 16:11:01.401602 27537 net.cpp:100] Creating Layer bn2c_branch2a
I1022 16:11:01.401609 27537 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I1022 16:11:01.401621 27537 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I1022 16:11:01.402273 27537 net.cpp:150] Setting up bn2c_branch2a
I1022 16:11:01.402287 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.402293 27537 net.cpp:165] Memory required for data: 84897804
I1022 16:11:01.402307 27537 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1022 16:11:01.402323 27537 net.cpp:100] Creating Layer scale2c_branch2a
I1022 16:11:01.402329 27537 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I1022 16:11:01.402340 27537 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I1022 16:11:01.402451 27537 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1022 16:11:01.402817 27537 net.cpp:150] Setting up scale2c_branch2a
I1022 16:11:01.402828 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.402835 27537 net.cpp:165] Memory required for data: 85700620
I1022 16:11:01.402845 27537 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I1022 16:11:01.402856 27537 net.cpp:100] Creating Layer res2c_branch2a_relu
I1022 16:11:01.402864 27537 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I1022 16:11:01.402873 27537 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I1022 16:11:01.403290 27537 net.cpp:150] Setting up res2c_branch2a_relu
I1022 16:11:01.403306 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.403313 27537 net.cpp:165] Memory required for data: 86503436
I1022 16:11:01.403318 27537 layer_factory.hpp:77] Creating layer res2c_branch2b
I1022 16:11:01.403337 27537 net.cpp:100] Creating Layer res2c_branch2b
I1022 16:11:01.403344 27537 net.cpp:444] res2c_branch2b <- res2c_branch2a
I1022 16:11:01.403354 27537 net.cpp:418] res2c_branch2b -> res2c_branch2b
I1022 16:11:01.409157 27537 net.cpp:150] Setting up res2c_branch2b
I1022 16:11:01.409184 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.409193 27537 net.cpp:165] Memory required for data: 87306252
I1022 16:11:01.409204 27537 layer_factory.hpp:77] Creating layer bn2c_branch2b
I1022 16:11:01.409217 27537 net.cpp:100] Creating Layer bn2c_branch2b
I1022 16:11:01.409225 27537 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I1022 16:11:01.409246 27537 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I1022 16:11:01.410004 27537 net.cpp:150] Setting up bn2c_branch2b
I1022 16:11:01.410017 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.410022 27537 net.cpp:165] Memory required for data: 88109068
I1022 16:11:01.410037 27537 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1022 16:11:01.410050 27537 net.cpp:100] Creating Layer scale2c_branch2b
I1022 16:11:01.410056 27537 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I1022 16:11:01.410066 27537 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I1022 16:11:01.410183 27537 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1022 16:11:01.410562 27537 net.cpp:150] Setting up scale2c_branch2b
I1022 16:11:01.410574 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.410579 27537 net.cpp:165] Memory required for data: 88911884
I1022 16:11:01.410589 27537 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I1022 16:11:01.410599 27537 net.cpp:100] Creating Layer res2c_branch2b_relu
I1022 16:11:01.410605 27537 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I1022 16:11:01.410616 27537 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I1022 16:11:01.411061 27537 net.cpp:150] Setting up res2c_branch2b_relu
I1022 16:11:01.411075 27537 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:11:01.411080 27537 net.cpp:165] Memory required for data: 89714700
I1022 16:11:01.411087 27537 layer_factory.hpp:77] Creating layer res2c_branch2c
I1022 16:11:01.411104 27537 net.cpp:100] Creating Layer res2c_branch2c
I1022 16:11:01.411113 27537 net.cpp:444] res2c_branch2c <- res2c_branch2b
I1022 16:11:01.411125 27537 net.cpp:418] res2c_branch2c -> res2c_branch2c
I1022 16:11:01.415781 27537 net.cpp:150] Setting up res2c_branch2c
I1022 16:11:01.415809 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.415815 27537 net.cpp:165] Memory required for data: 92925964
I1022 16:11:01.415827 27537 layer_factory.hpp:77] Creating layer bn2c_branch2c
I1022 16:11:01.415838 27537 net.cpp:100] Creating Layer bn2c_branch2c
I1022 16:11:01.415846 27537 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I1022 16:11:01.415859 27537 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I1022 16:11:01.416457 27537 net.cpp:150] Setting up bn2c_branch2c
I1022 16:11:01.416471 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.416476 27537 net.cpp:165] Memory required for data: 96137228
I1022 16:11:01.416502 27537 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1022 16:11:01.416514 27537 net.cpp:100] Creating Layer scale2c_branch2c
I1022 16:11:01.416522 27537 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I1022 16:11:01.416530 27537 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I1022 16:11:01.416664 27537 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1022 16:11:01.416988 27537 net.cpp:150] Setting up scale2c_branch2c
I1022 16:11:01.417003 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.417011 27537 net.cpp:165] Memory required for data: 99348492
I1022 16:11:01.417021 27537 layer_factory.hpp:77] Creating layer res2c
I1022 16:11:01.417030 27537 net.cpp:100] Creating Layer res2c
I1022 16:11:01.417038 27537 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I1022 16:11:01.417047 27537 net.cpp:444] res2c <- res2c_branch2c
I1022 16:11:01.417057 27537 net.cpp:418] res2c -> res2c
I1022 16:11:01.417119 27537 net.cpp:150] Setting up res2c
I1022 16:11:01.417129 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.417136 27537 net.cpp:165] Memory required for data: 102559756
I1022 16:11:01.417141 27537 layer_factory.hpp:77] Creating layer res2c_relu
I1022 16:11:01.417150 27537 net.cpp:100] Creating Layer res2c_relu
I1022 16:11:01.417156 27537 net.cpp:444] res2c_relu <- res2c
I1022 16:11:01.417166 27537 net.cpp:405] res2c_relu -> res2c (in-place)
I1022 16:11:01.418550 27537 net.cpp:150] Setting up res2c_relu
I1022 16:11:01.418570 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.418577 27537 net.cpp:165] Memory required for data: 105771020
I1022 16:11:01.418584 27537 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I1022 16:11:01.418598 27537 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I1022 16:11:01.418606 27537 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I1022 16:11:01.418615 27537 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I1022 16:11:01.418629 27537 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I1022 16:11:01.418748 27537 net.cpp:150] Setting up res2c_res2c_relu_0_split
I1022 16:11:01.418762 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.418771 27537 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:11:01.418778 27537 net.cpp:165] Memory required for data: 112193548
I1022 16:11:01.418782 27537 layer_factory.hpp:77] Creating layer res3a_branch1
I1022 16:11:01.418794 27537 net.cpp:100] Creating Layer res3a_branch1
I1022 16:11:01.418802 27537 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I1022 16:11:01.418813 27537 net.cpp:418] res3a_branch1 -> res3a_branch1
I1022 16:11:01.425945 27537 net.cpp:150] Setting up res3a_branch1
I1022 16:11:01.425976 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.425982 27537 net.cpp:165] Memory required for data: 113799180
I1022 16:11:01.425994 27537 layer_factory.hpp:77] Creating layer bn3a_branch1
I1022 16:11:01.426007 27537 net.cpp:100] Creating Layer bn3a_branch1
I1022 16:11:01.426014 27537 net.cpp:444] bn3a_branch1 <- res3a_branch1
I1022 16:11:01.426028 27537 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I1022 16:11:01.431875 27537 net.cpp:150] Setting up bn3a_branch1
I1022 16:11:01.431901 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.431907 27537 net.cpp:165] Memory required for data: 115404812
I1022 16:11:01.431921 27537 layer_factory.hpp:77] Creating layer scale3a_branch1
I1022 16:11:01.431934 27537 net.cpp:100] Creating Layer scale3a_branch1
I1022 16:11:01.431941 27537 net.cpp:444] scale3a_branch1 <- res3a_branch1
I1022 16:11:01.431951 27537 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I1022 16:11:01.432075 27537 layer_factory.hpp:77] Creating layer scale3a_branch1
I1022 16:11:01.432391 27537 net.cpp:150] Setting up scale3a_branch1
I1022 16:11:01.432404 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.432407 27537 net.cpp:165] Memory required for data: 117010444
I1022 16:11:01.432417 27537 layer_factory.hpp:77] Creating layer res3a_branch2a
I1022 16:11:01.432430 27537 net.cpp:100] Creating Layer res3a_branch2a
I1022 16:11:01.432438 27537 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I1022 16:11:01.432451 27537 net.cpp:418] res3a_branch2a -> res3a_branch2a
I1022 16:11:01.435400 27537 net.cpp:150] Setting up res3a_branch2a
I1022 16:11:01.435422 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.435427 27537 net.cpp:165] Memory required for data: 117411852
I1022 16:11:01.435436 27537 layer_factory.hpp:77] Creating layer bn3a_branch2a
I1022 16:11:01.435451 27537 net.cpp:100] Creating Layer bn3a_branch2a
I1022 16:11:01.435457 27537 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I1022 16:11:01.435468 27537 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I1022 16:11:01.436069 27537 net.cpp:150] Setting up bn3a_branch2a
I1022 16:11:01.436081 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.436086 27537 net.cpp:165] Memory required for data: 117813260
I1022 16:11:01.436098 27537 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1022 16:11:01.436110 27537 net.cpp:100] Creating Layer scale3a_branch2a
I1022 16:11:01.436116 27537 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I1022 16:11:01.436126 27537 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I1022 16:11:01.436237 27537 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1022 16:11:01.436558 27537 net.cpp:150] Setting up scale3a_branch2a
I1022 16:11:01.436570 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.436575 27537 net.cpp:165] Memory required for data: 118214668
I1022 16:11:01.436584 27537 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I1022 16:11:01.436596 27537 net.cpp:100] Creating Layer res3a_branch2a_relu
I1022 16:11:01.436605 27537 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I1022 16:11:01.436635 27537 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I1022 16:11:01.438014 27537 net.cpp:150] Setting up res3a_branch2a_relu
I1022 16:11:01.438035 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.438040 27537 net.cpp:165] Memory required for data: 118616076
I1022 16:11:01.438046 27537 layer_factory.hpp:77] Creating layer res3a_branch2b
I1022 16:11:01.438062 27537 net.cpp:100] Creating Layer res3a_branch2b
I1022 16:11:01.438068 27537 net.cpp:444] res3a_branch2b <- res3a_branch2a
I1022 16:11:01.438081 27537 net.cpp:418] res3a_branch2b -> res3a_branch2b
I1022 16:11:01.442085 27537 net.cpp:150] Setting up res3a_branch2b
I1022 16:11:01.442106 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.442112 27537 net.cpp:165] Memory required for data: 119017484
I1022 16:11:01.442121 27537 layer_factory.hpp:77] Creating layer bn3a_branch2b
I1022 16:11:01.442137 27537 net.cpp:100] Creating Layer bn3a_branch2b
I1022 16:11:01.442142 27537 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I1022 16:11:01.442150 27537 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I1022 16:11:01.442756 27537 net.cpp:150] Setting up bn3a_branch2b
I1022 16:11:01.442770 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.442775 27537 net.cpp:165] Memory required for data: 119418892
I1022 16:11:01.442786 27537 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1022 16:11:01.442795 27537 net.cpp:100] Creating Layer scale3a_branch2b
I1022 16:11:01.442801 27537 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I1022 16:11:01.442811 27537 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I1022 16:11:01.442919 27537 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1022 16:11:01.443244 27537 net.cpp:150] Setting up scale3a_branch2b
I1022 16:11:01.443256 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.443261 27537 net.cpp:165] Memory required for data: 119820300
I1022 16:11:01.443270 27537 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I1022 16:11:01.443279 27537 net.cpp:100] Creating Layer res3a_branch2b_relu
I1022 16:11:01.443284 27537 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I1022 16:11:01.443295 27537 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I1022 16:11:01.443682 27537 net.cpp:150] Setting up res3a_branch2b_relu
I1022 16:11:01.443696 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.443702 27537 net.cpp:165] Memory required for data: 120221708
I1022 16:11:01.443707 27537 layer_factory.hpp:77] Creating layer res3a_branch2c
I1022 16:11:01.443722 27537 net.cpp:100] Creating Layer res3a_branch2c
I1022 16:11:01.443729 27537 net.cpp:444] res3a_branch2c <- res3a_branch2b
I1022 16:11:01.443742 27537 net.cpp:418] res3a_branch2c -> res3a_branch2c
I1022 16:11:01.446599 27537 net.cpp:150] Setting up res3a_branch2c
I1022 16:11:01.446620 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.446625 27537 net.cpp:165] Memory required for data: 121827340
I1022 16:11:01.446635 27537 layer_factory.hpp:77] Creating layer bn3a_branch2c
I1022 16:11:01.446657 27537 net.cpp:100] Creating Layer bn3a_branch2c
I1022 16:11:01.446663 27537 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I1022 16:11:01.446673 27537 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I1022 16:11:01.449061 27537 net.cpp:150] Setting up bn3a_branch2c
I1022 16:11:01.449085 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.449091 27537 net.cpp:165] Memory required for data: 123432972
I1022 16:11:01.449110 27537 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1022 16:11:01.449126 27537 net.cpp:100] Creating Layer scale3a_branch2c
I1022 16:11:01.449134 27537 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I1022 16:11:01.449151 27537 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I1022 16:11:01.449291 27537 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1022 16:11:01.449642 27537 net.cpp:150] Setting up scale3a_branch2c
I1022 16:11:01.449654 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.449659 27537 net.cpp:165] Memory required for data: 125038604
I1022 16:11:01.449669 27537 layer_factory.hpp:77] Creating layer res3a
I1022 16:11:01.449682 27537 net.cpp:100] Creating Layer res3a
I1022 16:11:01.449689 27537 net.cpp:444] res3a <- res3a_branch1
I1022 16:11:01.449697 27537 net.cpp:444] res3a <- res3a_branch2c
I1022 16:11:01.449705 27537 net.cpp:418] res3a -> res3a
I1022 16:11:01.449777 27537 net.cpp:150] Setting up res3a
I1022 16:11:01.449789 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.449793 27537 net.cpp:165] Memory required for data: 126644236
I1022 16:11:01.449800 27537 layer_factory.hpp:77] Creating layer res3a_relu
I1022 16:11:01.449808 27537 net.cpp:100] Creating Layer res3a_relu
I1022 16:11:01.449816 27537 net.cpp:444] res3a_relu <- res3a
I1022 16:11:01.449825 27537 net.cpp:405] res3a_relu -> res3a (in-place)
I1022 16:11:01.451376 27537 net.cpp:150] Setting up res3a_relu
I1022 16:11:01.451398 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.451403 27537 net.cpp:165] Memory required for data: 128249868
I1022 16:11:01.451411 27537 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I1022 16:11:01.451424 27537 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I1022 16:11:01.451432 27537 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I1022 16:11:01.451445 27537 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I1022 16:11:01.451460 27537 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I1022 16:11:01.451591 27537 net.cpp:150] Setting up res3a_res3a_relu_0_split
I1022 16:11:01.451604 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.451611 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.451617 27537 net.cpp:165] Memory required for data: 131461132
I1022 16:11:01.451625 27537 layer_factory.hpp:77] Creating layer res3b_branch2a
I1022 16:11:01.451644 27537 net.cpp:100] Creating Layer res3b_branch2a
I1022 16:11:01.451653 27537 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I1022 16:11:01.451663 27537 net.cpp:418] res3b_branch2a -> res3b_branch2a
I1022 16:11:01.454826 27537 net.cpp:150] Setting up res3b_branch2a
I1022 16:11:01.454854 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.454859 27537 net.cpp:165] Memory required for data: 131862540
I1022 16:11:01.454869 27537 layer_factory.hpp:77] Creating layer bn3b_branch2a
I1022 16:11:01.454885 27537 net.cpp:100] Creating Layer bn3b_branch2a
I1022 16:11:01.454891 27537 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I1022 16:11:01.454903 27537 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I1022 16:11:01.455555 27537 net.cpp:150] Setting up bn3b_branch2a
I1022 16:11:01.455569 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.455574 27537 net.cpp:165] Memory required for data: 132263948
I1022 16:11:01.455588 27537 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1022 16:11:01.455601 27537 net.cpp:100] Creating Layer scale3b_branch2a
I1022 16:11:01.455606 27537 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I1022 16:11:01.455618 27537 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I1022 16:11:01.455734 27537 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1022 16:11:01.456089 27537 net.cpp:150] Setting up scale3b_branch2a
I1022 16:11:01.456100 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.456106 27537 net.cpp:165] Memory required for data: 132665356
I1022 16:11:01.456116 27537 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I1022 16:11:01.456127 27537 net.cpp:100] Creating Layer res3b_branch2a_relu
I1022 16:11:01.456133 27537 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I1022 16:11:01.456141 27537 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I1022 16:11:01.456569 27537 net.cpp:150] Setting up res3b_branch2a_relu
I1022 16:11:01.456584 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.456589 27537 net.cpp:165] Memory required for data: 133066764
I1022 16:11:01.456595 27537 layer_factory.hpp:77] Creating layer res3b_branch2b
I1022 16:11:01.456632 27537 net.cpp:100] Creating Layer res3b_branch2b
I1022 16:11:01.456640 27537 net.cpp:444] res3b_branch2b <- res3b_branch2a
I1022 16:11:01.456655 27537 net.cpp:418] res3b_branch2b -> res3b_branch2b
I1022 16:11:01.461032 27537 net.cpp:150] Setting up res3b_branch2b
I1022 16:11:01.461069 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.461076 27537 net.cpp:165] Memory required for data: 133468172
I1022 16:11:01.461086 27537 layer_factory.hpp:77] Creating layer bn3b_branch2b
I1022 16:11:01.461098 27537 net.cpp:100] Creating Layer bn3b_branch2b
I1022 16:11:01.461105 27537 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I1022 16:11:01.461117 27537 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I1022 16:11:01.461782 27537 net.cpp:150] Setting up bn3b_branch2b
I1022 16:11:01.461796 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.461802 27537 net.cpp:165] Memory required for data: 133869580
I1022 16:11:01.461817 27537 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1022 16:11:01.461828 27537 net.cpp:100] Creating Layer scale3b_branch2b
I1022 16:11:01.461835 27537 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I1022 16:11:01.461848 27537 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I1022 16:11:01.461961 27537 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1022 16:11:01.462325 27537 net.cpp:150] Setting up scale3b_branch2b
I1022 16:11:01.462338 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.462343 27537 net.cpp:165] Memory required for data: 134270988
I1022 16:11:01.462353 27537 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I1022 16:11:01.462363 27537 net.cpp:100] Creating Layer res3b_branch2b_relu
I1022 16:11:01.462368 27537 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I1022 16:11:01.462379 27537 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I1022 16:11:01.462803 27537 net.cpp:150] Setting up res3b_branch2b_relu
I1022 16:11:01.462817 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.462823 27537 net.cpp:165] Memory required for data: 134672396
I1022 16:11:01.462831 27537 layer_factory.hpp:77] Creating layer res3b_branch2c
I1022 16:11:01.462847 27537 net.cpp:100] Creating Layer res3b_branch2c
I1022 16:11:01.462853 27537 net.cpp:444] res3b_branch2c <- res3b_branch2b
I1022 16:11:01.462865 27537 net.cpp:418] res3b_branch2c -> res3b_branch2c
I1022 16:11:01.465919 27537 net.cpp:150] Setting up res3b_branch2c
I1022 16:11:01.465953 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.465958 27537 net.cpp:165] Memory required for data: 136278028
I1022 16:11:01.465968 27537 layer_factory.hpp:77] Creating layer bn3b_branch2c
I1022 16:11:01.465986 27537 net.cpp:100] Creating Layer bn3b_branch2c
I1022 16:11:01.465991 27537 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I1022 16:11:01.465999 27537 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I1022 16:11:01.466619 27537 net.cpp:150] Setting up bn3b_branch2c
I1022 16:11:01.466631 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.466636 27537 net.cpp:165] Memory required for data: 137883660
I1022 16:11:01.466655 27537 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1022 16:11:01.466665 27537 net.cpp:100] Creating Layer scale3b_branch2c
I1022 16:11:01.466670 27537 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I1022 16:11:01.466681 27537 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I1022 16:11:01.466799 27537 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1022 16:11:01.467135 27537 net.cpp:150] Setting up scale3b_branch2c
I1022 16:11:01.467146 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.467150 27537 net.cpp:165] Memory required for data: 139489292
I1022 16:11:01.467165 27537 layer_factory.hpp:77] Creating layer res3b
I1022 16:11:01.467175 27537 net.cpp:100] Creating Layer res3b
I1022 16:11:01.467180 27537 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I1022 16:11:01.467187 27537 net.cpp:444] res3b <- res3b_branch2c
I1022 16:11:01.467198 27537 net.cpp:418] res3b -> res3b
I1022 16:11:01.467260 27537 net.cpp:150] Setting up res3b
I1022 16:11:01.467272 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.467275 27537 net.cpp:165] Memory required for data: 141094924
I1022 16:11:01.467280 27537 layer_factory.hpp:77] Creating layer res3b_relu
I1022 16:11:01.467291 27537 net.cpp:100] Creating Layer res3b_relu
I1022 16:11:01.467299 27537 net.cpp:444] res3b_relu <- res3b
I1022 16:11:01.467306 27537 net.cpp:405] res3b_relu -> res3b (in-place)
I1022 16:11:01.469683 27537 net.cpp:150] Setting up res3b_relu
I1022 16:11:01.469714 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.469722 27537 net.cpp:165] Memory required for data: 142700556
I1022 16:11:01.469729 27537 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I1022 16:11:01.469741 27537 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I1022 16:11:01.469750 27537 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I1022 16:11:01.469765 27537 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I1022 16:11:01.469780 27537 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I1022 16:11:01.469969 27537 net.cpp:150] Setting up res3b_res3b_relu_0_split
I1022 16:11:01.469985 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.469992 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.470000 27537 net.cpp:165] Memory required for data: 145911820
I1022 16:11:01.470006 27537 layer_factory.hpp:77] Creating layer res3c_branch2a
I1022 16:11:01.470026 27537 net.cpp:100] Creating Layer res3c_branch2a
I1022 16:11:01.470034 27537 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I1022 16:11:01.470048 27537 net.cpp:418] res3c_branch2a -> res3c_branch2a
I1022 16:11:01.473465 27537 net.cpp:150] Setting up res3c_branch2a
I1022 16:11:01.473493 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.473502 27537 net.cpp:165] Memory required for data: 146313228
I1022 16:11:01.473515 27537 layer_factory.hpp:77] Creating layer bn3c_branch2a
I1022 16:11:01.473531 27537 net.cpp:100] Creating Layer bn3c_branch2a
I1022 16:11:01.473541 27537 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I1022 16:11:01.473553 27537 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I1022 16:11:01.474277 27537 net.cpp:150] Setting up bn3c_branch2a
I1022 16:11:01.474290 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.474299 27537 net.cpp:165] Memory required for data: 146714636
I1022 16:11:01.474313 27537 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1022 16:11:01.474330 27537 net.cpp:100] Creating Layer scale3c_branch2a
I1022 16:11:01.474339 27537 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I1022 16:11:01.474354 27537 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I1022 16:11:01.474480 27537 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1022 16:11:01.474869 27537 net.cpp:150] Setting up scale3c_branch2a
I1022 16:11:01.474882 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.474891 27537 net.cpp:165] Memory required for data: 147116044
I1022 16:11:01.474905 27537 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I1022 16:11:01.474916 27537 net.cpp:100] Creating Layer res3c_branch2a_relu
I1022 16:11:01.474922 27537 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I1022 16:11:01.474937 27537 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I1022 16:11:01.475389 27537 net.cpp:150] Setting up res3c_branch2a_relu
I1022 16:11:01.475404 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.475411 27537 net.cpp:165] Memory required for data: 147517452
I1022 16:11:01.475419 27537 layer_factory.hpp:77] Creating layer res3c_branch2b
I1022 16:11:01.475435 27537 net.cpp:100] Creating Layer res3c_branch2b
I1022 16:11:01.475443 27537 net.cpp:444] res3c_branch2b <- res3c_branch2a
I1022 16:11:01.475456 27537 net.cpp:418] res3c_branch2b -> res3c_branch2b
I1022 16:11:01.482903 27537 net.cpp:150] Setting up res3c_branch2b
I1022 16:11:01.482926 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.482933 27537 net.cpp:165] Memory required for data: 147918860
I1022 16:11:01.482944 27537 layer_factory.hpp:77] Creating layer bn3c_branch2b
I1022 16:11:01.482961 27537 net.cpp:100] Creating Layer bn3c_branch2b
I1022 16:11:01.482969 27537 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I1022 16:11:01.482981 27537 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I1022 16:11:01.483722 27537 net.cpp:150] Setting up bn3c_branch2b
I1022 16:11:01.483742 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.483748 27537 net.cpp:165] Memory required for data: 148320268
I1022 16:11:01.483762 27537 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1022 16:11:01.483773 27537 net.cpp:100] Creating Layer scale3c_branch2b
I1022 16:11:01.483780 27537 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I1022 16:11:01.483793 27537 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I1022 16:11:01.483923 27537 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1022 16:11:01.484314 27537 net.cpp:150] Setting up scale3c_branch2b
I1022 16:11:01.484328 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.484333 27537 net.cpp:165] Memory required for data: 148721676
I1022 16:11:01.484344 27537 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I1022 16:11:01.484354 27537 net.cpp:100] Creating Layer res3c_branch2b_relu
I1022 16:11:01.484361 27537 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I1022 16:11:01.484372 27537 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I1022 16:11:01.484885 27537 net.cpp:150] Setting up res3c_branch2b_relu
I1022 16:11:01.484901 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.484907 27537 net.cpp:165] Memory required for data: 149123084
I1022 16:11:01.484913 27537 layer_factory.hpp:77] Creating layer res3c_branch2c
I1022 16:11:01.484930 27537 net.cpp:100] Creating Layer res3c_branch2c
I1022 16:11:01.484936 27537 net.cpp:444] res3c_branch2c <- res3c_branch2b
I1022 16:11:01.484951 27537 net.cpp:418] res3c_branch2c -> res3c_branch2c
I1022 16:11:01.491488 27537 net.cpp:150] Setting up res3c_branch2c
I1022 16:11:01.491516 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.491523 27537 net.cpp:165] Memory required for data: 150728716
I1022 16:11:01.491534 27537 layer_factory.hpp:77] Creating layer bn3c_branch2c
I1022 16:11:01.491546 27537 net.cpp:100] Creating Layer bn3c_branch2c
I1022 16:11:01.491556 27537 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I1022 16:11:01.491569 27537 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I1022 16:11:01.492241 27537 net.cpp:150] Setting up bn3c_branch2c
I1022 16:11:01.492255 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.492260 27537 net.cpp:165] Memory required for data: 152334348
I1022 16:11:01.492274 27537 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1022 16:11:01.492287 27537 net.cpp:100] Creating Layer scale3c_branch2c
I1022 16:11:01.492293 27537 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I1022 16:11:01.492305 27537 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I1022 16:11:01.492435 27537 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1022 16:11:01.492842 27537 net.cpp:150] Setting up scale3c_branch2c
I1022 16:11:01.492856 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.492861 27537 net.cpp:165] Memory required for data: 153939980
I1022 16:11:01.492871 27537 layer_factory.hpp:77] Creating layer res3c
I1022 16:11:01.492882 27537 net.cpp:100] Creating Layer res3c
I1022 16:11:01.492887 27537 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I1022 16:11:01.492895 27537 net.cpp:444] res3c <- res3c_branch2c
I1022 16:11:01.492904 27537 net.cpp:418] res3c -> res3c
I1022 16:11:01.492974 27537 net.cpp:150] Setting up res3c
I1022 16:11:01.492985 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.492990 27537 net.cpp:165] Memory required for data: 155545612
I1022 16:11:01.492996 27537 layer_factory.hpp:77] Creating layer res3c_relu
I1022 16:11:01.493007 27537 net.cpp:100] Creating Layer res3c_relu
I1022 16:11:01.493013 27537 net.cpp:444] res3c_relu <- res3c
I1022 16:11:01.493024 27537 net.cpp:405] res3c_relu -> res3c (in-place)
I1022 16:11:01.493444 27537 net.cpp:150] Setting up res3c_relu
I1022 16:11:01.493463 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.493468 27537 net.cpp:165] Memory required for data: 157151244
I1022 16:11:01.493474 27537 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I1022 16:11:01.493484 27537 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I1022 16:11:01.493489 27537 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I1022 16:11:01.493501 27537 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I1022 16:11:01.493513 27537 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I1022 16:11:01.493646 27537 net.cpp:150] Setting up res3c_res3c_relu_0_split
I1022 16:11:01.493659 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.493666 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.493671 27537 net.cpp:165] Memory required for data: 160362508
I1022 16:11:01.493679 27537 layer_factory.hpp:77] Creating layer res3d_branch2a
I1022 16:11:01.493697 27537 net.cpp:100] Creating Layer res3d_branch2a
I1022 16:11:01.493706 27537 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I1022 16:11:01.493718 27537 net.cpp:418] res3d_branch2a -> res3d_branch2a
I1022 16:11:01.499320 27537 net.cpp:150] Setting up res3d_branch2a
I1022 16:11:01.499341 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.499346 27537 net.cpp:165] Memory required for data: 160763916
I1022 16:11:01.499356 27537 layer_factory.hpp:77] Creating layer bn3d_branch2a
I1022 16:11:01.499366 27537 net.cpp:100] Creating Layer bn3d_branch2a
I1022 16:11:01.499373 27537 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I1022 16:11:01.499384 27537 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I1022 16:11:01.500017 27537 net.cpp:150] Setting up bn3d_branch2a
I1022 16:11:01.500030 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.500036 27537 net.cpp:165] Memory required for data: 161165324
I1022 16:11:01.500064 27537 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1022 16:11:01.500077 27537 net.cpp:100] Creating Layer scale3d_branch2a
I1022 16:11:01.500087 27537 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I1022 16:11:01.500097 27537 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I1022 16:11:01.500211 27537 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1022 16:11:01.500547 27537 net.cpp:150] Setting up scale3d_branch2a
I1022 16:11:01.500558 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.500564 27537 net.cpp:165] Memory required for data: 161566732
I1022 16:11:01.500573 27537 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I1022 16:11:01.500581 27537 net.cpp:100] Creating Layer res3d_branch2a_relu
I1022 16:11:01.500587 27537 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I1022 16:11:01.500597 27537 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I1022 16:11:01.502005 27537 net.cpp:150] Setting up res3d_branch2a_relu
I1022 16:11:01.502025 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.502033 27537 net.cpp:165] Memory required for data: 161968140
I1022 16:11:01.502040 27537 layer_factory.hpp:77] Creating layer res3d_branch2b
I1022 16:11:01.502053 27537 net.cpp:100] Creating Layer res3d_branch2b
I1022 16:11:01.502059 27537 net.cpp:444] res3d_branch2b <- res3d_branch2a
I1022 16:11:01.502074 27537 net.cpp:418] res3d_branch2b -> res3d_branch2b
I1022 16:11:01.509745 27537 net.cpp:150] Setting up res3d_branch2b
I1022 16:11:01.509768 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.509774 27537 net.cpp:165] Memory required for data: 162369548
I1022 16:11:01.509784 27537 layer_factory.hpp:77] Creating layer bn3d_branch2b
I1022 16:11:01.509799 27537 net.cpp:100] Creating Layer bn3d_branch2b
I1022 16:11:01.509805 27537 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I1022 16:11:01.509817 27537 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I1022 16:11:01.510468 27537 net.cpp:150] Setting up bn3d_branch2b
I1022 16:11:01.510481 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.510486 27537 net.cpp:165] Memory required for data: 162770956
I1022 16:11:01.510499 27537 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1022 16:11:01.510510 27537 net.cpp:100] Creating Layer scale3d_branch2b
I1022 16:11:01.510519 27537 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I1022 16:11:01.510531 27537 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I1022 16:11:01.510644 27537 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1022 16:11:01.510987 27537 net.cpp:150] Setting up scale3d_branch2b
I1022 16:11:01.510999 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.511003 27537 net.cpp:165] Memory required for data: 163172364
I1022 16:11:01.511013 27537 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I1022 16:11:01.511021 27537 net.cpp:100] Creating Layer res3d_branch2b_relu
I1022 16:11:01.511027 27537 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I1022 16:11:01.511034 27537 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I1022 16:11:01.511471 27537 net.cpp:150] Setting up res3d_branch2b_relu
I1022 16:11:01.511484 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.511490 27537 net.cpp:165] Memory required for data: 163573772
I1022 16:11:01.511497 27537 layer_factory.hpp:77] Creating layer res3d_branch2c
I1022 16:11:01.511509 27537 net.cpp:100] Creating Layer res3d_branch2c
I1022 16:11:01.511518 27537 net.cpp:444] res3d_branch2c <- res3d_branch2b
I1022 16:11:01.511528 27537 net.cpp:418] res3d_branch2c -> res3d_branch2c
I1022 16:11:01.517181 27537 net.cpp:150] Setting up res3d_branch2c
I1022 16:11:01.517204 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.517210 27537 net.cpp:165] Memory required for data: 165179404
I1022 16:11:01.517220 27537 layer_factory.hpp:77] Creating layer bn3d_branch2c
I1022 16:11:01.517236 27537 net.cpp:100] Creating Layer bn3d_branch2c
I1022 16:11:01.517243 27537 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I1022 16:11:01.517254 27537 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I1022 16:11:01.517887 27537 net.cpp:150] Setting up bn3d_branch2c
I1022 16:11:01.517900 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.517905 27537 net.cpp:165] Memory required for data: 166785036
I1022 16:11:01.517917 27537 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1022 16:11:01.517930 27537 net.cpp:100] Creating Layer scale3d_branch2c
I1022 16:11:01.517936 27537 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I1022 16:11:01.517946 27537 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I1022 16:11:01.518064 27537 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1022 16:11:01.518404 27537 net.cpp:150] Setting up scale3d_branch2c
I1022 16:11:01.518415 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.518420 27537 net.cpp:165] Memory required for data: 168390668
I1022 16:11:01.518429 27537 layer_factory.hpp:77] Creating layer res3d
I1022 16:11:01.518441 27537 net.cpp:100] Creating Layer res3d
I1022 16:11:01.518447 27537 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I1022 16:11:01.518455 27537 net.cpp:444] res3d <- res3d_branch2c
I1022 16:11:01.518462 27537 net.cpp:418] res3d -> res3d
I1022 16:11:01.518527 27537 net.cpp:150] Setting up res3d
I1022 16:11:01.518538 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.518543 27537 net.cpp:165] Memory required for data: 169996300
I1022 16:11:01.518548 27537 layer_factory.hpp:77] Creating layer res3d_relu
I1022 16:11:01.518558 27537 net.cpp:100] Creating Layer res3d_relu
I1022 16:11:01.518565 27537 net.cpp:444] res3d_relu <- res3d
I1022 16:11:01.518573 27537 net.cpp:405] res3d_relu -> res3d (in-place)
I1022 16:11:01.518965 27537 net.cpp:150] Setting up res3d_relu
I1022 16:11:01.518980 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.518985 27537 net.cpp:165] Memory required for data: 171601932
I1022 16:11:01.518990 27537 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I1022 16:11:01.519002 27537 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I1022 16:11:01.519011 27537 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I1022 16:11:01.519021 27537 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I1022 16:11:01.519035 27537 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I1022 16:11:01.519048 27537 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_2
I1022 16:11:01.519204 27537 net.cpp:150] Setting up res3d_res3d_relu_0_split
I1022 16:11:01.519218 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.519225 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.519234 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.519239 27537 net.cpp:165] Memory required for data: 176418828
I1022 16:11:01.519244 27537 layer_factory.hpp:77] Creating layer res4a_branch1
I1022 16:11:01.519256 27537 net.cpp:100] Creating Layer res4a_branch1
I1022 16:11:01.519264 27537 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I1022 16:11:01.519278 27537 net.cpp:418] res4a_branch1 -> res4a_branch1
I1022 16:11:01.526870 27537 net.cpp:150] Setting up res4a_branch1
I1022 16:11:01.526895 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.526907 27537 net.cpp:165] Memory required for data: 177221644
I1022 16:11:01.526916 27537 layer_factory.hpp:77] Creating layer bn4a_branch1
I1022 16:11:01.526931 27537 net.cpp:100] Creating Layer bn4a_branch1
I1022 16:11:01.526937 27537 net.cpp:444] bn4a_branch1 <- res4a_branch1
I1022 16:11:01.526947 27537 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I1022 16:11:01.527604 27537 net.cpp:150] Setting up bn4a_branch1
I1022 16:11:01.527616 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.527621 27537 net.cpp:165] Memory required for data: 178024460
I1022 16:11:01.527638 27537 layer_factory.hpp:77] Creating layer scale4a_branch1
I1022 16:11:01.527648 27537 net.cpp:100] Creating Layer scale4a_branch1
I1022 16:11:01.527653 27537 net.cpp:444] scale4a_branch1 <- res4a_branch1
I1022 16:11:01.527663 27537 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I1022 16:11:01.527758 27537 layer_factory.hpp:77] Creating layer scale4a_branch1
I1022 16:11:01.528089 27537 net.cpp:150] Setting up scale4a_branch1
I1022 16:11:01.528100 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.528105 27537 net.cpp:165] Memory required for data: 178827276
I1022 16:11:01.528117 27537 layer_factory.hpp:77] Creating layer res4a_branch2a
I1022 16:11:01.528129 27537 net.cpp:100] Creating Layer res4a_branch2a
I1022 16:11:01.528136 27537 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I1022 16:11:01.528144 27537 net.cpp:418] res4a_branch2a -> res4a_branch2a
I1022 16:11:01.530997 27537 net.cpp:150] Setting up res4a_branch2a
I1022 16:11:01.531018 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.531023 27537 net.cpp:165] Memory required for data: 179027980
I1022 16:11:01.531041 27537 layer_factory.hpp:77] Creating layer bn4a_branch2a
I1022 16:11:01.531067 27537 net.cpp:100] Creating Layer bn4a_branch2a
I1022 16:11:01.531075 27537 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I1022 16:11:01.531082 27537 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I1022 16:11:01.531688 27537 net.cpp:150] Setting up bn4a_branch2a
I1022 16:11:01.531700 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.531705 27537 net.cpp:165] Memory required for data: 179228684
I1022 16:11:01.531721 27537 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1022 16:11:01.531729 27537 net.cpp:100] Creating Layer scale4a_branch2a
I1022 16:11:01.531734 27537 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I1022 16:11:01.531745 27537 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I1022 16:11:01.531848 27537 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1022 16:11:01.532176 27537 net.cpp:150] Setting up scale4a_branch2a
I1022 16:11:01.532186 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.532191 27537 net.cpp:165] Memory required for data: 179429388
I1022 16:11:01.532205 27537 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I1022 16:11:01.532213 27537 net.cpp:100] Creating Layer res4a_branch2a_relu
I1022 16:11:01.532217 27537 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I1022 16:11:01.532227 27537 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I1022 16:11:01.533576 27537 net.cpp:150] Setting up res4a_branch2a_relu
I1022 16:11:01.533596 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.533601 27537 net.cpp:165] Memory required for data: 179630092
I1022 16:11:01.533609 27537 layer_factory.hpp:77] Creating layer res4a_branch2b
I1022 16:11:01.533624 27537 net.cpp:100] Creating Layer res4a_branch2b
I1022 16:11:01.533630 27537 net.cpp:444] res4a_branch2b <- res4a_branch2a
I1022 16:11:01.533643 27537 net.cpp:418] res4a_branch2b -> res4a_branch2b
I1022 16:11:01.540634 27537 net.cpp:150] Setting up res4a_branch2b
I1022 16:11:01.540655 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.540670 27537 net.cpp:165] Memory required for data: 179830796
I1022 16:11:01.540680 27537 layer_factory.hpp:77] Creating layer bn4a_branch2b
I1022 16:11:01.540696 27537 net.cpp:100] Creating Layer bn4a_branch2b
I1022 16:11:01.540702 27537 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I1022 16:11:01.540714 27537 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I1022 16:11:01.541306 27537 net.cpp:150] Setting up bn4a_branch2b
I1022 16:11:01.541317 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.541322 27537 net.cpp:165] Memory required for data: 180031500
I1022 16:11:01.541339 27537 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1022 16:11:01.541350 27537 net.cpp:100] Creating Layer scale4a_branch2b
I1022 16:11:01.541357 27537 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I1022 16:11:01.541363 27537 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I1022 16:11:01.541468 27537 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1022 16:11:01.541786 27537 net.cpp:150] Setting up scale4a_branch2b
I1022 16:11:01.541800 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.541812 27537 net.cpp:165] Memory required for data: 180232204
I1022 16:11:01.541821 27537 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I1022 16:11:01.541829 27537 net.cpp:100] Creating Layer res4a_branch2b_relu
I1022 16:11:01.541834 27537 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I1022 16:11:01.541841 27537 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I1022 16:11:01.542245 27537 net.cpp:150] Setting up res4a_branch2b_relu
I1022 16:11:01.542261 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.542275 27537 net.cpp:165] Memory required for data: 180432908
I1022 16:11:01.542280 27537 layer_factory.hpp:77] Creating layer res4a_branch2c
I1022 16:11:01.542291 27537 net.cpp:100] Creating Layer res4a_branch2c
I1022 16:11:01.542296 27537 net.cpp:444] res4a_branch2c <- res4a_branch2b
I1022 16:11:01.542309 27537 net.cpp:418] res4a_branch2c -> res4a_branch2c
I1022 16:11:01.555189 27537 net.cpp:150] Setting up res4a_branch2c
I1022 16:11:01.555225 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.555230 27537 net.cpp:165] Memory required for data: 181235724
I1022 16:11:01.555239 27537 layer_factory.hpp:77] Creating layer bn4a_branch2c
I1022 16:11:01.555250 27537 net.cpp:100] Creating Layer bn4a_branch2c
I1022 16:11:01.555255 27537 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I1022 16:11:01.555265 27537 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I1022 16:11:01.555835 27537 net.cpp:150] Setting up bn4a_branch2c
I1022 16:11:01.555845 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.555850 27537 net.cpp:165] Memory required for data: 182038540
I1022 16:11:01.555868 27537 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1022 16:11:01.555881 27537 net.cpp:100] Creating Layer scale4a_branch2c
I1022 16:11:01.555886 27537 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I1022 16:11:01.555894 27537 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I1022 16:11:01.555984 27537 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1022 16:11:01.556313 27537 net.cpp:150] Setting up scale4a_branch2c
I1022 16:11:01.556324 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.556329 27537 net.cpp:165] Memory required for data: 182841356
I1022 16:11:01.556344 27537 layer_factory.hpp:77] Creating layer res4a
I1022 16:11:01.556351 27537 net.cpp:100] Creating Layer res4a
I1022 16:11:01.556356 27537 net.cpp:444] res4a <- res4a_branch1
I1022 16:11:01.556362 27537 net.cpp:444] res4a <- res4a_branch2c
I1022 16:11:01.556368 27537 net.cpp:418] res4a -> res4a
I1022 16:11:01.556427 27537 net.cpp:150] Setting up res4a
I1022 16:11:01.556437 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.556442 27537 net.cpp:165] Memory required for data: 183644172
I1022 16:11:01.556447 27537 layer_factory.hpp:77] Creating layer res4a_relu
I1022 16:11:01.556453 27537 net.cpp:100] Creating Layer res4a_relu
I1022 16:11:01.556458 27537 net.cpp:444] res4a_relu <- res4a
I1022 16:11:01.556466 27537 net.cpp:405] res4a_relu -> res4a (in-place)
I1022 16:11:01.557770 27537 net.cpp:150] Setting up res4a_relu
I1022 16:11:01.557790 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.557803 27537 net.cpp:165] Memory required for data: 184446988
I1022 16:11:01.557808 27537 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I1022 16:11:01.557821 27537 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I1022 16:11:01.557826 27537 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I1022 16:11:01.557837 27537 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I1022 16:11:01.557847 27537 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I1022 16:11:01.557965 27537 net.cpp:150] Setting up res4a_res4a_relu_0_split
I1022 16:11:01.557976 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.557982 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.557986 27537 net.cpp:165] Memory required for data: 186052620
I1022 16:11:01.557991 27537 layer_factory.hpp:77] Creating layer res4b_branch2a
I1022 16:11:01.558019 27537 net.cpp:100] Creating Layer res4b_branch2a
I1022 16:11:01.558027 27537 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I1022 16:11:01.558034 27537 net.cpp:418] res4b_branch2a -> res4b_branch2a
I1022 16:11:01.560835 27537 net.cpp:150] Setting up res4b_branch2a
I1022 16:11:01.560855 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.560860 27537 net.cpp:165] Memory required for data: 186253324
I1022 16:11:01.560875 27537 layer_factory.hpp:77] Creating layer bn4b_branch2a
I1022 16:11:01.560887 27537 net.cpp:100] Creating Layer bn4b_branch2a
I1022 16:11:01.560894 27537 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I1022 16:11:01.560904 27537 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I1022 16:11:01.561477 27537 net.cpp:150] Setting up bn4b_branch2a
I1022 16:11:01.561489 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.561493 27537 net.cpp:165] Memory required for data: 186454028
I1022 16:11:01.561511 27537 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1022 16:11:01.561522 27537 net.cpp:100] Creating Layer scale4b_branch2a
I1022 16:11:01.561527 27537 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I1022 16:11:01.561535 27537 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I1022 16:11:01.561633 27537 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1022 16:11:01.561938 27537 net.cpp:150] Setting up scale4b_branch2a
I1022 16:11:01.561947 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.561952 27537 net.cpp:165] Memory required for data: 186654732
I1022 16:11:01.561966 27537 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I1022 16:11:01.561976 27537 net.cpp:100] Creating Layer res4b_branch2a_relu
I1022 16:11:01.561981 27537 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I1022 16:11:01.561987 27537 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I1022 16:11:01.563257 27537 net.cpp:150] Setting up res4b_branch2a_relu
I1022 16:11:01.563277 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.563290 27537 net.cpp:165] Memory required for data: 186855436
I1022 16:11:01.563297 27537 layer_factory.hpp:77] Creating layer res4b_branch2b
I1022 16:11:01.563311 27537 net.cpp:100] Creating Layer res4b_branch2b
I1022 16:11:01.563316 27537 net.cpp:444] res4b_branch2b <- res4b_branch2a
I1022 16:11:01.563325 27537 net.cpp:418] res4b_branch2b -> res4b_branch2b
I1022 16:11:01.571841 27537 net.cpp:150] Setting up res4b_branch2b
I1022 16:11:01.571873 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.571878 27537 net.cpp:165] Memory required for data: 187056140
I1022 16:11:01.571887 27537 layer_factory.hpp:77] Creating layer bn4b_branch2b
I1022 16:11:01.571897 27537 net.cpp:100] Creating Layer bn4b_branch2b
I1022 16:11:01.571902 27537 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I1022 16:11:01.571911 27537 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I1022 16:11:01.572471 27537 net.cpp:150] Setting up bn4b_branch2b
I1022 16:11:01.572482 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.572497 27537 net.cpp:165] Memory required for data: 187256844
I1022 16:11:01.572506 27537 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1022 16:11:01.572515 27537 net.cpp:100] Creating Layer scale4b_branch2b
I1022 16:11:01.572520 27537 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I1022 16:11:01.572528 27537 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I1022 16:11:01.572665 27537 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1022 16:11:01.572968 27537 net.cpp:150] Setting up scale4b_branch2b
I1022 16:11:01.572978 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.572983 27537 net.cpp:165] Memory required for data: 187457548
I1022 16:11:01.572998 27537 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I1022 16:11:01.573004 27537 net.cpp:100] Creating Layer res4b_branch2b_relu
I1022 16:11:01.573010 27537 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I1022 16:11:01.573017 27537 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I1022 16:11:01.573381 27537 net.cpp:150] Setting up res4b_branch2b_relu
I1022 16:11:01.573392 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.573407 27537 net.cpp:165] Memory required for data: 187658252
I1022 16:11:01.573411 27537 layer_factory.hpp:77] Creating layer res4b_branch2c
I1022 16:11:01.573426 27537 net.cpp:100] Creating Layer res4b_branch2c
I1022 16:11:01.573431 27537 net.cpp:444] res4b_branch2c <- res4b_branch2b
I1022 16:11:01.573441 27537 net.cpp:418] res4b_branch2c -> res4b_branch2c
I1022 16:11:01.578461 27537 net.cpp:150] Setting up res4b_branch2c
I1022 16:11:01.578480 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.578485 27537 net.cpp:165] Memory required for data: 188461068
I1022 16:11:01.578496 27537 layer_factory.hpp:77] Creating layer bn4b_branch2c
I1022 16:11:01.578508 27537 net.cpp:100] Creating Layer bn4b_branch2c
I1022 16:11:01.578513 27537 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I1022 16:11:01.578522 27537 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I1022 16:11:01.579073 27537 net.cpp:150] Setting up bn4b_branch2c
I1022 16:11:01.579083 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.579087 27537 net.cpp:165] Memory required for data: 189263884
I1022 16:11:01.579105 27537 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1022 16:11:01.579118 27537 net.cpp:100] Creating Layer scale4b_branch2c
I1022 16:11:01.579121 27537 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I1022 16:11:01.579128 27537 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I1022 16:11:01.579218 27537 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1022 16:11:01.579524 27537 net.cpp:150] Setting up scale4b_branch2c
I1022 16:11:01.579533 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.579537 27537 net.cpp:165] Memory required for data: 190066700
I1022 16:11:01.579552 27537 layer_factory.hpp:77] Creating layer res4b
I1022 16:11:01.579560 27537 net.cpp:100] Creating Layer res4b
I1022 16:11:01.579565 27537 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I1022 16:11:01.579571 27537 net.cpp:444] res4b <- res4b_branch2c
I1022 16:11:01.579576 27537 net.cpp:418] res4b -> res4b
I1022 16:11:01.579632 27537 net.cpp:150] Setting up res4b
I1022 16:11:01.579643 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.579646 27537 net.cpp:165] Memory required for data: 190869516
I1022 16:11:01.579650 27537 layer_factory.hpp:77] Creating layer res4b_relu
I1022 16:11:01.579658 27537 net.cpp:100] Creating Layer res4b_relu
I1022 16:11:01.579661 27537 net.cpp:444] res4b_relu <- res4b
I1022 16:11:01.579666 27537 net.cpp:405] res4b_relu -> res4b (in-place)
I1022 16:11:01.580003 27537 net.cpp:150] Setting up res4b_relu
I1022 16:11:01.580014 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.580018 27537 net.cpp:165] Memory required for data: 191672332
I1022 16:11:01.580026 27537 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I1022 16:11:01.580034 27537 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I1022 16:11:01.580039 27537 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I1022 16:11:01.580047 27537 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I1022 16:11:01.580058 27537 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I1022 16:11:01.580164 27537 net.cpp:150] Setting up res4b_res4b_relu_0_split
I1022 16:11:01.580173 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.580179 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.580183 27537 net.cpp:165] Memory required for data: 193277964
I1022 16:11:01.580188 27537 layer_factory.hpp:77] Creating layer res4c_branch2a
I1022 16:11:01.580199 27537 net.cpp:100] Creating Layer res4c_branch2a
I1022 16:11:01.580206 27537 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I1022 16:11:01.580215 27537 net.cpp:418] res4c_branch2a -> res4c_branch2a
I1022 16:11:01.582872 27537 net.cpp:150] Setting up res4c_branch2a
I1022 16:11:01.582892 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.582904 27537 net.cpp:165] Memory required for data: 193478668
I1022 16:11:01.582912 27537 layer_factory.hpp:77] Creating layer bn4c_branch2a
I1022 16:11:01.582924 27537 net.cpp:100] Creating Layer bn4c_branch2a
I1022 16:11:01.582931 27537 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I1022 16:11:01.582938 27537 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I1022 16:11:01.583453 27537 net.cpp:150] Setting up bn4c_branch2a
I1022 16:11:01.583463 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.583467 27537 net.cpp:165] Memory required for data: 193679372
I1022 16:11:01.583485 27537 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1022 16:11:01.583495 27537 net.cpp:100] Creating Layer scale4c_branch2a
I1022 16:11:01.583499 27537 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I1022 16:11:01.583508 27537 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I1022 16:11:01.583596 27537 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1022 16:11:01.583874 27537 net.cpp:150] Setting up scale4c_branch2a
I1022 16:11:01.583889 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.583892 27537 net.cpp:165] Memory required for data: 193880076
I1022 16:11:01.583905 27537 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I1022 16:11:01.583914 27537 net.cpp:100] Creating Layer res4c_branch2a_relu
I1022 16:11:01.583919 27537 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I1022 16:11:01.583925 27537 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I1022 16:11:01.584234 27537 net.cpp:150] Setting up res4c_branch2a_relu
I1022 16:11:01.584245 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.584249 27537 net.cpp:165] Memory required for data: 194080780
I1022 16:11:01.584257 27537 layer_factory.hpp:77] Creating layer res4c_branch2b
I1022 16:11:01.584272 27537 net.cpp:100] Creating Layer res4c_branch2b
I1022 16:11:01.584278 27537 net.cpp:444] res4c_branch2b <- res4c_branch2a
I1022 16:11:01.584285 27537 net.cpp:418] res4c_branch2b -> res4c_branch2b
I1022 16:11:01.591657 27537 net.cpp:150] Setting up res4c_branch2b
I1022 16:11:01.591688 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.591693 27537 net.cpp:165] Memory required for data: 194281484
I1022 16:11:01.591701 27537 layer_factory.hpp:77] Creating layer bn4c_branch2b
I1022 16:11:01.591711 27537 net.cpp:100] Creating Layer bn4c_branch2b
I1022 16:11:01.591717 27537 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I1022 16:11:01.591725 27537 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I1022 16:11:01.592254 27537 net.cpp:150] Setting up bn4c_branch2b
I1022 16:11:01.592265 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.592268 27537 net.cpp:165] Memory required for data: 194482188
I1022 16:11:01.592284 27537 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1022 16:11:01.592294 27537 net.cpp:100] Creating Layer scale4c_branch2b
I1022 16:11:01.592303 27537 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I1022 16:11:01.592311 27537 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I1022 16:11:01.592404 27537 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1022 16:11:01.592718 27537 net.cpp:150] Setting up scale4c_branch2b
I1022 16:11:01.592730 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.592732 27537 net.cpp:165] Memory required for data: 194682892
I1022 16:11:01.592739 27537 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I1022 16:11:01.592748 27537 net.cpp:100] Creating Layer res4c_branch2b_relu
I1022 16:11:01.592752 27537 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I1022 16:11:01.592761 27537 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I1022 16:11:01.593907 27537 net.cpp:150] Setting up res4c_branch2b_relu
I1022 16:11:01.593922 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.593935 27537 net.cpp:165] Memory required for data: 194883596
I1022 16:11:01.593940 27537 layer_factory.hpp:77] Creating layer res4c_branch2c
I1022 16:11:01.593952 27537 net.cpp:100] Creating Layer res4c_branch2c
I1022 16:11:01.593956 27537 net.cpp:444] res4c_branch2c <- res4c_branch2b
I1022 16:11:01.593964 27537 net.cpp:418] res4c_branch2c -> res4c_branch2c
I1022 16:11:01.598728 27537 net.cpp:150] Setting up res4c_branch2c
I1022 16:11:01.598745 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.598749 27537 net.cpp:165] Memory required for data: 195686412
I1022 16:11:01.598763 27537 layer_factory.hpp:77] Creating layer bn4c_branch2c
I1022 16:11:01.598774 27537 net.cpp:100] Creating Layer bn4c_branch2c
I1022 16:11:01.598779 27537 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I1022 16:11:01.598785 27537 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I1022 16:11:01.599283 27537 net.cpp:150] Setting up bn4c_branch2c
I1022 16:11:01.599294 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.599298 27537 net.cpp:165] Memory required for data: 196489228
I1022 16:11:01.599315 27537 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1022 16:11:01.599325 27537 net.cpp:100] Creating Layer scale4c_branch2c
I1022 16:11:01.599329 27537 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I1022 16:11:01.599335 27537 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I1022 16:11:01.599419 27537 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1022 16:11:01.599699 27537 net.cpp:150] Setting up scale4c_branch2c
I1022 16:11:01.599717 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.599721 27537 net.cpp:165] Memory required for data: 197292044
I1022 16:11:01.599728 27537 layer_factory.hpp:77] Creating layer res4c
I1022 16:11:01.599745 27537 net.cpp:100] Creating Layer res4c
I1022 16:11:01.599750 27537 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I1022 16:11:01.599756 27537 net.cpp:444] res4c <- res4c_branch2c
I1022 16:11:01.599761 27537 net.cpp:418] res4c -> res4c
I1022 16:11:01.599812 27537 net.cpp:150] Setting up res4c
I1022 16:11:01.599822 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.599824 27537 net.cpp:165] Memory required for data: 198094860
I1022 16:11:01.599834 27537 layer_factory.hpp:77] Creating layer res4c_relu
I1022 16:11:01.599840 27537 net.cpp:100] Creating Layer res4c_relu
I1022 16:11:01.599846 27537 net.cpp:444] res4c_relu <- res4c
I1022 16:11:01.599851 27537 net.cpp:405] res4c_relu -> res4c (in-place)
I1022 16:11:01.600157 27537 net.cpp:150] Setting up res4c_relu
I1022 16:11:01.600167 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.600170 27537 net.cpp:165] Memory required for data: 198897676
I1022 16:11:01.600179 27537 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I1022 16:11:01.600186 27537 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I1022 16:11:01.600190 27537 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I1022 16:11:01.600198 27537 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I1022 16:11:01.600206 27537 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I1022 16:11:01.600301 27537 net.cpp:150] Setting up res4c_res4c_relu_0_split
I1022 16:11:01.600311 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.600316 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.600318 27537 net.cpp:165] Memory required for data: 200503308
I1022 16:11:01.600322 27537 layer_factory.hpp:77] Creating layer res4d_branch2a
I1022 16:11:01.600333 27537 net.cpp:100] Creating Layer res4d_branch2a
I1022 16:11:01.600339 27537 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I1022 16:11:01.600347 27537 net.cpp:418] res4d_branch2a -> res4d_branch2a
I1022 16:11:01.602823 27537 net.cpp:150] Setting up res4d_branch2a
I1022 16:11:01.602854 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.602857 27537 net.cpp:165] Memory required for data: 200704012
I1022 16:11:01.602864 27537 layer_factory.hpp:77] Creating layer bn4d_branch2a
I1022 16:11:01.602872 27537 net.cpp:100] Creating Layer bn4d_branch2a
I1022 16:11:01.602877 27537 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I1022 16:11:01.602886 27537 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I1022 16:11:01.603385 27537 net.cpp:150] Setting up bn4d_branch2a
I1022 16:11:01.603394 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.603399 27537 net.cpp:165] Memory required for data: 200904716
I1022 16:11:01.603416 27537 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1022 16:11:01.603425 27537 net.cpp:100] Creating Layer scale4d_branch2a
I1022 16:11:01.603430 27537 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I1022 16:11:01.603440 27537 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I1022 16:11:01.603525 27537 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1022 16:11:01.603785 27537 net.cpp:150] Setting up scale4d_branch2a
I1022 16:11:01.603794 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.603798 27537 net.cpp:165] Memory required for data: 201105420
I1022 16:11:01.603806 27537 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I1022 16:11:01.603811 27537 net.cpp:100] Creating Layer res4d_branch2a_relu
I1022 16:11:01.603816 27537 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I1022 16:11:01.603824 27537 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I1022 16:11:01.604131 27537 net.cpp:150] Setting up res4d_branch2a_relu
I1022 16:11:01.604142 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.604146 27537 net.cpp:165] Memory required for data: 201306124
I1022 16:11:01.604153 27537 layer_factory.hpp:77] Creating layer res4d_branch2b
I1022 16:11:01.604164 27537 net.cpp:100] Creating Layer res4d_branch2b
I1022 16:11:01.604168 27537 net.cpp:444] res4d_branch2b <- res4d_branch2a
I1022 16:11:01.604177 27537 net.cpp:418] res4d_branch2b -> res4d_branch2b
I1022 16:11:01.611400 27537 net.cpp:150] Setting up res4d_branch2b
I1022 16:11:01.611418 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.611431 27537 net.cpp:165] Memory required for data: 201506828
I1022 16:11:01.611438 27537 layer_factory.hpp:77] Creating layer bn4d_branch2b
I1022 16:11:01.611449 27537 net.cpp:100] Creating Layer bn4d_branch2b
I1022 16:11:01.611454 27537 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I1022 16:11:01.611460 27537 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I1022 16:11:01.611959 27537 net.cpp:150] Setting up bn4d_branch2b
I1022 16:11:01.611969 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.611973 27537 net.cpp:165] Memory required for data: 201707532
I1022 16:11:01.611990 27537 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1022 16:11:01.611999 27537 net.cpp:100] Creating Layer scale4d_branch2b
I1022 16:11:01.612004 27537 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I1022 16:11:01.612010 27537 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I1022 16:11:01.612098 27537 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1022 16:11:01.612360 27537 net.cpp:150] Setting up scale4d_branch2b
I1022 16:11:01.612368 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.612372 27537 net.cpp:165] Memory required for data: 201908236
I1022 16:11:01.612378 27537 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I1022 16:11:01.612387 27537 net.cpp:100] Creating Layer res4d_branch2b_relu
I1022 16:11:01.612393 27537 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I1022 16:11:01.612398 27537 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I1022 16:11:01.613521 27537 net.cpp:150] Setting up res4d_branch2b_relu
I1022 16:11:01.613536 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.613540 27537 net.cpp:165] Memory required for data: 202108940
I1022 16:11:01.613553 27537 layer_factory.hpp:77] Creating layer res4d_branch2c
I1022 16:11:01.613564 27537 net.cpp:100] Creating Layer res4d_branch2c
I1022 16:11:01.613569 27537 net.cpp:444] res4d_branch2c <- res4d_branch2b
I1022 16:11:01.613580 27537 net.cpp:418] res4d_branch2c -> res4d_branch2c
I1022 16:11:01.618067 27537 net.cpp:150] Setting up res4d_branch2c
I1022 16:11:01.618082 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.618085 27537 net.cpp:165] Memory required for data: 202911756
I1022 16:11:01.618098 27537 layer_factory.hpp:77] Creating layer bn4d_branch2c
I1022 16:11:01.618105 27537 net.cpp:100] Creating Layer bn4d_branch2c
I1022 16:11:01.618110 27537 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I1022 16:11:01.618119 27537 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I1022 16:11:01.618587 27537 net.cpp:150] Setting up bn4d_branch2c
I1022 16:11:01.618595 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.618598 27537 net.cpp:165] Memory required for data: 203714572
I1022 16:11:01.618616 27537 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1022 16:11:01.618625 27537 net.cpp:100] Creating Layer scale4d_branch2c
I1022 16:11:01.618629 27537 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I1022 16:11:01.618636 27537 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I1022 16:11:01.618715 27537 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1022 16:11:01.618975 27537 net.cpp:150] Setting up scale4d_branch2c
I1022 16:11:01.618984 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.618988 27537 net.cpp:165] Memory required for data: 204517388
I1022 16:11:01.618994 27537 layer_factory.hpp:77] Creating layer res4d
I1022 16:11:01.619000 27537 net.cpp:100] Creating Layer res4d
I1022 16:11:01.619004 27537 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I1022 16:11:01.619009 27537 net.cpp:444] res4d <- res4d_branch2c
I1022 16:11:01.619017 27537 net.cpp:418] res4d -> res4d
I1022 16:11:01.619068 27537 net.cpp:150] Setting up res4d
I1022 16:11:01.619077 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.619081 27537 net.cpp:165] Memory required for data: 205320204
I1022 16:11:01.619083 27537 layer_factory.hpp:77] Creating layer res4d_relu
I1022 16:11:01.619089 27537 net.cpp:100] Creating Layer res4d_relu
I1022 16:11:01.619092 27537 net.cpp:444] res4d_relu <- res4d
I1022 16:11:01.619099 27537 net.cpp:405] res4d_relu -> res4d (in-place)
I1022 16:11:01.619370 27537 net.cpp:150] Setting up res4d_relu
I1022 16:11:01.619391 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.619395 27537 net.cpp:165] Memory required for data: 206123020
I1022 16:11:01.619398 27537 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I1022 16:11:01.619415 27537 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I1022 16:11:01.619418 27537 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I1022 16:11:01.619426 27537 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I1022 16:11:01.619433 27537 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I1022 16:11:01.619521 27537 net.cpp:150] Setting up res4d_res4d_relu_0_split
I1022 16:11:01.619529 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.619534 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.619536 27537 net.cpp:165] Memory required for data: 207728652
I1022 16:11:01.619540 27537 layer_factory.hpp:77] Creating layer res4e_branch2a
I1022 16:11:01.619550 27537 net.cpp:100] Creating Layer res4e_branch2a
I1022 16:11:01.619555 27537 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I1022 16:11:01.619563 27537 net.cpp:418] res4e_branch2a -> res4e_branch2a
I1022 16:11:01.621871 27537 net.cpp:150] Setting up res4e_branch2a
I1022 16:11:01.621886 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.621901 27537 net.cpp:165] Memory required for data: 207929356
I1022 16:11:01.621907 27537 layer_factory.hpp:77] Creating layer bn4e_branch2a
I1022 16:11:01.621917 27537 net.cpp:100] Creating Layer bn4e_branch2a
I1022 16:11:01.621922 27537 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I1022 16:11:01.621927 27537 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I1022 16:11:01.622390 27537 net.cpp:150] Setting up bn4e_branch2a
I1022 16:11:01.622398 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.622401 27537 net.cpp:165] Memory required for data: 208130060
I1022 16:11:01.622419 27537 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1022 16:11:01.622428 27537 net.cpp:100] Creating Layer scale4e_branch2a
I1022 16:11:01.622431 27537 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I1022 16:11:01.622437 27537 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I1022 16:11:01.622517 27537 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1022 16:11:01.622756 27537 net.cpp:150] Setting up scale4e_branch2a
I1022 16:11:01.622766 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.622768 27537 net.cpp:165] Memory required for data: 208330764
I1022 16:11:01.622776 27537 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I1022 16:11:01.622783 27537 net.cpp:100] Creating Layer res4e_branch2a_relu
I1022 16:11:01.622788 27537 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I1022 16:11:01.622794 27537 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I1022 16:11:01.623064 27537 net.cpp:150] Setting up res4e_branch2a_relu
I1022 16:11:01.623081 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.623085 27537 net.cpp:165] Memory required for data: 208531468
I1022 16:11:01.623097 27537 layer_factory.hpp:77] Creating layer res4e_branch2b
I1022 16:11:01.623107 27537 net.cpp:100] Creating Layer res4e_branch2b
I1022 16:11:01.623111 27537 net.cpp:444] res4e_branch2b <- res4e_branch2a
I1022 16:11:01.623121 27537 net.cpp:418] res4e_branch2b -> res4e_branch2b
I1022 16:11:01.631407 27537 net.cpp:150] Setting up res4e_branch2b
I1022 16:11:01.631423 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.631436 27537 net.cpp:165] Memory required for data: 208732172
I1022 16:11:01.631443 27537 layer_factory.hpp:77] Creating layer bn4e_branch2b
I1022 16:11:01.631453 27537 net.cpp:100] Creating Layer bn4e_branch2b
I1022 16:11:01.631464 27537 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I1022 16:11:01.631471 27537 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I1022 16:11:01.631949 27537 net.cpp:150] Setting up bn4e_branch2b
I1022 16:11:01.631959 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.631963 27537 net.cpp:165] Memory required for data: 208932876
I1022 16:11:01.631979 27537 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1022 16:11:01.631988 27537 net.cpp:100] Creating Layer scale4e_branch2b
I1022 16:11:01.631991 27537 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I1022 16:11:01.631999 27537 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I1022 16:11:01.632099 27537 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1022 16:11:01.632334 27537 net.cpp:150] Setting up scale4e_branch2b
I1022 16:11:01.632344 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.632346 27537 net.cpp:165] Memory required for data: 209133580
I1022 16:11:01.632352 27537 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I1022 16:11:01.632359 27537 net.cpp:100] Creating Layer res4e_branch2b_relu
I1022 16:11:01.632362 27537 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I1022 16:11:01.632367 27537 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I1022 16:11:01.633410 27537 net.cpp:150] Setting up res4e_branch2b_relu
I1022 16:11:01.633424 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.633438 27537 net.cpp:165] Memory required for data: 209334284
I1022 16:11:01.633442 27537 layer_factory.hpp:77] Creating layer res4e_branch2c
I1022 16:11:01.633455 27537 net.cpp:100] Creating Layer res4e_branch2c
I1022 16:11:01.633461 27537 net.cpp:444] res4e_branch2c <- res4e_branch2b
I1022 16:11:01.633468 27537 net.cpp:418] res4e_branch2c -> res4e_branch2c
I1022 16:11:01.637686 27537 net.cpp:150] Setting up res4e_branch2c
I1022 16:11:01.637701 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.637704 27537 net.cpp:165] Memory required for data: 210137100
I1022 16:11:01.637720 27537 layer_factory.hpp:77] Creating layer bn4e_branch2c
I1022 16:11:01.637732 27537 net.cpp:100] Creating Layer bn4e_branch2c
I1022 16:11:01.637737 27537 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I1022 16:11:01.637743 27537 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I1022 16:11:01.638202 27537 net.cpp:150] Setting up bn4e_branch2c
I1022 16:11:01.638211 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.638214 27537 net.cpp:165] Memory required for data: 210939916
I1022 16:11:01.638231 27537 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1022 16:11:01.638238 27537 net.cpp:100] Creating Layer scale4e_branch2c
I1022 16:11:01.638242 27537 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I1022 16:11:01.638248 27537 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I1022 16:11:01.638322 27537 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1022 16:11:01.638572 27537 net.cpp:150] Setting up scale4e_branch2c
I1022 16:11:01.638581 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.638584 27537 net.cpp:165] Memory required for data: 211742732
I1022 16:11:01.638592 27537 layer_factory.hpp:77] Creating layer res4e
I1022 16:11:01.638597 27537 net.cpp:100] Creating Layer res4e
I1022 16:11:01.638603 27537 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I1022 16:11:01.638608 27537 net.cpp:444] res4e <- res4e_branch2c
I1022 16:11:01.638615 27537 net.cpp:418] res4e -> res4e
I1022 16:11:01.638662 27537 net.cpp:150] Setting up res4e
I1022 16:11:01.638670 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.638674 27537 net.cpp:165] Memory required for data: 212545548
I1022 16:11:01.638677 27537 layer_factory.hpp:77] Creating layer res4e_relu
I1022 16:11:01.638682 27537 net.cpp:100] Creating Layer res4e_relu
I1022 16:11:01.638687 27537 net.cpp:444] res4e_relu <- res4e
I1022 16:11:01.638695 27537 net.cpp:405] res4e_relu -> res4e (in-place)
I1022 16:11:01.638967 27537 net.cpp:150] Setting up res4e_relu
I1022 16:11:01.638984 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.638988 27537 net.cpp:165] Memory required for data: 213348364
I1022 16:11:01.638991 27537 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I1022 16:11:01.639005 27537 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I1022 16:11:01.639009 27537 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I1022 16:11:01.639015 27537 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I1022 16:11:01.639022 27537 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I1022 16:11:01.639109 27537 net.cpp:150] Setting up res4e_res4e_relu_0_split
I1022 16:11:01.639117 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.639122 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.639124 27537 net.cpp:165] Memory required for data: 214953996
I1022 16:11:01.639128 27537 layer_factory.hpp:77] Creating layer res4f_branch2a
I1022 16:11:01.639139 27537 net.cpp:100] Creating Layer res4f_branch2a
I1022 16:11:01.639143 27537 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I1022 16:11:01.639148 27537 net.cpp:418] res4f_branch2a -> res4f_branch2a
I1022 16:11:01.641382 27537 net.cpp:150] Setting up res4f_branch2a
I1022 16:11:01.641396 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.641399 27537 net.cpp:165] Memory required for data: 215154700
I1022 16:11:01.641417 27537 layer_factory.hpp:77] Creating layer bn4f_branch2a
I1022 16:11:01.641425 27537 net.cpp:100] Creating Layer bn4f_branch2a
I1022 16:11:01.641430 27537 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I1022 16:11:01.641438 27537 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I1022 16:11:01.641863 27537 net.cpp:150] Setting up bn4f_branch2a
I1022 16:11:01.641871 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.641875 27537 net.cpp:165] Memory required for data: 215355404
I1022 16:11:01.641893 27537 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1022 16:11:01.641901 27537 net.cpp:100] Creating Layer scale4f_branch2a
I1022 16:11:01.641904 27537 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I1022 16:11:01.641911 27537 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I1022 16:11:01.641988 27537 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1022 16:11:01.642213 27537 net.cpp:150] Setting up scale4f_branch2a
I1022 16:11:01.642221 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.642225 27537 net.cpp:165] Memory required for data: 215556108
I1022 16:11:01.642230 27537 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I1022 16:11:01.642237 27537 net.cpp:100] Creating Layer res4f_branch2a_relu
I1022 16:11:01.642241 27537 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I1022 16:11:01.642246 27537 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I1022 16:11:01.642494 27537 net.cpp:150] Setting up res4f_branch2a_relu
I1022 16:11:01.642503 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.642506 27537 net.cpp:165] Memory required for data: 215756812
I1022 16:11:01.642510 27537 layer_factory.hpp:77] Creating layer res4f_branch2b
I1022 16:11:01.642520 27537 net.cpp:100] Creating Layer res4f_branch2b
I1022 16:11:01.642525 27537 net.cpp:444] res4f_branch2b <- res4f_branch2a
I1022 16:11:01.642530 27537 net.cpp:418] res4f_branch2b -> res4f_branch2b
I1022 16:11:01.651096 27537 net.cpp:150] Setting up res4f_branch2b
I1022 16:11:01.651126 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.651130 27537 net.cpp:165] Memory required for data: 215957516
I1022 16:11:01.651137 27537 layer_factory.hpp:77] Creating layer bn4f_branch2b
I1022 16:11:01.651145 27537 net.cpp:100] Creating Layer bn4f_branch2b
I1022 16:11:01.651150 27537 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I1022 16:11:01.651157 27537 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I1022 16:11:01.651600 27537 net.cpp:150] Setting up bn4f_branch2b
I1022 16:11:01.651612 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.651614 27537 net.cpp:165] Memory required for data: 216158220
I1022 16:11:01.651631 27537 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1022 16:11:01.651638 27537 net.cpp:100] Creating Layer scale4f_branch2b
I1022 16:11:01.651643 27537 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I1022 16:11:01.651648 27537 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I1022 16:11:01.651726 27537 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1022 16:11:01.651953 27537 net.cpp:150] Setting up scale4f_branch2b
I1022 16:11:01.651962 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.651964 27537 net.cpp:165] Memory required for data: 216358924
I1022 16:11:01.651970 27537 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I1022 16:11:01.651978 27537 net.cpp:100] Creating Layer res4f_branch2b_relu
I1022 16:11:01.651981 27537 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I1022 16:11:01.651988 27537 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I1022 16:11:01.652245 27537 net.cpp:150] Setting up res4f_branch2b_relu
I1022 16:11:01.652253 27537 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:11:01.652257 27537 net.cpp:165] Memory required for data: 216559628
I1022 16:11:01.652261 27537 layer_factory.hpp:77] Creating layer res4f_branch2c
I1022 16:11:01.652271 27537 net.cpp:100] Creating Layer res4f_branch2c
I1022 16:11:01.652274 27537 net.cpp:444] res4f_branch2c <- res4f_branch2b
I1022 16:11:01.652282 27537 net.cpp:418] res4f_branch2c -> res4f_branch2c
I1022 16:11:01.656318 27537 net.cpp:150] Setting up res4f_branch2c
I1022 16:11:01.656333 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.656337 27537 net.cpp:165] Memory required for data: 217362444
I1022 16:11:01.656350 27537 layer_factory.hpp:77] Creating layer bn4f_branch2c
I1022 16:11:01.656360 27537 net.cpp:100] Creating Layer bn4f_branch2c
I1022 16:11:01.656364 27537 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I1022 16:11:01.656373 27537 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I1022 16:11:01.656821 27537 net.cpp:150] Setting up bn4f_branch2c
I1022 16:11:01.656831 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.656833 27537 net.cpp:165] Memory required for data: 218165260
I1022 16:11:01.656862 27537 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1022 16:11:01.656870 27537 net.cpp:100] Creating Layer scale4f_branch2c
I1022 16:11:01.656873 27537 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I1022 16:11:01.656878 27537 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I1022 16:11:01.656953 27537 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1022 16:11:01.657203 27537 net.cpp:150] Setting up scale4f_branch2c
I1022 16:11:01.657212 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.657215 27537 net.cpp:165] Memory required for data: 218968076
I1022 16:11:01.657222 27537 layer_factory.hpp:77] Creating layer res4f
I1022 16:11:01.657228 27537 net.cpp:100] Creating Layer res4f
I1022 16:11:01.657232 27537 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I1022 16:11:01.657236 27537 net.cpp:444] res4f <- res4f_branch2c
I1022 16:11:01.657241 27537 net.cpp:418] res4f -> res4f
I1022 16:11:01.657289 27537 net.cpp:150] Setting up res4f
I1022 16:11:01.657295 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.657299 27537 net.cpp:165] Memory required for data: 219770892
I1022 16:11:01.657301 27537 layer_factory.hpp:77] Creating layer res4f_relu
I1022 16:11:01.657307 27537 net.cpp:100] Creating Layer res4f_relu
I1022 16:11:01.657313 27537 net.cpp:444] res4f_relu <- res4f
I1022 16:11:01.657317 27537 net.cpp:405] res4f_relu -> res4f (in-place)
I1022 16:11:01.658349 27537 net.cpp:150] Setting up res4f_relu
I1022 16:11:01.658365 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.658368 27537 net.cpp:165] Memory required for data: 220573708
I1022 16:11:01.658380 27537 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I1022 16:11:01.658387 27537 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I1022 16:11:01.658391 27537 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I1022 16:11:01.658398 27537 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I1022 16:11:01.658406 27537 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I1022 16:11:01.658412 27537 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I1022 16:11:01.658537 27537 net.cpp:150] Setting up res4f_res4f_relu_0_split
I1022 16:11:01.658545 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.658548 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.658552 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.658555 27537 net.cpp:165] Memory required for data: 222982156
I1022 16:11:01.658558 27537 layer_factory.hpp:77] Creating layer res5a_branch1
I1022 16:11:01.658569 27537 net.cpp:100] Creating Layer res5a_branch1
I1022 16:11:01.658574 27537 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I1022 16:11:01.658581 27537 net.cpp:418] res5a_branch1 -> res5a_branch1
I1022 16:11:01.666546 27537 net.cpp:150] Setting up res5a_branch1
I1022 16:11:01.666560 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.666564 27537 net.cpp:165] Memory required for data: 223383564
I1022 16:11:01.666579 27537 layer_factory.hpp:77] Creating layer bn5a_branch1
I1022 16:11:01.666587 27537 net.cpp:100] Creating Layer bn5a_branch1
I1022 16:11:01.666591 27537 net.cpp:444] bn5a_branch1 <- res5a_branch1
I1022 16:11:01.666599 27537 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I1022 16:11:01.667122 27537 net.cpp:150] Setting up bn5a_branch1
I1022 16:11:01.667130 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.667134 27537 net.cpp:165] Memory required for data: 223784972
I1022 16:11:01.667150 27537 layer_factory.hpp:77] Creating layer scale5a_branch1
I1022 16:11:01.667157 27537 net.cpp:100] Creating Layer scale5a_branch1
I1022 16:11:01.667160 27537 net.cpp:444] scale5a_branch1 <- res5a_branch1
I1022 16:11:01.667165 27537 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I1022 16:11:01.667240 27537 layer_factory.hpp:77] Creating layer scale5a_branch1
I1022 16:11:01.667481 27537 net.cpp:150] Setting up scale5a_branch1
I1022 16:11:01.667490 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.667491 27537 net.cpp:165] Memory required for data: 224186380
I1022 16:11:01.667497 27537 layer_factory.hpp:77] Creating layer res5a_branch2a
I1022 16:11:01.667510 27537 net.cpp:100] Creating Layer res5a_branch2a
I1022 16:11:01.667515 27537 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I1022 16:11:01.667520 27537 net.cpp:418] res5a_branch2a -> res5a_branch2a
I1022 16:11:01.673120 27537 net.cpp:150] Setting up res5a_branch2a
I1022 16:11:01.673136 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.673140 27537 net.cpp:165] Memory required for data: 224286732
I1022 16:11:01.673152 27537 layer_factory.hpp:77] Creating layer bn5a_branch2a
I1022 16:11:01.673161 27537 net.cpp:100] Creating Layer bn5a_branch2a
I1022 16:11:01.673166 27537 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I1022 16:11:01.673177 27537 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I1022 16:11:01.673609 27537 net.cpp:150] Setting up bn5a_branch2a
I1022 16:11:01.673617 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.673620 27537 net.cpp:165] Memory required for data: 224387084
I1022 16:11:01.673637 27537 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1022 16:11:01.673645 27537 net.cpp:100] Creating Layer scale5a_branch2a
I1022 16:11:01.673648 27537 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I1022 16:11:01.673655 27537 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I1022 16:11:01.673725 27537 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1022 16:11:01.673961 27537 net.cpp:150] Setting up scale5a_branch2a
I1022 16:11:01.673970 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.673974 27537 net.cpp:165] Memory required for data: 224487436
I1022 16:11:01.673979 27537 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I1022 16:11:01.673987 27537 net.cpp:100] Creating Layer res5a_branch2a_relu
I1022 16:11:01.673992 27537 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I1022 16:11:01.673997 27537 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I1022 16:11:01.674237 27537 net.cpp:150] Setting up res5a_branch2a_relu
I1022 16:11:01.674247 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.674249 27537 net.cpp:165] Memory required for data: 224587788
I1022 16:11:01.674254 27537 layer_factory.hpp:77] Creating layer res5a_branch2b
I1022 16:11:01.674264 27537 net.cpp:100] Creating Layer res5a_branch2b
I1022 16:11:01.674270 27537 net.cpp:444] res5a_branch2b <- res5a_branch2a
I1022 16:11:01.674276 27537 net.cpp:418] res5a_branch2b -> res5a_branch2b
I1022 16:11:01.681231 27537 net.cpp:150] Setting up res5a_branch2b
I1022 16:11:01.681246 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.681251 27537 net.cpp:165] Memory required for data: 224688140
I1022 16:11:01.681265 27537 layer_factory.hpp:77] Creating layer bn5a_branch2b
I1022 16:11:01.681275 27537 net.cpp:100] Creating Layer bn5a_branch2b
I1022 16:11:01.681278 27537 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I1022 16:11:01.681286 27537 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I1022 16:11:01.681717 27537 net.cpp:150] Setting up bn5a_branch2b
I1022 16:11:01.681727 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.681730 27537 net.cpp:165] Memory required for data: 224788492
I1022 16:11:01.681746 27537 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1022 16:11:01.681752 27537 net.cpp:100] Creating Layer scale5a_branch2b
I1022 16:11:01.681756 27537 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I1022 16:11:01.681763 27537 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I1022 16:11:01.681834 27537 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1022 16:11:01.682077 27537 net.cpp:150] Setting up scale5a_branch2b
I1022 16:11:01.682086 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.682090 27537 net.cpp:165] Memory required for data: 224888844
I1022 16:11:01.682097 27537 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I1022 16:11:01.682103 27537 net.cpp:100] Creating Layer res5a_branch2b_relu
I1022 16:11:01.682107 27537 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I1022 16:11:01.682114 27537 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I1022 16:11:01.682368 27537 net.cpp:150] Setting up res5a_branch2b_relu
I1022 16:11:01.682376 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.682379 27537 net.cpp:165] Memory required for data: 224989196
I1022 16:11:01.682382 27537 layer_factory.hpp:77] Creating layer res5a_branch2c
I1022 16:11:01.682391 27537 net.cpp:100] Creating Layer res5a_branch2c
I1022 16:11:01.682395 27537 net.cpp:444] res5a_branch2c <- res5a_branch2b
I1022 16:11:01.682402 27537 net.cpp:418] res5a_branch2c -> res5a_branch2c
I1022 16:11:01.689087 27537 net.cpp:150] Setting up res5a_branch2c
I1022 16:11:01.689103 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.689106 27537 net.cpp:165] Memory required for data: 225390604
I1022 16:11:01.689113 27537 layer_factory.hpp:77] Creating layer bn5a_branch2c
I1022 16:11:01.689126 27537 net.cpp:100] Creating Layer bn5a_branch2c
I1022 16:11:01.689129 27537 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I1022 16:11:01.689136 27537 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I1022 16:11:01.689579 27537 net.cpp:150] Setting up bn5a_branch2c
I1022 16:11:01.689586 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.689589 27537 net.cpp:165] Memory required for data: 225792012
I1022 16:11:01.689596 27537 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1022 16:11:01.689606 27537 net.cpp:100] Creating Layer scale5a_branch2c
I1022 16:11:01.689610 27537 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I1022 16:11:01.689613 27537 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I1022 16:11:01.689689 27537 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1022 16:11:01.689931 27537 net.cpp:150] Setting up scale5a_branch2c
I1022 16:11:01.689939 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.689942 27537 net.cpp:165] Memory required for data: 226193420
I1022 16:11:01.689947 27537 layer_factory.hpp:77] Creating layer res5a
I1022 16:11:01.689955 27537 net.cpp:100] Creating Layer res5a
I1022 16:11:01.689959 27537 net.cpp:444] res5a <- res5a_branch1
I1022 16:11:01.689962 27537 net.cpp:444] res5a <- res5a_branch2c
I1022 16:11:01.689967 27537 net.cpp:418] res5a -> res5a
I1022 16:11:01.690013 27537 net.cpp:150] Setting up res5a
I1022 16:11:01.690021 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.690023 27537 net.cpp:165] Memory required for data: 226594828
I1022 16:11:01.690026 27537 layer_factory.hpp:77] Creating layer res5a_relu
I1022 16:11:01.690032 27537 net.cpp:100] Creating Layer res5a_relu
I1022 16:11:01.690034 27537 net.cpp:444] res5a_relu <- res5a
I1022 16:11:01.690038 27537 net.cpp:405] res5a_relu -> res5a (in-place)
I1022 16:11:01.691015 27537 net.cpp:150] Setting up res5a_relu
I1022 16:11:01.691043 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.691047 27537 net.cpp:165] Memory required for data: 226996236
I1022 16:11:01.691051 27537 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I1022 16:11:01.691057 27537 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I1022 16:11:01.691061 27537 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I1022 16:11:01.691068 27537 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I1022 16:11:01.691076 27537 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I1022 16:11:01.691169 27537 net.cpp:150] Setting up res5a_res5a_relu_0_split
I1022 16:11:01.691176 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.691179 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.691184 27537 net.cpp:165] Memory required for data: 227799052
I1022 16:11:01.691186 27537 layer_factory.hpp:77] Creating layer res5b_branch2a
I1022 16:11:01.691196 27537 net.cpp:100] Creating Layer res5b_branch2a
I1022 16:11:01.691200 27537 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I1022 16:11:01.691206 27537 net.cpp:418] res5b_branch2a -> res5b_branch2a
I1022 16:11:01.696637 27537 net.cpp:150] Setting up res5b_branch2a
I1022 16:11:01.696655 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.696657 27537 net.cpp:165] Memory required for data: 227899404
I1022 16:11:01.696663 27537 layer_factory.hpp:77] Creating layer bn5b_branch2a
I1022 16:11:01.696681 27537 net.cpp:100] Creating Layer bn5b_branch2a
I1022 16:11:01.696686 27537 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I1022 16:11:01.696691 27537 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I1022 16:11:01.697119 27537 net.cpp:150] Setting up bn5b_branch2a
I1022 16:11:01.697127 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.697131 27537 net.cpp:165] Memory required for data: 227999756
I1022 16:11:01.697139 27537 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1022 16:11:01.697144 27537 net.cpp:100] Creating Layer scale5b_branch2a
I1022 16:11:01.697147 27537 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I1022 16:11:01.697154 27537 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I1022 16:11:01.697228 27537 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1022 16:11:01.697471 27537 net.cpp:150] Setting up scale5b_branch2a
I1022 16:11:01.697479 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.697484 27537 net.cpp:165] Memory required for data: 228100108
I1022 16:11:01.697489 27537 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I1022 16:11:01.697495 27537 net.cpp:100] Creating Layer res5b_branch2a_relu
I1022 16:11:01.697499 27537 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I1022 16:11:01.697505 27537 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I1022 16:11:01.697748 27537 net.cpp:150] Setting up res5b_branch2a_relu
I1022 16:11:01.697757 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.697760 27537 net.cpp:165] Memory required for data: 228200460
I1022 16:11:01.697764 27537 layer_factory.hpp:77] Creating layer res5b_branch2b
I1022 16:11:01.697775 27537 net.cpp:100] Creating Layer res5b_branch2b
I1022 16:11:01.697780 27537 net.cpp:444] res5b_branch2b <- res5b_branch2a
I1022 16:11:01.697788 27537 net.cpp:418] res5b_branch2b -> res5b_branch2b
I1022 16:11:01.704632 27537 net.cpp:150] Setting up res5b_branch2b
I1022 16:11:01.704658 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.704661 27537 net.cpp:165] Memory required for data: 228300812
I1022 16:11:01.704679 27537 layer_factory.hpp:77] Creating layer bn5b_branch2b
I1022 16:11:01.704689 27537 net.cpp:100] Creating Layer bn5b_branch2b
I1022 16:11:01.704692 27537 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I1022 16:11:01.704700 27537 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I1022 16:11:01.705127 27537 net.cpp:150] Setting up bn5b_branch2b
I1022 16:11:01.705137 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.705139 27537 net.cpp:165] Memory required for data: 228401164
I1022 16:11:01.705147 27537 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1022 16:11:01.705155 27537 net.cpp:100] Creating Layer scale5b_branch2b
I1022 16:11:01.705159 27537 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I1022 16:11:01.705164 27537 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I1022 16:11:01.705235 27537 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1022 16:11:01.705483 27537 net.cpp:150] Setting up scale5b_branch2b
I1022 16:11:01.705493 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.705497 27537 net.cpp:165] Memory required for data: 228501516
I1022 16:11:01.705502 27537 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I1022 16:11:01.705507 27537 net.cpp:100] Creating Layer res5b_branch2b_relu
I1022 16:11:01.705512 27537 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I1022 16:11:01.705516 27537 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I1022 16:11:01.705780 27537 net.cpp:150] Setting up res5b_branch2b_relu
I1022 16:11:01.705791 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.705796 27537 net.cpp:165] Memory required for data: 228601868
I1022 16:11:01.705806 27537 layer_factory.hpp:77] Creating layer res5b_branch2c
I1022 16:11:01.705813 27537 net.cpp:100] Creating Layer res5b_branch2c
I1022 16:11:01.705817 27537 net.cpp:444] res5b_branch2c <- res5b_branch2b
I1022 16:11:01.705830 27537 net.cpp:418] res5b_branch2c -> res5b_branch2c
I1022 16:11:01.712837 27537 net.cpp:150] Setting up res5b_branch2c
I1022 16:11:01.712854 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.712857 27537 net.cpp:165] Memory required for data: 229003276
I1022 16:11:01.712864 27537 layer_factory.hpp:77] Creating layer bn5b_branch2c
I1022 16:11:01.712872 27537 net.cpp:100] Creating Layer bn5b_branch2c
I1022 16:11:01.712877 27537 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I1022 16:11:01.712883 27537 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I1022 16:11:01.713344 27537 net.cpp:150] Setting up bn5b_branch2c
I1022 16:11:01.713352 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.713356 27537 net.cpp:165] Memory required for data: 229404684
I1022 16:11:01.713368 27537 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1022 16:11:01.713376 27537 net.cpp:100] Creating Layer scale5b_branch2c
I1022 16:11:01.713380 27537 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I1022 16:11:01.713387 27537 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I1022 16:11:01.713460 27537 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1022 16:11:01.713711 27537 net.cpp:150] Setting up scale5b_branch2c
I1022 16:11:01.713718 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.713721 27537 net.cpp:165] Memory required for data: 229806092
I1022 16:11:01.713726 27537 layer_factory.hpp:77] Creating layer res5b
I1022 16:11:01.713737 27537 net.cpp:100] Creating Layer res5b
I1022 16:11:01.713740 27537 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I1022 16:11:01.713744 27537 net.cpp:444] res5b <- res5b_branch2c
I1022 16:11:01.713749 27537 net.cpp:418] res5b -> res5b
I1022 16:11:01.713799 27537 net.cpp:150] Setting up res5b
I1022 16:11:01.713806 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.713809 27537 net.cpp:165] Memory required for data: 230207500
I1022 16:11:01.713812 27537 layer_factory.hpp:77] Creating layer res5b_relu
I1022 16:11:01.713817 27537 net.cpp:100] Creating Layer res5b_relu
I1022 16:11:01.713820 27537 net.cpp:444] res5b_relu <- res5b
I1022 16:11:01.713826 27537 net.cpp:405] res5b_relu -> res5b (in-place)
I1022 16:11:01.714823 27537 net.cpp:150] Setting up res5b_relu
I1022 16:11:01.714835 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.714838 27537 net.cpp:165] Memory required for data: 230608908
I1022 16:11:01.714841 27537 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I1022 16:11:01.714850 27537 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I1022 16:11:01.714854 27537 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I1022 16:11:01.714860 27537 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I1022 16:11:01.714869 27537 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I1022 16:11:01.714956 27537 net.cpp:150] Setting up res5b_res5b_relu_0_split
I1022 16:11:01.714964 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.714969 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.714972 27537 net.cpp:165] Memory required for data: 231411724
I1022 16:11:01.714975 27537 layer_factory.hpp:77] Creating layer res5c_branch2a
I1022 16:11:01.714987 27537 net.cpp:100] Creating Layer res5c_branch2a
I1022 16:11:01.714993 27537 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I1022 16:11:01.714998 27537 net.cpp:418] res5c_branch2a -> res5c_branch2a
I1022 16:11:01.720762 27537 net.cpp:150] Setting up res5c_branch2a
I1022 16:11:01.720782 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.720784 27537 net.cpp:165] Memory required for data: 231512076
I1022 16:11:01.720793 27537 layer_factory.hpp:77] Creating layer bn5c_branch2a
I1022 16:11:01.720803 27537 net.cpp:100] Creating Layer bn5c_branch2a
I1022 16:11:01.720808 27537 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I1022 16:11:01.720815 27537 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I1022 16:11:01.721284 27537 net.cpp:150] Setting up bn5c_branch2a
I1022 16:11:01.721292 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.721295 27537 net.cpp:165] Memory required for data: 231612428
I1022 16:11:01.721305 27537 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1022 16:11:01.721314 27537 net.cpp:100] Creating Layer scale5c_branch2a
I1022 16:11:01.721318 27537 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I1022 16:11:01.721324 27537 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I1022 16:11:01.721398 27537 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1022 16:11:01.721657 27537 net.cpp:150] Setting up scale5c_branch2a
I1022 16:11:01.721664 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.721668 27537 net.cpp:165] Memory required for data: 231712780
I1022 16:11:01.721674 27537 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I1022 16:11:01.721679 27537 net.cpp:100] Creating Layer res5c_branch2a_relu
I1022 16:11:01.721683 27537 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I1022 16:11:01.721688 27537 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I1022 16:11:01.721962 27537 net.cpp:150] Setting up res5c_branch2a_relu
I1022 16:11:01.721971 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.721981 27537 net.cpp:165] Memory required for data: 231813132
I1022 16:11:01.721983 27537 layer_factory.hpp:77] Creating layer res5c_branch2b
I1022 16:11:01.722004 27537 net.cpp:100] Creating Layer res5c_branch2b
I1022 16:11:01.722007 27537 net.cpp:444] res5c_branch2b <- res5c_branch2a
I1022 16:11:01.722013 27537 net.cpp:418] res5c_branch2b -> res5c_branch2b
I1022 16:11:01.730808 27537 net.cpp:150] Setting up res5c_branch2b
I1022 16:11:01.730855 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.730859 27537 net.cpp:165] Memory required for data: 231913484
I1022 16:11:01.730870 27537 layer_factory.hpp:77] Creating layer bn5c_branch2b
I1022 16:11:01.730885 27537 net.cpp:100] Creating Layer bn5c_branch2b
I1022 16:11:01.730890 27537 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I1022 16:11:01.730901 27537 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I1022 16:11:01.731398 27537 net.cpp:150] Setting up bn5c_branch2b
I1022 16:11:01.731410 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.731412 27537 net.cpp:165] Memory required for data: 232013836
I1022 16:11:01.731431 27537 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1022 16:11:01.731439 27537 net.cpp:100] Creating Layer scale5c_branch2b
I1022 16:11:01.731443 27537 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I1022 16:11:01.731449 27537 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I1022 16:11:01.731526 27537 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1022 16:11:01.731792 27537 net.cpp:150] Setting up scale5c_branch2b
I1022 16:11:01.731801 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.731803 27537 net.cpp:165] Memory required for data: 232114188
I1022 16:11:01.731809 27537 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I1022 16:11:01.731815 27537 net.cpp:100] Creating Layer res5c_branch2b_relu
I1022 16:11:01.731819 27537 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I1022 16:11:01.731824 27537 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I1022 16:11:01.732203 27537 net.cpp:150] Setting up res5c_branch2b_relu
I1022 16:11:01.732213 27537 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:11:01.732215 27537 net.cpp:165] Memory required for data: 232214540
I1022 16:11:01.732228 27537 layer_factory.hpp:77] Creating layer res5c_branch2c
I1022 16:11:01.732240 27537 net.cpp:100] Creating Layer res5c_branch2c
I1022 16:11:01.732244 27537 net.cpp:444] res5c_branch2c <- res5c_branch2b
I1022 16:11:01.732252 27537 net.cpp:418] res5c_branch2c -> res5c_branch2c
I1022 16:11:01.738193 27537 net.cpp:150] Setting up res5c_branch2c
I1022 16:11:01.738207 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.738210 27537 net.cpp:165] Memory required for data: 232615948
I1022 16:11:01.738224 27537 layer_factory.hpp:77] Creating layer bn5c_branch2c
I1022 16:11:01.738234 27537 net.cpp:100] Creating Layer bn5c_branch2c
I1022 16:11:01.738237 27537 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I1022 16:11:01.738243 27537 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I1022 16:11:01.738721 27537 net.cpp:150] Setting up bn5c_branch2c
I1022 16:11:01.738729 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.738732 27537 net.cpp:165] Memory required for data: 233017356
I1022 16:11:01.738751 27537 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1022 16:11:01.738759 27537 net.cpp:100] Creating Layer scale5c_branch2c
I1022 16:11:01.738764 27537 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I1022 16:11:01.738767 27537 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I1022 16:11:01.738844 27537 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1022 16:11:01.739102 27537 net.cpp:150] Setting up scale5c_branch2c
I1022 16:11:01.739110 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.739114 27537 net.cpp:165] Memory required for data: 233418764
I1022 16:11:01.739120 27537 layer_factory.hpp:77] Creating layer res5c
I1022 16:11:01.739127 27537 net.cpp:100] Creating Layer res5c
I1022 16:11:01.739131 27537 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I1022 16:11:01.739135 27537 net.cpp:444] res5c <- res5c_branch2c
I1022 16:11:01.739142 27537 net.cpp:418] res5c -> res5c
I1022 16:11:01.739188 27537 net.cpp:150] Setting up res5c
I1022 16:11:01.739195 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.739198 27537 net.cpp:165] Memory required for data: 233820172
I1022 16:11:01.739202 27537 layer_factory.hpp:77] Creating layer res5c_relu
I1022 16:11:01.739209 27537 net.cpp:100] Creating Layer res5c_relu
I1022 16:11:01.739214 27537 net.cpp:444] res5c_relu <- res5c
I1022 16:11:01.739221 27537 net.cpp:405] res5c_relu -> res5c (in-place)
I1022 16:11:01.739466 27537 net.cpp:150] Setting up res5c_relu
I1022 16:11:01.739475 27537 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:11:01.739478 27537 net.cpp:165] Memory required for data: 234221580
I1022 16:11:01.739481 27537 layer_factory.hpp:77] Creating layer upP4
I1022 16:11:01.739491 27537 net.cpp:100] Creating Layer upP4
I1022 16:11:01.739496 27537 net.cpp:444] upP4 <- res5c
I1022 16:11:01.739502 27537 net.cpp:418] upP4 -> upP4
I1022 16:11:01.741566 27537 net.cpp:150] Setting up upP4
I1022 16:11:01.741575 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.741578 27537 net.cpp:165] Memory required for data: 234622988
I1022 16:11:01.741593 27537 layer_factory.hpp:77] Creating layer newC4
I1022 16:11:01.741603 27537 net.cpp:100] Creating Layer newC4
I1022 16:11:01.741606 27537 net.cpp:444] newC4 <- res4f_res4f_relu_0_split_2
I1022 16:11:01.741616 27537 net.cpp:418] newC4 -> c4
I1022 16:11:01.751736 27537 net.cpp:150] Setting up newC4
I1022 16:11:01.751752 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.751755 27537 net.cpp:165] Memory required for data: 235024396
I1022 16:11:01.751770 27537 layer_factory.hpp:77] Creating layer eltwise_bnc4_bnp4
I1022 16:11:01.751777 27537 net.cpp:100] Creating Layer eltwise_bnc4_bnp4
I1022 16:11:01.751781 27537 net.cpp:444] eltwise_bnc4_bnp4 <- c4
I1022 16:11:01.751786 27537 net.cpp:444] eltwise_bnc4_bnp4 <- upP4
I1022 16:11:01.751793 27537 net.cpp:418] eltwise_bnc4_bnp4 -> skip_eltwise1
I1022 16:11:01.751860 27537 net.cpp:150] Setting up eltwise_bnc4_bnp4
I1022 16:11:01.751868 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.751870 27537 net.cpp:165] Memory required for data: 235425804
I1022 16:11:01.751875 27537 layer_factory.hpp:77] Creating layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 16:11:01.751883 27537 net.cpp:100] Creating Layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 16:11:01.751888 27537 net.cpp:444] skip_eltwise1_eltwise_bnc4_bnp4_0_split <- skip_eltwise1
I1022 16:11:01.751893 27537 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1022 16:11:01.751904 27537 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1022 16:11:01.751984 27537 net.cpp:150] Setting up skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 16:11:01.751991 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.751996 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.751998 27537 net.cpp:165] Memory required for data: 236228620
I1022 16:11:01.752002 27537 layer_factory.hpp:77] Creating layer bnp4_conv
I1022 16:11:01.752013 27537 net.cpp:100] Creating Layer bnp4_conv
I1022 16:11:01.752018 27537 net.cpp:444] bnp4_conv <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1022 16:11:01.752024 27537 net.cpp:418] bnp4_conv -> bnp4_conv
I1022 16:11:01.757568 27537 net.cpp:150] Setting up bnp4_conv
I1022 16:11:01.757583 27537 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:11:01.757598 27537 net.cpp:165] Memory required for data: 236328972
I1022 16:11:01.757604 27537 layer_factory.hpp:77] Creating layer bnp4_bn
I1022 16:11:01.757614 27537 net.cpp:100] Creating Layer bnp4_bn
I1022 16:11:01.757617 27537 net.cpp:444] bnp4_bn <- bnp4_conv
I1022 16:11:01.757624 27537 net.cpp:405] bnp4_bn -> bnp4_conv (in-place)
I1022 16:11:01.758074 27537 net.cpp:150] Setting up bnp4_bn
I1022 16:11:01.758085 27537 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:11:01.758088 27537 net.cpp:165] Memory required for data: 236429324
I1022 16:11:01.758105 27537 layer_factory.hpp:77] Creating layer bnp4_scale
I1022 16:11:01.758111 27537 net.cpp:100] Creating Layer bnp4_scale
I1022 16:11:01.758114 27537 net.cpp:444] bnp4_scale <- bnp4_conv
I1022 16:11:01.758121 27537 net.cpp:405] bnp4_scale -> bnp4_conv (in-place)
I1022 16:11:01.758199 27537 layer_factory.hpp:77] Creating layer bnp4_scale
I1022 16:11:01.758435 27537 net.cpp:150] Setting up bnp4_scale
I1022 16:11:01.758443 27537 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:11:01.758446 27537 net.cpp:165] Memory required for data: 236529676
I1022 16:11:01.758452 27537 layer_factory.hpp:77] Creating layer bnp4_ReLU
I1022 16:11:01.758460 27537 net.cpp:100] Creating Layer bnp4_ReLU
I1022 16:11:01.758462 27537 net.cpp:444] bnp4_ReLU <- bnp4_conv
I1022 16:11:01.758467 27537 net.cpp:405] bnp4_ReLU -> bnp4_conv (in-place)
I1022 16:11:01.759483 27537 net.cpp:150] Setting up bnp4_ReLU
I1022 16:11:01.759523 27537 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:11:01.759527 27537 net.cpp:165] Memory required for data: 236630028
I1022 16:11:01.759531 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_conv
I1022 16:11:01.759542 27537 net.cpp:100] Creating Layer bn_eltwise_1_1_conv
I1022 16:11:01.759546 27537 net.cpp:444] bn_eltwise_1_1_conv <- bnp4_conv
I1022 16:11:01.759553 27537 net.cpp:418] bn_eltwise_1_1_conv -> bn_eltwise_1_1_conv
I1022 16:11:01.766010 27537 net.cpp:150] Setting up bn_eltwise_1_1_conv
I1022 16:11:01.766038 27537 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:11:01.766053 27537 net.cpp:165] Memory required for data: 236730380
I1022 16:11:01.766067 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_bn
I1022 16:11:01.766079 27537 net.cpp:100] Creating Layer bn_eltwise_1_1_bn
I1022 16:11:01.766086 27537 net.cpp:444] bn_eltwise_1_1_bn <- bn_eltwise_1_1_conv
I1022 16:11:01.766103 27537 net.cpp:405] bn_eltwise_1_1_bn -> bn_eltwise_1_1_conv (in-place)
I1022 16:11:01.766592 27537 net.cpp:150] Setting up bn_eltwise_1_1_bn
I1022 16:11:01.766599 27537 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:11:01.766602 27537 net.cpp:165] Memory required for data: 236830732
I1022 16:11:01.766619 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1022 16:11:01.766628 27537 net.cpp:100] Creating Layer bn_eltwise_1_1_scale
I1022 16:11:01.766631 27537 net.cpp:444] bn_eltwise_1_1_scale <- bn_eltwise_1_1_conv
I1022 16:11:01.766636 27537 net.cpp:405] bn_eltwise_1_1_scale -> bn_eltwise_1_1_conv (in-place)
I1022 16:11:01.766713 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1022 16:11:01.766955 27537 net.cpp:150] Setting up bn_eltwise_1_1_scale
I1022 16:11:01.766963 27537 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:11:01.766966 27537 net.cpp:165] Memory required for data: 236931084
I1022 16:11:01.766973 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_ReLU
I1022 16:11:01.766981 27537 net.cpp:100] Creating Layer bn_eltwise_1_1_ReLU
I1022 16:11:01.766985 27537 net.cpp:444] bn_eltwise_1_1_ReLU <- bn_eltwise_1_1_conv
I1022 16:11:01.766989 27537 net.cpp:405] bn_eltwise_1_1_ReLU -> bn_eltwise_1_1_conv (in-place)
I1022 16:11:01.767264 27537 net.cpp:150] Setting up bn_eltwise_1_1_ReLU
I1022 16:11:01.767287 27537 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:11:01.767289 27537 net.cpp:165] Memory required for data: 237031436
I1022 16:11:01.767302 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_conv
I1022 16:11:01.767313 27537 net.cpp:100] Creating Layer bn_eltwise_1_2_conv
I1022 16:11:01.767315 27537 net.cpp:444] bn_eltwise_1_2_conv <- bn_eltwise_1_1_conv
I1022 16:11:01.767323 27537 net.cpp:418] bn_eltwise_1_2_conv -> bn_eltwise_1_2_conv
I1022 16:11:01.771064 27537 net.cpp:150] Setting up bn_eltwise_1_2_conv
I1022 16:11:01.771080 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.771083 27537 net.cpp:165] Memory required for data: 237432844
I1022 16:11:01.771097 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_bn
I1022 16:11:01.771106 27537 net.cpp:100] Creating Layer bn_eltwise_1_2_bn
I1022 16:11:01.771111 27537 net.cpp:444] bn_eltwise_1_2_bn <- bn_eltwise_1_2_conv
I1022 16:11:01.771118 27537 net.cpp:405] bn_eltwise_1_2_bn -> bn_eltwise_1_2_conv (in-place)
I1022 16:11:01.771571 27537 net.cpp:150] Setting up bn_eltwise_1_2_bn
I1022 16:11:01.771579 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.771584 27537 net.cpp:165] Memory required for data: 237834252
I1022 16:11:01.771601 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1022 16:11:01.771623 27537 net.cpp:100] Creating Layer bn_eltwise_1_2_scale
I1022 16:11:01.771626 27537 net.cpp:444] bn_eltwise_1_2_scale <- bn_eltwise_1_2_conv
I1022 16:11:01.771632 27537 net.cpp:405] bn_eltwise_1_2_scale -> bn_eltwise_1_2_conv (in-place)
I1022 16:11:01.771701 27537 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1022 16:11:01.771956 27537 net.cpp:150] Setting up bn_eltwise_1_2_scale
I1022 16:11:01.771965 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.771967 27537 net.cpp:165] Memory required for data: 238235660
I1022 16:11:01.771973 27537 layer_factory.hpp:77] Creating layer p3
I1022 16:11:01.771980 27537 net.cpp:100] Creating Layer p3
I1022 16:11:01.771983 27537 net.cpp:444] p3 <- bn_eltwise_1_2_conv
I1022 16:11:01.771987 27537 net.cpp:444] p3 <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1022 16:11:01.771994 27537 net.cpp:418] p3 -> p3
I1022 16:11:01.772044 27537 net.cpp:150] Setting up p3
I1022 16:11:01.772053 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.772055 27537 net.cpp:165] Memory required for data: 238637068
I1022 16:11:01.772058 27537 layer_factory.hpp:77] Creating layer p3_relu
I1022 16:11:01.772065 27537 net.cpp:100] Creating Layer p3_relu
I1022 16:11:01.772068 27537 net.cpp:444] p3_relu <- p3
I1022 16:11:01.772073 27537 net.cpp:405] p3_relu -> p3 (in-place)
I1022 16:11:01.772312 27537 net.cpp:150] Setting up p3_relu
I1022 16:11:01.772320 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.772323 27537 net.cpp:165] Memory required for data: 239038476
I1022 16:11:01.772327 27537 layer_factory.hpp:77] Creating layer p3_p3_relu_0_split
I1022 16:11:01.772336 27537 net.cpp:100] Creating Layer p3_p3_relu_0_split
I1022 16:11:01.772339 27537 net.cpp:444] p3_p3_relu_0_split <- p3
I1022 16:11:01.772346 27537 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_0
I1022 16:11:01.772354 27537 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_1
I1022 16:11:01.772361 27537 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_2
I1022 16:11:01.772475 27537 net.cpp:150] Setting up p3_p3_relu_0_split
I1022 16:11:01.772482 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.772486 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.772490 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.772492 27537 net.cpp:165] Memory required for data: 240242700
I1022 16:11:01.772495 27537 layer_factory.hpp:77] Creating layer newC3
I1022 16:11:01.772508 27537 net.cpp:100] Creating Layer newC3
I1022 16:11:01.772514 27537 net.cpp:444] newC3 <- res3d_res3d_relu_0_split_2
I1022 16:11:01.772521 27537 net.cpp:418] newC3 -> c3
I1022 16:11:01.784811 27537 net.cpp:150] Setting up newC3
I1022 16:11:01.784827 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.784831 27537 net.cpp:165] Memory required for data: 241848332
I1022 16:11:01.784844 27537 layer_factory.hpp:77] Creating layer upP3
I1022 16:11:01.784857 27537 net.cpp:100] Creating Layer upP3
I1022 16:11:01.784860 27537 net.cpp:444] upP3 <- p3_p3_relu_0_split_0
I1022 16:11:01.784867 27537 net.cpp:418] upP3 -> upP3
I1022 16:11:01.785742 27537 net.cpp:150] Setting up upP3
I1022 16:11:01.785749 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.785753 27537 net.cpp:165] Memory required for data: 243453964
I1022 16:11:01.785758 27537 layer_factory.hpp:77] Creating layer eltwise_bnc3_bnp3
I1022 16:11:01.785776 27537 net.cpp:100] Creating Layer eltwise_bnc3_bnp3
I1022 16:11:01.785779 27537 net.cpp:444] eltwise_bnc3_bnp3 <- c3
I1022 16:11:01.785784 27537 net.cpp:444] eltwise_bnc3_bnp3 <- upP3
I1022 16:11:01.785791 27537 net.cpp:418] eltwise_bnc3_bnp3 -> skip_eltwise2
I1022 16:11:01.785838 27537 net.cpp:150] Setting up eltwise_bnc3_bnp3
I1022 16:11:01.785846 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.785851 27537 net.cpp:165] Memory required for data: 245059596
I1022 16:11:01.785853 27537 layer_factory.hpp:77] Creating layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 16:11:01.785858 27537 net.cpp:100] Creating Layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 16:11:01.785863 27537 net.cpp:444] skip_eltwise2_eltwise_bnc3_bnp3_0_split <- skip_eltwise2
I1022 16:11:01.785869 27537 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1022 16:11:01.785876 27537 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1022 16:11:01.785953 27537 net.cpp:150] Setting up skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 16:11:01.785962 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.785966 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.785969 27537 net.cpp:165] Memory required for data: 248270860
I1022 16:11:01.785972 27537 layer_factory.hpp:77] Creating layer bnp3_conv
I1022 16:11:01.785980 27537 net.cpp:100] Creating Layer bnp3_conv
I1022 16:11:01.785984 27537 net.cpp:444] bnp3_conv <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1022 16:11:01.785991 27537 net.cpp:418] bnp3_conv -> bnp3_conv
I1022 16:11:01.788748 27537 net.cpp:150] Setting up bnp3_conv
I1022 16:11:01.788763 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.788766 27537 net.cpp:165] Memory required for data: 248672268
I1022 16:11:01.788781 27537 layer_factory.hpp:77] Creating layer bnp3_bn
I1022 16:11:01.788789 27537 net.cpp:100] Creating Layer bnp3_bn
I1022 16:11:01.788794 27537 net.cpp:444] bnp3_bn <- bnp3_conv
I1022 16:11:01.788800 27537 net.cpp:405] bnp3_bn -> bnp3_conv (in-place)
I1022 16:11:01.789288 27537 net.cpp:150] Setting up bnp3_bn
I1022 16:11:01.789296 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.789299 27537 net.cpp:165] Memory required for data: 249073676
I1022 16:11:01.789316 27537 layer_factory.hpp:77] Creating layer bnp3_scale
I1022 16:11:01.789324 27537 net.cpp:100] Creating Layer bnp3_scale
I1022 16:11:01.789328 27537 net.cpp:444] bnp3_scale <- bnp3_conv
I1022 16:11:01.789335 27537 net.cpp:405] bnp3_scale -> bnp3_conv (in-place)
I1022 16:11:01.789413 27537 layer_factory.hpp:77] Creating layer bnp3_scale
I1022 16:11:01.789661 27537 net.cpp:150] Setting up bnp3_scale
I1022 16:11:01.789670 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.789672 27537 net.cpp:165] Memory required for data: 249475084
I1022 16:11:01.789680 27537 layer_factory.hpp:77] Creating layer bnp3_ReLU
I1022 16:11:01.789687 27537 net.cpp:100] Creating Layer bnp3_ReLU
I1022 16:11:01.789691 27537 net.cpp:444] bnp3_ReLU <- bnp3_conv
I1022 16:11:01.789695 27537 net.cpp:405] bnp3_ReLU -> bnp3_conv (in-place)
I1022 16:11:01.790720 27537 net.cpp:150] Setting up bnp3_ReLU
I1022 16:11:01.790733 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.790747 27537 net.cpp:165] Memory required for data: 249876492
I1022 16:11:01.790750 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_conv
I1022 16:11:01.790762 27537 net.cpp:100] Creating Layer bn_eltwise_2_1_conv
I1022 16:11:01.790766 27537 net.cpp:444] bn_eltwise_2_1_conv <- bnp3_conv
I1022 16:11:01.790774 27537 net.cpp:418] bn_eltwise_2_1_conv -> bn_eltwise_2_1_conv
I1022 16:11:01.795092 27537 net.cpp:150] Setting up bn_eltwise_2_1_conv
I1022 16:11:01.795107 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.795111 27537 net.cpp:165] Memory required for data: 250277900
I1022 16:11:01.795123 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_bn
I1022 16:11:01.795133 27537 net.cpp:100] Creating Layer bn_eltwise_2_1_bn
I1022 16:11:01.795137 27537 net.cpp:444] bn_eltwise_2_1_bn <- bn_eltwise_2_1_conv
I1022 16:11:01.795143 27537 net.cpp:405] bn_eltwise_2_1_bn -> bn_eltwise_2_1_conv (in-place)
I1022 16:11:01.795611 27537 net.cpp:150] Setting up bn_eltwise_2_1_bn
I1022 16:11:01.795619 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.795624 27537 net.cpp:165] Memory required for data: 250679308
I1022 16:11:01.795640 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1022 16:11:01.795647 27537 net.cpp:100] Creating Layer bn_eltwise_2_1_scale
I1022 16:11:01.795650 27537 net.cpp:444] bn_eltwise_2_1_scale <- bn_eltwise_2_1_conv
I1022 16:11:01.795657 27537 net.cpp:405] bn_eltwise_2_1_scale -> bn_eltwise_2_1_conv (in-place)
I1022 16:11:01.795738 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1022 16:11:01.795986 27537 net.cpp:150] Setting up bn_eltwise_2_1_scale
I1022 16:11:01.795994 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.795997 27537 net.cpp:165] Memory required for data: 251080716
I1022 16:11:01.796003 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_ReLU
I1022 16:11:01.796011 27537 net.cpp:100] Creating Layer bn_eltwise_2_1_ReLU
I1022 16:11:01.796015 27537 net.cpp:444] bn_eltwise_2_1_ReLU <- bn_eltwise_2_1_conv
I1022 16:11:01.796021 27537 net.cpp:405] bn_eltwise_2_1_ReLU -> bn_eltwise_2_1_conv (in-place)
I1022 16:11:01.796279 27537 net.cpp:150] Setting up bn_eltwise_2_1_ReLU
I1022 16:11:01.796288 27537 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:11:01.796291 27537 net.cpp:165] Memory required for data: 251482124
I1022 16:11:01.796295 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_conv
I1022 16:11:01.796308 27537 net.cpp:100] Creating Layer bn_eltwise_2_2_conv
I1022 16:11:01.796314 27537 net.cpp:444] bn_eltwise_2_2_conv <- bn_eltwise_2_1_conv
I1022 16:11:01.796319 27537 net.cpp:418] bn_eltwise_2_2_conv -> bn_eltwise_2_2_conv
I1022 16:11:01.804015 27537 net.cpp:150] Setting up bn_eltwise_2_2_conv
I1022 16:11:01.804031 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.804034 27537 net.cpp:165] Memory required for data: 253087756
I1022 16:11:01.804049 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_bn
I1022 16:11:01.804059 27537 net.cpp:100] Creating Layer bn_eltwise_2_2_bn
I1022 16:11:01.804064 27537 net.cpp:444] bn_eltwise_2_2_bn <- bn_eltwise_2_2_conv
I1022 16:11:01.804070 27537 net.cpp:405] bn_eltwise_2_2_bn -> bn_eltwise_2_2_conv (in-place)
I1022 16:11:01.804540 27537 net.cpp:150] Setting up bn_eltwise_2_2_bn
I1022 16:11:01.804549 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.804553 27537 net.cpp:165] Memory required for data: 254693388
I1022 16:11:01.804569 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1022 16:11:01.804579 27537 net.cpp:100] Creating Layer bn_eltwise_2_2_scale
I1022 16:11:01.804584 27537 net.cpp:444] bn_eltwise_2_2_scale <- bn_eltwise_2_2_conv
I1022 16:11:01.804590 27537 net.cpp:405] bn_eltwise_2_2_scale -> bn_eltwise_2_2_conv (in-place)
I1022 16:11:01.804711 27537 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1022 16:11:01.804975 27537 net.cpp:150] Setting up bn_eltwise_2_2_scale
I1022 16:11:01.804985 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.804987 27537 net.cpp:165] Memory required for data: 256299020
I1022 16:11:01.804993 27537 layer_factory.hpp:77] Creating layer p2
I1022 16:11:01.804999 27537 net.cpp:100] Creating Layer p2
I1022 16:11:01.805003 27537 net.cpp:444] p2 <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1022 16:11:01.805008 27537 net.cpp:444] p2 <- bn_eltwise_2_2_conv
I1022 16:11:01.805013 27537 net.cpp:418] p2 -> p2
I1022 16:11:01.805069 27537 net.cpp:150] Setting up p2
I1022 16:11:01.805078 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.805080 27537 net.cpp:165] Memory required for data: 257904652
I1022 16:11:01.805083 27537 layer_factory.hpp:77] Creating layer p2_relu
I1022 16:11:01.805090 27537 net.cpp:100] Creating Layer p2_relu
I1022 16:11:01.805094 27537 net.cpp:444] p2_relu <- p2
I1022 16:11:01.805100 27537 net.cpp:405] p2_relu -> p2 (in-place)
I1022 16:11:01.805352 27537 net.cpp:150] Setting up p2_relu
I1022 16:11:01.805361 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.805364 27537 net.cpp:165] Memory required for data: 259510284
I1022 16:11:01.805367 27537 layer_factory.hpp:77] Creating layer p2_p2_relu_0_split
I1022 16:11:01.805374 27537 net.cpp:100] Creating Layer p2_p2_relu_0_split
I1022 16:11:01.805380 27537 net.cpp:444] p2_p2_relu_0_split <- p2
I1022 16:11:01.805387 27537 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_0
I1022 16:11:01.805397 27537 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_1
I1022 16:11:01.805492 27537 net.cpp:150] Setting up p2_p2_relu_0_split
I1022 16:11:01.805500 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.805505 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.805507 27537 net.cpp:165] Memory required for data: 262721548
I1022 16:11:01.805510 27537 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p2
I1022 16:11:01.805521 27537 net.cpp:100] Creating Layer rpn_conv/3x3_p2
I1022 16:11:01.805526 27537 net.cpp:444] rpn_conv/3x3_p2 <- p2_p2_relu_0_split_0
I1022 16:11:01.805536 27537 net.cpp:418] rpn_conv/3x3_p2 -> rpn/output_p2
I1022 16:11:01.838248 27537 net.cpp:150] Setting up rpn_conv/3x3_p2
I1022 16:11:01.838266 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.838269 27537 net.cpp:165] Memory required for data: 264327180
I1022 16:11:01.838281 27537 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p2
I1022 16:11:01.838287 27537 net.cpp:100] Creating Layer rpn_relu/3x3_p2
I1022 16:11:01.838291 27537 net.cpp:444] rpn_relu/3x3_p2 <- rpn/output_p2
I1022 16:11:01.838299 27537 net.cpp:405] rpn_relu/3x3_p2 -> rpn/output_p2 (in-place)
I1022 16:11:01.843825 27537 net.cpp:150] Setting up rpn_relu/3x3_p2
I1022 16:11:01.843840 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.843843 27537 net.cpp:165] Memory required for data: 265932812
I1022 16:11:01.843847 27537 layer_factory.hpp:77] Creating layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 16:11:01.843854 27537 net.cpp:100] Creating Layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 16:11:01.843858 27537 net.cpp:444] rpn/output_p2_rpn_relu/3x3_p2_0_split <- rpn/output_p2
I1022 16:11:01.843864 27537 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1022 16:11:01.843880 27537 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1022 16:11:01.843976 27537 net.cpp:150] Setting up rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 16:11:01.843983 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.843987 27537 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:11:01.843991 27537 net.cpp:165] Memory required for data: 269144076
I1022 16:11:01.843993 27537 layer_factory.hpp:77] Creating layer rpn_cls_score_p2
I1022 16:11:01.844007 27537 net.cpp:100] Creating Layer rpn_cls_score_p2
I1022 16:11:01.844012 27537 net.cpp:444] rpn_cls_score_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1022 16:11:01.844019 27537 net.cpp:418] rpn_cls_score_p2 -> rpn_cls_score_p2
I1022 16:11:01.852303 27537 net.cpp:150] Setting up rpn_cls_score_p2
I1022 16:11:01.852318 27537 net.cpp:157] Top shape: 1 22 28 28 (17248)
I1022 16:11:01.852321 27537 net.cpp:165] Memory required for data: 269213068
I1022 16:11:01.852334 27537 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p2
I1022 16:11:01.852349 27537 net.cpp:100] Creating Layer rpn_bbox_pred_p2
I1022 16:11:01.852353 27537 net.cpp:444] rpn_bbox_pred_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1022 16:11:01.852360 27537 net.cpp:418] rpn_bbox_pred_p2 -> rpn_bbox_pred_p2
I1022 16:11:01.854837 27537 net.cpp:150] Setting up rpn_bbox_pred_p2
I1022 16:11:01.854851 27537 net.cpp:157] Top shape: 1 44 28 28 (34496)
I1022 16:11:01.854854 27537 net.cpp:165] Memory required for data: 269351052
I1022 16:11:01.854866 27537 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p2
I1022 16:11:01.854876 27537 net.cpp:100] Creating Layer rpn_cls_score_reshape_p2
I1022 16:11:01.854881 27537 net.cpp:444] rpn_cls_score_reshape_p2 <- rpn_cls_score_p2
I1022 16:11:01.854888 27537 net.cpp:418] rpn_cls_score_reshape_p2 -> rpn_cls_score_reshape_p2
I1022 16:11:01.854951 27537 net.cpp:150] Setting up rpn_cls_score_reshape_p2
I1022 16:11:01.854962 27537 net.cpp:157] Top shape: 1 2 308 28 (17248)
I1022 16:11:01.854965 27537 net.cpp:165] Memory required for data: 269420044
I1022 16:11:01.854969 27537 layer_factory.hpp:77] Creating layer rpn_cls_prob_p2
I1022 16:11:01.854977 27537 net.cpp:100] Creating Layer rpn_cls_prob_p2
I1022 16:11:01.854982 27537 net.cpp:444] rpn_cls_prob_p2 <- rpn_cls_score_reshape_p2
I1022 16:11:01.854988 27537 net.cpp:418] rpn_cls_prob_p2 -> rpn_cls_prob_p2
I1022 16:11:01.855382 27537 net.cpp:150] Setting up rpn_cls_prob_p2
I1022 16:11:01.855391 27537 net.cpp:157] Top shape: 1 2 308 28 (17248)
I1022 16:11:01.855394 27537 net.cpp:165] Memory required for data: 269489036
I1022 16:11:01.855398 27537 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p2
I1022 16:11:01.855404 27537 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p2
I1022 16:11:01.855407 27537 net.cpp:444] rpn_cls_prob_reshape_p2 <- rpn_cls_prob_p2
I1022 16:11:01.855415 27537 net.cpp:418] rpn_cls_prob_reshape_p2 -> rpn_cls_prob_reshape_p2
I1022 16:11:01.855465 27537 net.cpp:150] Setting up rpn_cls_prob_reshape_p2
I1022 16:11:01.855473 27537 net.cpp:157] Top shape: 1 22 28 28 (17248)
I1022 16:11:01.855476 27537 net.cpp:165] Memory required for data: 269558028
I1022 16:11:01.855479 27537 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p3
I1022 16:11:01.855494 27537 net.cpp:100] Creating Layer rpn_conv/3x3_p3
I1022 16:11:01.855499 27537 net.cpp:444] rpn_conv/3x3_p3 <- p3_p3_relu_0_split_1
I1022 16:11:01.855505 27537 net.cpp:418] rpn_conv/3x3_p3 -> rpn/output_p3
I1022 16:11:01.892083 27537 net.cpp:150] Setting up rpn_conv/3x3_p3
I1022 16:11:01.892129 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.892133 27537 net.cpp:165] Memory required for data: 269959436
I1022 16:11:01.892146 27537 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p3
I1022 16:11:01.892158 27537 net.cpp:100] Creating Layer rpn_relu/3x3_p3
I1022 16:11:01.892164 27537 net.cpp:444] rpn_relu/3x3_p3 <- rpn/output_p3
I1022 16:11:01.892171 27537 net.cpp:405] rpn_relu/3x3_p3 -> rpn/output_p3 (in-place)
I1022 16:11:01.892446 27537 net.cpp:150] Setting up rpn_relu/3x3_p3
I1022 16:11:01.892467 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.892470 27537 net.cpp:165] Memory required for data: 270360844
I1022 16:11:01.892474 27537 layer_factory.hpp:77] Creating layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 16:11:01.892493 27537 net.cpp:100] Creating Layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 16:11:01.892496 27537 net.cpp:444] rpn/output_p3_rpn_relu/3x3_p3_0_split <- rpn/output_p3
I1022 16:11:01.892504 27537 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1022 16:11:01.892513 27537 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1022 16:11:01.892639 27537 net.cpp:150] Setting up rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 16:11:01.892660 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.892664 27537 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:11:01.892666 27537 net.cpp:165] Memory required for data: 271163660
I1022 16:11:01.892670 27537 layer_factory.hpp:77] Creating layer rpn_cls_score_p3
I1022 16:11:01.892686 27537 net.cpp:100] Creating Layer rpn_cls_score_p3
I1022 16:11:01.892693 27537 net.cpp:444] rpn_cls_score_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1022 16:11:01.892700 27537 net.cpp:418] rpn_cls_score_p3 -> rpn_cls_score_p3
I1022 16:11:01.895053 27537 net.cpp:150] Setting up rpn_cls_score_p3
I1022 16:11:01.895067 27537 net.cpp:157] Top shape: 1 22 14 14 (4312)
I1022 16:11:01.895071 27537 net.cpp:165] Memory required for data: 271180908
I1022 16:11:01.895084 27537 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p3
I1022 16:11:01.895098 27537 net.cpp:100] Creating Layer rpn_bbox_pred_p3
I1022 16:11:01.895103 27537 net.cpp:444] rpn_bbox_pred_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1022 16:11:01.895109 27537 net.cpp:418] rpn_bbox_pred_p3 -> rpn_bbox_pred_p3
I1022 16:11:01.899212 27537 net.cpp:150] Setting up rpn_bbox_pred_p3
I1022 16:11:01.899227 27537 net.cpp:157] Top shape: 1 44 14 14 (8624)
I1022 16:11:01.899231 27537 net.cpp:165] Memory required for data: 271215404
I1022 16:11:01.899246 27537 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p3
I1022 16:11:01.899258 27537 net.cpp:100] Creating Layer rpn_cls_score_reshape_p3
I1022 16:11:01.899262 27537 net.cpp:444] rpn_cls_score_reshape_p3 <- rpn_cls_score_p3
I1022 16:11:01.899272 27537 net.cpp:418] rpn_cls_score_reshape_p3 -> rpn_cls_score_reshape_p3
I1022 16:11:01.899333 27537 net.cpp:150] Setting up rpn_cls_score_reshape_p3
I1022 16:11:01.899341 27537 net.cpp:157] Top shape: 1 2 154 14 (4312)
I1022 16:11:01.899345 27537 net.cpp:165] Memory required for data: 271232652
I1022 16:11:01.899348 27537 layer_factory.hpp:77] Creating layer rpn_cls_prob_p3
I1022 16:11:01.899356 27537 net.cpp:100] Creating Layer rpn_cls_prob_p3
I1022 16:11:01.899363 27537 net.cpp:444] rpn_cls_prob_p3 <- rpn_cls_score_reshape_p3
I1022 16:11:01.899368 27537 net.cpp:418] rpn_cls_prob_p3 -> rpn_cls_prob_p3
I1022 16:11:01.899757 27537 net.cpp:150] Setting up rpn_cls_prob_p3
I1022 16:11:01.899770 27537 net.cpp:157] Top shape: 1 2 154 14 (4312)
I1022 16:11:01.899772 27537 net.cpp:165] Memory required for data: 271249900
I1022 16:11:01.899782 27537 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p3
I1022 16:11:01.899788 27537 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p3
I1022 16:11:01.899792 27537 net.cpp:444] rpn_cls_prob_reshape_p3 <- rpn_cls_prob_p3
I1022 16:11:01.899799 27537 net.cpp:418] rpn_cls_prob_reshape_p3 -> rpn_cls_prob_reshape_p3
I1022 16:11:01.899849 27537 net.cpp:150] Setting up rpn_cls_prob_reshape_p3
I1022 16:11:01.899857 27537 net.cpp:157] Top shape: 1 22 14 14 (4312)
I1022 16:11:01.899861 27537 net.cpp:165] Memory required for data: 271267148
I1022 16:11:01.899864 27537 layer_factory.hpp:77] Creating layer proposal
I1022 16:11:01.901444 27537 net.cpp:100] Creating Layer proposal
I1022 16:11:01.901458 27537 net.cpp:444] proposal <- im_info
I1022 16:11:01.901473 27537 net.cpp:444] proposal <- rpn_bbox_pred_p2
I1022 16:11:01.901476 27537 net.cpp:444] proposal <- rpn_bbox_pred_p3
I1022 16:11:01.901480 27537 net.cpp:444] proposal <- rpn_cls_prob_reshape_p2
I1022 16:11:01.901484 27537 net.cpp:444] proposal <- rpn_cls_prob_reshape_p3
I1022 16:11:01.901491 27537 net.cpp:418] proposal -> rpn_rois_p2
I1022 16:11:01.901499 27537 net.cpp:418] proposal -> rpn_rois_p3
I1022 16:11:01.902683 27537 net.cpp:150] Setting up proposal
I1022 16:11:01.902696 27537 net.cpp:157] Top shape: 1 5 (5)
I1022 16:11:01.902701 27537 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 16:11:01.902704 27537 net.cpp:165] Memory required for data: 271267172
I1022 16:11:01.902711 27537 layer_factory.hpp:77] Creating layer rpn_rois_p2_proposal_0_split
I1022 16:11:01.902717 27537 net.cpp:100] Creating Layer rpn_rois_p2_proposal_0_split
I1022 16:11:01.902721 27537 net.cpp:444] rpn_rois_p2_proposal_0_split <- rpn_rois_p2
I1022 16:11:01.902727 27537 net.cpp:418] rpn_rois_p2_proposal_0_split -> rpn_rois_p2_proposal_0_split_0
I1022 16:11:01.902735 27537 net.cpp:418] rpn_rois_p2_proposal_0_split -> rpn_rois_p2_proposal_0_split_1
I1022 16:11:01.902818 27537 net.cpp:150] Setting up rpn_rois_p2_proposal_0_split
I1022 16:11:01.902827 27537 net.cpp:157] Top shape: 1 5 (5)
I1022 16:11:01.902829 27537 net.cpp:157] Top shape: 1 5 (5)
I1022 16:11:01.902832 27537 net.cpp:165] Memory required for data: 271267212
I1022 16:11:01.902837 27537 layer_factory.hpp:77] Creating layer rpn_rois_p3_proposal_1_split
I1022 16:11:01.902842 27537 net.cpp:100] Creating Layer rpn_rois_p3_proposal_1_split
I1022 16:11:01.902845 27537 net.cpp:444] rpn_rois_p3_proposal_1_split <- rpn_rois_p3
I1022 16:11:01.902850 27537 net.cpp:418] rpn_rois_p3_proposal_1_split -> rpn_rois_p3_proposal_1_split_0
I1022 16:11:01.902860 27537 net.cpp:418] rpn_rois_p3_proposal_1_split -> rpn_rois_p3_proposal_1_split_1
I1022 16:11:01.902933 27537 net.cpp:150] Setting up rpn_rois_p3_proposal_1_split
I1022 16:11:01.902940 27537 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 16:11:01.902945 27537 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 16:11:01.902947 27537 net.cpp:165] Memory required for data: 271267220
I1022 16:11:01.902951 27537 layer_factory.hpp:77] Creating layer conv_new_p2
I1022 16:11:01.902961 27537 net.cpp:100] Creating Layer conv_new_p2
I1022 16:11:01.902966 27537 net.cpp:444] conv_new_p2 <- p2_p2_relu_0_split_1
I1022 16:11:01.902972 27537 net.cpp:418] conv_new_p2 -> conv_new_p2
I1022 16:11:01.915901 27537 net.cpp:150] Setting up conv_new_p2
I1022 16:11:01.915941 27537 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 16:11:01.915944 27537 net.cpp:165] Memory required for data: 274478484
I1022 16:11:01.915956 27537 layer_factory.hpp:77] Creating layer conv_new_p2_relu
I1022 16:11:01.915971 27537 net.cpp:100] Creating Layer conv_new_p2_relu
I1022 16:11:01.915976 27537 net.cpp:444] conv_new_p2_relu <- conv_new_p2
I1022 16:11:01.915982 27537 net.cpp:405] conv_new_p2_relu -> conv_new_p2 (in-place)
I1022 16:11:01.917088 27537 net.cpp:150] Setting up conv_new_p2_relu
I1022 16:11:01.917101 27537 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 16:11:01.917105 27537 net.cpp:165] Memory required for data: 277689748
I1022 16:11:01.917116 27537 layer_factory.hpp:77] Creating layer conv_new_p2_conv_new_p2_relu_0_split
I1022 16:11:01.917124 27537 net.cpp:100] Creating Layer conv_new_p2_conv_new_p2_relu_0_split
I1022 16:11:01.917129 27537 net.cpp:444] conv_new_p2_conv_new_p2_relu_0_split <- conv_new_p2
I1022 16:11:01.917136 27537 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_0
I1022 16:11:01.917145 27537 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_1
I1022 16:11:01.917243 27537 net.cpp:150] Setting up conv_new_p2_conv_new_p2_relu_0_split
I1022 16:11:01.917251 27537 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 16:11:01.917255 27537 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 16:11:01.917258 27537 net.cpp:165] Memory required for data: 284112276
I1022 16:11:01.917263 27537 layer_factory.hpp:77] Creating layer rfcn_cls_p2
I1022 16:11:01.917275 27537 net.cpp:100] Creating Layer rfcn_cls_p2
I1022 16:11:01.917280 27537 net.cpp:444] rfcn_cls_p2 <- conv_new_p2_conv_new_p2_relu_0_split_0
I1022 16:11:01.917289 27537 net.cpp:418] rfcn_cls_p2 -> rfcn_cls_p2
I1022 16:11:01.920738 27537 net.cpp:150] Setting up rfcn_cls_p2
I1022 16:11:01.920758 27537 net.cpp:157] Top shape: 1 98 28 28 (76832)
I1022 16:11:01.920771 27537 net.cpp:165] Memory required for data: 284419604
I1022 16:11:01.920779 27537 layer_factory.hpp:77] Creating layer rfcn_bbox_p2
I1022 16:11:01.920794 27537 net.cpp:100] Creating Layer rfcn_bbox_p2
I1022 16:11:01.920797 27537 net.cpp:444] rfcn_bbox_p2 <- conv_new_p2_conv_new_p2_relu_0_split_1
I1022 16:11:01.920805 27537 net.cpp:418] rfcn_bbox_p2 -> rfcn_bbox_p2
I1022 16:11:01.931170 27537 net.cpp:150] Setting up rfcn_bbox_p2
I1022 16:11:01.931208 27537 net.cpp:157] Top shape: 1 392 28 28 (307328)
I1022 16:11:01.931211 27537 net.cpp:165] Memory required for data: 285648916
I1022 16:11:01.931221 27537 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p2
I1022 16:11:01.931234 27537 net.cpp:100] Creating Layer psroipooled_cls_rois_p2
I1022 16:11:01.931241 27537 net.cpp:444] psroipooled_cls_rois_p2 <- rfcn_cls_p2
I1022 16:11:01.931247 27537 net.cpp:444] psroipooled_cls_rois_p2 <- rpn_rois_p2_proposal_0_split_0
I1022 16:11:01.931257 27537 net.cpp:418] psroipooled_cls_rois_p2 -> psroipooled_cls_rois_p2
I1022 16:11:01.931270 27537 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1022 16:11:01.931371 27537 net.cpp:150] Setting up psroipooled_cls_rois_p2
I1022 16:11:01.931380 27537 net.cpp:157] Top shape: 1 2 7 7 (98)
I1022 16:11:01.931382 27537 net.cpp:165] Memory required for data: 285649308
I1022 16:11:01.931385 27537 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p2
I1022 16:11:01.931394 27537 net.cpp:100] Creating Layer ave_cls_score_rois_p2
I1022 16:11:01.931401 27537 net.cpp:444] ave_cls_score_rois_p2 <- psroipooled_cls_rois_p2
I1022 16:11:01.931407 27537 net.cpp:418] ave_cls_score_rois_p2 -> cls_score_p2
I1022 16:11:01.931708 27537 net.cpp:150] Setting up ave_cls_score_rois_p2
I1022 16:11:01.931718 27537 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 16:11:01.931721 27537 net.cpp:165] Memory required for data: 285649316
I1022 16:11:01.931730 27537 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p2
I1022 16:11:01.931736 27537 net.cpp:100] Creating Layer psroipooled_loc_rois_p2
I1022 16:11:01.931740 27537 net.cpp:444] psroipooled_loc_rois_p2 <- rfcn_bbox_p2
I1022 16:11:01.931756 27537 net.cpp:444] psroipooled_loc_rois_p2 <- rpn_rois_p2_proposal_0_split_1
I1022 16:11:01.931763 27537 net.cpp:418] psroipooled_loc_rois_p2 -> psroipooled_loc_rois_p2
I1022 16:11:01.931771 27537 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1022 16:11:01.931859 27537 net.cpp:150] Setting up psroipooled_loc_rois_p2
I1022 16:11:01.931866 27537 net.cpp:157] Top shape: 1 8 7 7 (392)
I1022 16:11:01.931870 27537 net.cpp:165] Memory required for data: 285650884
I1022 16:11:01.931874 27537 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p2
I1022 16:11:01.931881 27537 net.cpp:100] Creating Layer ave_bbox_pred_rois_p2
I1022 16:11:01.931885 27537 net.cpp:444] ave_bbox_pred_rois_p2 <- psroipooled_loc_rois_p2
I1022 16:11:01.931890 27537 net.cpp:418] ave_bbox_pred_rois_p2 -> bbox_pred_pre_p2
I1022 16:11:01.932183 27537 net.cpp:150] Setting up ave_bbox_pred_rois_p2
I1022 16:11:01.932193 27537 net.cpp:157] Top shape: 1 8 1 1 (8)
I1022 16:11:01.932195 27537 net.cpp:165] Memory required for data: 285650916
I1022 16:11:01.932209 27537 layer_factory.hpp:77] Creating layer conv_new_p3
I1022 16:11:01.932221 27537 net.cpp:100] Creating Layer conv_new_p3
I1022 16:11:01.932226 27537 net.cpp:444] conv_new_p3 <- p3_p3_relu_0_split_2
I1022 16:11:01.932235 27537 net.cpp:418] conv_new_p3 -> conv_new_p3
I1022 16:11:01.942288 27537 net.cpp:150] Setting up conv_new_p3
I1022 16:11:01.942306 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.942309 27537 net.cpp:165] Memory required for data: 286453732
I1022 16:11:01.942327 27537 layer_factory.hpp:77] Creating layer conv_new_p3_relu
I1022 16:11:01.942337 27537 net.cpp:100] Creating Layer conv_new_p3_relu
I1022 16:11:01.942342 27537 net.cpp:444] conv_new_p3_relu <- conv_new_p3
I1022 16:11:01.942348 27537 net.cpp:405] conv_new_p3_relu -> conv_new_p3 (in-place)
I1022 16:11:01.943394 27537 net.cpp:150] Setting up conv_new_p3_relu
I1022 16:11:01.943408 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.943410 27537 net.cpp:165] Memory required for data: 287256548
I1022 16:11:01.943423 27537 layer_factory.hpp:77] Creating layer conv_new_p3_conv_new_p3_relu_0_split
I1022 16:11:01.943431 27537 net.cpp:100] Creating Layer conv_new_p3_conv_new_p3_relu_0_split
I1022 16:11:01.943434 27537 net.cpp:444] conv_new_p3_conv_new_p3_relu_0_split <- conv_new_p3
I1022 16:11:01.943442 27537 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_0
I1022 16:11:01.943451 27537 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_1
I1022 16:11:01.943560 27537 net.cpp:150] Setting up conv_new_p3_conv_new_p3_relu_0_split
I1022 16:11:01.943568 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.943572 27537 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:11:01.943575 27537 net.cpp:165] Memory required for data: 288862180
I1022 16:11:01.943578 27537 layer_factory.hpp:77] Creating layer rfcn_cls_p3
I1022 16:11:01.943593 27537 net.cpp:100] Creating Layer rfcn_cls_p3
I1022 16:11:01.943598 27537 net.cpp:444] rfcn_cls_p3 <- conv_new_p3_conv_new_p3_relu_0_split_0
I1022 16:11:01.943608 27537 net.cpp:418] rfcn_cls_p3 -> rfcn_cls_p3
I1022 16:11:01.946943 27537 net.cpp:150] Setting up rfcn_cls_p3
I1022 16:11:01.946956 27537 net.cpp:157] Top shape: 1 98 14 14 (19208)
I1022 16:11:01.946959 27537 net.cpp:165] Memory required for data: 288939012
I1022 16:11:01.946974 27537 layer_factory.hpp:77] Creating layer rfcn_bbox_p3
I1022 16:11:01.946985 27537 net.cpp:100] Creating Layer rfcn_bbox_p3
I1022 16:11:01.946988 27537 net.cpp:444] rfcn_bbox_p3 <- conv_new_p3_conv_new_p3_relu_0_split_1
I1022 16:11:01.946997 27537 net.cpp:418] rfcn_bbox_p3 -> rfcn_bbox_p3
I1022 16:11:01.956029 27537 net.cpp:150] Setting up rfcn_bbox_p3
I1022 16:11:01.956045 27537 net.cpp:157] Top shape: 1 392 14 14 (76832)
I1022 16:11:01.956049 27537 net.cpp:165] Memory required for data: 289246340
I1022 16:11:01.956063 27537 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p3
I1022 16:11:01.956074 27537 net.cpp:100] Creating Layer psroipooled_cls_rois_p3
I1022 16:11:01.956079 27537 net.cpp:444] psroipooled_cls_rois_p3 <- rfcn_cls_p3
I1022 16:11:01.956084 27537 net.cpp:444] psroipooled_cls_rois_p3 <- rpn_rois_p3_proposal_1_split_0
I1022 16:11:01.956092 27537 net.cpp:418] psroipooled_cls_rois_p3 -> psroipooled_cls_rois_p3
I1022 16:11:01.956102 27537 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1022 16:11:01.956209 27537 net.cpp:150] Setting up psroipooled_cls_rois_p3
I1022 16:11:01.956216 27537 net.cpp:157] Top shape: 1 2 7 7 (98)
I1022 16:11:01.956219 27537 net.cpp:165] Memory required for data: 289246732
I1022 16:11:01.956223 27537 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p3
I1022 16:11:01.956233 27537 net.cpp:100] Creating Layer ave_cls_score_rois_p3
I1022 16:11:01.956236 27537 net.cpp:444] ave_cls_score_rois_p3 <- psroipooled_cls_rois_p3
I1022 16:11:01.956243 27537 net.cpp:418] ave_cls_score_rois_p3 -> cls_score_p3
I1022 16:11:01.956547 27537 net.cpp:150] Setting up ave_cls_score_rois_p3
I1022 16:11:01.956557 27537 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 16:11:01.956559 27537 net.cpp:165] Memory required for data: 289246740
I1022 16:11:01.956563 27537 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p3
I1022 16:11:01.956569 27537 net.cpp:100] Creating Layer psroipooled_loc_rois_p3
I1022 16:11:01.956573 27537 net.cpp:444] psroipooled_loc_rois_p3 <- rfcn_bbox_p3
I1022 16:11:01.956578 27537 net.cpp:444] psroipooled_loc_rois_p3 <- rpn_rois_p3_proposal_1_split_1
I1022 16:11:01.956584 27537 net.cpp:418] psroipooled_loc_rois_p3 -> psroipooled_loc_rois_p3
I1022 16:11:01.956593 27537 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1022 16:11:01.956713 27537 net.cpp:150] Setting up psroipooled_loc_rois_p3
I1022 16:11:01.956722 27537 net.cpp:157] Top shape: 1 8 7 7 (392)
I1022 16:11:01.956725 27537 net.cpp:165] Memory required for data: 289248308
I1022 16:11:01.956729 27537 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p3
I1022 16:11:01.956737 27537 net.cpp:100] Creating Layer ave_bbox_pred_rois_p3
I1022 16:11:01.956742 27537 net.cpp:444] ave_bbox_pred_rois_p3 <- psroipooled_loc_rois_p3
I1022 16:11:01.956746 27537 net.cpp:418] ave_bbox_pred_rois_p3 -> bbox_pred_pre_p3
I1022 16:11:01.957037 27537 net.cpp:150] Setting up ave_bbox_pred_rois_p3
I1022 16:11:01.957046 27537 net.cpp:157] Top shape: 1 8 1 1 (8)
I1022 16:11:01.957049 27537 net.cpp:165] Memory required for data: 289248340
I1022 16:11:01.957052 27537 layer_factory.hpp:77] Creating layer cls_prob_pre_p2
I1022 16:11:01.957062 27537 net.cpp:100] Creating Layer cls_prob_pre_p2
I1022 16:11:01.957065 27537 net.cpp:444] cls_prob_pre_p2 <- cls_score_p2
I1022 16:11:01.957070 27537 net.cpp:418] cls_prob_pre_p2 -> cls_prob_pre_p2
I1022 16:11:01.958271 27537 net.cpp:150] Setting up cls_prob_pre_p2
I1022 16:11:01.958286 27537 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 16:11:01.958287 27537 net.cpp:165] Memory required for data: 289248348
I1022 16:11:01.958292 27537 layer_factory.hpp:77] Creating layer cls_prob_pre_p3
I1022 16:11:01.958300 27537 net.cpp:100] Creating Layer cls_prob_pre_p3
I1022 16:11:01.958305 27537 net.cpp:444] cls_prob_pre_p3 <- cls_score_p3
I1022 16:11:01.958312 27537 net.cpp:418] cls_prob_pre_p3 -> cls_prob_pre_p3
I1022 16:11:01.958706 27537 net.cpp:150] Setting up cls_prob_pre_p3
I1022 16:11:01.958715 27537 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 16:11:01.958719 27537 net.cpp:165] Memory required for data: 289248356
I1022 16:11:01.958721 27537 layer_factory.hpp:77] Creating layer cls_prob_reshape_p2
I1022 16:11:01.958739 27537 net.cpp:100] Creating Layer cls_prob_reshape_p2
I1022 16:11:01.958745 27537 net.cpp:444] cls_prob_reshape_p2 <- cls_prob_pre_p2
I1022 16:11:01.958750 27537 net.cpp:418] cls_prob_reshape_p2 -> cls_prob_p2
I1022 16:11:01.958807 27537 net.cpp:150] Setting up cls_prob_reshape_p2
I1022 16:11:01.958817 27537 net.cpp:157] Top shape: 1 2 (2)
I1022 16:11:01.958818 27537 net.cpp:165] Memory required for data: 289248364
I1022 16:11:01.958822 27537 layer_factory.hpp:77] Creating layer cls_prob_reshape_p3
I1022 16:11:01.958827 27537 net.cpp:100] Creating Layer cls_prob_reshape_p3
I1022 16:11:01.958832 27537 net.cpp:444] cls_prob_reshape_p3 <- cls_prob_pre_p3
I1022 16:11:01.958835 27537 net.cpp:418] cls_prob_reshape_p3 -> cls_prob_p3
I1022 16:11:01.958886 27537 net.cpp:150] Setting up cls_prob_reshape_p3
I1022 16:11:01.958894 27537 net.cpp:157] Top shape: 1 2 (2)
I1022 16:11:01.958897 27537 net.cpp:165] Memory required for data: 289248372
I1022 16:11:01.958900 27537 layer_factory.hpp:77] Creating layer bbox_pred_reshape_p2
I1022 16:11:01.958905 27537 net.cpp:100] Creating Layer bbox_pred_reshape_p2
I1022 16:11:01.958909 27537 net.cpp:444] bbox_pred_reshape_p2 <- bbox_pred_pre_p2
I1022 16:11:01.958915 27537 net.cpp:418] bbox_pred_reshape_p2 -> bbox_pred_p2
I1022 16:11:01.958961 27537 net.cpp:150] Setting up bbox_pred_reshape_p2
I1022 16:11:01.958968 27537 net.cpp:157] Top shape: 1 8 (8)
I1022 16:11:01.958971 27537 net.cpp:165] Memory required for data: 289248404
I1022 16:11:01.958974 27537 layer_factory.hpp:77] Creating layer bbox_pred_reshape_p3
I1022 16:11:01.958981 27537 net.cpp:100] Creating Layer bbox_pred_reshape_p3
I1022 16:11:01.958986 27537 net.cpp:444] bbox_pred_reshape_p3 <- bbox_pred_pre_p3
I1022 16:11:01.958992 27537 net.cpp:418] bbox_pred_reshape_p3 -> bbox_pred_p3
I1022 16:11:01.959038 27537 net.cpp:150] Setting up bbox_pred_reshape_p3
I1022 16:11:01.959045 27537 net.cpp:157] Top shape: 1 8 (8)
I1022 16:11:01.959048 27537 net.cpp:165] Memory required for data: 289248436
I1022 16:11:01.959053 27537 net.cpp:228] bbox_pred_reshape_p3 does not need backward computation.
I1022 16:11:01.959055 27537 net.cpp:228] bbox_pred_reshape_p2 does not need backward computation.
I1022 16:11:01.959059 27537 net.cpp:228] cls_prob_reshape_p3 does not need backward computation.
I1022 16:11:01.959064 27537 net.cpp:228] cls_prob_reshape_p2 does not need backward computation.
I1022 16:11:01.959066 27537 net.cpp:228] cls_prob_pre_p3 does not need backward computation.
I1022 16:11:01.959069 27537 net.cpp:228] cls_prob_pre_p2 does not need backward computation.
I1022 16:11:01.959074 27537 net.cpp:228] ave_bbox_pred_rois_p3 does not need backward computation.
I1022 16:11:01.959076 27537 net.cpp:228] psroipooled_loc_rois_p3 does not need backward computation.
I1022 16:11:01.959080 27537 net.cpp:228] ave_cls_score_rois_p3 does not need backward computation.
I1022 16:11:01.959084 27537 net.cpp:228] psroipooled_cls_rois_p3 does not need backward computation.
I1022 16:11:01.959087 27537 net.cpp:228] rfcn_bbox_p3 does not need backward computation.
I1022 16:11:01.959091 27537 net.cpp:228] rfcn_cls_p3 does not need backward computation.
I1022 16:11:01.959095 27537 net.cpp:228] conv_new_p3_conv_new_p3_relu_0_split does not need backward computation.
I1022 16:11:01.959098 27537 net.cpp:228] conv_new_p3_relu does not need backward computation.
I1022 16:11:01.959101 27537 net.cpp:228] conv_new_p3 does not need backward computation.
I1022 16:11:01.959105 27537 net.cpp:228] ave_bbox_pred_rois_p2 does not need backward computation.
I1022 16:11:01.959110 27537 net.cpp:228] psroipooled_loc_rois_p2 does not need backward computation.
I1022 16:11:01.959113 27537 net.cpp:228] ave_cls_score_rois_p2 does not need backward computation.
I1022 16:11:01.959117 27537 net.cpp:228] psroipooled_cls_rois_p2 does not need backward computation.
I1022 16:11:01.959126 27537 net.cpp:228] rfcn_bbox_p2 does not need backward computation.
I1022 16:11:01.959131 27537 net.cpp:228] rfcn_cls_p2 does not need backward computation.
I1022 16:11:01.959133 27537 net.cpp:228] conv_new_p2_conv_new_p2_relu_0_split does not need backward computation.
I1022 16:11:01.959137 27537 net.cpp:228] conv_new_p2_relu does not need backward computation.
I1022 16:11:01.959141 27537 net.cpp:228] conv_new_p2 does not need backward computation.
I1022 16:11:01.959144 27537 net.cpp:228] rpn_rois_p3_proposal_1_split does not need backward computation.
I1022 16:11:01.959148 27537 net.cpp:228] rpn_rois_p2_proposal_0_split does not need backward computation.
I1022 16:11:01.959152 27537 net.cpp:228] proposal does not need backward computation.
I1022 16:11:01.959158 27537 net.cpp:228] rpn_cls_prob_reshape_p3 does not need backward computation.
I1022 16:11:01.959164 27537 net.cpp:228] rpn_cls_prob_p3 does not need backward computation.
I1022 16:11:01.959167 27537 net.cpp:228] rpn_cls_score_reshape_p3 does not need backward computation.
I1022 16:11:01.959172 27537 net.cpp:228] rpn_bbox_pred_p3 does not need backward computation.
I1022 16:11:01.959177 27537 net.cpp:228] rpn_cls_score_p3 does not need backward computation.
I1022 16:11:01.959179 27537 net.cpp:228] rpn/output_p3_rpn_relu/3x3_p3_0_split does not need backward computation.
I1022 16:11:01.959183 27537 net.cpp:228] rpn_relu/3x3_p3 does not need backward computation.
I1022 16:11:01.959187 27537 net.cpp:228] rpn_conv/3x3_p3 does not need backward computation.
I1022 16:11:01.959190 27537 net.cpp:228] rpn_cls_prob_reshape_p2 does not need backward computation.
I1022 16:11:01.959194 27537 net.cpp:228] rpn_cls_prob_p2 does not need backward computation.
I1022 16:11:01.959198 27537 net.cpp:228] rpn_cls_score_reshape_p2 does not need backward computation.
I1022 16:11:01.959204 27537 net.cpp:228] rpn_bbox_pred_p2 does not need backward computation.
I1022 16:11:01.959208 27537 net.cpp:228] rpn_cls_score_p2 does not need backward computation.
I1022 16:11:01.959213 27537 net.cpp:228] rpn/output_p2_rpn_relu/3x3_p2_0_split does not need backward computation.
I1022 16:11:01.959215 27537 net.cpp:228] rpn_relu/3x3_p2 does not need backward computation.
I1022 16:11:01.959218 27537 net.cpp:228] rpn_conv/3x3_p2 does not need backward computation.
I1022 16:11:01.959223 27537 net.cpp:228] p2_p2_relu_0_split does not need backward computation.
I1022 16:11:01.959228 27537 net.cpp:228] p2_relu does not need backward computation.
I1022 16:11:01.959230 27537 net.cpp:228] p2 does not need backward computation.
I1022 16:11:01.959235 27537 net.cpp:228] bn_eltwise_2_2_scale does not need backward computation.
I1022 16:11:01.959239 27537 net.cpp:228] bn_eltwise_2_2_bn does not need backward computation.
I1022 16:11:01.959242 27537 net.cpp:228] bn_eltwise_2_2_conv does not need backward computation.
I1022 16:11:01.959245 27537 net.cpp:228] bn_eltwise_2_1_ReLU does not need backward computation.
I1022 16:11:01.959249 27537 net.cpp:228] bn_eltwise_2_1_scale does not need backward computation.
I1022 16:11:01.959252 27537 net.cpp:228] bn_eltwise_2_1_bn does not need backward computation.
I1022 16:11:01.959255 27537 net.cpp:228] bn_eltwise_2_1_conv does not need backward computation.
I1022 16:11:01.959259 27537 net.cpp:228] bnp3_ReLU does not need backward computation.
I1022 16:11:01.959264 27537 net.cpp:228] bnp3_scale does not need backward computation.
I1022 16:11:01.959266 27537 net.cpp:228] bnp3_bn does not need backward computation.
I1022 16:11:01.959270 27537 net.cpp:228] bnp3_conv does not need backward computation.
I1022 16:11:01.959273 27537 net.cpp:228] skip_eltwise2_eltwise_bnc3_bnp3_0_split does not need backward computation.
I1022 16:11:01.959276 27537 net.cpp:228] eltwise_bnc3_bnp3 does not need backward computation.
I1022 16:11:01.959281 27537 net.cpp:228] upP3 does not need backward computation.
I1022 16:11:01.959285 27537 net.cpp:228] newC3 does not need backward computation.
I1022 16:11:01.959290 27537 net.cpp:228] p3_p3_relu_0_split does not need backward computation.
I1022 16:11:01.959293 27537 net.cpp:228] p3_relu does not need backward computation.
I1022 16:11:01.959296 27537 net.cpp:228] p3 does not need backward computation.
I1022 16:11:01.959300 27537 net.cpp:228] bn_eltwise_1_2_scale does not need backward computation.
I1022 16:11:01.959305 27537 net.cpp:228] bn_eltwise_1_2_bn does not need backward computation.
I1022 16:11:01.959307 27537 net.cpp:228] bn_eltwise_1_2_conv does not need backward computation.
I1022 16:11:01.959311 27537 net.cpp:228] bn_eltwise_1_1_ReLU does not need backward computation.
I1022 16:11:01.959314 27537 net.cpp:228] bn_eltwise_1_1_scale does not need backward computation.
I1022 16:11:01.959317 27537 net.cpp:228] bn_eltwise_1_1_bn does not need backward computation.
I1022 16:11:01.959321 27537 net.cpp:228] bn_eltwise_1_1_conv does not need backward computation.
I1022 16:11:01.959324 27537 net.cpp:228] bnp4_ReLU does not need backward computation.
I1022 16:11:01.959328 27537 net.cpp:228] bnp4_scale does not need backward computation.
I1022 16:11:01.959331 27537 net.cpp:228] bnp4_bn does not need backward computation.
I1022 16:11:01.959334 27537 net.cpp:228] bnp4_conv does not need backward computation.
I1022 16:11:01.959339 27537 net.cpp:228] skip_eltwise1_eltwise_bnc4_bnp4_0_split does not need backward computation.
I1022 16:11:01.959342 27537 net.cpp:228] eltwise_bnc4_bnp4 does not need backward computation.
I1022 16:11:01.959347 27537 net.cpp:228] newC4 does not need backward computation.
I1022 16:11:01.959350 27537 net.cpp:228] upP4 does not need backward computation.
I1022 16:11:01.959354 27537 net.cpp:228] res5c_relu does not need backward computation.
I1022 16:11:01.959357 27537 net.cpp:228] res5c does not need backward computation.
I1022 16:11:01.959362 27537 net.cpp:228] scale5c_branch2c does not need backward computation.
I1022 16:11:01.959365 27537 net.cpp:228] bn5c_branch2c does not need backward computation.
I1022 16:11:01.959368 27537 net.cpp:228] res5c_branch2c does not need backward computation.
I1022 16:11:01.959372 27537 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I1022 16:11:01.959375 27537 net.cpp:228] scale5c_branch2b does not need backward computation.
I1022 16:11:01.959378 27537 net.cpp:228] bn5c_branch2b does not need backward computation.
I1022 16:11:01.959383 27537 net.cpp:228] res5c_branch2b does not need backward computation.
I1022 16:11:01.959386 27537 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I1022 16:11:01.959389 27537 net.cpp:228] scale5c_branch2a does not need backward computation.
I1022 16:11:01.959393 27537 net.cpp:228] bn5c_branch2a does not need backward computation.
I1022 16:11:01.959395 27537 net.cpp:228] res5c_branch2a does not need backward computation.
I1022 16:11:01.959399 27537 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I1022 16:11:01.959403 27537 net.cpp:228] res5b_relu does not need backward computation.
I1022 16:11:01.959406 27537 net.cpp:228] res5b does not need backward computation.
I1022 16:11:01.959411 27537 net.cpp:228] scale5b_branch2c does not need backward computation.
I1022 16:11:01.959414 27537 net.cpp:228] bn5b_branch2c does not need backward computation.
I1022 16:11:01.959417 27537 net.cpp:228] res5b_branch2c does not need backward computation.
I1022 16:11:01.959420 27537 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I1022 16:11:01.959425 27537 net.cpp:228] scale5b_branch2b does not need backward computation.
I1022 16:11:01.959429 27537 net.cpp:228] bn5b_branch2b does not need backward computation.
I1022 16:11:01.959431 27537 net.cpp:228] res5b_branch2b does not need backward computation.
I1022 16:11:01.959434 27537 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I1022 16:11:01.959439 27537 net.cpp:228] scale5b_branch2a does not need backward computation.
I1022 16:11:01.959441 27537 net.cpp:228] bn5b_branch2a does not need backward computation.
I1022 16:11:01.959444 27537 net.cpp:228] res5b_branch2a does not need backward computation.
I1022 16:11:01.959448 27537 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I1022 16:11:01.959452 27537 net.cpp:228] res5a_relu does not need backward computation.
I1022 16:11:01.959455 27537 net.cpp:228] res5a does not need backward computation.
I1022 16:11:01.959461 27537 net.cpp:228] scale5a_branch2c does not need backward computation.
I1022 16:11:01.959465 27537 net.cpp:228] bn5a_branch2c does not need backward computation.
I1022 16:11:01.959468 27537 net.cpp:228] res5a_branch2c does not need backward computation.
I1022 16:11:01.959471 27537 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I1022 16:11:01.959475 27537 net.cpp:228] scale5a_branch2b does not need backward computation.
I1022 16:11:01.959478 27537 net.cpp:228] bn5a_branch2b does not need backward computation.
I1022 16:11:01.959482 27537 net.cpp:228] res5a_branch2b does not need backward computation.
I1022 16:11:01.959486 27537 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I1022 16:11:01.959488 27537 net.cpp:228] scale5a_branch2a does not need backward computation.
I1022 16:11:01.959492 27537 net.cpp:228] bn5a_branch2a does not need backward computation.
I1022 16:11:01.959496 27537 net.cpp:228] res5a_branch2a does not need backward computation.
I1022 16:11:01.959499 27537 net.cpp:228] scale5a_branch1 does not need backward computation.
I1022 16:11:01.959503 27537 net.cpp:228] bn5a_branch1 does not need backward computation.
I1022 16:11:01.959506 27537 net.cpp:228] res5a_branch1 does not need backward computation.
I1022 16:11:01.959511 27537 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I1022 16:11:01.959514 27537 net.cpp:228] res4f_relu does not need backward computation.
I1022 16:11:01.959517 27537 net.cpp:228] res4f does not need backward computation.
I1022 16:11:01.959522 27537 net.cpp:228] scale4f_branch2c does not need backward computation.
I1022 16:11:01.959525 27537 net.cpp:228] bn4f_branch2c does not need backward computation.
I1022 16:11:01.959529 27537 net.cpp:228] res4f_branch2c does not need backward computation.
I1022 16:11:01.959532 27537 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I1022 16:11:01.959537 27537 net.cpp:228] scale4f_branch2b does not need backward computation.
I1022 16:11:01.959539 27537 net.cpp:228] bn4f_branch2b does not need backward computation.
I1022 16:11:01.959542 27537 net.cpp:228] res4f_branch2b does not need backward computation.
I1022 16:11:01.959545 27537 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I1022 16:11:01.959549 27537 net.cpp:228] scale4f_branch2a does not need backward computation.
I1022 16:11:01.959553 27537 net.cpp:228] bn4f_branch2a does not need backward computation.
I1022 16:11:01.959556 27537 net.cpp:228] res4f_branch2a does not need backward computation.
I1022 16:11:01.959559 27537 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I1022 16:11:01.959563 27537 net.cpp:228] res4e_relu does not need backward computation.
I1022 16:11:01.959568 27537 net.cpp:228] res4e does not need backward computation.
I1022 16:11:01.959571 27537 net.cpp:228] scale4e_branch2c does not need backward computation.
I1022 16:11:01.959575 27537 net.cpp:228] bn4e_branch2c does not need backward computation.
I1022 16:11:01.959578 27537 net.cpp:228] res4e_branch2c does not need backward computation.
I1022 16:11:01.959583 27537 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I1022 16:11:01.959585 27537 net.cpp:228] scale4e_branch2b does not need backward computation.
I1022 16:11:01.959589 27537 net.cpp:228] bn4e_branch2b does not need backward computation.
I1022 16:11:01.959591 27537 net.cpp:228] res4e_branch2b does not need backward computation.
I1022 16:11:01.959595 27537 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I1022 16:11:01.959599 27537 net.cpp:228] scale4e_branch2a does not need backward computation.
I1022 16:11:01.959602 27537 net.cpp:228] bn4e_branch2a does not need backward computation.
I1022 16:11:01.959605 27537 net.cpp:228] res4e_branch2a does not need backward computation.
I1022 16:11:01.959609 27537 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I1022 16:11:01.959612 27537 net.cpp:228] res4d_relu does not need backward computation.
I1022 16:11:01.959615 27537 net.cpp:228] res4d does not need backward computation.
I1022 16:11:01.959619 27537 net.cpp:228] scale4d_branch2c does not need backward computation.
I1022 16:11:01.959623 27537 net.cpp:228] bn4d_branch2c does not need backward computation.
I1022 16:11:01.959626 27537 net.cpp:228] res4d_branch2c does not need backward computation.
I1022 16:11:01.959630 27537 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I1022 16:11:01.959633 27537 net.cpp:228] scale4d_branch2b does not need backward computation.
I1022 16:11:01.959636 27537 net.cpp:228] bn4d_branch2b does not need backward computation.
I1022 16:11:01.959640 27537 net.cpp:228] res4d_branch2b does not need backward computation.
I1022 16:11:01.959645 27537 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I1022 16:11:01.959647 27537 net.cpp:228] scale4d_branch2a does not need backward computation.
I1022 16:11:01.959651 27537 net.cpp:228] bn4d_branch2a does not need backward computation.
I1022 16:11:01.959655 27537 net.cpp:228] res4d_branch2a does not need backward computation.
I1022 16:11:01.959658 27537 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I1022 16:11:01.959661 27537 net.cpp:228] res4c_relu does not need backward computation.
I1022 16:11:01.959666 27537 net.cpp:228] res4c does not need backward computation.
I1022 16:11:01.959669 27537 net.cpp:228] scale4c_branch2c does not need backward computation.
I1022 16:11:01.959672 27537 net.cpp:228] bn4c_branch2c does not need backward computation.
I1022 16:11:01.959676 27537 net.cpp:228] res4c_branch2c does not need backward computation.
I1022 16:11:01.959679 27537 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I1022 16:11:01.959682 27537 net.cpp:228] scale4c_branch2b does not need backward computation.
I1022 16:11:01.959686 27537 net.cpp:228] bn4c_branch2b does not need backward computation.
I1022 16:11:01.959689 27537 net.cpp:228] res4c_branch2b does not need backward computation.
I1022 16:11:01.959693 27537 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I1022 16:11:01.959697 27537 net.cpp:228] scale4c_branch2a does not need backward computation.
I1022 16:11:01.959699 27537 net.cpp:228] bn4c_branch2a does not need backward computation.
I1022 16:11:01.959702 27537 net.cpp:228] res4c_branch2a does not need backward computation.
I1022 16:11:01.959707 27537 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I1022 16:11:01.959710 27537 net.cpp:228] res4b_relu does not need backward computation.
I1022 16:11:01.959713 27537 net.cpp:228] res4b does not need backward computation.
I1022 16:11:01.959717 27537 net.cpp:228] scale4b_branch2c does not need backward computation.
I1022 16:11:01.959722 27537 net.cpp:228] bn4b_branch2c does not need backward computation.
I1022 16:11:01.959725 27537 net.cpp:228] res4b_branch2c does not need backward computation.
I1022 16:11:01.959728 27537 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I1022 16:11:01.959731 27537 net.cpp:228] scale4b_branch2b does not need backward computation.
I1022 16:11:01.959734 27537 net.cpp:228] bn4b_branch2b does not need backward computation.
I1022 16:11:01.959738 27537 net.cpp:228] res4b_branch2b does not need backward computation.
I1022 16:11:01.959741 27537 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I1022 16:11:01.959745 27537 net.cpp:228] scale4b_branch2a does not need backward computation.
I1022 16:11:01.959748 27537 net.cpp:228] bn4b_branch2a does not need backward computation.
I1022 16:11:01.959751 27537 net.cpp:228] res4b_branch2a does not need backward computation.
I1022 16:11:01.959755 27537 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I1022 16:11:01.959758 27537 net.cpp:228] res4a_relu does not need backward computation.
I1022 16:11:01.959764 27537 net.cpp:228] res4a does not need backward computation.
I1022 16:11:01.959767 27537 net.cpp:228] scale4a_branch2c does not need backward computation.
I1022 16:11:01.959770 27537 net.cpp:228] bn4a_branch2c does not need backward computation.
I1022 16:11:01.959774 27537 net.cpp:228] res4a_branch2c does not need backward computation.
I1022 16:11:01.959777 27537 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I1022 16:11:01.959780 27537 net.cpp:228] scale4a_branch2b does not need backward computation.
I1022 16:11:01.959784 27537 net.cpp:228] bn4a_branch2b does not need backward computation.
I1022 16:11:01.959786 27537 net.cpp:228] res4a_branch2b does not need backward computation.
I1022 16:11:01.959790 27537 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I1022 16:11:01.959794 27537 net.cpp:228] scale4a_branch2a does not need backward computation.
I1022 16:11:01.959797 27537 net.cpp:228] bn4a_branch2a does not need backward computation.
I1022 16:11:01.959800 27537 net.cpp:228] res4a_branch2a does not need backward computation.
I1022 16:11:01.959805 27537 net.cpp:228] scale4a_branch1 does not need backward computation.
I1022 16:11:01.959808 27537 net.cpp:228] bn4a_branch1 does not need backward computation.
I1022 16:11:01.959811 27537 net.cpp:228] res4a_branch1 does not need backward computation.
I1022 16:11:01.959815 27537 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I1022 16:11:01.959820 27537 net.cpp:228] res3d_relu does not need backward computation.
I1022 16:11:01.959822 27537 net.cpp:228] res3d does not need backward computation.
I1022 16:11:01.959828 27537 net.cpp:228] scale3d_branch2c does not need backward computation.
I1022 16:11:01.959833 27537 net.cpp:228] bn3d_branch2c does not need backward computation.
I1022 16:11:01.959837 27537 net.cpp:228] res3d_branch2c does not need backward computation.
I1022 16:11:01.959841 27537 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I1022 16:11:01.959844 27537 net.cpp:228] scale3d_branch2b does not need backward computation.
I1022 16:11:01.959847 27537 net.cpp:228] bn3d_branch2b does not need backward computation.
I1022 16:11:01.959851 27537 net.cpp:228] res3d_branch2b does not need backward computation.
I1022 16:11:01.959854 27537 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I1022 16:11:01.959857 27537 net.cpp:228] scale3d_branch2a does not need backward computation.
I1022 16:11:01.959861 27537 net.cpp:228] bn3d_branch2a does not need backward computation.
I1022 16:11:01.959864 27537 net.cpp:228] res3d_branch2a does not need backward computation.
I1022 16:11:01.959867 27537 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I1022 16:11:01.959872 27537 net.cpp:228] res3c_relu does not need backward computation.
I1022 16:11:01.959877 27537 net.cpp:228] res3c does not need backward computation.
I1022 16:11:01.959880 27537 net.cpp:228] scale3c_branch2c does not need backward computation.
I1022 16:11:01.959884 27537 net.cpp:228] bn3c_branch2c does not need backward computation.
I1022 16:11:01.959887 27537 net.cpp:228] res3c_branch2c does not need backward computation.
I1022 16:11:01.959890 27537 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I1022 16:11:01.959894 27537 net.cpp:228] scale3c_branch2b does not need backward computation.
I1022 16:11:01.959897 27537 net.cpp:228] bn3c_branch2b does not need backward computation.
I1022 16:11:01.959900 27537 net.cpp:228] res3c_branch2b does not need backward computation.
I1022 16:11:01.959903 27537 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I1022 16:11:01.959908 27537 net.cpp:228] scale3c_branch2a does not need backward computation.
I1022 16:11:01.959910 27537 net.cpp:228] bn3c_branch2a does not need backward computation.
I1022 16:11:01.959913 27537 net.cpp:228] res3c_branch2a does not need backward computation.
I1022 16:11:01.959916 27537 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I1022 16:11:01.959920 27537 net.cpp:228] res3b_relu does not need backward computation.
I1022 16:11:01.959923 27537 net.cpp:228] res3b does not need backward computation.
I1022 16:11:01.959928 27537 net.cpp:228] scale3b_branch2c does not need backward computation.
I1022 16:11:01.959931 27537 net.cpp:228] bn3b_branch2c does not need backward computation.
I1022 16:11:01.959935 27537 net.cpp:228] res3b_branch2c does not need backward computation.
I1022 16:11:01.959939 27537 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I1022 16:11:01.959942 27537 net.cpp:228] scale3b_branch2b does not need backward computation.
I1022 16:11:01.959945 27537 net.cpp:228] bn3b_branch2b does not need backward computation.
I1022 16:11:01.959949 27537 net.cpp:228] res3b_branch2b does not need backward computation.
I1022 16:11:01.959952 27537 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I1022 16:11:01.959956 27537 net.cpp:228] scale3b_branch2a does not need backward computation.
I1022 16:11:01.959959 27537 net.cpp:228] bn3b_branch2a does not need backward computation.
I1022 16:11:01.959964 27537 net.cpp:228] res3b_branch2a does not need backward computation.
I1022 16:11:01.959967 27537 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I1022 16:11:01.959970 27537 net.cpp:228] res3a_relu does not need backward computation.
I1022 16:11:01.959975 27537 net.cpp:228] res3a does not need backward computation.
I1022 16:11:01.959978 27537 net.cpp:228] scale3a_branch2c does not need backward computation.
I1022 16:11:01.959982 27537 net.cpp:228] bn3a_branch2c does not need backward computation.
I1022 16:11:01.959986 27537 net.cpp:228] res3a_branch2c does not need backward computation.
I1022 16:11:01.959990 27537 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I1022 16:11:01.959993 27537 net.cpp:228] scale3a_branch2b does not need backward computation.
I1022 16:11:01.959996 27537 net.cpp:228] bn3a_branch2b does not need backward computation.
I1022 16:11:01.960000 27537 net.cpp:228] res3a_branch2b does not need backward computation.
I1022 16:11:01.960002 27537 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I1022 16:11:01.960006 27537 net.cpp:228] scale3a_branch2a does not need backward computation.
I1022 16:11:01.960009 27537 net.cpp:228] bn3a_branch2a does not need backward computation.
I1022 16:11:01.960012 27537 net.cpp:228] res3a_branch2a does not need backward computation.
I1022 16:11:01.960016 27537 net.cpp:228] scale3a_branch1 does not need backward computation.
I1022 16:11:01.960021 27537 net.cpp:228] bn3a_branch1 does not need backward computation.
I1022 16:11:01.960024 27537 net.cpp:228] res3a_branch1 does not need backward computation.
I1022 16:11:01.960028 27537 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I1022 16:11:01.960031 27537 net.cpp:228] res2c_relu does not need backward computation.
I1022 16:11:01.960036 27537 net.cpp:228] res2c does not need backward computation.
I1022 16:11:01.960039 27537 net.cpp:228] scale2c_branch2c does not need backward computation.
I1022 16:11:01.960042 27537 net.cpp:228] bn2c_branch2c does not need backward computation.
I1022 16:11:01.960047 27537 net.cpp:228] res2c_branch2c does not need backward computation.
I1022 16:11:01.960049 27537 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I1022 16:11:01.960053 27537 net.cpp:228] scale2c_branch2b does not need backward computation.
I1022 16:11:01.960057 27537 net.cpp:228] bn2c_branch2b does not need backward computation.
I1022 16:11:01.960059 27537 net.cpp:228] res2c_branch2b does not need backward computation.
I1022 16:11:01.960063 27537 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I1022 16:11:01.960067 27537 net.cpp:228] scale2c_branch2a does not need backward computation.
I1022 16:11:01.960069 27537 net.cpp:228] bn2c_branch2a does not need backward computation.
I1022 16:11:01.960072 27537 net.cpp:228] res2c_branch2a does not need backward computation.
I1022 16:11:01.960077 27537 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I1022 16:11:01.960080 27537 net.cpp:228] res2b_relu does not need backward computation.
I1022 16:11:01.960084 27537 net.cpp:228] res2b does not need backward computation.
I1022 16:11:01.960088 27537 net.cpp:228] scale2b_branch2c does not need backward computation.
I1022 16:11:01.960091 27537 net.cpp:228] bn2b_branch2c does not need backward computation.
I1022 16:11:01.960094 27537 net.cpp:228] res2b_branch2c does not need backward computation.
I1022 16:11:01.960098 27537 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I1022 16:11:01.960101 27537 net.cpp:228] scale2b_branch2b does not need backward computation.
I1022 16:11:01.960104 27537 net.cpp:228] bn2b_branch2b does not need backward computation.
I1022 16:11:01.960108 27537 net.cpp:228] res2b_branch2b does not need backward computation.
I1022 16:11:01.960110 27537 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I1022 16:11:01.960114 27537 net.cpp:228] scale2b_branch2a does not need backward computation.
I1022 16:11:01.960119 27537 net.cpp:228] bn2b_branch2a does not need backward computation.
I1022 16:11:01.960121 27537 net.cpp:228] res2b_branch2a does not need backward computation.
I1022 16:11:01.960124 27537 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I1022 16:11:01.960127 27537 net.cpp:228] res2a_relu does not need backward computation.
I1022 16:11:01.960130 27537 net.cpp:228] res2a does not need backward computation.
I1022 16:11:01.960135 27537 net.cpp:228] scale2a_branch2c does not need backward computation.
I1022 16:11:01.960139 27537 net.cpp:228] bn2a_branch2c does not need backward computation.
I1022 16:11:01.960141 27537 net.cpp:228] res2a_branch2c does not need backward computation.
I1022 16:11:01.960145 27537 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I1022 16:11:01.960148 27537 net.cpp:228] scale2a_branch2b does not need backward computation.
I1022 16:11:01.960152 27537 net.cpp:228] bn2a_branch2b does not need backward computation.
I1022 16:11:01.960155 27537 net.cpp:228] res2a_branch2b does not need backward computation.
I1022 16:11:01.960158 27537 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I1022 16:11:01.960161 27537 net.cpp:228] scale2a_branch2a does not need backward computation.
I1022 16:11:01.960165 27537 net.cpp:228] bn2a_branch2a does not need backward computation.
I1022 16:11:01.960167 27537 net.cpp:228] res2a_branch2a does not need backward computation.
I1022 16:11:01.960171 27537 net.cpp:228] scale2a_branch1 does not need backward computation.
I1022 16:11:01.960175 27537 net.cpp:228] bn2a_branch1 does not need backward computation.
I1022 16:11:01.960178 27537 net.cpp:228] res2a_branch1 does not need backward computation.
I1022 16:11:01.960182 27537 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I1022 16:11:01.960188 27537 net.cpp:228] pool1 does not need backward computation.
I1022 16:11:01.960192 27537 net.cpp:228] conv1_relu does not need backward computation.
I1022 16:11:01.960196 27537 net.cpp:228] scale_conv1 does not need backward computation.
I1022 16:11:01.960199 27537 net.cpp:228] bn_conv1 does not need backward computation.
I1022 16:11:01.960202 27537 net.cpp:228] conv1 does not need backward computation.
I1022 16:11:01.960206 27537 net.cpp:228] input does not need backward computation.
I1022 16:11:01.960208 27537 net.cpp:270] This network produces output bbox_pred_p2
I1022 16:11:01.960212 27537 net.cpp:270] This network produces output bbox_pred_p3
I1022 16:11:01.960217 27537 net.cpp:270] This network produces output cls_prob_p2
I1022 16:11:01.960220 27537 net.cpp:270] This network produces output cls_prob_p3
I1022 16:11:01.960400 27537 net.cpp:283] Network initialization done.
I1022 16:11:02.059912 27537 net.cpp:771] Ignoring source layer input-data
I1022 16:11:02.059937 27537 net.cpp:771] Ignoring source layer data_input-data_0_split
I1022 16:11:02.059940 27537 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I1022 16:11:02.059943 27537 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I1022 16:11:02.059947 27537 net.cpp:774] Copying source layer conv1
I1022 16:11:02.059967 27537 net.cpp:774] Copying source layer bn_conv1
I1022 16:11:02.059974 27537 net.cpp:774] Copying source layer scale_conv1
I1022 16:11:02.059979 27537 net.cpp:774] Copying source layer conv1_relu
I1022 16:11:02.059983 27537 net.cpp:774] Copying source layer pool1
I1022 16:11:02.059986 27537 net.cpp:774] Copying source layer pool1_pool1_0_split
I1022 16:11:02.059988 27537 net.cpp:774] Copying source layer res2a_branch1
I1022 16:11:02.060014 27537 net.cpp:774] Copying source layer bn2a_branch1
I1022 16:11:02.060022 27537 net.cpp:774] Copying source layer scale2a_branch1
I1022 16:11:02.060029 27537 net.cpp:774] Copying source layer res2a_branch2a
I1022 16:11:02.060039 27537 net.cpp:774] Copying source layer bn2a_branch2a
I1022 16:11:02.060045 27537 net.cpp:774] Copying source layer scale2a_branch2a
I1022 16:11:02.060050 27537 net.cpp:774] Copying source layer res2a_branch2a_relu
I1022 16:11:02.060053 27537 net.cpp:774] Copying source layer res2a_branch2b
I1022 16:11:02.060096 27537 net.cpp:774] Copying source layer bn2a_branch2b
I1022 16:11:02.060104 27537 net.cpp:774] Copying source layer scale2a_branch2b
I1022 16:11:02.060109 27537 net.cpp:774] Copying source layer res2a_branch2b_relu
I1022 16:11:02.060113 27537 net.cpp:774] Copying source layer res2a_branch2c
I1022 16:11:02.060138 27537 net.cpp:774] Copying source layer bn2a_branch2c
I1022 16:11:02.060147 27537 net.cpp:774] Copying source layer scale2a_branch2c
I1022 16:11:02.060153 27537 net.cpp:774] Copying source layer res2a
I1022 16:11:02.060158 27537 net.cpp:774] Copying source layer res2a_relu
I1022 16:11:02.060161 27537 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I1022 16:11:02.060163 27537 net.cpp:774] Copying source layer res2b_branch2a
I1022 16:11:02.060189 27537 net.cpp:774] Copying source layer bn2b_branch2a
I1022 16:11:02.060197 27537 net.cpp:774] Copying source layer scale2b_branch2a
I1022 16:11:02.060201 27537 net.cpp:774] Copying source layer res2b_branch2a_relu
I1022 16:11:02.060204 27537 net.cpp:774] Copying source layer res2b_branch2b
I1022 16:11:02.060250 27537 net.cpp:774] Copying source layer bn2b_branch2b
I1022 16:11:02.060257 27537 net.cpp:774] Copying source layer scale2b_branch2b
I1022 16:11:02.060261 27537 net.cpp:774] Copying source layer res2b_branch2b_relu
I1022 16:11:02.060264 27537 net.cpp:774] Copying source layer res2b_branch2c
I1022 16:11:02.060289 27537 net.cpp:774] Copying source layer bn2b_branch2c
I1022 16:11:02.060298 27537 net.cpp:774] Copying source layer scale2b_branch2c
I1022 16:11:02.060303 27537 net.cpp:774] Copying source layer res2b
I1022 16:11:02.060307 27537 net.cpp:774] Copying source layer res2b_relu
I1022 16:11:02.060310 27537 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I1022 16:11:02.060314 27537 net.cpp:774] Copying source layer res2c_branch2a
I1022 16:11:02.060339 27537 net.cpp:774] Copying source layer bn2c_branch2a
I1022 16:11:02.060346 27537 net.cpp:774] Copying source layer scale2c_branch2a
I1022 16:11:02.060351 27537 net.cpp:774] Copying source layer res2c_branch2a_relu
I1022 16:11:02.060354 27537 net.cpp:774] Copying source layer res2c_branch2b
I1022 16:11:02.060400 27537 net.cpp:774] Copying source layer bn2c_branch2b
I1022 16:11:02.060408 27537 net.cpp:774] Copying source layer scale2c_branch2b
I1022 16:11:02.060413 27537 net.cpp:774] Copying source layer res2c_branch2b_relu
I1022 16:11:02.060418 27537 net.cpp:774] Copying source layer res2c_branch2c
I1022 16:11:02.060443 27537 net.cpp:774] Copying source layer bn2c_branch2c
I1022 16:11:02.060451 27537 net.cpp:774] Copying source layer scale2c_branch2c
I1022 16:11:02.060456 27537 net.cpp:774] Copying source layer res2c
I1022 16:11:02.060461 27537 net.cpp:774] Copying source layer res2c_relu
I1022 16:11:02.060464 27537 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I1022 16:11:02.060467 27537 net.cpp:774] Copying source layer res3a_branch1
I1022 16:11:02.060601 27537 net.cpp:774] Copying source layer bn3a_branch1
I1022 16:11:02.060631 27537 net.cpp:774] Copying source layer scale3a_branch1
I1022 16:11:02.060636 27537 net.cpp:774] Copying source layer res3a_branch2a
I1022 16:11:02.060691 27537 net.cpp:774] Copying source layer bn3a_branch2a
I1022 16:11:02.060699 27537 net.cpp:774] Copying source layer scale3a_branch2a
I1022 16:11:02.060705 27537 net.cpp:774] Copying source layer res3a_branch2a_relu
I1022 16:11:02.060709 27537 net.cpp:774] Copying source layer res3a_branch2b
I1022 16:11:02.060863 27537 net.cpp:774] Copying source layer bn3a_branch2b
I1022 16:11:02.060870 27537 net.cpp:774] Copying source layer scale3a_branch2b
I1022 16:11:02.060876 27537 net.cpp:774] Copying source layer res3a_branch2b_relu
I1022 16:11:02.060881 27537 net.cpp:774] Copying source layer res3a_branch2c
I1022 16:11:02.060953 27537 net.cpp:774] Copying source layer bn3a_branch2c
I1022 16:11:02.060962 27537 net.cpp:774] Copying source layer scale3a_branch2c
I1022 16:11:02.060971 27537 net.cpp:774] Copying source layer res3a
I1022 16:11:02.060976 27537 net.cpp:774] Copying source layer res3a_relu
I1022 16:11:02.060979 27537 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I1022 16:11:02.060982 27537 net.cpp:774] Copying source layer res3b_branch2a
I1022 16:11:02.061058 27537 net.cpp:774] Copying source layer bn3b_branch2a
I1022 16:11:02.061066 27537 net.cpp:774] Copying source layer scale3b_branch2a
I1022 16:11:02.061072 27537 net.cpp:774] Copying source layer res3b_branch2a_relu
I1022 16:11:02.061075 27537 net.cpp:774] Copying source layer res3b_branch2b
I1022 16:11:02.061223 27537 net.cpp:774] Copying source layer bn3b_branch2b
I1022 16:11:02.061231 27537 net.cpp:774] Copying source layer scale3b_branch2b
I1022 16:11:02.061236 27537 net.cpp:774] Copying source layer res3b_branch2b_relu
I1022 16:11:02.061239 27537 net.cpp:774] Copying source layer res3b_branch2c
I1022 16:11:02.061312 27537 net.cpp:774] Copying source layer bn3b_branch2c
I1022 16:11:02.061321 27537 net.cpp:774] Copying source layer scale3b_branch2c
I1022 16:11:02.061328 27537 net.cpp:774] Copying source layer res3b
I1022 16:11:02.061331 27537 net.cpp:774] Copying source layer res3b_relu
I1022 16:11:02.061336 27537 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I1022 16:11:02.061338 27537 net.cpp:774] Copying source layer res3c_branch2a
I1022 16:11:02.061410 27537 net.cpp:774] Copying source layer bn3c_branch2a
I1022 16:11:02.061419 27537 net.cpp:774] Copying source layer scale3c_branch2a
I1022 16:11:02.061424 27537 net.cpp:774] Copying source layer res3c_branch2a_relu
I1022 16:11:02.061426 27537 net.cpp:774] Copying source layer res3c_branch2b
I1022 16:11:02.061573 27537 net.cpp:774] Copying source layer bn3c_branch2b
I1022 16:11:02.061580 27537 net.cpp:774] Copying source layer scale3c_branch2b
I1022 16:11:02.061585 27537 net.cpp:774] Copying source layer res3c_branch2b_relu
I1022 16:11:02.061589 27537 net.cpp:774] Copying source layer res3c_branch2c
I1022 16:11:02.061661 27537 net.cpp:774] Copying source layer bn3c_branch2c
I1022 16:11:02.061671 27537 net.cpp:774] Copying source layer scale3c_branch2c
I1022 16:11:02.061677 27537 net.cpp:774] Copying source layer res3c
I1022 16:11:02.061681 27537 net.cpp:774] Copying source layer res3c_relu
I1022 16:11:02.061683 27537 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I1022 16:11:02.061686 27537 net.cpp:774] Copying source layer res3d_branch2a
I1022 16:11:02.061754 27537 net.cpp:774] Copying source layer bn3d_branch2a
I1022 16:11:02.061761 27537 net.cpp:774] Copying source layer scale3d_branch2a
I1022 16:11:02.061766 27537 net.cpp:774] Copying source layer res3d_branch2a_relu
I1022 16:11:02.061769 27537 net.cpp:774] Copying source layer res3d_branch2b
I1022 16:11:02.061918 27537 net.cpp:774] Copying source layer bn3d_branch2b
I1022 16:11:02.061924 27537 net.cpp:774] Copying source layer scale3d_branch2b
I1022 16:11:02.061930 27537 net.cpp:774] Copying source layer res3d_branch2b_relu
I1022 16:11:02.061933 27537 net.cpp:774] Copying source layer res3d_branch2c
I1022 16:11:02.062005 27537 net.cpp:774] Copying source layer bn3d_branch2c
I1022 16:11:02.062013 27537 net.cpp:774] Copying source layer scale3d_branch2c
I1022 16:11:02.062019 27537 net.cpp:774] Copying source layer res3d
I1022 16:11:02.062022 27537 net.cpp:774] Copying source layer res3d_relu
I1022 16:11:02.062026 27537 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I1022 16:11:02.062028 27537 net.cpp:774] Copying source layer res4a_branch1
I1022 16:11:02.062523 27537 net.cpp:774] Copying source layer bn4a_branch1
I1022 16:11:02.062535 27537 net.cpp:774] Copying source layer scale4a_branch1
I1022 16:11:02.062541 27537 net.cpp:774] Copying source layer res4a_branch2a
I1022 16:11:02.062669 27537 net.cpp:774] Copying source layer bn4a_branch2a
I1022 16:11:02.062678 27537 net.cpp:774] Copying source layer scale4a_branch2a
I1022 16:11:02.062683 27537 net.cpp:774] Copying source layer res4a_branch2a_relu
I1022 16:11:02.062687 27537 net.cpp:774] Copying source layer res4a_branch2b
I1022 16:11:02.063244 27537 net.cpp:774] Copying source layer bn4a_branch2b
I1022 16:11:02.063252 27537 net.cpp:774] Copying source layer scale4a_branch2b
I1022 16:11:02.063257 27537 net.cpp:774] Copying source layer res4a_branch2b_relu
I1022 16:11:02.063261 27537 net.cpp:774] Copying source layer res4a_branch2c
I1022 16:11:02.063514 27537 net.cpp:774] Copying source layer bn4a_branch2c
I1022 16:11:02.063524 27537 net.cpp:774] Copying source layer scale4a_branch2c
I1022 16:11:02.063530 27537 net.cpp:774] Copying source layer res4a
I1022 16:11:02.063536 27537 net.cpp:774] Copying source layer res4a_relu
I1022 16:11:02.063539 27537 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I1022 16:11:02.063542 27537 net.cpp:774] Copying source layer res4b_branch2a
I1022 16:11:02.063792 27537 net.cpp:774] Copying source layer bn4b_branch2a
I1022 16:11:02.063802 27537 net.cpp:774] Copying source layer scale4b_branch2a
I1022 16:11:02.063807 27537 net.cpp:774] Copying source layer res4b_branch2a_relu
I1022 16:11:02.063810 27537 net.cpp:774] Copying source layer res4b_branch2b
I1022 16:11:02.064365 27537 net.cpp:774] Copying source layer bn4b_branch2b
I1022 16:11:02.064374 27537 net.cpp:774] Copying source layer scale4b_branch2b
I1022 16:11:02.064379 27537 net.cpp:774] Copying source layer res4b_branch2b_relu
I1022 16:11:02.064383 27537 net.cpp:774] Copying source layer res4b_branch2c
I1022 16:11:02.064687 27537 net.cpp:774] Copying source layer bn4b_branch2c
I1022 16:11:02.064699 27537 net.cpp:774] Copying source layer scale4b_branch2c
I1022 16:11:02.064705 27537 net.cpp:774] Copying source layer res4b
I1022 16:11:02.064708 27537 net.cpp:774] Copying source layer res4b_relu
I1022 16:11:02.064712 27537 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I1022 16:11:02.064715 27537 net.cpp:774] Copying source layer res4c_branch2a
I1022 16:11:02.064967 27537 net.cpp:774] Copying source layer bn4c_branch2a
I1022 16:11:02.064976 27537 net.cpp:774] Copying source layer scale4c_branch2a
I1022 16:11:02.064982 27537 net.cpp:774] Copying source layer res4c_branch2a_relu
I1022 16:11:02.064986 27537 net.cpp:774] Copying source layer res4c_branch2b
I1022 16:11:02.065551 27537 net.cpp:774] Copying source layer bn4c_branch2b
I1022 16:11:02.065560 27537 net.cpp:774] Copying source layer scale4c_branch2b
I1022 16:11:02.065565 27537 net.cpp:774] Copying source layer res4c_branch2b_relu
I1022 16:11:02.065569 27537 net.cpp:774] Copying source layer res4c_branch2c
I1022 16:11:02.065822 27537 net.cpp:774] Copying source layer bn4c_branch2c
I1022 16:11:02.065834 27537 net.cpp:774] Copying source layer scale4c_branch2c
I1022 16:11:02.065841 27537 net.cpp:774] Copying source layer res4c
I1022 16:11:02.065846 27537 net.cpp:774] Copying source layer res4c_relu
I1022 16:11:02.065850 27537 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I1022 16:11:02.065853 27537 net.cpp:774] Copying source layer res4d_branch2a
I1022 16:11:02.066107 27537 net.cpp:774] Copying source layer bn4d_branch2a
I1022 16:11:02.066117 27537 net.cpp:774] Copying source layer scale4d_branch2a
I1022 16:11:02.066121 27537 net.cpp:774] Copying source layer res4d_branch2a_relu
I1022 16:11:02.066125 27537 net.cpp:774] Copying source layer res4d_branch2b
I1022 16:11:02.066681 27537 net.cpp:774] Copying source layer bn4d_branch2b
I1022 16:11:02.066690 27537 net.cpp:774] Copying source layer scale4d_branch2b
I1022 16:11:02.066696 27537 net.cpp:774] Copying source layer res4d_branch2b_relu
I1022 16:11:02.066699 27537 net.cpp:774] Copying source layer res4d_branch2c
I1022 16:11:02.066953 27537 net.cpp:774] Copying source layer bn4d_branch2c
I1022 16:11:02.066967 27537 net.cpp:774] Copying source layer scale4d_branch2c
I1022 16:11:02.066977 27537 net.cpp:774] Copying source layer res4d
I1022 16:11:02.066980 27537 net.cpp:774] Copying source layer res4d_relu
I1022 16:11:02.066984 27537 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I1022 16:11:02.066987 27537 net.cpp:774] Copying source layer res4e_branch2a
I1022 16:11:02.067239 27537 net.cpp:774] Copying source layer bn4e_branch2a
I1022 16:11:02.067246 27537 net.cpp:774] Copying source layer scale4e_branch2a
I1022 16:11:02.067252 27537 net.cpp:774] Copying source layer res4e_branch2a_relu
I1022 16:11:02.067256 27537 net.cpp:774] Copying source layer res4e_branch2b
I1022 16:11:02.067817 27537 net.cpp:774] Copying source layer bn4e_branch2b
I1022 16:11:02.067826 27537 net.cpp:774] Copying source layer scale4e_branch2b
I1022 16:11:02.067832 27537 net.cpp:774] Copying source layer res4e_branch2b_relu
I1022 16:11:02.067836 27537 net.cpp:774] Copying source layer res4e_branch2c
I1022 16:11:02.068089 27537 net.cpp:774] Copying source layer bn4e_branch2c
I1022 16:11:02.068099 27537 net.cpp:774] Copying source layer scale4e_branch2c
I1022 16:11:02.068107 27537 net.cpp:774] Copying source layer res4e
I1022 16:11:02.068112 27537 net.cpp:774] Copying source layer res4e_relu
I1022 16:11:02.068116 27537 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I1022 16:11:02.068120 27537 net.cpp:774] Copying source layer res4f_branch2a
I1022 16:11:02.068369 27537 net.cpp:774] Copying source layer bn4f_branch2a
I1022 16:11:02.068377 27537 net.cpp:774] Copying source layer scale4f_branch2a
I1022 16:11:02.068383 27537 net.cpp:774] Copying source layer res4f_branch2a_relu
I1022 16:11:02.068387 27537 net.cpp:774] Copying source layer res4f_branch2b
I1022 16:11:02.068985 27537 net.cpp:774] Copying source layer bn4f_branch2b
I1022 16:11:02.068995 27537 net.cpp:774] Copying source layer scale4f_branch2b
I1022 16:11:02.069001 27537 net.cpp:774] Copying source layer res4f_branch2b_relu
I1022 16:11:02.069005 27537 net.cpp:774] Copying source layer res4f_branch2c
I1022 16:11:02.069255 27537 net.cpp:774] Copying source layer bn4f_branch2c
I1022 16:11:02.069268 27537 net.cpp:774] Copying source layer scale4f_branch2c
I1022 16:11:02.069278 27537 net.cpp:774] Copying source layer res4f
I1022 16:11:02.069283 27537 net.cpp:774] Copying source layer res4f_relu
I1022 16:11:02.069288 27537 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I1022 16:11:02.069293 27537 net.cpp:774] Copying source layer res5a_branch1
I1022 16:11:02.071204 27537 net.cpp:774] Copying source layer bn5a_branch1
I1022 16:11:02.071221 27537 net.cpp:774] Copying source layer scale5a_branch1
I1022 16:11:02.071231 27537 net.cpp:774] Copying source layer res5a_branch2a
I1022 16:11:02.071713 27537 net.cpp:774] Copying source layer bn5a_branch2a
I1022 16:11:02.071723 27537 net.cpp:774] Copying source layer scale5a_branch2a
I1022 16:11:02.071729 27537 net.cpp:774] Copying source layer res5a_branch2a_relu
I1022 16:11:02.071733 27537 net.cpp:774] Copying source layer res5a_branch2b
I1022 16:11:02.073956 27537 net.cpp:774] Copying source layer bn5a_branch2b
I1022 16:11:02.073969 27537 net.cpp:774] Copying source layer scale5a_branch2b
I1022 16:11:02.073976 27537 net.cpp:774] Copying source layer res5a_branch2b_relu
I1022 16:11:02.073978 27537 net.cpp:774] Copying source layer res5a_branch2c
I1022 16:11:02.074944 27537 net.cpp:774] Copying source layer bn5a_branch2c
I1022 16:11:02.074959 27537 net.cpp:774] Copying source layer scale5a_branch2c
I1022 16:11:02.074970 27537 net.cpp:774] Copying source layer res5a
I1022 16:11:02.074972 27537 net.cpp:774] Copying source layer res5a_relu
I1022 16:11:02.074977 27537 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I1022 16:11:02.074980 27537 net.cpp:774] Copying source layer res5b_branch2a
I1022 16:11:02.075953 27537 net.cpp:774] Copying source layer bn5b_branch2a
I1022 16:11:02.075963 27537 net.cpp:774] Copying source layer scale5b_branch2a
I1022 16:11:02.075969 27537 net.cpp:774] Copying source layer res5b_branch2a_relu
I1022 16:11:02.075973 27537 net.cpp:774] Copying source layer res5b_branch2b
I1022 16:11:02.078191 27537 net.cpp:774] Copying source layer bn5b_branch2b
I1022 16:11:02.078205 27537 net.cpp:774] Copying source layer scale5b_branch2b
I1022 16:11:02.078212 27537 net.cpp:774] Copying source layer res5b_branch2b_relu
I1022 16:11:02.078217 27537 net.cpp:774] Copying source layer res5b_branch2c
I1022 16:11:02.079181 27537 net.cpp:774] Copying source layer bn5b_branch2c
I1022 16:11:02.079208 27537 net.cpp:774] Copying source layer scale5b_branch2c
I1022 16:11:02.079219 27537 net.cpp:774] Copying source layer res5b
I1022 16:11:02.079222 27537 net.cpp:774] Copying source layer res5b_relu
I1022 16:11:02.079226 27537 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I1022 16:11:02.079231 27537 net.cpp:774] Copying source layer res5c_branch2a
I1022 16:11:02.080191 27537 net.cpp:774] Copying source layer bn5c_branch2a
I1022 16:11:02.080201 27537 net.cpp:774] Copying source layer scale5c_branch2a
I1022 16:11:02.080209 27537 net.cpp:774] Copying source layer res5c_branch2a_relu
I1022 16:11:02.080212 27537 net.cpp:774] Copying source layer res5c_branch2b
I1022 16:11:02.082444 27537 net.cpp:774] Copying source layer bn5c_branch2b
I1022 16:11:02.082458 27537 net.cpp:774] Copying source layer scale5c_branch2b
I1022 16:11:02.082465 27537 net.cpp:774] Copying source layer res5c_branch2b_relu
I1022 16:11:02.082468 27537 net.cpp:774] Copying source layer res5c_branch2c
I1022 16:11:02.083456 27537 net.cpp:774] Copying source layer bn5c_branch2c
I1022 16:11:02.083482 27537 net.cpp:774] Copying source layer scale5c_branch2c
I1022 16:11:02.083492 27537 net.cpp:774] Copying source layer res5c
I1022 16:11:02.083497 27537 net.cpp:774] Copying source layer res5c_relu
I1022 16:11:02.083499 27537 net.cpp:774] Copying source layer upP4
I1022 16:11:02.083539 27537 net.cpp:774] Copying source layer newC4
I1022 16:11:02.084043 27537 net.cpp:774] Copying source layer eltwise_bnc4_bnp4
I1022 16:11:02.084049 27537 net.cpp:774] Copying source layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 16:11:02.084053 27537 net.cpp:774] Copying source layer bnp4_conv
I1022 16:11:02.084136 27537 net.cpp:774] Copying source layer bnp4_bn
I1022 16:11:02.084146 27537 net.cpp:774] Copying source layer bnp4_scale
I1022 16:11:02.084149 27537 net.cpp:774] Copying source layer bnp4_ReLU
I1022 16:11:02.084154 27537 net.cpp:774] Copying source layer bn_eltwise_1_1_conv
I1022 16:11:02.084301 27537 net.cpp:774] Copying source layer bn_eltwise_1_1_bn
I1022 16:11:02.084309 27537 net.cpp:774] Copying source layer bn_eltwise_1_1_scale
I1022 16:11:02.084316 27537 net.cpp:774] Copying source layer bn_eltwise_1_1_ReLU
I1022 16:11:02.084321 27537 net.cpp:774] Copying source layer bn_eltwise_1_2_conv
I1022 16:11:02.084390 27537 net.cpp:774] Copying source layer bn_eltwise_1_2_bn
I1022 16:11:02.084399 27537 net.cpp:774] Copying source layer bn_eltwise_1_2_scale
I1022 16:11:02.084405 27537 net.cpp:774] Copying source layer p3
I1022 16:11:02.084409 27537 net.cpp:774] Copying source layer p3_relu
I1022 16:11:02.084412 27537 net.cpp:774] Copying source layer p3_p3_relu_0_split
I1022 16:11:02.084416 27537 net.cpp:774] Copying source layer newC3
I1022 16:11:02.084717 27537 net.cpp:774] Copying source layer upP3
I1022 16:11:02.084740 27537 net.cpp:774] Copying source layer eltwise_bnc3_bnp3
I1022 16:11:02.084744 27537 net.cpp:774] Copying source layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 16:11:02.084748 27537 net.cpp:774] Copying source layer bnp3_conv
I1022 16:11:02.084818 27537 net.cpp:774] Copying source layer bnp3_bn
I1022 16:11:02.084826 27537 net.cpp:774] Copying source layer bnp3_scale
I1022 16:11:02.084831 27537 net.cpp:774] Copying source layer bnp3_ReLU
I1022 16:11:02.084836 27537 net.cpp:774] Copying source layer bn_eltwise_2_1_conv
I1022 16:11:02.084981 27537 net.cpp:774] Copying source layer bn_eltwise_2_1_bn
I1022 16:11:02.084990 27537 net.cpp:774] Copying source layer bn_eltwise_2_1_scale
I1022 16:11:02.084995 27537 net.cpp:774] Copying source layer bn_eltwise_2_1_ReLU
I1022 16:11:02.085000 27537 net.cpp:774] Copying source layer bn_eltwise_2_2_conv
I1022 16:11:02.085070 27537 net.cpp:774] Copying source layer bn_eltwise_2_2_bn
I1022 16:11:02.085080 27537 net.cpp:774] Copying source layer bn_eltwise_2_2_scale
I1022 16:11:02.085090 27537 net.cpp:774] Copying source layer p2
I1022 16:11:02.085094 27537 net.cpp:774] Copying source layer p2_relu
I1022 16:11:02.085098 27537 net.cpp:774] Copying source layer p2_p2_relu_0_split
I1022 16:11:02.085103 27537 net.cpp:774] Copying source layer rpn_conv/3x3_p2
I1022 16:11:02.087275 27537 net.cpp:774] Copying source layer rpn_relu/3x3_p2
I1022 16:11:02.087285 27537 net.cpp:774] Copying source layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 16:11:02.087291 27537 net.cpp:774] Copying source layer rpn_cls_score_p2
I1022 16:11:02.087311 27537 net.cpp:771] Ignoring source layer rpn_cls_score_p2_rpn_cls_score_p2_0_split
I1022 16:11:02.087314 27537 net.cpp:774] Copying source layer rpn_bbox_pred_p2
I1022 16:11:02.087345 27537 net.cpp:771] Ignoring source layer rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split
I1022 16:11:02.087350 27537 net.cpp:774] Copying source layer rpn_cls_score_reshape_p2
I1022 16:11:02.087354 27537 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split
I1022 16:11:02.087357 27537 net.cpp:774] Copying source layer rpn_cls_prob_p2
I1022 16:11:02.087360 27537 net.cpp:774] Copying source layer rpn_cls_prob_reshape_p2
I1022 16:11:02.087363 27537 net.cpp:774] Copying source layer rpn_conv/3x3_p3
I1022 16:11:02.089557 27537 net.cpp:774] Copying source layer rpn_relu/3x3_p3
I1022 16:11:02.089566 27537 net.cpp:774] Copying source layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 16:11:02.089570 27537 net.cpp:774] Copying source layer rpn_cls_score_p3
I1022 16:11:02.089589 27537 net.cpp:771] Ignoring source layer rpn_cls_score_p3_rpn_cls_score_p3_0_split
I1022 16:11:02.089594 27537 net.cpp:774] Copying source layer rpn_bbox_pred_p3
I1022 16:11:02.089624 27537 net.cpp:771] Ignoring source layer rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split
I1022 16:11:02.089629 27537 net.cpp:774] Copying source layer rpn_cls_score_reshape_p3
I1022 16:11:02.089632 27537 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split
I1022 16:11:02.089637 27537 net.cpp:774] Copying source layer rpn_cls_prob_p3
I1022 16:11:02.089640 27537 net.cpp:774] Copying source layer rpn_cls_prob_reshape_p3
I1022 16:11:02.089643 27537 net.cpp:771] Ignoring source layer rpn-data
I1022 16:11:02.089646 27537 net.cpp:771] Ignoring source layer rpn_loss_cls_p2
I1022 16:11:02.089650 27537 net.cpp:771] Ignoring source layer rpn_loss_bbox_p2
I1022 16:11:02.089653 27537 net.cpp:771] Ignoring source layer rpn_loss_cls_p3
I1022 16:11:02.089658 27537 net.cpp:771] Ignoring source layer rpn_loss_bbox_p3
I1022 16:11:02.089660 27537 net.cpp:774] Copying source layer proposal
I1022 16:11:02.089663 27537 net.cpp:771] Ignoring source layer roi-data
I1022 16:11:02.089666 27537 net.cpp:771] Ignoring source layer rois_p2_roi-data_0_split
I1022 16:11:02.089669 27537 net.cpp:771] Ignoring source layer rois_p3_roi-data_1_split
I1022 16:11:02.089673 27537 net.cpp:771] Ignoring source layer labels_p2_roi-data_2_split
I1022 16:11:02.089675 27537 net.cpp:771] Ignoring source layer labels_p3_roi-data_3_split
I1022 16:11:02.089679 27537 net.cpp:771] Ignoring source layer bbox_targets_p2_roi-data_4_split
I1022 16:11:02.089681 27537 net.cpp:771] Ignoring source layer bbox_targets_p3_roi-data_5_split
I1022 16:11:02.089684 27537 net.cpp:771] Ignoring source layer bbox_inside_weights_p2_roi-data_6_split
I1022 16:11:02.089689 27537 net.cpp:771] Ignoring source layer bbox_inside_weights_p3_roi-data_7_split
I1022 16:11:02.089691 27537 net.cpp:774] Copying source layer conv_new_p2
I1022 16:11:02.090190 27537 net.cpp:774] Copying source layer conv_new_p2_relu
I1022 16:11:02.090196 27537 net.cpp:774] Copying source layer conv_new_p2_conv_new_p2_relu_0_split
I1022 16:11:02.090200 27537 net.cpp:774] Copying source layer rfcn_cls_p2
I1022 16:11:02.090304 27537 net.cpp:774] Copying source layer rfcn_bbox_p2
I1022 16:11:02.090692 27537 net.cpp:774] Copying source layer psroipooled_cls_rois_p2
I1022 16:11:02.090698 27537 net.cpp:774] Copying source layer ave_cls_score_rois_p2
I1022 16:11:02.090701 27537 net.cpp:771] Ignoring source layer cls_score_p2_ave_cls_score_rois_p2_0_split
I1022 16:11:02.090704 27537 net.cpp:774] Copying source layer psroipooled_loc_rois_p2
I1022 16:11:02.090708 27537 net.cpp:774] Copying source layer ave_bbox_pred_rois_p2
I1022 16:11:02.090709 27537 net.cpp:771] Ignoring source layer bbox_pred_p2_ave_bbox_pred_rois_p2_0_split
I1022 16:11:02.090715 27537 net.cpp:771] Ignoring source layer per_roi_loss_cls_p2
I1022 16:11:02.090719 27537 net.cpp:771] Ignoring source layer per_roi_loss_bbox_p2
I1022 16:11:02.090723 27537 net.cpp:771] Ignoring source layer per_roi_loss_p2
I1022 16:11:02.090726 27537 net.cpp:771] Ignoring source layer annotator_detector_p2
I1022 16:11:02.090729 27537 net.cpp:771] Ignoring source layer labels_ohem_p2_annotator_detector_p2_0_split
I1022 16:11:02.090732 27537 net.cpp:774] Copying source layer conv_new_p3
I1022 16:11:02.091244 27537 net.cpp:774] Copying source layer conv_new_p3_relu
I1022 16:11:02.091250 27537 net.cpp:774] Copying source layer conv_new_p3_conv_new_p3_relu_0_split
I1022 16:11:02.091254 27537 net.cpp:774] Copying source layer rfcn_cls_p3
I1022 16:11:02.091356 27537 net.cpp:774] Copying source layer rfcn_bbox_p3
I1022 16:11:02.091740 27537 net.cpp:774] Copying source layer psroipooled_cls_rois_p3
I1022 16:11:02.091745 27537 net.cpp:774] Copying source layer ave_cls_score_rois_p3
I1022 16:11:02.091748 27537 net.cpp:771] Ignoring source layer cls_score_p3_ave_cls_score_rois_p3_0_split
I1022 16:11:02.091751 27537 net.cpp:774] Copying source layer psroipooled_loc_rois_p3
I1022 16:11:02.091754 27537 net.cpp:774] Copying source layer ave_bbox_pred_rois_p3
I1022 16:11:02.091758 27537 net.cpp:771] Ignoring source layer bbox_pred_p3_ave_bbox_pred_rois_p3_0_split
I1022 16:11:02.091761 27537 net.cpp:771] Ignoring source layer per_roi_loss_cls_p3
I1022 16:11:02.091764 27537 net.cpp:771] Ignoring source layer per_roi_loss_bbox_p3
I1022 16:11:02.091768 27537 net.cpp:771] Ignoring source layer per_roi_loss_p3
I1022 16:11:02.091770 27537 net.cpp:771] Ignoring source layer annotator_detector_p3
I1022 16:11:02.091773 27537 net.cpp:771] Ignoring source layer labels_ohem_p3_annotator_detector_p3_0_split
I1022 16:11:02.091776 27537 net.cpp:771] Ignoring source layer loss_p2
I1022 16:11:02.091781 27537 net.cpp:771] Ignoring source layer loss_p3
I1022 16:11:02.091784 27537 net.cpp:771] Ignoring source layer accuarcy_p2
I1022 16:11:02.091787 27537 net.cpp:771] Ignoring source layer accuarcy_p3
I1022 16:11:02.091790 27537 net.cpp:771] Ignoring source layer loss_bbox_p2
I1022 16:11:02.091794 27537 net.cpp:771] Ignoring source layer loss_bbox_p3
I1022 16:11:02.091796 27537 net.cpp:771] Ignoring source layer silence
im_detect: 1/4024 1.196s 0.001s
im_detect: 2/4024 0.718s 0.001s
im_detect: 3/4024 0.553s 0.001s
im_detect: 4/4024 0.472s 0.001s
im_detect: 5/4024 0.427s 0.001s
im_detect: 6/4024 0.393s 0.001s
im_detect: 7/4024 0.374s 0.001s
im_detect: 8/4024 0.354s 0.001s
im_detect: 9/4024 0.339s 0.001s
im_detect: 10/4024 0.328s 0.001s
im_detect: 11/4024 0.319s 0.001s
im_detect: 12/4024 0.314s 0.001s
im_detect: 13/4024 0.307s 0.001s
im_detect: 14/4024 0.301s 0.001s
im_detect: 15/4024 0.296s 0.001s
im_detect: 16/4024 0.291s 0.001s
im_detect: 17/4024 0.286s 0.001s
im_detect: 18/4024 0.283s 0.001s
im_detect: 19/4024 0.280s 0.001s
im_detect: 20/4024 0.277s 0.001s
im_detect: 21/4024 0.274s 0.001s
im_detect: 22/4024 0.272s 0.001s
im_detect: 23/4024 0.269s 0.001s
im_detect: 24/4024 0.267s 0.001s
im_detect: 25/4024 0.265s 0.001s
im_detect: 26/4024 0.264s 0.001s
im_detect: 27/4024 0.263s 0.001s
im_detect: 28/4024 0.261s 0.001s
im_detect: 29/4024 0.259s 0.001s
im_detect: 30/4024 0.258s 0.001s
im_detect: 31/4024 0.257s 0.001s
im_detect: 32/4024 0.256s 0.001s
im_detect: 33/4024 0.254s 0.001s
im_detect: 34/4024 0.253s 0.001s
im_detect: 35/4024 0.253s 0.001s
im_detect: 36/4024 0.252s 0.001s
im_detect: 37/4024 0.252s 0.001s
im_detect: 38/4024 0.251s 0.001s
im_detect: 39/4024 0.250s 0.001s
im_detect: 40/4024 0.249s 0.001s
im_detect: 41/4024 0.248s 0.001s
im_detect: 42/4024 0.246s 0.001s
im_detect: 43/4024 0.246s 0.001s
im_detect: 44/4024 0.245s 0.001s
im_detect: 45/4024 0.245s 0.001s
im_detect: 46/4024 0.244s 0.001s
im_detect: 47/4024 0.244s 0.001s
im_detect: 48/4024 0.243s 0.001s
im_detect: 49/4024 0.243s 0.001s
im_detect: 50/4024 0.242s 0.001s
im_detect: 51/4024 0.243s 0.001s
im_detect: 52/4024 0.242s 0.001s
im_detect: 53/4024 0.242s 0.001s
im_detect: 54/4024 0.242s 0.001s
im_detect: 55/4024 0.243s 0.001s
im_detect: 56/4024 0.242s 0.001s
im_detect: 57/4024 0.242s 0.001s
im_detect: 58/4024 0.241s 0.001s
im_detect: 59/4024 0.240s 0.001s
im_detect: 60/4024 0.240s 0.001s
im_detect: 61/4024 0.240s 0.001s
im_detect: 62/4024 0.240s 0.001s
im_detect: 63/4024 0.239s 0.001s
im_detect: 64/4024 0.239s 0.001s
im_detect: 65/4024 0.239s 0.001s
im_detect: 66/4024 0.239s 0.001s
im_detect: 67/4024 0.239s 0.001s
im_detect: 68/4024 0.238s 0.001s
im_detect: 69/4024 0.238s 0.001s
im_detect: 70/4024 0.238s 0.001s
im_detect: 71/4024 0.237s 0.001s
im_detect: 72/4024 0.237s 0.001s
im_detect: 73/4024 0.236s 0.001s
im_detect: 74/4024 0.236s 0.001s
im_detect: 75/4024 0.235s 0.001s
im_detect: 76/4024 0.235s 0.001s
im_detect: 77/4024 0.234s 0.001s
im_detect: 78/4024 0.234s 0.001s
im_detect: 79/4024 0.233s 0.001s
im_detect: 80/4024 0.233s 0.001s
im_detect: 81/4024 0.232s 0.001s
im_detect: 82/4024 0.232s 0.001s
im_detect: 83/4024 0.232s 0.001s
im_detect: 84/4024 0.232s 0.001s
im_detect: 85/4024 0.232s 0.001s
im_detect: 86/4024 0.231s 0.001s
im_detect: 87/4024 0.231s 0.001s
im_detect: 88/4024 0.231s 0.001s
im_detect: 89/4024 0.231s 0.001s
im_detect: 90/4024 0.231s 0.001s
im_detect: 91/4024 0.231s 0.001s
im_detect: 92/4024 0.231s 0.001s
im_detect: 93/4024 0.231s 0.001s
im_detect: 94/4024 0.231s 0.001s
im_detect: 95/4024 0.230s 0.001s
im_detect: 96/4024 0.230s 0.001s
im_detect: 97/4024 0.230s 0.001s
im_detect: 98/4024 0.230s 0.001s
im_detect: 99/4024 0.230s 0.001s
im_detect: 100/4024 0.229s 0.001s
im_detect: 101/4024 0.229s 0.001s
im_detect: 102/4024 0.229s 0.001s
im_detect: 103/4024 0.229s 0.001s
im_detect: 104/4024 0.229s 0.001s
im_detect: 105/4024 0.229s 0.001s
im_detect: 106/4024 0.229s 0.001s
im_detect: 107/4024 0.229s 0.001s
im_detect: 108/4024 0.229s 0.001s
im_detect: 109/4024 0.229s 0.001s
im_detect: 110/4024 0.229s 0.001s
im_detect: 111/4024 0.229s 0.001s
im_detect: 112/4024 0.229s 0.001s
im_detect: 113/4024 0.229s 0.001s
im_detect: 114/4024 0.230s 0.001s
im_detect: 115/4024 0.229s 0.001s
im_detect: 116/4024 0.229s 0.001s
im_detect: 117/4024 0.229s 0.001s
im_detect: 118/4024 0.229s 0.001s
im_detect: 119/4024 0.229s 0.001s
im_detect: 120/4024 0.229s 0.001s
im_detect: 121/4024 0.229s 0.001s
im_detect: 122/4024 0.229s 0.001s
im_detect: 123/4024 0.229s 0.001s
im_detect: 124/4024 0.229s 0.001s
im_detect: 125/4024 0.229s 0.001s
im_detect: 126/4024 0.229s 0.001s
im_detect: 127/4024 0.229s 0.001s
im_detect: 128/4024 0.229s 0.001s
im_detect: 129/4024 0.229s 0.001s
im_detect: 130/4024 0.229s 0.001s
im_detect: 131/4024 0.229s 0.001s
im_detect: 132/4024 0.229s 0.001s
im_detect: 133/4024 0.229s 0.001s
im_detect: 134/4024 0.229s 0.001s
im_detect: 135/4024 0.229s 0.001s
im_detect: 136/4024 0.229s 0.001s
im_detect: 137/4024 0.229s 0.001s
im_detect: 138/4024 0.229s 0.001s
im_detect: 139/4024 0.229s 0.001s
im_detect: 140/4024 0.229s 0.001s
im_detect: 141/4024 0.229s 0.001s
im_detect: 142/4024 0.229s 0.001s
im_detect: 143/4024 0.229s 0.001s
im_detect: 144/4024 0.229s 0.001s
im_detect: 145/4024 0.229s 0.001s
im_detect: 146/4024 0.229s 0.001s
im_detect: 147/4024 0.229s 0.001s
im_detect: 148/4024 0.229s 0.001s
im_detect: 149/4024 0.229s 0.001s
im_detect: 150/4024 0.229s 0.001s
im_detect: 151/4024 0.229s 0.001s
im_detect: 152/4024 0.229s 0.001s
im_detect: 153/4024 0.229s 0.001s
im_detect: 154/4024 0.229s 0.001s
im_detect: 155/4024 0.229s 0.001s
im_detect: 156/4024 0.229s 0.001s
im_detect: 157/4024 0.230s 0.001s
im_detect: 158/4024 0.230s 0.001s
im_detect: 159/4024 0.229s 0.001s
im_detect: 160/4024 0.229s 0.001s
im_detect: 161/4024 0.230s 0.001s
im_detect: 162/4024 0.230s 0.001s
im_detect: 163/4024 0.230s 0.001s
im_detect: 164/4024 0.230s 0.001s
im_detect: 165/4024 0.230s 0.001s
im_detect: 166/4024 0.230s 0.001s
im_detect: 167/4024 0.230s 0.001s
im_detect: 168/4024 0.230s 0.001s
im_detect: 169/4024 0.230s 0.001s
im_detect: 170/4024 0.230s 0.001s
im_detect: 171/4024 0.230s 0.001s
im_detect: 172/4024 0.230s 0.001s
im_detect: 173/4024 0.230s 0.001s
im_detect: 174/4024 0.230s 0.001s
im_detect: 175/4024 0.230s 0.001s
im_detect: 176/4024 0.230s 0.001s
im_detect: 177/4024 0.230s 0.001s
im_detect: 178/4024 0.230s 0.001s
im_detect: 179/4024 0.230s 0.001s
im_detect: 180/4024 0.230s 0.001s
im_detect: 181/4024 0.230s 0.001s
im_detect: 182/4024 0.230s 0.001s
im_detect: 183/4024 0.230s 0.001s
im_detect: 184/4024 0.230s 0.001s
im_detect: 185/4024 0.230s 0.001s
im_detect: 186/4024 0.230s 0.001s
im_detect: 187/4024 0.230s 0.001s
im_detect: 188/4024 0.230s 0.001s
im_detect: 189/4024 0.230s 0.001s
im_detect: 190/4024 0.230s 0.001s
im_detect: 191/4024 0.230s 0.001s
im_detect: 192/4024 0.230s 0.001s
im_detect: 193/4024 0.230s 0.001s
im_detect: 194/4024 0.230s 0.001s
im_detect: 195/4024 0.230s 0.001s
im_detect: 196/4024 0.230s 0.001s
im_detect: 197/4024 0.230s 0.001s
im_detect: 198/4024 0.230s 0.001s
im_detect: 199/4024 0.230s 0.001s
im_detect: 200/4024 0.230s 0.001s
im_detect: 201/4024 0.230s 0.001s
im_detect: 202/4024 0.230s 0.001s
im_detect: 203/4024 0.230s 0.001s
im_detect: 204/4024 0.230s 0.001s
im_detect: 205/4024 0.230s 0.001s
im_detect: 206/4024 0.230s 0.001s
im_detect: 207/4024 0.230s 0.001s
im_detect: 208/4024 0.230s 0.001s
im_detect: 209/4024 0.230s 0.001s
im_detect: 210/4024 0.230s 0.001s
im_detect: 211/4024 0.230s 0.001s
im_detect: 212/4024 0.230s 0.001s
im_detect: 213/4024 0.230s 0.001s
im_detect: 214/4024 0.230s 0.001s
im_detect: 215/4024 0.230s 0.001s
im_detect: 216/4024 0.230s 0.001s
im_detect: 217/4024 0.231s 0.001s
im_detect: 218/4024 0.231s 0.001s
im_detect: 219/4024 0.231s 0.001s
im_detect: 220/4024 0.231s 0.001s
im_detect: 221/4024 0.230s 0.001s
im_detect: 222/4024 0.230s 0.001s
im_detect: 223/4024 0.230s 0.001s
im_detect: 224/4024 0.230s 0.001s
im_detect: 225/4024 0.230s 0.001s
im_detect: 226/4024 0.230s 0.001s
im_detect: 227/4024 0.230s 0.001s
im_detect: 228/4024 0.230s 0.001s
im_detect: 229/4024 0.230s 0.001s
im_detect: 230/4024 0.230s 0.001s
im_detect: 231/4024 0.230s 0.001s
im_detect: 232/4024 0.231s 0.001s
im_detect: 233/4024 0.231s 0.001s
im_detect: 234/4024 0.230s 0.001s
im_detect: 235/4024 0.230s 0.001s
im_detect: 236/4024 0.230s 0.001s
im_detect: 237/4024 0.230s 0.001s
im_detect: 238/4024 0.230s 0.001s
im_detect: 239/4024 0.230s 0.001s
im_detect: 240/4024 0.230s 0.001s
im_detect: 241/4024 0.230s 0.001s
im_detect: 242/4024 0.230s 0.001s
im_detect: 243/4024 0.230s 0.001s
im_detect: 244/4024 0.230s 0.001s
im_detect: 245/4024 0.230s 0.001s
im_detect: 246/4024 0.231s 0.001s
im_detect: 247/4024 0.231s 0.001s
im_detect: 248/4024 0.231s 0.001s
im_detect: 249/4024 0.231s 0.001s
im_detect: 250/4024 0.231s 0.001s
im_detect: 251/4024 0.231s 0.001s
im_detect: 252/4024 0.231s 0.001s
im_detect: 253/4024 0.231s 0.001s
im_detect: 254/4024 0.231s 0.001s
im_detect: 255/4024 0.231s 0.001s
im_detect: 256/4024 0.231s 0.001s
im_detect: 257/4024 0.230s 0.001s
im_detect: 258/4024 0.230s 0.001s
im_detect: 259/4024 0.231s 0.001s
im_detect: 260/4024 0.231s 0.001s
im_detect: 261/4024 0.231s 0.001s
im_detect: 262/4024 0.231s 0.001s
im_detect: 263/4024 0.231s 0.001s
im_detect: 264/4024 0.231s 0.001s
im_detect: 265/4024 0.230s 0.001s
im_detect: 266/4024 0.230s 0.001s
im_detect: 267/4024 0.230s 0.001s
im_detect: 268/4024 0.231s 0.001s
im_detect: 269/4024 0.231s 0.001s
im_detect: 270/4024 0.231s 0.001s
im_detect: 271/4024 0.231s 0.001s
im_detect: 272/4024 0.231s 0.001s
im_detect: 273/4024 0.231s 0.001s
im_detect: 274/4024 0.231s 0.001s
im_detect: 275/4024 0.231s 0.001s
im_detect: 276/4024 0.231s 0.001s
im_detect: 277/4024 0.231s 0.001s
im_detect: 278/4024 0.231s 0.001s
im_detect: 279/4024 0.231s 0.001s
im_detect: 280/4024 0.231s 0.001s
im_detect: 281/4024 0.231s 0.001s
im_detect: 282/4024 0.231s 0.001s
im_detect: 283/4024 0.231s 0.001s
im_detect: 284/4024 0.231s 0.001s
im_detect: 285/4024 0.231s 0.001s
im_detect: 286/4024 0.231s 0.001s
im_detect: 287/4024 0.231s 0.001s
im_detect: 288/4024 0.231s 0.001s
im_detect: 289/4024 0.230s 0.001s
im_detect: 290/4024 0.230s 0.001s
im_detect: 291/4024 0.230s 0.001s
im_detect: 292/4024 0.230s 0.001s
im_detect: 293/4024 0.230s 0.001s
im_detect: 294/4024 0.230s 0.001s
im_detect: 295/4024 0.230s 0.001s
im_detect: 296/4024 0.230s 0.001s
im_detect: 297/4024 0.230s 0.001s
im_detect: 298/4024 0.230s 0.001s
im_detect: 299/4024 0.230s 0.001s
im_detect: 300/4024 0.230s 0.001s
im_detect: 301/4024 0.230s 0.001s
im_detect: 302/4024 0.230s 0.001s
im_detect: 303/4024 0.230s 0.001s
im_detect: 304/4024 0.230s 0.001s
im_detect: 305/4024 0.230s 0.001s
im_detect: 306/4024 0.230s 0.001s
im_detect: 307/4024 0.230s 0.001s
im_detect: 308/4024 0.230s 0.001s
im_detect: 309/4024 0.230s 0.001s
im_detect: 310/4024 0.230s 0.001s
im_detect: 311/4024 0.230s 0.001s
im_detect: 312/4024 0.230s 0.001s
im_detect: 313/4024 0.230s 0.001s
im_detect: 314/4024 0.230s 0.001s
im_detect: 315/4024 0.230s 0.001s
im_detect: 316/4024 0.230s 0.001s
im_detect: 317/4024 0.230s 0.001s
im_detect: 318/4024 0.230s 0.001s
im_detect: 319/4024 0.230s 0.001s
im_detect: 320/4024 0.230s 0.001s
im_detect: 321/4024 0.230s 0.001s
im_detect: 322/4024 0.230s 0.001s
im_detect: 323/4024 0.230s 0.001s
im_detect: 324/4024 0.230s 0.001s
im_detect: 325/4024 0.230s 0.001s
im_detect: 326/4024 0.230s 0.001s
im_detect: 327/4024 0.230s 0.001s
im_detect: 328/4024 0.230s 0.001s
im_detect: 329/4024 0.230s 0.001s
im_detect: 330/4024 0.230s 0.001s
im_detect: 331/4024 0.230s 0.001s
im_detect: 332/4024 0.230s 0.001s
im_detect: 333/4024 0.230s 0.001s
im_detect: 334/4024 0.230s 0.001s
im_detect: 335/4024 0.230s 0.001s
im_detect: 336/4024 0.230s 0.001s
im_detect: 337/4024 0.230s 0.001s
im_detect: 338/4024 0.230s 0.001s
im_detect: 339/4024 0.230s 0.001s
im_detect: 340/4024 0.230s 0.001s
im_detect: 341/4024 0.230s 0.001s
im_detect: 342/4024 0.229s 0.001s
im_detect: 343/4024 0.229s 0.001s
im_detect: 344/4024 0.229s 0.001s
im_detect: 345/4024 0.229s 0.001s
im_detect: 346/4024 0.229s 0.001s
im_detect: 347/4024 0.229s 0.001s
im_detect: 348/4024 0.229s 0.001s
im_detect: 349/4024 0.229s 0.001s
im_detect: 350/4024 0.229s 0.001s
im_detect: 351/4024 0.229s 0.001s
im_detect: 352/4024 0.229s 0.001s
im_detect: 353/4024 0.229s 0.001s
im_detect: 354/4024 0.229s 0.001s
im_detect: 355/4024 0.229s 0.001s
im_detect: 356/4024 0.229s 0.001s
im_detect: 357/4024 0.229s 0.001s
im_detect: 358/4024 0.229s 0.001s
im_detect: 359/4024 0.229s 0.001s
im_detect: 360/4024 0.229s 0.001s
im_detect: 361/4024 0.229s 0.001s
im_detect: 362/4024 0.229s 0.001s
im_detect: 363/4024 0.228s 0.001s
im_detect: 364/4024 0.228s 0.001s
im_detect: 365/4024 0.229s 0.001s
im_detect: 366/4024 0.228s 0.001s
im_detect: 367/4024 0.228s 0.001s
im_detect: 368/4024 0.228s 0.001s
im_detect: 369/4024 0.229s 0.001s
im_detect: 370/4024 0.229s 0.001s
im_detect: 371/4024 0.229s 0.001s
im_detect: 372/4024 0.229s 0.001s
im_detect: 373/4024 0.229s 0.001s
im_detect: 374/4024 0.229s 0.001s
im_detect: 375/4024 0.229s 0.001s
im_detect: 376/4024 0.229s 0.001s
im_detect: 377/4024 0.229s 0.001s
im_detect: 378/4024 0.229s 0.001s
im_detect: 379/4024 0.229s 0.001s
im_detect: 380/4024 0.229s 0.001s
im_detect: 381/4024 0.229s 0.001s
im_detect: 382/4024 0.229s 0.001s
im_detect: 383/4024 0.229s 0.001s
im_detect: 384/4024 0.229s 0.001s
im_detect: 385/4024 0.229s 0.001s
im_detect: 386/4024 0.229s 0.001s
im_detect: 387/4024 0.229s 0.001s
im_detect: 388/4024 0.229s 0.001s
im_detect: 389/4024 0.229s 0.001s
im_detect: 390/4024 0.229s 0.001s
im_detect: 391/4024 0.229s 0.001s
im_detect: 392/4024 0.229s 0.001s
im_detect: 393/4024 0.229s 0.001s
im_detect: 394/4024 0.229s 0.001s
im_detect: 395/4024 0.229s 0.001s
im_detect: 396/4024 0.229s 0.001s
im_detect: 397/4024 0.229s 0.001s
im_detect: 398/4024 0.229s 0.001s
im_detect: 399/4024 0.229s 0.001s
im_detect: 400/4024 0.229s 0.001s
im_detect: 401/4024 0.229s 0.001s
im_detect: 402/4024 0.229s 0.001s
im_detect: 403/4024 0.229s 0.001s
im_detect: 404/4024 0.229s 0.001s
im_detect: 405/4024 0.229s 0.001s
im_detect: 406/4024 0.229s 0.001s
im_detect: 407/4024 0.229s 0.001s
im_detect: 408/4024 0.229s 0.001s
im_detect: 409/4024 0.229s 0.001s
im_detect: 410/4024 0.229s 0.001s
im_detect: 411/4024 0.229s 0.001s
im_detect: 412/4024 0.229s 0.001s
im_detect: 413/4024 0.228s 0.001s
im_detect: 414/4024 0.229s 0.001s
im_detect: 415/4024 0.229s 0.001s
im_detect: 416/4024 0.228s 0.001s
im_detect: 417/4024 0.228s 0.001s
im_detect: 418/4024 0.228s 0.001s
im_detect: 419/4024 0.228s 0.001s
im_detect: 420/4024 0.228s 0.001s
im_detect: 421/4024 0.228s 0.001s
im_detect: 422/4024 0.228s 0.001s
im_detect: 423/4024 0.228s 0.001s
im_detect: 424/4024 0.228s 0.001s
im_detect: 425/4024 0.228s 0.001s
im_detect: 426/4024 0.228s 0.001s
im_detect: 427/4024 0.228s 0.001s
im_detect: 428/4024 0.228s 0.001s
im_detect: 429/4024 0.228s 0.001s
im_detect: 430/4024 0.228s 0.001s
im_detect: 431/4024 0.228s 0.001s
im_detect: 432/4024 0.228s 0.001s
im_detect: 433/4024 0.228s 0.001s
im_detect: 434/4024 0.228s 0.001s
im_detect: 435/4024 0.228s 0.001s
im_detect: 436/4024 0.228s 0.001s
im_detect: 437/4024 0.228s 0.001s
im_detect: 438/4024 0.228s 0.001s
im_detect: 439/4024 0.228s 0.001s
im_detect: 440/4024 0.228s 0.001s
im_detect: 441/4024 0.228s 0.001s
im_detect: 442/4024 0.228s 0.001s
im_detect: 443/4024 0.228s 0.001s
im_detect: 444/4024 0.228s 0.001s
im_detect: 445/4024 0.228s 0.001s
im_detect: 446/4024 0.228s 0.001s
im_detect: 447/4024 0.228s 0.001s
im_detect: 448/4024 0.228s 0.001s
im_detect: 449/4024 0.228s 0.001s
im_detect: 450/4024 0.228s 0.001s
im_detect: 451/4024 0.227s 0.001s
im_detect: 452/4024 0.227s 0.001s
im_detect: 453/4024 0.227s 0.001s
im_detect: 454/4024 0.227s 0.001s
im_detect: 455/4024 0.227s 0.001s
im_detect: 456/4024 0.227s 0.001s
im_detect: 457/4024 0.227s 0.001s
im_detect: 458/4024 0.227s 0.001s
im_detect: 459/4024 0.227s 0.001s
im_detect: 460/4024 0.227s 0.001s
im_detect: 461/4024 0.227s 0.001s
im_detect: 462/4024 0.227s 0.001s
im_detect: 463/4024 0.228s 0.001s
im_detect: 464/4024 0.228s 0.001s
im_detect: 465/4024 0.228s 0.001s
im_detect: 466/4024 0.227s 0.001s
im_detect: 467/4024 0.227s 0.001s
im_detect: 468/4024 0.227s 0.001s
im_detect: 469/4024 0.227s 0.001s
im_detect: 470/4024 0.227s 0.001s
im_detect: 471/4024 0.227s 0.001s
im_detect: 472/4024 0.227s 0.001s
im_detect: 473/4024 0.228s 0.001s
im_detect: 474/4024 0.227s 0.001s
im_detect: 475/4024 0.228s 0.001s
im_detect: 476/4024 0.228s 0.001s
im_detect: 477/4024 0.227s 0.001s
im_detect: 478/4024 0.227s 0.001s
im_detect: 479/4024 0.227s 0.001s
im_detect: 480/4024 0.227s 0.001s
im_detect: 481/4024 0.227s 0.001s
im_detect: 482/4024 0.227s 0.001s
im_detect: 483/4024 0.227s 0.001s
im_detect: 484/4024 0.227s 0.001s
im_detect: 485/4024 0.227s 0.001s
im_detect: 486/4024 0.227s 0.001s
im_detect: 487/4024 0.227s 0.001s
im_detect: 488/4024 0.227s 0.001s
im_detect: 489/4024 0.227s 0.001s
im_detect: 490/4024 0.227s 0.001s
im_detect: 491/4024 0.227s 0.001s
im_detect: 492/4024 0.227s 0.001s
im_detect: 493/4024 0.227s 0.001s
im_detect: 494/4024 0.227s 0.001s
im_detect: 495/4024 0.227s 0.001s
im_detect: 496/4024 0.227s 0.001s
im_detect: 497/4024 0.227s 0.001s
im_detect: 498/4024 0.227s 0.001s
im_detect: 499/4024 0.227s 0.001s
im_detect: 500/4024 0.227s 0.001s
im_detect: 501/4024 0.227s 0.001s
im_detect: 502/4024 0.227s 0.001s
im_detect: 503/4024 0.227s 0.001s
im_detect: 504/4024 0.227s 0.001s
im_detect: 505/4024 0.227s 0.001s
im_detect: 506/4024 0.227s 0.001s
im_detect: 507/4024 0.227s 0.001s
im_detect: 508/4024 0.227s 0.001s
im_detect: 509/4024 0.227s 0.001s
im_detect: 510/4024 0.227s 0.001s
im_detect: 511/4024 0.227s 0.001s
im_detect: 512/4024 0.227s 0.001s
im_detect: 513/4024 0.227s 0.001s
im_detect: 514/4024 0.227s 0.001s
im_detect: 515/4024 0.227s 0.001s
im_detect: 516/4024 0.227s 0.001s
im_detect: 517/4024 0.226s 0.001s
im_detect: 518/4024 0.226s 0.001s
im_detect: 519/4024 0.226s 0.001s
im_detect: 520/4024 0.226s 0.001s
im_detect: 521/4024 0.226s 0.001s
im_detect: 522/4024 0.226s 0.001s
im_detect: 523/4024 0.226s 0.001s
im_detect: 524/4024 0.226s 0.001s
im_detect: 525/4024 0.226s 0.001s
im_detect: 526/4024 0.226s 0.001s
im_detect: 527/4024 0.226s 0.001s
im_detect: 528/4024 0.226s 0.001s
im_detect: 529/4024 0.226s 0.001s
im_detect: 530/4024 0.226s 0.001s
im_detect: 531/4024 0.226s 0.001s
im_detect: 532/4024 0.226s 0.001s
im_detect: 533/4024 0.226s 0.001s
im_detect: 534/4024 0.226s 0.001s
im_detect: 535/4024 0.226s 0.001s
im_detect: 536/4024 0.226s 0.001s
im_detect: 537/4024 0.226s 0.001s
im_detect: 538/4024 0.226s 0.001s
im_detect: 539/4024 0.226s 0.001s
im_detect: 540/4024 0.226s 0.001s
im_detect: 541/4024 0.226s 0.001s
im_detect: 542/4024 0.226s 0.001s
im_detect: 543/4024 0.226s 0.001s
im_detect: 544/4024 0.226s 0.001s
im_detect: 545/4024 0.226s 0.001s
im_detect: 546/4024 0.226s 0.001s
im_detect: 547/4024 0.226s 0.001s
im_detect: 548/4024 0.226s 0.001s
im_detect: 549/4024 0.226s 0.001s
im_detect: 550/4024 0.226s 0.001s
im_detect: 551/4024 0.226s 0.001s
im_detect: 552/4024 0.225s 0.001s
im_detect: 553/4024 0.225s 0.001s
im_detect: 554/4024 0.225s 0.001s
im_detect: 555/4024 0.225s 0.001s
im_detect: 556/4024 0.225s 0.001s
im_detect: 557/4024 0.225s 0.001s
im_detect: 558/4024 0.225s 0.001s
im_detect: 559/4024 0.225s 0.001s
im_detect: 560/4024 0.225s 0.001s
im_detect: 561/4024 0.225s 0.001s
im_detect: 562/4024 0.225s 0.001s
im_detect: 563/4024 0.225s 0.001s
im_detect: 564/4024 0.225s 0.001s
im_detect: 565/4024 0.225s 0.001s
im_detect: 566/4024 0.225s 0.001s
im_detect: 567/4024 0.225s 0.001s
im_detect: 568/4024 0.225s 0.001s
im_detect: 569/4024 0.225s 0.001s
im_detect: 570/4024 0.225s 0.001s
im_detect: 571/4024 0.225s 0.001s
im_detect: 572/4024 0.225s 0.001s
im_detect: 573/4024 0.225s 0.001s
im_detect: 574/4024 0.225s 0.001s
im_detect: 575/4024 0.225s 0.001s
im_detect: 576/4024 0.225s 0.001s
im_detect: 577/4024 0.225s 0.001s
im_detect: 578/4024 0.225s 0.001s
im_detect: 579/4024 0.225s 0.001s
im_detect: 580/4024 0.225s 0.001s
im_detect: 581/4024 0.225s 0.001s
im_detect: 582/4024 0.225s 0.001s
im_detect: 583/4024 0.225s 0.001s
im_detect: 584/4024 0.225s 0.001s
im_detect: 585/4024 0.225s 0.001s
im_detect: 586/4024 0.225s 0.001s
im_detect: 587/4024 0.225s 0.001s
im_detect: 588/4024 0.225s 0.001s
im_detect: 589/4024 0.225s 0.001s
im_detect: 590/4024 0.225s 0.001s
im_detect: 591/4024 0.225s 0.001s
im_detect: 592/4024 0.225s 0.001s
im_detect: 593/4024 0.225s 0.001s
im_detect: 594/4024 0.225s 0.001s
im_detect: 595/4024 0.225s 0.001s
im_detect: 596/4024 0.225s 0.001s
im_detect: 597/4024 0.225s 0.001s
im_detect: 598/4024 0.225s 0.001s
im_detect: 599/4024 0.225s 0.001s
im_detect: 600/4024 0.225s 0.001s
im_detect: 601/4024 0.225s 0.001s
im_detect: 602/4024 0.225s 0.001s
im_detect: 603/4024 0.225s 0.001s
im_detect: 604/4024 0.225s 0.001s
im_detect: 605/4024 0.225s 0.001s
im_detect: 606/4024 0.225s 0.001s
im_detect: 607/4024 0.225s 0.001s
im_detect: 608/4024 0.225s 0.001s
im_detect: 609/4024 0.225s 0.001s
im_detect: 610/4024 0.225s 0.001s
im_detect: 611/4024 0.225s 0.001s
im_detect: 612/4024 0.225s 0.001s
im_detect: 613/4024 0.225s 0.001s
im_detect: 614/4024 0.225s 0.001s
im_detect: 615/4024 0.225s 0.001s
im_detect: 616/4024 0.225s 0.001s
im_detect: 617/4024 0.225s 0.001s
im_detect: 618/4024 0.225s 0.001s
im_detect: 619/4024 0.225s 0.001s
im_detect: 620/4024 0.225s 0.001s
im_detect: 621/4024 0.225s 0.001s
im_detect: 622/4024 0.224s 0.001s
im_detect: 623/4024 0.224s 0.001s
im_detect: 624/4024 0.224s 0.001s
im_detect: 625/4024 0.224s 0.001s
im_detect: 626/4024 0.224s 0.001s
im_detect: 627/4024 0.224s 0.001s
im_detect: 628/4024 0.224s 0.001s
im_detect: 629/4024 0.224s 0.001s
im_detect: 630/4024 0.224s 0.001s
im_detect: 631/4024 0.224s 0.001s
im_detect: 632/4024 0.224s 0.001s
im_detect: 633/4024 0.224s 0.001s
im_detect: 634/4024 0.224s 0.001s
im_detect: 635/4024 0.224s 0.001s
im_detect: 636/4024 0.224s 0.001s
im_detect: 637/4024 0.224s 0.001s
im_detect: 638/4024 0.224s 0.001s
im_detect: 639/4024 0.224s 0.001s
im_detect: 640/4024 0.224s 0.001s
im_detect: 641/4024 0.224s 0.001s
im_detect: 642/4024 0.224s 0.001s
im_detect: 643/4024 0.224s 0.001s
im_detect: 644/4024 0.224s 0.001s
im_detect: 645/4024 0.224s 0.001s
im_detect: 646/4024 0.224s 0.001s
im_detect: 647/4024 0.224s 0.001s
im_detect: 648/4024 0.224s 0.001s
im_detect: 649/4024 0.224s 0.001s
im_detect: 650/4024 0.224s 0.001s
im_detect: 651/4024 0.224s 0.001s
im_detect: 652/4024 0.224s 0.001s
im_detect: 653/4024 0.224s 0.001s
im_detect: 654/4024 0.224s 0.001s
im_detect: 655/4024 0.223s 0.001s
im_detect: 656/4024 0.223s 0.001s
im_detect: 657/4024 0.223s 0.001s
im_detect: 658/4024 0.223s 0.001s
im_detect: 659/4024 0.223s 0.001s
im_detect: 660/4024 0.223s 0.001s
im_detect: 661/4024 0.223s 0.001s
im_detect: 662/4024 0.223s 0.001s
im_detect: 663/4024 0.223s 0.001s
im_detect: 664/4024 0.223s 0.001s
im_detect: 665/4024 0.223s 0.001s
im_detect: 666/4024 0.223s 0.001s
im_detect: 667/4024 0.223s 0.001s
im_detect: 668/4024 0.223s 0.001s
im_detect: 669/4024 0.223s 0.001s
im_detect: 670/4024 0.223s 0.001s
im_detect: 671/4024 0.223s 0.001s
im_detect: 672/4024 0.223s 0.001s
im_detect: 673/4024 0.223s 0.001s
im_detect: 674/4024 0.223s 0.001s
im_detect: 675/4024 0.223s 0.001s
im_detect: 676/4024 0.223s 0.001s
im_detect: 677/4024 0.223s 0.001s
im_detect: 678/4024 0.223s 0.001s
im_detect: 679/4024 0.223s 0.001s
im_detect: 680/4024 0.224s 0.001s
im_detect: 681/4024 0.224s 0.001s
im_detect: 682/4024 0.224s 0.001s
im_detect: 683/4024 0.223s 0.001s
im_detect: 684/4024 0.223s 0.001s
im_detect: 685/4024 0.223s 0.001s
im_detect: 686/4024 0.223s 0.001s
im_detect: 687/4024 0.223s 0.001s
im_detect: 688/4024 0.223s 0.001s
im_detect: 689/4024 0.223s 0.001s
im_detect: 690/4024 0.223s 0.001s
im_detect: 691/4024 0.223s 0.001s
im_detect: 692/4024 0.223s 0.001s
im_detect: 693/4024 0.223s 0.001s
im_detect: 694/4024 0.223s 0.001s
im_detect: 695/4024 0.223s 0.001s
im_detect: 696/4024 0.223s 0.001s
im_detect: 697/4024 0.223s 0.001s
im_detect: 698/4024 0.223s 0.001s
im_detect: 699/4024 0.223s 0.001s
im_detect: 700/4024 0.223s 0.001s
im_detect: 701/4024 0.223s 0.001s
im_detect: 702/4024 0.223s 0.001s
im_detect: 703/4024 0.223s 0.001s
im_detect: 704/4024 0.223s 0.001s
im_detect: 705/4024 0.223s 0.001s
im_detect: 706/4024 0.223s 0.001s
im_detect: 707/4024 0.223s 0.001s
im_detect: 708/4024 0.223s 0.001s
im_detect: 709/4024 0.223s 0.001s
im_detect: 710/4024 0.223s 0.001s
im_detect: 711/4024 0.223s 0.001s
im_detect: 712/4024 0.223s 0.001s
im_detect: 713/4024 0.223s 0.001s
im_detect: 714/4024 0.223s 0.001s
im_detect: 715/4024 0.223s 0.001s
im_detect: 716/4024 0.223s 0.001s
im_detect: 717/4024 0.223s 0.001s
im_detect: 718/4024 0.223s 0.001s
im_detect: 719/4024 0.223s 0.001s
im_detect: 720/4024 0.223s 0.001s
im_detect: 721/4024 0.223s 0.001s
im_detect: 722/4024 0.223s 0.001s
im_detect: 723/4024 0.223s 0.001s
im_detect: 724/4024 0.223s 0.001s
im_detect: 725/4024 0.223s 0.001s
im_detect: 726/4024 0.223s 0.001s
im_detect: 727/4024 0.223s 0.001s
im_detect: 728/4024 0.223s 0.001s
im_detect: 729/4024 0.223s 0.001s
im_detect: 730/4024 0.223s 0.001s
im_detect: 731/4024 0.223s 0.001s
im_detect: 732/4024 0.223s 0.001s
im_detect: 733/4024 0.223s 0.001s
im_detect: 734/4024 0.223s 0.001s
im_detect: 735/4024 0.223s 0.001s
im_detect: 736/4024 0.223s 0.001s
im_detect: 737/4024 0.223s 0.001s
im_detect: 738/4024 0.223s 0.001s
im_detect: 739/4024 0.223s 0.001s
im_detect: 740/4024 0.223s 0.001s
im_detect: 741/4024 0.223s 0.001s
im_detect: 742/4024 0.223s 0.001s
im_detect: 743/4024 0.223s 0.001s
im_detect: 744/4024 0.223s 0.001s
im_detect: 745/4024 0.223s 0.001s
im_detect: 746/4024 0.223s 0.001s
im_detect: 747/4024 0.223s 0.001s
im_detect: 748/4024 0.223s 0.001s
im_detect: 749/4024 0.223s 0.001s
im_detect: 750/4024 0.223s 0.001s
im_detect: 751/4024 0.223s 0.001s
im_detect: 752/4024 0.223s 0.001s
im_detect: 753/4024 0.223s 0.001s
im_detect: 754/4024 0.223s 0.001s
im_detect: 755/4024 0.223s 0.001s
im_detect: 756/4024 0.223s 0.001s
im_detect: 757/4024 0.223s 0.001s
im_detect: 758/4024 0.223s 0.001s
im_detect: 759/4024 0.223s 0.001s
im_detect: 760/4024 0.223s 0.001s
im_detect: 761/4024 0.223s 0.001s
im_detect: 762/4024 0.223s 0.001s
im_detect: 763/4024 0.223s 0.001s
im_detect: 764/4024 0.223s 0.001s
im_detect: 765/4024 0.223s 0.001s
im_detect: 766/4024 0.223s 0.001s
im_detect: 767/4024 0.223s 0.001s
im_detect: 768/4024 0.223s 0.001s
im_detect: 769/4024 0.223s 0.001s
im_detect: 770/4024 0.223s 0.001s
im_detect: 771/4024 0.223s 0.001s
im_detect: 772/4024 0.223s 0.001s
im_detect: 773/4024 0.223s 0.001s
im_detect: 774/4024 0.223s 0.001s
im_detect: 775/4024 0.223s 0.001s
im_detect: 776/4024 0.223s 0.001s
im_detect: 777/4024 0.223s 0.001s
im_detect: 778/4024 0.223s 0.001s
im_detect: 779/4024 0.223s 0.001s
im_detect: 780/4024 0.223s 0.001s
im_detect: 781/4024 0.223s 0.001s
im_detect: 782/4024 0.223s 0.001s
im_detect: 783/4024 0.223s 0.001s
im_detect: 784/4024 0.223s 0.001s
im_detect: 785/4024 0.223s 0.001s
im_detect: 786/4024 0.223s 0.001s
im_detect: 787/4024 0.223s 0.001s
im_detect: 788/4024 0.223s 0.001s
im_detect: 789/4024 0.223s 0.001s
im_detect: 790/4024 0.223s 0.001s
im_detect: 791/4024 0.223s 0.001s
im_detect: 792/4024 0.223s 0.001s
im_detect: 793/4024 0.223s 0.001s
im_detect: 794/4024 0.223s 0.001s
im_detect: 795/4024 0.223s 0.001s
im_detect: 796/4024 0.223s 0.001s
im_detect: 797/4024 0.223s 0.001s
im_detect: 798/4024 0.223s 0.001s
im_detect: 799/4024 0.223s 0.001s
im_detect: 800/4024 0.223s 0.001s
im_detect: 801/4024 0.223s 0.001s
im_detect: 802/4024 0.223s 0.001s
im_detect: 803/4024 0.223s 0.001s
im_detect: 804/4024 0.223s 0.001s
im_detect: 805/4024 0.223s 0.001s
im_detect: 806/4024 0.223s 0.001s
im_detect: 807/4024 0.223s 0.001s
im_detect: 808/4024 0.223s 0.001s
im_detect: 809/4024 0.223s 0.001s
im_detect: 810/4024 0.223s 0.001s
im_detect: 811/4024 0.223s 0.001s
im_detect: 812/4024 0.223s 0.001s
im_detect: 813/4024 0.223s 0.001s
im_detect: 814/4024 0.223s 0.001s
im_detect: 815/4024 0.223s 0.001s
im_detect: 816/4024 0.223s 0.001s
im_detect: 817/4024 0.223s 0.001s
im_detect: 818/4024 0.223s 0.001s
im_detect: 819/4024 0.223s 0.001s
im_detect: 820/4024 0.223s 0.001s
im_detect: 821/4024 0.223s 0.001s
im_detect: 822/4024 0.223s 0.001s
im_detect: 823/4024 0.223s 0.001s
im_detect: 824/4024 0.223s 0.001s
im_detect: 825/4024 0.223s 0.001s
im_detect: 826/4024 0.223s 0.001s
im_detect: 827/4024 0.223s 0.001s
im_detect: 828/4024 0.222s 0.001s
im_detect: 829/4024 0.222s 0.001s
im_detect: 830/4024 0.222s 0.001s
im_detect: 831/4024 0.222s 0.001s
im_detect: 832/4024 0.222s 0.001s
im_detect: 833/4024 0.222s 0.001s
im_detect: 834/4024 0.222s 0.001s
im_detect: 835/4024 0.222s 0.001s
im_detect: 836/4024 0.222s 0.001s
im_detect: 837/4024 0.222s 0.001s
im_detect: 838/4024 0.222s 0.001s
im_detect: 839/4024 0.222s 0.001s
im_detect: 840/4024 0.222s 0.001s
im_detect: 841/4024 0.222s 0.001s
im_detect: 842/4024 0.222s 0.001s
im_detect: 843/4024 0.222s 0.001s
im_detect: 844/4024 0.222s 0.001s
im_detect: 845/4024 0.222s 0.001s
im_detect: 846/4024 0.222s 0.001s
im_detect: 847/4024 0.222s 0.001s
im_detect: 848/4024 0.222s 0.001s
im_detect: 849/4024 0.222s 0.001s
im_detect: 850/4024 0.222s 0.001s
im_detect: 851/4024 0.222s 0.001s
im_detect: 852/4024 0.222s 0.001s
im_detect: 853/4024 0.222s 0.001s
im_detect: 854/4024 0.222s 0.001s
im_detect: 855/4024 0.222s 0.001s
im_detect: 856/4024 0.222s 0.001s
im_detect: 857/4024 0.222s 0.001s
im_detect: 858/4024 0.222s 0.001s
im_detect: 859/4024 0.222s 0.001s
im_detect: 860/4024 0.222s 0.001s
im_detect: 861/4024 0.222s 0.001s
im_detect: 862/4024 0.222s 0.001s
im_detect: 863/4024 0.222s 0.001s
im_detect: 864/4024 0.222s 0.001s
im_detect: 865/4024 0.222s 0.001s
im_detect: 866/4024 0.222s 0.001s
im_detect: 867/4024 0.222s 0.001s
im_detect: 868/4024 0.222s 0.001s
im_detect: 869/4024 0.222s 0.001s
im_detect: 870/4024 0.222s 0.001s
im_detect: 871/4024 0.222s 0.001s
im_detect: 872/4024 0.222s 0.001s
im_detect: 873/4024 0.222s 0.001s
im_detect: 874/4024 0.222s 0.001s
im_detect: 875/4024 0.222s 0.001s
im_detect: 876/4024 0.222s 0.001s
im_detect: 877/4024 0.222s 0.001s
im_detect: 878/4024 0.222s 0.001s
im_detect: 879/4024 0.222s 0.001s
im_detect: 880/4024 0.222s 0.001s
im_detect: 881/4024 0.222s 0.001s
im_detect: 882/4024 0.222s 0.001s
im_detect: 883/4024 0.222s 0.001s
im_detect: 884/4024 0.222s 0.001s
im_detect: 885/4024 0.222s 0.001s
im_detect: 886/4024 0.222s 0.001s
im_detect: 887/4024 0.222s 0.001s
im_detect: 888/4024 0.222s 0.001s
im_detect: 889/4024 0.222s 0.001s
im_detect: 890/4024 0.222s 0.001s
im_detect: 891/4024 0.222s 0.001s
im_detect: 892/4024 0.222s 0.001s
im_detect: 893/4024 0.222s 0.001s
im_detect: 894/4024 0.222s 0.001s
im_detect: 895/4024 0.222s 0.001s
im_detect: 896/4024 0.222s 0.001s
im_detect: 897/4024 0.222s 0.001s
im_detect: 898/4024 0.222s 0.001s
im_detect: 899/4024 0.222s 0.001s
im_detect: 900/4024 0.222s 0.001s
im_detect: 901/4024 0.222s 0.001s
im_detect: 902/4024 0.222s 0.001s
im_detect: 903/4024 0.222s 0.001s
im_detect: 904/4024 0.222s 0.001s
im_detect: 905/4024 0.222s 0.001s
im_detect: 906/4024 0.222s 0.001s
im_detect: 907/4024 0.222s 0.001s
im_detect: 908/4024 0.222s 0.001s
im_detect: 909/4024 0.222s 0.001s
im_detect: 910/4024 0.222s 0.001s
im_detect: 911/4024 0.222s 0.001s
im_detect: 912/4024 0.222s 0.001s
im_detect: 913/4024 0.222s 0.001s
im_detect: 914/4024 0.222s 0.001s
im_detect: 915/4024 0.222s 0.001s
im_detect: 916/4024 0.222s 0.001s
im_detect: 917/4024 0.222s 0.001s
im_detect: 918/4024 0.222s 0.001s
im_detect: 919/4024 0.222s 0.001s
im_detect: 920/4024 0.222s 0.001s
im_detect: 921/4024 0.222s 0.001s
im_detect: 922/4024 0.222s 0.001s
im_detect: 923/4024 0.222s 0.001s
im_detect: 924/4024 0.222s 0.001s
im_detect: 925/4024 0.222s 0.001s
im_detect: 926/4024 0.222s 0.001s
im_detect: 927/4024 0.222s 0.001s
im_detect: 928/4024 0.222s 0.001s
im_detect: 929/4024 0.222s 0.001s
im_detect: 930/4024 0.222s 0.001s
im_detect: 931/4024 0.222s 0.001s
im_detect: 932/4024 0.222s 0.001s
im_detect: 933/4024 0.222s 0.001s
im_detect: 934/4024 0.222s 0.001s
im_detect: 935/4024 0.222s 0.001s
im_detect: 936/4024 0.222s 0.001s
im_detect: 937/4024 0.222s 0.001s
im_detect: 938/4024 0.222s 0.001s
im_detect: 939/4024 0.222s 0.001s
im_detect: 940/4024 0.222s 0.001s
im_detect: 941/4024 0.222s 0.001s
im_detect: 942/4024 0.222s 0.001s
im_detect: 943/4024 0.222s 0.001s
im_detect: 944/4024 0.222s 0.001s
im_detect: 945/4024 0.222s 0.001s
im_detect: 946/4024 0.222s 0.001s
im_detect: 947/4024 0.222s 0.001s
im_detect: 948/4024 0.222s 0.001s
im_detect: 949/4024 0.222s 0.001s
im_detect: 950/4024 0.222s 0.001s
im_detect: 951/4024 0.222s 0.001s
im_detect: 952/4024 0.222s 0.001s
im_detect: 953/4024 0.222s 0.001s
im_detect: 954/4024 0.222s 0.001s
im_detect: 955/4024 0.222s 0.001s
im_detect: 956/4024 0.222s 0.001s
im_detect: 957/4024 0.222s 0.001s
im_detect: 958/4024 0.222s 0.001s
im_detect: 959/4024 0.222s 0.001s
im_detect: 960/4024 0.222s 0.001s
im_detect: 961/4024 0.222s 0.001s
im_detect: 962/4024 0.222s 0.001s
im_detect: 963/4024 0.222s 0.001s
im_detect: 964/4024 0.222s 0.001s
im_detect: 965/4024 0.222s 0.001s
im_detect: 966/4024 0.222s 0.001s
im_detect: 967/4024 0.222s 0.001s
im_detect: 968/4024 0.222s 0.001s
im_detect: 969/4024 0.222s 0.001s
im_detect: 970/4024 0.222s 0.001s
im_detect: 971/4024 0.222s 0.001s
im_detect: 972/4024 0.222s 0.001s
im_detect: 973/4024 0.222s 0.001s
im_detect: 974/4024 0.222s 0.001s
im_detect: 975/4024 0.222s 0.001s
im_detect: 976/4024 0.222s 0.001s
im_detect: 977/4024 0.222s 0.001s
im_detect: 978/4024 0.222s 0.001s
im_detect: 979/4024 0.222s 0.001s
im_detect: 980/4024 0.222s 0.001s
im_detect: 981/4024 0.222s 0.001s
im_detect: 982/4024 0.222s 0.001s
im_detect: 983/4024 0.222s 0.001s
im_detect: 984/4024 0.222s 0.001s
im_detect: 985/4024 0.222s 0.001s
im_detect: 986/4024 0.222s 0.001s
im_detect: 987/4024 0.222s 0.001s
im_detect: 988/4024 0.222s 0.001s
im_detect: 989/4024 0.222s 0.001s
im_detect: 990/4024 0.222s 0.001s
im_detect: 991/4024 0.222s 0.001s
im_detect: 992/4024 0.222s 0.001s
im_detect: 993/4024 0.222s 0.001s
im_detect: 994/4024 0.222s 0.001s
im_detect: 995/4024 0.222s 0.001s
im_detect: 996/4024 0.222s 0.001s
im_detect: 997/4024 0.222s 0.001s
im_detect: 998/4024 0.222s 0.001s
im_detect: 999/4024 0.222s 0.001s
im_detect: 1000/4024 0.222s 0.001s
im_detect: 1001/4024 0.222s 0.001s
im_detect: 1002/4024 0.222s 0.001s
im_detect: 1003/4024 0.222s 0.001s
im_detect: 1004/4024 0.222s 0.001s
im_detect: 1005/4024 0.222s 0.001s
im_detect: 1006/4024 0.222s 0.001s
im_detect: 1007/4024 0.222s 0.001s
im_detect: 1008/4024 0.222s 0.001s
im_detect: 1009/4024 0.222s 0.001s
im_detect: 1010/4024 0.222s 0.001s
im_detect: 1011/4024 0.222s 0.001s
im_detect: 1012/4024 0.222s 0.001s
im_detect: 1013/4024 0.222s 0.001s
im_detect: 1014/4024 0.222s 0.001s
im_detect: 1015/4024 0.222s 0.001s
im_detect: 1016/4024 0.222s 0.001s
im_detect: 1017/4024 0.222s 0.001s
im_detect: 1018/4024 0.222s 0.001s
im_detect: 1019/4024 0.222s 0.001s
im_detect: 1020/4024 0.222s 0.001s
im_detect: 1021/4024 0.222s 0.001s
im_detect: 1022/4024 0.222s 0.001s
im_detect: 1023/4024 0.222s 0.001s
im_detect: 1024/4024 0.222s 0.001s
im_detect: 1025/4024 0.222s 0.001s
im_detect: 1026/4024 0.222s 0.001s
im_detect: 1027/4024 0.222s 0.001s
im_detect: 1028/4024 0.222s 0.001s
im_detect: 1029/4024 0.222s 0.001s
im_detect: 1030/4024 0.222s 0.001s
im_detect: 1031/4024 0.222s 0.001s
im_detect: 1032/4024 0.222s 0.001s
im_detect: 1033/4024 0.222s 0.001s
im_detect: 1034/4024 0.222s 0.001s
im_detect: 1035/4024 0.222s 0.001s
im_detect: 1036/4024 0.222s 0.001s
im_detect: 1037/4024 0.222s 0.001s
im_detect: 1038/4024 0.222s 0.001s
im_detect: 1039/4024 0.222s 0.001s
im_detect: 1040/4024 0.222s 0.001s
im_detect: 1041/4024 0.222s 0.001s
im_detect: 1042/4024 0.222s 0.001s
im_detect: 1043/4024 0.222s 0.001s
im_detect: 1044/4024 0.222s 0.001s
im_detect: 1045/4024 0.221s 0.001s
im_detect: 1046/4024 0.221s 0.001s
im_detect: 1047/4024 0.221s 0.001s
im_detect: 1048/4024 0.221s 0.001s
im_detect: 1049/4024 0.221s 0.001s
im_detect: 1050/4024 0.221s 0.001s
im_detect: 1051/4024 0.221s 0.001s
im_detect: 1052/4024 0.221s 0.001s
im_detect: 1053/4024 0.221s 0.001s
im_detect: 1054/4024 0.221s 0.001s
im_detect: 1055/4024 0.221s 0.001s
im_detect: 1056/4024 0.221s 0.001s
im_detect: 1057/4024 0.221s 0.001s
im_detect: 1058/4024 0.221s 0.001s
im_detect: 1059/4024 0.222s 0.001s
im_detect: 1060/4024 0.222s 0.001s
im_detect: 1061/4024 0.222s 0.001s
im_detect: 1062/4024 0.222s 0.001s
im_detect: 1063/4024 0.222s 0.001s
im_detect: 1064/4024 0.222s 0.001s
im_detect: 1065/4024 0.221s 0.001s
im_detect: 1066/4024 0.221s 0.001s
im_detect: 1067/4024 0.221s 0.001s
im_detect: 1068/4024 0.221s 0.001s
im_detect: 1069/4024 0.221s 0.001s
im_detect: 1070/4024 0.221s 0.001s
im_detect: 1071/4024 0.221s 0.001s
im_detect: 1072/4024 0.221s 0.001s
im_detect: 1073/4024 0.221s 0.001s
im_detect: 1074/4024 0.221s 0.001s
im_detect: 1075/4024 0.221s 0.001s
im_detect: 1076/4024 0.221s 0.001s
im_detect: 1077/4024 0.221s 0.001s
im_detect: 1078/4024 0.221s 0.001s
im_detect: 1079/4024 0.221s 0.001s
im_detect: 1080/4024 0.221s 0.001s
im_detect: 1081/4024 0.221s 0.001s
im_detect: 1082/4024 0.221s 0.001s
im_detect: 1083/4024 0.221s 0.001s
im_detect: 1084/4024 0.221s 0.001s
im_detect: 1085/4024 0.221s 0.001s
im_detect: 1086/4024 0.221s 0.001s
im_detect: 1087/4024 0.221s 0.001s
im_detect: 1088/4024 0.221s 0.001s
im_detect: 1089/4024 0.221s 0.001s
im_detect: 1090/4024 0.221s 0.001s
im_detect: 1091/4024 0.221s 0.001s
im_detect: 1092/4024 0.221s 0.001s
im_detect: 1093/4024 0.221s 0.001s
im_detect: 1094/4024 0.221s 0.001s
im_detect: 1095/4024 0.221s 0.001s
im_detect: 1096/4024 0.221s 0.001s
im_detect: 1097/4024 0.221s 0.001s
im_detect: 1098/4024 0.221s 0.001s
im_detect: 1099/4024 0.221s 0.001s
im_detect: 1100/4024 0.221s 0.001s
im_detect: 1101/4024 0.221s 0.001s
im_detect: 1102/4024 0.221s 0.001s
im_detect: 1103/4024 0.221s 0.001s
im_detect: 1104/4024 0.221s 0.001s
im_detect: 1105/4024 0.221s 0.001s
im_detect: 1106/4024 0.221s 0.001s
im_detect: 1107/4024 0.221s 0.001s
im_detect: 1108/4024 0.221s 0.001s
im_detect: 1109/4024 0.221s 0.001s
im_detect: 1110/4024 0.221s 0.001s
im_detect: 1111/4024 0.221s 0.001s
im_detect: 1112/4024 0.221s 0.001s
im_detect: 1113/4024 0.221s 0.001s
im_detect: 1114/4024 0.221s 0.001s
im_detect: 1115/4024 0.221s 0.001s
im_detect: 1116/4024 0.221s 0.001s
im_detect: 1117/4024 0.221s 0.001s
im_detect: 1118/4024 0.221s 0.001s
im_detect: 1119/4024 0.221s 0.001s
im_detect: 1120/4024 0.221s 0.001s
im_detect: 1121/4024 0.221s 0.001s
im_detect: 1122/4024 0.221s 0.001s
im_detect: 1123/4024 0.221s 0.001s
im_detect: 1124/4024 0.221s 0.001s
im_detect: 1125/4024 0.221s 0.001s
im_detect: 1126/4024 0.221s 0.001s
im_detect: 1127/4024 0.221s 0.001s
im_detect: 1128/4024 0.221s 0.001s
im_detect: 1129/4024 0.221s 0.001s
im_detect: 1130/4024 0.221s 0.001s
im_detect: 1131/4024 0.221s 0.001s
im_detect: 1132/4024 0.221s 0.001s
im_detect: 1133/4024 0.221s 0.001s
im_detect: 1134/4024 0.221s 0.001s
im_detect: 1135/4024 0.221s 0.001s
im_detect: 1136/4024 0.221s 0.001s
im_detect: 1137/4024 0.221s 0.001s
im_detect: 1138/4024 0.221s 0.001s
im_detect: 1139/4024 0.221s 0.001s
im_detect: 1140/4024 0.221s 0.001s
im_detect: 1141/4024 0.221s 0.001s
im_detect: 1142/4024 0.221s 0.001s
im_detect: 1143/4024 0.221s 0.001s
im_detect: 1144/4024 0.221s 0.001s
im_detect: 1145/4024 0.221s 0.001s
im_detect: 1146/4024 0.221s 0.001s
im_detect: 1147/4024 0.221s 0.001s
im_detect: 1148/4024 0.221s 0.001s
im_detect: 1149/4024 0.221s 0.001s
im_detect: 1150/4024 0.220s 0.001s
im_detect: 1151/4024 0.220s 0.001s
im_detect: 1152/4024 0.220s 0.001s
im_detect: 1153/4024 0.220s 0.001s
im_detect: 1154/4024 0.220s 0.001s
im_detect: 1155/4024 0.220s 0.001s
im_detect: 1156/4024 0.220s 0.001s
im_detect: 1157/4024 0.220s 0.001s
im_detect: 1158/4024 0.220s 0.001s
im_detect: 1159/4024 0.220s 0.001s
im_detect: 1160/4024 0.220s 0.001s
im_detect: 1161/4024 0.220s 0.001s
im_detect: 1162/4024 0.220s 0.001s
im_detect: 1163/4024 0.220s 0.001s
im_detect: 1164/4024 0.220s 0.001s
im_detect: 1165/4024 0.220s 0.001s
im_detect: 1166/4024 0.220s 0.001s
im_detect: 1167/4024 0.220s 0.001s
im_detect: 1168/4024 0.220s 0.001s
im_detect: 1169/4024 0.220s 0.001s
im_detect: 1170/4024 0.220s 0.001s
im_detect: 1171/4024 0.220s 0.001s
im_detect: 1172/4024 0.220s 0.001s
im_detect: 1173/4024 0.220s 0.001s
im_detect: 1174/4024 0.220s 0.001s
im_detect: 1175/4024 0.220s 0.001s
im_detect: 1176/4024 0.220s 0.001s
im_detect: 1177/4024 0.220s 0.001s
im_detect: 1178/4024 0.220s 0.001s
im_detect: 1179/4024 0.220s 0.001s
im_detect: 1180/4024 0.220s 0.001s
im_detect: 1181/4024 0.220s 0.001s
im_detect: 1182/4024 0.220s 0.001s
im_detect: 1183/4024 0.220s 0.001s
im_detect: 1184/4024 0.220s 0.001s
im_detect: 1185/4024 0.220s 0.001s
im_detect: 1186/4024 0.220s 0.001s
im_detect: 1187/4024 0.220s 0.001s
im_detect: 1188/4024 0.220s 0.001s
im_detect: 1189/4024 0.220s 0.001s
im_detect: 1190/4024 0.220s 0.001s
im_detect: 1191/4024 0.220s 0.001s
im_detect: 1192/4024 0.220s 0.001s
im_detect: 1193/4024 0.220s 0.001s
im_detect: 1194/4024 0.220s 0.001s
im_detect: 1195/4024 0.220s 0.001s
im_detect: 1196/4024 0.220s 0.001s
im_detect: 1197/4024 0.220s 0.001s
im_detect: 1198/4024 0.220s 0.001s
im_detect: 1199/4024 0.220s 0.001s
im_detect: 1200/4024 0.220s 0.001s
im_detect: 1201/4024 0.220s 0.001s
im_detect: 1202/4024 0.220s 0.001s
im_detect: 1203/4024 0.220s 0.001s
im_detect: 1204/4024 0.220s 0.001s
im_detect: 1205/4024 0.220s 0.001s
im_detect: 1206/4024 0.220s 0.001s
im_detect: 1207/4024 0.220s 0.001s
im_detect: 1208/4024 0.220s 0.001s
im_detect: 1209/4024 0.220s 0.001s
im_detect: 1210/4024 0.220s 0.001s
im_detect: 1211/4024 0.220s 0.001s
im_detect: 1212/4024 0.220s 0.001s
im_detect: 1213/4024 0.220s 0.001s
im_detect: 1214/4024 0.220s 0.001s
im_detect: 1215/4024 0.220s 0.001s
im_detect: 1216/4024 0.220s 0.001s
im_detect: 1217/4024 0.220s 0.001s
im_detect: 1218/4024 0.220s 0.001s
im_detect: 1219/4024 0.220s 0.001s
im_detect: 1220/4024 0.220s 0.001s
im_detect: 1221/4024 0.220s 0.001s
im_detect: 1222/4024 0.220s 0.001s
im_detect: 1223/4024 0.220s 0.001s
im_detect: 1224/4024 0.220s 0.001s
im_detect: 1225/4024 0.220s 0.001s
im_detect: 1226/4024 0.220s 0.001s
im_detect: 1227/4024 0.220s 0.001s
im_detect: 1228/4024 0.220s 0.001s
im_detect: 1229/4024 0.220s 0.001s
im_detect: 1230/4024 0.220s 0.001s
im_detect: 1231/4024 0.220s 0.001s
im_detect: 1232/4024 0.220s 0.001s
im_detect: 1233/4024 0.220s 0.001s
im_detect: 1234/4024 0.220s 0.001s
im_detect: 1235/4024 0.220s 0.001s
im_detect: 1236/4024 0.220s 0.001s
im_detect: 1237/4024 0.220s 0.001s
im_detect: 1238/4024 0.220s 0.001s
im_detect: 1239/4024 0.220s 0.001s
im_detect: 1240/4024 0.220s 0.001s
im_detect: 1241/4024 0.220s 0.001s
im_detect: 1242/4024 0.220s 0.001s
im_detect: 1243/4024 0.220s 0.001s
im_detect: 1244/4024 0.220s 0.001s
im_detect: 1245/4024 0.220s 0.001s
im_detect: 1246/4024 0.220s 0.001s
im_detect: 1247/4024 0.220s 0.001s
im_detect: 1248/4024 0.220s 0.001s
im_detect: 1249/4024 0.220s 0.001s
im_detect: 1250/4024 0.220s 0.001s
im_detect: 1251/4024 0.220s 0.001s
im_detect: 1252/4024 0.220s 0.001s
im_detect: 1253/4024 0.220s 0.001s
im_detect: 1254/4024 0.220s 0.001s
im_detect: 1255/4024 0.220s 0.001s
im_detect: 1256/4024 0.220s 0.001s
im_detect: 1257/4024 0.220s 0.001s
im_detect: 1258/4024 0.220s 0.001s
im_detect: 1259/4024 0.220s 0.001s
im_detect: 1260/4024 0.220s 0.001s
im_detect: 1261/4024 0.220s 0.001s
im_detect: 1262/4024 0.220s 0.001s
im_detect: 1263/4024 0.220s 0.001s
im_detect: 1264/4024 0.220s 0.001s
im_detect: 1265/4024 0.220s 0.001s
im_detect: 1266/4024 0.220s 0.001s
im_detect: 1267/4024 0.220s 0.001s
im_detect: 1268/4024 0.220s 0.001s
im_detect: 1269/4024 0.220s 0.001s
im_detect: 1270/4024 0.220s 0.001s
im_detect: 1271/4024 0.220s 0.001s
im_detect: 1272/4024 0.220s 0.001s
im_detect: 1273/4024 0.220s 0.001s
im_detect: 1274/4024 0.220s 0.001s
im_detect: 1275/4024 0.220s 0.001s
im_detect: 1276/4024 0.220s 0.001s
im_detect: 1277/4024 0.220s 0.001s
im_detect: 1278/4024 0.220s 0.001s
im_detect: 1279/4024 0.219s 0.001s
im_detect: 1280/4024 0.219s 0.001s
im_detect: 1281/4024 0.219s 0.001s
im_detect: 1282/4024 0.219s 0.001s
im_detect: 1283/4024 0.219s 0.001s
im_detect: 1284/4024 0.219s 0.001s
im_detect: 1285/4024 0.219s 0.001s
im_detect: 1286/4024 0.219s 0.001s
im_detect: 1287/4024 0.219s 0.001s
im_detect: 1288/4024 0.219s 0.001s
im_detect: 1289/4024 0.219s 0.001s
im_detect: 1290/4024 0.219s 0.001s
im_detect: 1291/4024 0.219s 0.001s
im_detect: 1292/4024 0.219s 0.001s
im_detect: 1293/4024 0.219s 0.001s
im_detect: 1294/4024 0.219s 0.001s
im_detect: 1295/4024 0.219s 0.001s
im_detect: 1296/4024 0.219s 0.001s
im_detect: 1297/4024 0.219s 0.001s
im_detect: 1298/4024 0.219s 0.001s
im_detect: 1299/4024 0.219s 0.001s
im_detect: 1300/4024 0.219s 0.001s
im_detect: 1301/4024 0.219s 0.001s
im_detect: 1302/4024 0.219s 0.001s
im_detect: 1303/4024 0.219s 0.001s
im_detect: 1304/4024 0.219s 0.001s
im_detect: 1305/4024 0.219s 0.001s
im_detect: 1306/4024 0.219s 0.001s
im_detect: 1307/4024 0.219s 0.001s
im_detect: 1308/4024 0.219s 0.001s
im_detect: 1309/4024 0.219s 0.001s
im_detect: 1310/4024 0.219s 0.001s
im_detect: 1311/4024 0.219s 0.001s
im_detect: 1312/4024 0.219s 0.001s
im_detect: 1313/4024 0.219s 0.001s
im_detect: 1314/4024 0.219s 0.001s
im_detect: 1315/4024 0.219s 0.001s
im_detect: 1316/4024 0.219s 0.001s
im_detect: 1317/4024 0.219s 0.001s
im_detect: 1318/4024 0.219s 0.001s
im_detect: 1319/4024 0.219s 0.001s
im_detect: 1320/4024 0.219s 0.001s
im_detect: 1321/4024 0.219s 0.001s
im_detect: 1322/4024 0.219s 0.001s
im_detect: 1323/4024 0.219s 0.001s
im_detect: 1324/4024 0.219s 0.001s
im_detect: 1325/4024 0.219s 0.001s
im_detect: 1326/4024 0.219s 0.001s
im_detect: 1327/4024 0.219s 0.001s
im_detect: 1328/4024 0.219s 0.001s
im_detect: 1329/4024 0.219s 0.001s
im_detect: 1330/4024 0.219s 0.001s
im_detect: 1331/4024 0.219s 0.001s
im_detect: 1332/4024 0.219s 0.001s
im_detect: 1333/4024 0.219s 0.001s
im_detect: 1334/4024 0.219s 0.001s
im_detect: 1335/4024 0.219s 0.001s
im_detect: 1336/4024 0.219s 0.001s
im_detect: 1337/4024 0.219s 0.001s
im_detect: 1338/4024 0.219s 0.001s
im_detect: 1339/4024 0.219s 0.001s
im_detect: 1340/4024 0.219s 0.001s
im_detect: 1341/4024 0.219s 0.001s
im_detect: 1342/4024 0.219s 0.001s
im_detect: 1343/4024 0.219s 0.001s
im_detect: 1344/4024 0.219s 0.001s
im_detect: 1345/4024 0.219s 0.001s
im_detect: 1346/4024 0.219s 0.001s
im_detect: 1347/4024 0.219s 0.001s
im_detect: 1348/4024 0.219s 0.001s
im_detect: 1349/4024 0.219s 0.001s
im_detect: 1350/4024 0.219s 0.001s
im_detect: 1351/4024 0.219s 0.001s
im_detect: 1352/4024 0.219s 0.001s
im_detect: 1353/4024 0.219s 0.001s
im_detect: 1354/4024 0.219s 0.001s
im_detect: 1355/4024 0.219s 0.001s
im_detect: 1356/4024 0.219s 0.001s
im_detect: 1357/4024 0.219s 0.001s
im_detect: 1358/4024 0.219s 0.001s
im_detect: 1359/4024 0.219s 0.001s
im_detect: 1360/4024 0.219s 0.001s
im_detect: 1361/4024 0.219s 0.001s
im_detect: 1362/4024 0.219s 0.001s
im_detect: 1363/4024 0.219s 0.001s
im_detect: 1364/4024 0.219s 0.001s
im_detect: 1365/4024 0.219s 0.001s
im_detect: 1366/4024 0.219s 0.001s
im_detect: 1367/4024 0.219s 0.001s
im_detect: 1368/4024 0.219s 0.001s
im_detect: 1369/4024 0.219s 0.001s
im_detect: 1370/4024 0.219s 0.001s
im_detect: 1371/4024 0.219s 0.001s
im_detect: 1372/4024 0.219s 0.001s
im_detect: 1373/4024 0.219s 0.001s
im_detect: 1374/4024 0.219s 0.001s
im_detect: 1375/4024 0.219s 0.001s
im_detect: 1376/4024 0.219s 0.001s
im_detect: 1377/4024 0.219s 0.001s
im_detect: 1378/4024 0.219s 0.001s
im_detect: 1379/4024 0.219s 0.001s
im_detect: 1380/4024 0.219s 0.001s
im_detect: 1381/4024 0.219s 0.001s
im_detect: 1382/4024 0.219s 0.001s
im_detect: 1383/4024 0.219s 0.001s
im_detect: 1384/4024 0.219s 0.001s
im_detect: 1385/4024 0.219s 0.001s
im_detect: 1386/4024 0.219s 0.001s
im_detect: 1387/4024 0.219s 0.001s
im_detect: 1388/4024 0.219s 0.001s
im_detect: 1389/4024 0.219s 0.001s
im_detect: 1390/4024 0.219s 0.001s
im_detect: 1391/4024 0.219s 0.001s
im_detect: 1392/4024 0.219s 0.001s
im_detect: 1393/4024 0.219s 0.001s
im_detect: 1394/4024 0.219s 0.001s
im_detect: 1395/4024 0.219s 0.001s
im_detect: 1396/4024 0.219s 0.001s
im_detect: 1397/4024 0.219s 0.001s
im_detect: 1398/4024 0.219s 0.001s
im_detect: 1399/4024 0.219s 0.001s
im_detect: 1400/4024 0.219s 0.001s
im_detect: 1401/4024 0.219s 0.001s
im_detect: 1402/4024 0.219s 0.001s
im_detect: 1403/4024 0.219s 0.001s
im_detect: 1404/4024 0.219s 0.001s
im_detect: 1405/4024 0.219s 0.001s
im_detect: 1406/4024 0.219s 0.001s
im_detect: 1407/4024 0.219s 0.001s
im_detect: 1408/4024 0.219s 0.001s
im_detect: 1409/4024 0.219s 0.001s
im_detect: 1410/4024 0.219s 0.001s
im_detect: 1411/4024 0.219s 0.001s
im_detect: 1412/4024 0.219s 0.001s
im_detect: 1413/4024 0.219s 0.001s
im_detect: 1414/4024 0.219s 0.001s
im_detect: 1415/4024 0.219s 0.001s
im_detect: 1416/4024 0.219s 0.001s
im_detect: 1417/4024 0.219s 0.001s
im_detect: 1418/4024 0.219s 0.001s
im_detect: 1419/4024 0.219s 0.001s
im_detect: 1420/4024 0.219s 0.001s
im_detect: 1421/4024 0.219s 0.001s
im_detect: 1422/4024 0.219s 0.001s
im_detect: 1423/4024 0.219s 0.001s
im_detect: 1424/4024 0.219s 0.001s
im_detect: 1425/4024 0.219s 0.001s
im_detect: 1426/4024 0.219s 0.001s
im_detect: 1427/4024 0.219s 0.001s
im_detect: 1428/4024 0.219s 0.001s
im_detect: 1429/4024 0.219s 0.001s
im_detect: 1430/4024 0.219s 0.001s
im_detect: 1431/4024 0.219s 0.001s
im_detect: 1432/4024 0.219s 0.001s
im_detect: 1433/4024 0.219s 0.001s
im_detect: 1434/4024 0.219s 0.001s
im_detect: 1435/4024 0.219s 0.001s
im_detect: 1436/4024 0.219s 0.001s
im_detect: 1437/4024 0.219s 0.001s
im_detect: 1438/4024 0.219s 0.001s
im_detect: 1439/4024 0.219s 0.001s
im_detect: 1440/4024 0.219s 0.001s
im_detect: 1441/4024 0.219s 0.001s
im_detect: 1442/4024 0.219s 0.001s
im_detect: 1443/4024 0.219s 0.001s
im_detect: 1444/4024 0.219s 0.001s
im_detect: 1445/4024 0.219s 0.001s
im_detect: 1446/4024 0.219s 0.001s
im_detect: 1447/4024 0.219s 0.001s
im_detect: 1448/4024 0.219s 0.001s
im_detect: 1449/4024 0.219s 0.001s
im_detect: 1450/4024 0.219s 0.001s
im_detect: 1451/4024 0.219s 0.001s
im_detect: 1452/4024 0.219s 0.001s
im_detect: 1453/4024 0.219s 0.001s
im_detect: 1454/4024 0.219s 0.001s
im_detect: 1455/4024 0.219s 0.001s
im_detect: 1456/4024 0.219s 0.001s
im_detect: 1457/4024 0.219s 0.001s
im_detect: 1458/4024 0.219s 0.001s
im_detect: 1459/4024 0.219s 0.001s
im_detect: 1460/4024 0.219s 0.001s
im_detect: 1461/4024 0.219s 0.001s
im_detect: 1462/4024 0.219s 0.001s
im_detect: 1463/4024 0.219s 0.001s
im_detect: 1464/4024 0.219s 0.001s
im_detect: 1465/4024 0.219s 0.001s
im_detect: 1466/4024 0.219s 0.001s
im_detect: 1467/4024 0.219s 0.001s
im_detect: 1468/4024 0.219s 0.001s
im_detect: 1469/4024 0.219s 0.001s
im_detect: 1470/4024 0.219s 0.001s
im_detect: 1471/4024 0.219s 0.001s
im_detect: 1472/4024 0.219s 0.001s
im_detect: 1473/4024 0.219s 0.001s
im_detect: 1474/4024 0.219s 0.001s
im_detect: 1475/4024 0.219s 0.001s
im_detect: 1476/4024 0.219s 0.001s
im_detect: 1477/4024 0.219s 0.001s
im_detect: 1478/4024 0.219s 0.001s
im_detect: 1479/4024 0.219s 0.001s
im_detect: 1480/4024 0.219s 0.001s
im_detect: 1481/4024 0.219s 0.001s
im_detect: 1482/4024 0.219s 0.001s
im_detect: 1483/4024 0.219s 0.001s
im_detect: 1484/4024 0.219s 0.001s
im_detect: 1485/4024 0.219s 0.001s
im_detect: 1486/4024 0.219s 0.001s
im_detect: 1487/4024 0.219s 0.001s
im_detect: 1488/4024 0.219s 0.001s
im_detect: 1489/4024 0.219s 0.001s
im_detect: 1490/4024 0.219s 0.001s
im_detect: 1491/4024 0.219s 0.001s
im_detect: 1492/4024 0.219s 0.001s
im_detect: 1493/4024 0.219s 0.001s
im_detect: 1494/4024 0.219s 0.001s
im_detect: 1495/4024 0.219s 0.001s
im_detect: 1496/4024 0.219s 0.001s
im_detect: 1497/4024 0.219s 0.001s
im_detect: 1498/4024 0.219s 0.001s
im_detect: 1499/4024 0.219s 0.001s
im_detect: 1500/4024 0.219s 0.001s
im_detect: 1501/4024 0.219s 0.001s
im_detect: 1502/4024 0.219s 0.001s
im_detect: 1503/4024 0.219s 0.001s
im_detect: 1504/4024 0.219s 0.001s
im_detect: 1505/4024 0.219s 0.001s
im_detect: 1506/4024 0.219s 0.001s
im_detect: 1507/4024 0.219s 0.001s
im_detect: 1508/4024 0.219s 0.001s
im_detect: 1509/4024 0.219s 0.001s
im_detect: 1510/4024 0.219s 0.001s
im_detect: 1511/4024 0.219s 0.001s
im_detect: 1512/4024 0.219s 0.001s
im_detect: 1513/4024 0.219s 0.001s
im_detect: 1514/4024 0.219s 0.001s
im_detect: 1515/4024 0.219s 0.001s
im_detect: 1516/4024 0.219s 0.001s
im_detect: 1517/4024 0.219s 0.001s
im_detect: 1518/4024 0.219s 0.001s
im_detect: 1519/4024 0.219s 0.001s
im_detect: 1520/4024 0.219s 0.001s
im_detect: 1521/4024 0.219s 0.001s
im_detect: 1522/4024 0.219s 0.001s
im_detect: 1523/4024 0.219s 0.001s
im_detect: 1524/4024 0.219s 0.001s
im_detect: 1525/4024 0.219s 0.001s
im_detect: 1526/4024 0.219s 0.001s
im_detect: 1527/4024 0.219s 0.001s
im_detect: 1528/4024 0.219s 0.001s
im_detect: 1529/4024 0.219s 0.001s
im_detect: 1530/4024 0.219s 0.001s
im_detect: 1531/4024 0.219s 0.001s
im_detect: 1532/4024 0.219s 0.001s
im_detect: 1533/4024 0.219s 0.001s
im_detect: 1534/4024 0.219s 0.001s
im_detect: 1535/4024 0.219s 0.001s
im_detect: 1536/4024 0.219s 0.001s
im_detect: 1537/4024 0.219s 0.001s
im_detect: 1538/4024 0.219s 0.001s
im_detect: 1539/4024 0.219s 0.001s
im_detect: 1540/4024 0.219s 0.001s
im_detect: 1541/4024 0.219s 0.001s
im_detect: 1542/4024 0.219s 0.001s
im_detect: 1543/4024 0.219s 0.001s
im_detect: 1544/4024 0.219s 0.001s
im_detect: 1545/4024 0.219s 0.001s
im_detect: 1546/4024 0.219s 0.001s
im_detect: 1547/4024 0.219s 0.001s
im_detect: 1548/4024 0.219s 0.001s
im_detect: 1549/4024 0.219s 0.001s
im_detect: 1550/4024 0.219s 0.001s
im_detect: 1551/4024 0.219s 0.001s
im_detect: 1552/4024 0.219s 0.001s
im_detect: 1553/4024 0.219s 0.001s
im_detect: 1554/4024 0.219s 0.001s
im_detect: 1555/4024 0.219s 0.001s
im_detect: 1556/4024 0.219s 0.001s
im_detect: 1557/4024 0.219s 0.001s
im_detect: 1558/4024 0.219s 0.001s
im_detect: 1559/4024 0.219s 0.001s
im_detect: 1560/4024 0.219s 0.001s
im_detect: 1561/4024 0.219s 0.001s
im_detect: 1562/4024 0.219s 0.001s
im_detect: 1563/4024 0.219s 0.001s
im_detect: 1564/4024 0.219s 0.001s
im_detect: 1565/4024 0.219s 0.001s
im_detect: 1566/4024 0.219s 0.001s
im_detect: 1567/4024 0.219s 0.001s
im_detect: 1568/4024 0.219s 0.001s
im_detect: 1569/4024 0.219s 0.001s
im_detect: 1570/4024 0.219s 0.001s
im_detect: 1571/4024 0.219s 0.001s
im_detect: 1572/4024 0.219s 0.001s
im_detect: 1573/4024 0.219s 0.001s
im_detect: 1574/4024 0.219s 0.001s
im_detect: 1575/4024 0.219s 0.001s
im_detect: 1576/4024 0.219s 0.001s
im_detect: 1577/4024 0.219s 0.001s
im_detect: 1578/4024 0.219s 0.001s
im_detect: 1579/4024 0.219s 0.001s
im_detect: 1580/4024 0.219s 0.001s
im_detect: 1581/4024 0.219s 0.001s
im_detect: 1582/4024 0.219s 0.001s
im_detect: 1583/4024 0.219s 0.001s
im_detect: 1584/4024 0.219s 0.001s
im_detect: 1585/4024 0.219s 0.001s
im_detect: 1586/4024 0.219s 0.001s
im_detect: 1587/4024 0.219s 0.001s
im_detect: 1588/4024 0.219s 0.001s
im_detect: 1589/4024 0.219s 0.001s
im_detect: 1590/4024 0.219s 0.001s
im_detect: 1591/4024 0.219s 0.001s
im_detect: 1592/4024 0.219s 0.001s
im_detect: 1593/4024 0.219s 0.001s
im_detect: 1594/4024 0.219s 0.001s
im_detect: 1595/4024 0.219s 0.001s
im_detect: 1596/4024 0.219s 0.001s
im_detect: 1597/4024 0.219s 0.001s
im_detect: 1598/4024 0.219s 0.001s
im_detect: 1599/4024 0.219s 0.001s
im_detect: 1600/4024 0.219s 0.001s
im_detect: 1601/4024 0.219s 0.001s
im_detect: 1602/4024 0.219s 0.001s
im_detect: 1603/4024 0.219s 0.001s
im_detect: 1604/4024 0.219s 0.001s
im_detect: 1605/4024 0.219s 0.001s
im_detect: 1606/4024 0.219s 0.001s
im_detect: 1607/4024 0.219s 0.001s
im_detect: 1608/4024 0.219s 0.001s
im_detect: 1609/4024 0.219s 0.001s
im_detect: 1610/4024 0.219s 0.001s
im_detect: 1611/4024 0.219s 0.001s
im_detect: 1612/4024 0.219s 0.001s
im_detect: 1613/4024 0.219s 0.001s
im_detect: 1614/4024 0.219s 0.001s
im_detect: 1615/4024 0.219s 0.001s
im_detect: 1616/4024 0.219s 0.001s
im_detect: 1617/4024 0.219s 0.001s
im_detect: 1618/4024 0.219s 0.001s
im_detect: 1619/4024 0.219s 0.001s
im_detect: 1620/4024 0.219s 0.001s
im_detect: 1621/4024 0.219s 0.001s
im_detect: 1622/4024 0.219s 0.001s
im_detect: 1623/4024 0.219s 0.001s
im_detect: 1624/4024 0.219s 0.001s
im_detect: 1625/4024 0.219s 0.001s
im_detect: 1626/4024 0.219s 0.001s
im_detect: 1627/4024 0.219s 0.001s
im_detect: 1628/4024 0.219s 0.001s
im_detect: 1629/4024 0.219s 0.001s
im_detect: 1630/4024 0.219s 0.001s
im_detect: 1631/4024 0.219s 0.001s
im_detect: 1632/4024 0.219s 0.001s
im_detect: 1633/4024 0.219s 0.001s
im_detect: 1634/4024 0.219s 0.001s
im_detect: 1635/4024 0.219s 0.001s
im_detect: 1636/4024 0.219s 0.001s
im_detect: 1637/4024 0.219s 0.001s
im_detect: 1638/4024 0.219s 0.001s
im_detect: 1639/4024 0.219s 0.001s
im_detect: 1640/4024 0.219s 0.001s
im_detect: 1641/4024 0.219s 0.001s
im_detect: 1642/4024 0.219s 0.001s
im_detect: 1643/4024 0.219s 0.001s
im_detect: 1644/4024 0.219s 0.001s
im_detect: 1645/4024 0.219s 0.001s
im_detect: 1646/4024 0.219s 0.001s
im_detect: 1647/4024 0.219s 0.001s
im_detect: 1648/4024 0.219s 0.001s
im_detect: 1649/4024 0.219s 0.001s
im_detect: 1650/4024 0.219s 0.001s
im_detect: 1651/4024 0.219s 0.001s
im_detect: 1652/4024 0.219s 0.001s
im_detect: 1653/4024 0.219s 0.001s
im_detect: 1654/4024 0.219s 0.001s
im_detect: 1655/4024 0.219s 0.001s
im_detect: 1656/4024 0.219s 0.001s
im_detect: 1657/4024 0.219s 0.001s
im_detect: 1658/4024 0.219s 0.001s
im_detect: 1659/4024 0.219s 0.001s
im_detect: 1660/4024 0.219s 0.001s
im_detect: 1661/4024 0.219s 0.001s
im_detect: 1662/4024 0.218s 0.001s
im_detect: 1663/4024 0.218s 0.001s
im_detect: 1664/4024 0.218s 0.001s
im_detect: 1665/4024 0.218s 0.001s
im_detect: 1666/4024 0.218s 0.001s
im_detect: 1667/4024 0.218s 0.001s
im_detect: 1668/4024 0.218s 0.001s
im_detect: 1669/4024 0.218s 0.001s
im_detect: 1670/4024 0.218s 0.001s
im_detect: 1671/4024 0.218s 0.001s
im_detect: 1672/4024 0.218s 0.001s
im_detect: 1673/4024 0.218s 0.001s
im_detect: 1674/4024 0.218s 0.001s
im_detect: 1675/4024 0.218s 0.001s
im_detect: 1676/4024 0.218s 0.001s
im_detect: 1677/4024 0.218s 0.001s
im_detect: 1678/4024 0.218s 0.001s
im_detect: 1679/4024 0.218s 0.001s
im_detect: 1680/4024 0.218s 0.001s
im_detect: 1681/4024 0.218s 0.001s
im_detect: 1682/4024 0.218s 0.001s
im_detect: 1683/4024 0.218s 0.000s
im_detect: 1684/4024 0.218s 0.000s
im_detect: 1685/4024 0.218s 0.000s
im_detect: 1686/4024 0.218s 0.000s
im_detect: 1687/4024 0.218s 0.000s
im_detect: 1688/4024 0.218s 0.000s
im_detect: 1689/4024 0.218s 0.000s
im_detect: 1690/4024 0.218s 0.000s
im_detect: 1691/4024 0.218s 0.000s
im_detect: 1692/4024 0.218s 0.000s
im_detect: 1693/4024 0.218s 0.000s
im_detect: 1694/4024 0.218s 0.000s
im_detect: 1695/4024 0.218s 0.000s
im_detect: 1696/4024 0.218s 0.000s
im_detect: 1697/4024 0.218s 0.000s
im_detect: 1698/4024 0.218s 0.000s
im_detect: 1699/4024 0.218s 0.000s
im_detect: 1700/4024 0.218s 0.000s
im_detect: 1701/4024 0.218s 0.000s
im_detect: 1702/4024 0.218s 0.000s
im_detect: 1703/4024 0.218s 0.000s
im_detect: 1704/4024 0.218s 0.000s
im_detect: 1705/4024 0.218s 0.000s
im_detect: 1706/4024 0.218s 0.000s
im_detect: 1707/4024 0.218s 0.000s
im_detect: 1708/4024 0.218s 0.000s
im_detect: 1709/4024 0.218s 0.000s
im_detect: 1710/4024 0.218s 0.000s
im_detect: 1711/4024 0.218s 0.000s
im_detect: 1712/4024 0.218s 0.000s
im_detect: 1713/4024 0.218s 0.000s
im_detect: 1714/4024 0.218s 0.000s
im_detect: 1715/4024 0.218s 0.000s
im_detect: 1716/4024 0.218s 0.000s
im_detect: 1717/4024 0.218s 0.000s
im_detect: 1718/4024 0.218s 0.000s
im_detect: 1719/4024 0.218s 0.000s
im_detect: 1720/4024 0.218s 0.000s
im_detect: 1721/4024 0.218s 0.000s
im_detect: 1722/4024 0.218s 0.000s
im_detect: 1723/4024 0.218s 0.000s
im_detect: 1724/4024 0.218s 0.000s
im_detect: 1725/4024 0.218s 0.000s
im_detect: 1726/4024 0.218s 0.000s
im_detect: 1727/4024 0.218s 0.000s
im_detect: 1728/4024 0.218s 0.000s
im_detect: 1729/4024 0.218s 0.000s
im_detect: 1730/4024 0.218s 0.000s
im_detect: 1731/4024 0.218s 0.000s
im_detect: 1732/4024 0.218s 0.000s
im_detect: 1733/4024 0.218s 0.000s
im_detect: 1734/4024 0.218s 0.000s
im_detect: 1735/4024 0.218s 0.000s
im_detect: 1736/4024 0.218s 0.000s
im_detect: 1737/4024 0.218s 0.000s
im_detect: 1738/4024 0.218s 0.000s
im_detect: 1739/4024 0.218s 0.000s
im_detect: 1740/4024 0.218s 0.000s
im_detect: 1741/4024 0.218s 0.000s
im_detect: 1742/4024 0.218s 0.000s
im_detect: 1743/4024 0.218s 0.000s
im_detect: 1744/4024 0.218s 0.000s
im_detect: 1745/4024 0.218s 0.000s
im_detect: 1746/4024 0.218s 0.000s
im_detect: 1747/4024 0.218s 0.000s
im_detect: 1748/4024 0.218s 0.000s
im_detect: 1749/4024 0.218s 0.000s
im_detect: 1750/4024 0.218s 0.000s
im_detect: 1751/4024 0.218s 0.000s
im_detect: 1752/4024 0.218s 0.000s
im_detect: 1753/4024 0.218s 0.000s
im_detect: 1754/4024 0.218s 0.000s
im_detect: 1755/4024 0.218s 0.000s
im_detect: 1756/4024 0.218s 0.000s
im_detect: 1757/4024 0.218s 0.000s
im_detect: 1758/4024 0.218s 0.000s
im_detect: 1759/4024 0.218s 0.000s
im_detect: 1760/4024 0.218s 0.000s
im_detect: 1761/4024 0.218s 0.000s
im_detect: 1762/4024 0.218s 0.000s
im_detect: 1763/4024 0.218s 0.000s
im_detect: 1764/4024 0.218s 0.000s
im_detect: 1765/4024 0.218s 0.000s
im_detect: 1766/4024 0.218s 0.000s
im_detect: 1767/4024 0.218s 0.000s
im_detect: 1768/4024 0.218s 0.000s
im_detect: 1769/4024 0.218s 0.000s
im_detect: 1770/4024 0.218s 0.000s
im_detect: 1771/4024 0.218s 0.000s
im_detect: 1772/4024 0.218s 0.000s
im_detect: 1773/4024 0.218s 0.000s
im_detect: 1774/4024 0.218s 0.000s
im_detect: 1775/4024 0.218s 0.000s
im_detect: 1776/4024 0.218s 0.000s
im_detect: 1777/4024 0.218s 0.000s
im_detect: 1778/4024 0.218s 0.000s
im_detect: 1779/4024 0.218s 0.000s
im_detect: 1780/4024 0.218s 0.000s
im_detect: 1781/4024 0.218s 0.000s
im_detect: 1782/4024 0.218s 0.000s
im_detect: 1783/4024 0.218s 0.000s
im_detect: 1784/4024 0.218s 0.000s
im_detect: 1785/4024 0.218s 0.000s
im_detect: 1786/4024 0.218s 0.000s
im_detect: 1787/4024 0.218s 0.000s
im_detect: 1788/4024 0.218s 0.000s
im_detect: 1789/4024 0.218s 0.000s
im_detect: 1790/4024 0.218s 0.000s
im_detect: 1791/4024 0.218s 0.000s
im_detect: 1792/4024 0.218s 0.000s
im_detect: 1793/4024 0.218s 0.000s
im_detect: 1794/4024 0.218s 0.000s
im_detect: 1795/4024 0.218s 0.000s
im_detect: 1796/4024 0.218s 0.000s
im_detect: 1797/4024 0.218s 0.000s
im_detect: 1798/4024 0.218s 0.000s
im_detect: 1799/4024 0.218s 0.000s
im_detect: 1800/4024 0.218s 0.000s
im_detect: 1801/4024 0.218s 0.000s
im_detect: 1802/4024 0.218s 0.000s
im_detect: 1803/4024 0.218s 0.000s
im_detect: 1804/4024 0.218s 0.000s
im_detect: 1805/4024 0.218s 0.000s
im_detect: 1806/4024 0.218s 0.000s
im_detect: 1807/4024 0.218s 0.000s
im_detect: 1808/4024 0.218s 0.000s
im_detect: 1809/4024 0.218s 0.000s
im_detect: 1810/4024 0.218s 0.000s
im_detect: 1811/4024 0.218s 0.000s
im_detect: 1812/4024 0.218s 0.000s
im_detect: 1813/4024 0.218s 0.000s
im_detect: 1814/4024 0.218s 0.000s
im_detect: 1815/4024 0.218s 0.000s
im_detect: 1816/4024 0.218s 0.000s
im_detect: 1817/4024 0.218s 0.000s
im_detect: 1818/4024 0.218s 0.000s
im_detect: 1819/4024 0.218s 0.000s
im_detect: 1820/4024 0.218s 0.000s
im_detect: 1821/4024 0.218s 0.000s
im_detect: 1822/4024 0.218s 0.000s
im_detect: 1823/4024 0.218s 0.000s
im_detect: 1824/4024 0.218s 0.000s
im_detect: 1825/4024 0.218s 0.000s
im_detect: 1826/4024 0.218s 0.000s
im_detect: 1827/4024 0.218s 0.000s
im_detect: 1828/4024 0.218s 0.000s
im_detect: 1829/4024 0.218s 0.000s
im_detect: 1830/4024 0.218s 0.000s
im_detect: 1831/4024 0.218s 0.000s
im_detect: 1832/4024 0.218s 0.000s
im_detect: 1833/4024 0.218s 0.000s
im_detect: 1834/4024 0.218s 0.000s
im_detect: 1835/4024 0.218s 0.000s
im_detect: 1836/4024 0.218s 0.000s
im_detect: 1837/4024 0.218s 0.000s
im_detect: 1838/4024 0.218s 0.000s
im_detect: 1839/4024 0.218s 0.000s
im_detect: 1840/4024 0.218s 0.000s
im_detect: 1841/4024 0.218s 0.000s
im_detect: 1842/4024 0.218s 0.000s
im_detect: 1843/4024 0.218s 0.000s
im_detect: 1844/4024 0.218s 0.000s
im_detect: 1845/4024 0.218s 0.000s
im_detect: 1846/4024 0.218s 0.000s
im_detect: 1847/4024 0.218s 0.000s
im_detect: 1848/4024 0.218s 0.000s
im_detect: 1849/4024 0.218s 0.000s
im_detect: 1850/4024 0.218s 0.000s
im_detect: 1851/4024 0.218s 0.000s
im_detect: 1852/4024 0.218s 0.000s
im_detect: 1853/4024 0.218s 0.000s
im_detect: 1854/4024 0.218s 0.000s
im_detect: 1855/4024 0.218s 0.000s
im_detect: 1856/4024 0.218s 0.000s
im_detect: 1857/4024 0.218s 0.000s
im_detect: 1858/4024 0.218s 0.000s
im_detect: 1859/4024 0.218s 0.000s
im_detect: 1860/4024 0.218s 0.000s
im_detect: 1861/4024 0.218s 0.000s
im_detect: 1862/4024 0.218s 0.000s
im_detect: 1863/4024 0.218s 0.000s
im_detect: 1864/4024 0.218s 0.000s
im_detect: 1865/4024 0.218s 0.000s
im_detect: 1866/4024 0.218s 0.000s
im_detect: 1867/4024 0.218s 0.000s
im_detect: 1868/4024 0.218s 0.000s
im_detect: 1869/4024 0.218s 0.000s
im_detect: 1870/4024 0.218s 0.000s
im_detect: 1871/4024 0.218s 0.000s
im_detect: 1872/4024 0.218s 0.000s
im_detect: 1873/4024 0.218s 0.000s
im_detect: 1874/4024 0.218s 0.000s
im_detect: 1875/4024 0.218s 0.000s
im_detect: 1876/4024 0.218s 0.000s
im_detect: 1877/4024 0.218s 0.000s
im_detect: 1878/4024 0.218s 0.000s
im_detect: 1879/4024 0.218s 0.000s
im_detect: 1880/4024 0.218s 0.000s
im_detect: 1881/4024 0.218s 0.000s
im_detect: 1882/4024 0.218s 0.000s
im_detect: 1883/4024 0.218s 0.000s
im_detect: 1884/4024 0.218s 0.000s
im_detect: 1885/4024 0.218s 0.000s
im_detect: 1886/4024 0.218s 0.000s
im_detect: 1887/4024 0.218s 0.000s
im_detect: 1888/4024 0.218s 0.000s
im_detect: 1889/4024 0.218s 0.000s
im_detect: 1890/4024 0.218s 0.000s
im_detect: 1891/4024 0.218s 0.000s
im_detect: 1892/4024 0.218s 0.000s
im_detect: 1893/4024 0.218s 0.000s
im_detect: 1894/4024 0.218s 0.000s
im_detect: 1895/4024 0.218s 0.000s
im_detect: 1896/4024 0.218s 0.000s
im_detect: 1897/4024 0.218s 0.000s
im_detect: 1898/4024 0.218s 0.000s
im_detect: 1899/4024 0.218s 0.000s
im_detect: 1900/4024 0.218s 0.000s
im_detect: 1901/4024 0.218s 0.000s
im_detect: 1902/4024 0.218s 0.000s
im_detect: 1903/4024 0.218s 0.000s
im_detect: 1904/4024 0.218s 0.000s
im_detect: 1905/4024 0.218s 0.000s
im_detect: 1906/4024 0.218s 0.000s
im_detect: 1907/4024 0.218s 0.000s
im_detect: 1908/4024 0.218s 0.000s
im_detect: 1909/4024 0.218s 0.000s
im_detect: 1910/4024 0.218s 0.000s
im_detect: 1911/4024 0.218s 0.000s
im_detect: 1912/4024 0.218s 0.000s
im_detect: 1913/4024 0.218s 0.000s
im_detect: 1914/4024 0.218s 0.000s
im_detect: 1915/4024 0.218s 0.000s
im_detect: 1916/4024 0.218s 0.000s
im_detect: 1917/4024 0.218s 0.000s
im_detect: 1918/4024 0.218s 0.000s
im_detect: 1919/4024 0.218s 0.000s
im_detect: 1920/4024 0.218s 0.001s
im_detect: 1921/4024 0.218s 0.001s
im_detect: 1922/4024 0.218s 0.001s
im_detect: 1923/4024 0.218s 0.001s
im_detect: 1924/4024 0.218s 0.001s
im_detect: 1925/4024 0.218s 0.001s
im_detect: 1926/4024 0.218s 0.001s
im_detect: 1927/4024 0.218s 0.001s
im_detect: 1928/4024 0.218s 0.001s
im_detect: 1929/4024 0.218s 0.001s
im_detect: 1930/4024 0.218s 0.001s
im_detect: 1931/4024 0.218s 0.001s
im_detect: 1932/4024 0.218s 0.001s
im_detect: 1933/4024 0.218s 0.001s
im_detect: 1934/4024 0.218s 0.001s
im_detect: 1935/4024 0.218s 0.001s
im_detect: 1936/4024 0.218s 0.001s
im_detect: 1937/4024 0.218s 0.001s
im_detect: 1938/4024 0.218s 0.001s
im_detect: 1939/4024 0.218s 0.001s
im_detect: 1940/4024 0.218s 0.001s
im_detect: 1941/4024 0.218s 0.001s
im_detect: 1942/4024 0.218s 0.001s
im_detect: 1943/4024 0.218s 0.001s
im_detect: 1944/4024 0.218s 0.001s
im_detect: 1945/4024 0.218s 0.001s
im_detect: 1946/4024 0.218s 0.001s
im_detect: 1947/4024 0.218s 0.001s
im_detect: 1948/4024 0.218s 0.001s
im_detect: 1949/4024 0.218s 0.001s
im_detect: 1950/4024 0.218s 0.001s
im_detect: 1951/4024 0.218s 0.001s
im_detect: 1952/4024 0.218s 0.001s
im_detect: 1953/4024 0.218s 0.001s
im_detect: 1954/4024 0.218s 0.001s
im_detect: 1955/4024 0.218s 0.001s
im_detect: 1956/4024 0.218s 0.001s
im_detect: 1957/4024 0.218s 0.001s
im_detect: 1958/4024 0.218s 0.001s
im_detect: 1959/4024 0.218s 0.001s
im_detect: 1960/4024 0.218s 0.001s
im_detect: 1961/4024 0.218s 0.001s
im_detect: 1962/4024 0.218s 0.001s
im_detect: 1963/4024 0.218s 0.001s
im_detect: 1964/4024 0.218s 0.001s
im_detect: 1965/4024 0.218s 0.001s
im_detect: 1966/4024 0.218s 0.001s
im_detect: 1967/4024 0.218s 0.001s
im_detect: 1968/4024 0.218s 0.001s
im_detect: 1969/4024 0.218s 0.001s
im_detect: 1970/4024 0.218s 0.001s
im_detect: 1971/4024 0.218s 0.001s
im_detect: 1972/4024 0.218s 0.001s
im_detect: 1973/4024 0.218s 0.001s
im_detect: 1974/4024 0.218s 0.001s
im_detect: 1975/4024 0.218s 0.001s
im_detect: 1976/4024 0.218s 0.001s
im_detect: 1977/4024 0.218s 0.001s
im_detect: 1978/4024 0.218s 0.001s
im_detect: 1979/4024 0.218s 0.001s
im_detect: 1980/4024 0.218s 0.001s
im_detect: 1981/4024 0.218s 0.001s
im_detect: 1982/4024 0.218s 0.001s
im_detect: 1983/4024 0.218s 0.001s
im_detect: 1984/4024 0.218s 0.001s
im_detect: 1985/4024 0.218s 0.001s
im_detect: 1986/4024 0.218s 0.001s
im_detect: 1987/4024 0.218s 0.001s
im_detect: 1988/4024 0.218s 0.001s
im_detect: 1989/4024 0.218s 0.001s
im_detect: 1990/4024 0.218s 0.001s
im_detect: 1991/4024 0.218s 0.001s
im_detect: 1992/4024 0.218s 0.001s
im_detect: 1993/4024 0.218s 0.001s
im_detect: 1994/4024 0.218s 0.001s
im_detect: 1995/4024 0.218s 0.001s
im_detect: 1996/4024 0.218s 0.001s
im_detect: 1997/4024 0.218s 0.001s
im_detect: 1998/4024 0.218s 0.001s
im_detect: 1999/4024 0.218s 0.001s
im_detect: 2000/4024 0.218s 0.001s
im_detect: 2001/4024 0.218s 0.001s
im_detect: 2002/4024 0.218s 0.001s
im_detect: 2003/4024 0.218s 0.001s
im_detect: 2004/4024 0.218s 0.001s
im_detect: 2005/4024 0.218s 0.001s
im_detect: 2006/4024 0.218s 0.001s
im_detect: 2007/4024 0.218s 0.001s
im_detect: 2008/4024 0.218s 0.001s
im_detect: 2009/4024 0.218s 0.001s
im_detect: 2010/4024 0.218s 0.001s
im_detect: 2011/4024 0.218s 0.001s
im_detect: 2012/4024 0.218s 0.001s
im_detect: 2013/4024 0.218s 0.001s
im_detect: 2014/4024 0.218s 0.001s
im_detect: 2015/4024 0.218s 0.001s
im_detect: 2016/4024 0.218s 0.001s
im_detect: 2017/4024 0.218s 0.001s
im_detect: 2018/4024 0.218s 0.001s
im_detect: 2019/4024 0.218s 0.001s
im_detect: 2020/4024 0.218s 0.001s
im_detect: 2021/4024 0.218s 0.001s
im_detect: 2022/4024 0.218s 0.001s
im_detect: 2023/4024 0.218s 0.001s
im_detect: 2024/4024 0.218s 0.001s
im_detect: 2025/4024 0.218s 0.001s
im_detect: 2026/4024 0.218s 0.001s
im_detect: 2027/4024 0.218s 0.001s
im_detect: 2028/4024 0.218s 0.001s
im_detect: 2029/4024 0.218s 0.001s
im_detect: 2030/4024 0.218s 0.001s
im_detect: 2031/4024 0.218s 0.001s
im_detect: 2032/4024 0.218s 0.001s
im_detect: 2033/4024 0.218s 0.001s
im_detect: 2034/4024 0.218s 0.001s
im_detect: 2035/4024 0.218s 0.001s
im_detect: 2036/4024 0.218s 0.001s
im_detect: 2037/4024 0.218s 0.001s
im_detect: 2038/4024 0.218s 0.001s
im_detect: 2039/4024 0.218s 0.001s
im_detect: 2040/4024 0.218s 0.001s
im_detect: 2041/4024 0.218s 0.001s
im_detect: 2042/4024 0.218s 0.001s
im_detect: 2043/4024 0.218s 0.001s
im_detect: 2044/4024 0.218s 0.001s
im_detect: 2045/4024 0.218s 0.001s
im_detect: 2046/4024 0.218s 0.001s
im_detect: 2047/4024 0.218s 0.001s
im_detect: 2048/4024 0.218s 0.001s
im_detect: 2049/4024 0.218s 0.001s
im_detect: 2050/4024 0.218s 0.001s
im_detect: 2051/4024 0.218s 0.001s
im_detect: 2052/4024 0.218s 0.001s
im_detect: 2053/4024 0.218s 0.001s
im_detect: 2054/4024 0.218s 0.001s
im_detect: 2055/4024 0.218s 0.001s
im_detect: 2056/4024 0.218s 0.001s
im_detect: 2057/4024 0.218s 0.001s
im_detect: 2058/4024 0.218s 0.001s
im_detect: 2059/4024 0.218s 0.001s
im_detect: 2060/4024 0.218s 0.001s
im_detect: 2061/4024 0.218s 0.001s
im_detect: 2062/4024 0.218s 0.001s
im_detect: 2063/4024 0.218s 0.001s
im_detect: 2064/4024 0.218s 0.001s
im_detect: 2065/4024 0.218s 0.001s
im_detect: 2066/4024 0.218s 0.001s
im_detect: 2067/4024 0.218s 0.001s
im_detect: 2068/4024 0.218s 0.001s
im_detect: 2069/4024 0.218s 0.001s
im_detect: 2070/4024 0.218s 0.001s
im_detect: 2071/4024 0.218s 0.001s
im_detect: 2072/4024 0.218s 0.001s
im_detect: 2073/4024 0.218s 0.001s
im_detect: 2074/4024 0.218s 0.001s
im_detect: 2075/4024 0.218s 0.001s
im_detect: 2076/4024 0.218s 0.001s
im_detect: 2077/4024 0.218s 0.001s
im_detect: 2078/4024 0.218s 0.001s
im_detect: 2079/4024 0.218s 0.001s
im_detect: 2080/4024 0.218s 0.001s
im_detect: 2081/4024 0.218s 0.001s
im_detect: 2082/4024 0.218s 0.001s
im_detect: 2083/4024 0.218s 0.001s
im_detect: 2084/4024 0.218s 0.001s
im_detect: 2085/4024 0.218s 0.001s
im_detect: 2086/4024 0.218s 0.001s
im_detect: 2087/4024 0.218s 0.001s
im_detect: 2088/4024 0.218s 0.001s
im_detect: 2089/4024 0.218s 0.001s
im_detect: 2090/4024 0.218s 0.001s
im_detect: 2091/4024 0.218s 0.001s
im_detect: 2092/4024 0.218s 0.001s
im_detect: 2093/4024 0.218s 0.001s
im_detect: 2094/4024 0.218s 0.001s
im_detect: 2095/4024 0.218s 0.001s
im_detect: 2096/4024 0.218s 0.001s
im_detect: 2097/4024 0.218s 0.001s
im_detect: 2098/4024 0.218s 0.001s
im_detect: 2099/4024 0.218s 0.001s
im_detect: 2100/4024 0.218s 0.001s
im_detect: 2101/4024 0.218s 0.001s
im_detect: 2102/4024 0.218s 0.001s
im_detect: 2103/4024 0.218s 0.001s
im_detect: 2104/4024 0.218s 0.001s
im_detect: 2105/4024 0.218s 0.001s
im_detect: 2106/4024 0.218s 0.001s
im_detect: 2107/4024 0.218s 0.001s
im_detect: 2108/4024 0.218s 0.001s
im_detect: 2109/4024 0.218s 0.001s
im_detect: 2110/4024 0.218s 0.001s
im_detect: 2111/4024 0.218s 0.001s
im_detect: 2112/4024 0.218s 0.001s
im_detect: 2113/4024 0.218s 0.001s
im_detect: 2114/4024 0.218s 0.001s
im_detect: 2115/4024 0.218s 0.001s
im_detect: 2116/4024 0.218s 0.001s
im_detect: 2117/4024 0.218s 0.001s
im_detect: 2118/4024 0.218s 0.001s
im_detect: 2119/4024 0.218s 0.001s
im_detect: 2120/4024 0.218s 0.001s
im_detect: 2121/4024 0.218s 0.001s
im_detect: 2122/4024 0.218s 0.001s
im_detect: 2123/4024 0.218s 0.001s
im_detect: 2124/4024 0.218s 0.001s
im_detect: 2125/4024 0.218s 0.001s
im_detect: 2126/4024 0.218s 0.001s
im_detect: 2127/4024 0.219s 0.001s
im_detect: 2128/4024 0.219s 0.001s
im_detect: 2129/4024 0.219s 0.001s
im_detect: 2130/4024 0.219s 0.001s
im_detect: 2131/4024 0.219s 0.001s
im_detect: 2132/4024 0.219s 0.001s
im_detect: 2133/4024 0.219s 0.001s
im_detect: 2134/4024 0.219s 0.001s
im_detect: 2135/4024 0.219s 0.001s
im_detect: 2136/4024 0.219s 0.001s
im_detect: 2137/4024 0.219s 0.001s
im_detect: 2138/4024 0.219s 0.001s
im_detect: 2139/4024 0.219s 0.001s
im_detect: 2140/4024 0.219s 0.001s
im_detect: 2141/4024 0.219s 0.001s
im_detect: 2142/4024 0.219s 0.001s
im_detect: 2143/4024 0.219s 0.001s
im_detect: 2144/4024 0.219s 0.001s
im_detect: 2145/4024 0.219s 0.001s
im_detect: 2146/4024 0.219s 0.001s
im_detect: 2147/4024 0.219s 0.001s
im_detect: 2148/4024 0.219s 0.001s
im_detect: 2149/4024 0.219s 0.001s
im_detect: 2150/4024 0.219s 0.001s
im_detect: 2151/4024 0.219s 0.001s
im_detect: 2152/4024 0.219s 0.001s
im_detect: 2153/4024 0.219s 0.001s
im_detect: 2154/4024 0.219s 0.001s
im_detect: 2155/4024 0.219s 0.001s
im_detect: 2156/4024 0.219s 0.001s
im_detect: 2157/4024 0.219s 0.001s
im_detect: 2158/4024 0.219s 0.001s
im_detect: 2159/4024 0.219s 0.001s
im_detect: 2160/4024 0.219s 0.001s
im_detect: 2161/4024 0.219s 0.001s
im_detect: 2162/4024 0.219s 0.001s
im_detect: 2163/4024 0.219s 0.001s
im_detect: 2164/4024 0.219s 0.001s
im_detect: 2165/4024 0.219s 0.001s
im_detect: 2166/4024 0.219s 0.001s
im_detect: 2167/4024 0.219s 0.001s
im_detect: 2168/4024 0.219s 0.001s
im_detect: 2169/4024 0.219s 0.001s
im_detect: 2170/4024 0.219s 0.001s
im_detect: 2171/4024 0.219s 0.001s
im_detect: 2172/4024 0.219s 0.001s
im_detect: 2173/4024 0.219s 0.001s
im_detect: 2174/4024 0.219s 0.001s
im_detect: 2175/4024 0.219s 0.001s
im_detect: 2176/4024 0.219s 0.001s
im_detect: 2177/4024 0.219s 0.001s
im_detect: 2178/4024 0.219s 0.001s
im_detect: 2179/4024 0.219s 0.001s
im_detect: 2180/4024 0.219s 0.001s
im_detect: 2181/4024 0.219s 0.001s
im_detect: 2182/4024 0.219s 0.001s
im_detect: 2183/4024 0.219s 0.001s
im_detect: 2184/4024 0.219s 0.001s
im_detect: 2185/4024 0.219s 0.001s
im_detect: 2186/4024 0.219s 0.001s
im_detect: 2187/4024 0.219s 0.001s
im_detect: 2188/4024 0.219s 0.001s
im_detect: 2189/4024 0.219s 0.001s
im_detect: 2190/4024 0.219s 0.001s
im_detect: 2191/4024 0.219s 0.001s
im_detect: 2192/4024 0.219s 0.001s
im_detect: 2193/4024 0.219s 0.001s
im_detect: 2194/4024 0.219s 0.001s
im_detect: 2195/4024 0.219s 0.001s
im_detect: 2196/4024 0.219s 0.001s
im_detect: 2197/4024 0.219s 0.001s
im_detect: 2198/4024 0.219s 0.001s
im_detect: 2199/4024 0.219s 0.001s
im_detect: 2200/4024 0.219s 0.001s
im_detect: 2201/4024 0.219s 0.001s
im_detect: 2202/4024 0.219s 0.001s
im_detect: 2203/4024 0.219s 0.001s
im_detect: 2204/4024 0.219s 0.001s
im_detect: 2205/4024 0.219s 0.001s
im_detect: 2206/4024 0.219s 0.001s
im_detect: 2207/4024 0.219s 0.001s
im_detect: 2208/4024 0.219s 0.001s
im_detect: 2209/4024 0.219s 0.001s
im_detect: 2210/4024 0.219s 0.001s
im_detect: 2211/4024 0.219s 0.001s
im_detect: 2212/4024 0.219s 0.001s
im_detect: 2213/4024 0.219s 0.001s
im_detect: 2214/4024 0.219s 0.001s
im_detect: 2215/4024 0.219s 0.001s
im_detect: 2216/4024 0.219s 0.001s
im_detect: 2217/4024 0.219s 0.001s
im_detect: 2218/4024 0.219s 0.001s
im_detect: 2219/4024 0.219s 0.001s
im_detect: 2220/4024 0.219s 0.001s
im_detect: 2221/4024 0.219s 0.001s
im_detect: 2222/4024 0.219s 0.001s
im_detect: 2223/4024 0.219s 0.001s
im_detect: 2224/4024 0.219s 0.001s
im_detect: 2225/4024 0.219s 0.001s
im_detect: 2226/4024 0.219s 0.001s
im_detect: 2227/4024 0.219s 0.001s
im_detect: 2228/4024 0.219s 0.001s
im_detect: 2229/4024 0.219s 0.001s
im_detect: 2230/4024 0.219s 0.001s
im_detect: 2231/4024 0.219s 0.001s
im_detect: 2232/4024 0.219s 0.001s
im_detect: 2233/4024 0.219s 0.001s
im_detect: 2234/4024 0.219s 0.001s
im_detect: 2235/4024 0.219s 0.001s
im_detect: 2236/4024 0.219s 0.001s
im_detect: 2237/4024 0.219s 0.001s
im_detect: 2238/4024 0.219s 0.001s
im_detect: 2239/4024 0.219s 0.001s
im_detect: 2240/4024 0.219s 0.001s
im_detect: 2241/4024 0.219s 0.001s
im_detect: 2242/4024 0.219s 0.001s
im_detect: 2243/4024 0.219s 0.001s
im_detect: 2244/4024 0.219s 0.001s
im_detect: 2245/4024 0.219s 0.001s
im_detect: 2246/4024 0.219s 0.001s
im_detect: 2247/4024 0.219s 0.001s
im_detect: 2248/4024 0.219s 0.001s
im_detect: 2249/4024 0.219s 0.001s
im_detect: 2250/4024 0.219s 0.001s
im_detect: 2251/4024 0.219s 0.001s
im_detect: 2252/4024 0.219s 0.001s
im_detect: 2253/4024 0.219s 0.001s
im_detect: 2254/4024 0.219s 0.001s
im_detect: 2255/4024 0.219s 0.001s
im_detect: 2256/4024 0.219s 0.001s
im_detect: 2257/4024 0.219s 0.001s
im_detect: 2258/4024 0.219s 0.001s
im_detect: 2259/4024 0.219s 0.001s
im_detect: 2260/4024 0.219s 0.001s
im_detect: 2261/4024 0.219s 0.001s
im_detect: 2262/4024 0.219s 0.001s
im_detect: 2263/4024 0.219s 0.001s
im_detect: 2264/4024 0.219s 0.001s
im_detect: 2265/4024 0.219s 0.001s
im_detect: 2266/4024 0.219s 0.001s
im_detect: 2267/4024 0.219s 0.001s
im_detect: 2268/4024 0.219s 0.001s
im_detect: 2269/4024 0.219s 0.001s
im_detect: 2270/4024 0.219s 0.001s
im_detect: 2271/4024 0.219s 0.001s
im_detect: 2272/4024 0.219s 0.001s
im_detect: 2273/4024 0.219s 0.001s
im_detect: 2274/4024 0.219s 0.001s
im_detect: 2275/4024 0.219s 0.001s
im_detect: 2276/4024 0.219s 0.001s
im_detect: 2277/4024 0.219s 0.001s
im_detect: 2278/4024 0.219s 0.001s
im_detect: 2279/4024 0.219s 0.001s
im_detect: 2280/4024 0.219s 0.001s
im_detect: 2281/4024 0.219s 0.001s
im_detect: 2282/4024 0.219s 0.001s
im_detect: 2283/4024 0.219s 0.001s
im_detect: 2284/4024 0.219s 0.001s
im_detect: 2285/4024 0.219s 0.001s
im_detect: 2286/4024 0.219s 0.001s
im_detect: 2287/4024 0.219s 0.001s
im_detect: 2288/4024 0.219s 0.001s
im_detect: 2289/4024 0.219s 0.001s
im_detect: 2290/4024 0.219s 0.001s
im_detect: 2291/4024 0.219s 0.001s
im_detect: 2292/4024 0.219s 0.001s
im_detect: 2293/4024 0.219s 0.001s
im_detect: 2294/4024 0.219s 0.001s
im_detect: 2295/4024 0.219s 0.001s
im_detect: 2296/4024 0.219s 0.001s
im_detect: 2297/4024 0.219s 0.001s
im_detect: 2298/4024 0.219s 0.001s
im_detect: 2299/4024 0.219s 0.001s
im_detect: 2300/4024 0.219s 0.001s
im_detect: 2301/4024 0.219s 0.001s
im_detect: 2302/4024 0.219s 0.001s
im_detect: 2303/4024 0.219s 0.001s
im_detect: 2304/4024 0.219s 0.001s
im_detect: 2305/4024 0.219s 0.001s
im_detect: 2306/4024 0.219s 0.001s
im_detect: 2307/4024 0.219s 0.001s
im_detect: 2308/4024 0.219s 0.001s
im_detect: 2309/4024 0.219s 0.001s
im_detect: 2310/4024 0.219s 0.001s
im_detect: 2311/4024 0.219s 0.001s
im_detect: 2312/4024 0.219s 0.001s
im_detect: 2313/4024 0.219s 0.001s
im_detect: 2314/4024 0.219s 0.001s
im_detect: 2315/4024 0.219s 0.001s
im_detect: 2316/4024 0.219s 0.001s
im_detect: 2317/4024 0.219s 0.001s
im_detect: 2318/4024 0.219s 0.001s
im_detect: 2319/4024 0.219s 0.001s
im_detect: 2320/4024 0.219s 0.001s
im_detect: 2321/4024 0.219s 0.001s
im_detect: 2322/4024 0.219s 0.001s
im_detect: 2323/4024 0.219s 0.001s
im_detect: 2324/4024 0.219s 0.001s
im_detect: 2325/4024 0.219s 0.001s
im_detect: 2326/4024 0.219s 0.001s
im_detect: 2327/4024 0.219s 0.001s
im_detect: 2328/4024 0.219s 0.001s
im_detect: 2329/4024 0.219s 0.001s
im_detect: 2330/4024 0.219s 0.001s
im_detect: 2331/4024 0.219s 0.001s
im_detect: 2332/4024 0.219s 0.001s
im_detect: 2333/4024 0.219s 0.001s
im_detect: 2334/4024 0.219s 0.001s
im_detect: 2335/4024 0.219s 0.001s
im_detect: 2336/4024 0.219s 0.001s
im_detect: 2337/4024 0.219s 0.001s
im_detect: 2338/4024 0.219s 0.001s
im_detect: 2339/4024 0.219s 0.001s
im_detect: 2340/4024 0.219s 0.001s
im_detect: 2341/4024 0.219s 0.001s
im_detect: 2342/4024 0.219s 0.001s
im_detect: 2343/4024 0.219s 0.001s
im_detect: 2344/4024 0.219s 0.001s
im_detect: 2345/4024 0.219s 0.001s
im_detect: 2346/4024 0.219s 0.001s
im_detect: 2347/4024 0.219s 0.001s
im_detect: 2348/4024 0.219s 0.001s
im_detect: 2349/4024 0.219s 0.001s
im_detect: 2350/4024 0.219s 0.001s
im_detect: 2351/4024 0.219s 0.001s
im_detect: 2352/4024 0.219s 0.001s
im_detect: 2353/4024 0.219s 0.001s
im_detect: 2354/4024 0.219s 0.001s
im_detect: 2355/4024 0.219s 0.001s
im_detect: 2356/4024 0.219s 0.001s
im_detect: 2357/4024 0.219s 0.001s
im_detect: 2358/4024 0.219s 0.001s
im_detect: 2359/4024 0.219s 0.001s
im_detect: 2360/4024 0.219s 0.001s
im_detect: 2361/4024 0.219s 0.001s
im_detect: 2362/4024 0.219s 0.001s
im_detect: 2363/4024 0.219s 0.001s
im_detect: 2364/4024 0.219s 0.001s
im_detect: 2365/4024 0.219s 0.001s
im_detect: 2366/4024 0.219s 0.001s
im_detect: 2367/4024 0.219s 0.001s
im_detect: 2368/4024 0.219s 0.001s
im_detect: 2369/4024 0.219s 0.001s
im_detect: 2370/4024 0.219s 0.001s
im_detect: 2371/4024 0.219s 0.001s
im_detect: 2372/4024 0.219s 0.001s
im_detect: 2373/4024 0.219s 0.001s
im_detect: 2374/4024 0.219s 0.001s
im_detect: 2375/4024 0.219s 0.001s
im_detect: 2376/4024 0.219s 0.001s
im_detect: 2377/4024 0.219s 0.001s
im_detect: 2378/4024 0.219s 0.001s
im_detect: 2379/4024 0.219s 0.001s
im_detect: 2380/4024 0.219s 0.001s
im_detect: 2381/4024 0.219s 0.001s
im_detect: 2382/4024 0.219s 0.001s
im_detect: 2383/4024 0.219s 0.001s
im_detect: 2384/4024 0.219s 0.001s
im_detect: 2385/4024 0.219s 0.001s
im_detect: 2386/4024 0.219s 0.001s
im_detect: 2387/4024 0.219s 0.001s
im_detect: 2388/4024 0.219s 0.001s
im_detect: 2389/4024 0.219s 0.001s
im_detect: 2390/4024 0.219s 0.001s
im_detect: 2391/4024 0.219s 0.001s
im_detect: 2392/4024 0.219s 0.001s
im_detect: 2393/4024 0.219s 0.001s
im_detect: 2394/4024 0.219s 0.001s
im_detect: 2395/4024 0.219s 0.001s
im_detect: 2396/4024 0.219s 0.001s
im_detect: 2397/4024 0.219s 0.001s
im_detect: 2398/4024 0.219s 0.001s
im_detect: 2399/4024 0.219s 0.001s
im_detect: 2400/4024 0.219s 0.001s
im_detect: 2401/4024 0.219s 0.001s
im_detect: 2402/4024 0.219s 0.001s
im_detect: 2403/4024 0.219s 0.001s
im_detect: 2404/4024 0.219s 0.001s
im_detect: 2405/4024 0.219s 0.001s
im_detect: 2406/4024 0.219s 0.001s
im_detect: 2407/4024 0.219s 0.001s
im_detect: 2408/4024 0.219s 0.001s
im_detect: 2409/4024 0.219s 0.001s
im_detect: 2410/4024 0.219s 0.001s
im_detect: 2411/4024 0.219s 0.001s
im_detect: 2412/4024 0.219s 0.001s
im_detect: 2413/4024 0.219s 0.001s
im_detect: 2414/4024 0.219s 0.001s
im_detect: 2415/4024 0.219s 0.001s
im_detect: 2416/4024 0.219s 0.001s
im_detect: 2417/4024 0.219s 0.001s
im_detect: 2418/4024 0.219s 0.001s
im_detect: 2419/4024 0.219s 0.001s
im_detect: 2420/4024 0.219s 0.001s
im_detect: 2421/4024 0.219s 0.001s
im_detect: 2422/4024 0.219s 0.001s
im_detect: 2423/4024 0.219s 0.001s
im_detect: 2424/4024 0.219s 0.001s
im_detect: 2425/4024 0.219s 0.001s
im_detect: 2426/4024 0.219s 0.001s
im_detect: 2427/4024 0.219s 0.001s
im_detect: 2428/4024 0.219s 0.001s
im_detect: 2429/4024 0.219s 0.001s
im_detect: 2430/4024 0.219s 0.001s
im_detect: 2431/4024 0.219s 0.001s
im_detect: 2432/4024 0.219s 0.001s
im_detect: 2433/4024 0.219s 0.001s
im_detect: 2434/4024 0.219s 0.001s
im_detect: 2435/4024 0.219s 0.001s
im_detect: 2436/4024 0.219s 0.001s
im_detect: 2437/4024 0.219s 0.001s
im_detect: 2438/4024 0.219s 0.001s
im_detect: 2439/4024 0.219s 0.001s
im_detect: 2440/4024 0.219s 0.001s
im_detect: 2441/4024 0.219s 0.001s
im_detect: 2442/4024 0.219s 0.001s
im_detect: 2443/4024 0.219s 0.001s
im_detect: 2444/4024 0.219s 0.001s
im_detect: 2445/4024 0.219s 0.001s
im_detect: 2446/4024 0.219s 0.001s
im_detect: 2447/4024 0.219s 0.001s
im_detect: 2448/4024 0.219s 0.001s
im_detect: 2449/4024 0.219s 0.001s
im_detect: 2450/4024 0.220s 0.001s
im_detect: 2451/4024 0.220s 0.001s
im_detect: 2452/4024 0.220s 0.001s
im_detect: 2453/4024 0.220s 0.001s
im_detect: 2454/4024 0.220s 0.001s
im_detect: 2455/4024 0.220s 0.001s
im_detect: 2456/4024 0.220s 0.001s
im_detect: 2457/4024 0.220s 0.001s
im_detect: 2458/4024 0.220s 0.001s
im_detect: 2459/4024 0.220s 0.001s
im_detect: 2460/4024 0.220s 0.001s
im_detect: 2461/4024 0.220s 0.001s
im_detect: 2462/4024 0.220s 0.001s
im_detect: 2463/4024 0.220s 0.001s
im_detect: 2464/4024 0.220s 0.001s
im_detect: 2465/4024 0.220s 0.001s
im_detect: 2466/4024 0.220s 0.001s
im_detect: 2467/4024 0.220s 0.001s
im_detect: 2468/4024 0.220s 0.001s
im_detect: 2469/4024 0.220s 0.001s
im_detect: 2470/4024 0.220s 0.001s
im_detect: 2471/4024 0.220s 0.001s
im_detect: 2472/4024 0.220s 0.001s
im_detect: 2473/4024 0.220s 0.001s
im_detect: 2474/4024 0.220s 0.001s
im_detect: 2475/4024 0.220s 0.001s
im_detect: 2476/4024 0.220s 0.001s
im_detect: 2477/4024 0.220s 0.001s
im_detect: 2478/4024 0.220s 0.001s
im_detect: 2479/4024 0.220s 0.001s
im_detect: 2480/4024 0.220s 0.001s
im_detect: 2481/4024 0.220s 0.001s
im_detect: 2482/4024 0.220s 0.001s
im_detect: 2483/4024 0.220s 0.001s
im_detect: 2484/4024 0.220s 0.001s
im_detect: 2485/4024 0.220s 0.001s
im_detect: 2486/4024 0.220s 0.001s
im_detect: 2487/4024 0.220s 0.001s
im_detect: 2488/4024 0.220s 0.001s
im_detect: 2489/4024 0.220s 0.001s
im_detect: 2490/4024 0.220s 0.001s
im_detect: 2491/4024 0.220s 0.001s
im_detect: 2492/4024 0.220s 0.001s
im_detect: 2493/4024 0.220s 0.001s
im_detect: 2494/4024 0.220s 0.001s
im_detect: 2495/4024 0.220s 0.001s
im_detect: 2496/4024 0.220s 0.001s
im_detect: 2497/4024 0.220s 0.001s
im_detect: 2498/4024 0.220s 0.001s
im_detect: 2499/4024 0.220s 0.001s
im_detect: 2500/4024 0.220s 0.001s
im_detect: 2501/4024 0.220s 0.001s
im_detect: 2502/4024 0.220s 0.001s
im_detect: 2503/4024 0.220s 0.001s
im_detect: 2504/4024 0.220s 0.001s
im_detect: 2505/4024 0.220s 0.001s
im_detect: 2506/4024 0.220s 0.001s
im_detect: 2507/4024 0.220s 0.001s
im_detect: 2508/4024 0.220s 0.001s
im_detect: 2509/4024 0.220s 0.001s
im_detect: 2510/4024 0.220s 0.001s
im_detect: 2511/4024 0.220s 0.001s
im_detect: 2512/4024 0.220s 0.001s
im_detect: 2513/4024 0.220s 0.001s
im_detect: 2514/4024 0.220s 0.001s
im_detect: 2515/4024 0.220s 0.001s
im_detect: 2516/4024 0.220s 0.001s
im_detect: 2517/4024 0.220s 0.001s
im_detect: 2518/4024 0.220s 0.001s
im_detect: 2519/4024 0.220s 0.001s
im_detect: 2520/4024 0.220s 0.001s
im_detect: 2521/4024 0.220s 0.001s
im_detect: 2522/4024 0.220s 0.001s
im_detect: 2523/4024 0.219s 0.001s
im_detect: 2524/4024 0.219s 0.001s
im_detect: 2525/4024 0.219s 0.001s
im_detect: 2526/4024 0.219s 0.001s
im_detect: 2527/4024 0.219s 0.001s
im_detect: 2528/4024 0.219s 0.001s
im_detect: 2529/4024 0.219s 0.001s
im_detect: 2530/4024 0.219s 0.001s
im_detect: 2531/4024 0.219s 0.001s
im_detect: 2532/4024 0.219s 0.001s
im_detect: 2533/4024 0.219s 0.001s
im_detect: 2534/4024 0.219s 0.001s
im_detect: 2535/4024 0.219s 0.001s
im_detect: 2536/4024 0.219s 0.001s
im_detect: 2537/4024 0.219s 0.001s
im_detect: 2538/4024 0.219s 0.001s
im_detect: 2539/4024 0.219s 0.001s
im_detect: 2540/4024 0.219s 0.001s
im_detect: 2541/4024 0.219s 0.001s
im_detect: 2542/4024 0.219s 0.001s
im_detect: 2543/4024 0.219s 0.001s
im_detect: 2544/4024 0.219s 0.001s
im_detect: 2545/4024 0.219s 0.001s
im_detect: 2546/4024 0.219s 0.001s
im_detect: 2547/4024 0.219s 0.001s
im_detect: 2548/4024 0.219s 0.001s
im_detect: 2549/4024 0.219s 0.001s
im_detect: 2550/4024 0.219s 0.001s
im_detect: 2551/4024 0.219s 0.001s
im_detect: 2552/4024 0.219s 0.001s
im_detect: 2553/4024 0.219s 0.001s
im_detect: 2554/4024 0.219s 0.001s
im_detect: 2555/4024 0.219s 0.001s
im_detect: 2556/4024 0.219s 0.001s
im_detect: 2557/4024 0.219s 0.001s
im_detect: 2558/4024 0.219s 0.001s
im_detect: 2559/4024 0.219s 0.001s
im_detect: 2560/4024 0.219s 0.001s
im_detect: 2561/4024 0.219s 0.001s
im_detect: 2562/4024 0.219s 0.001s
im_detect: 2563/4024 0.219s 0.001s
im_detect: 2564/4024 0.219s 0.001s
im_detect: 2565/4024 0.219s 0.001s
im_detect: 2566/4024 0.219s 0.001s
im_detect: 2567/4024 0.219s 0.001s
im_detect: 2568/4024 0.219s 0.001s
im_detect: 2569/4024 0.219s 0.001s
im_detect: 2570/4024 0.219s 0.001s
im_detect: 2571/4024 0.219s 0.001s
im_detect: 2572/4024 0.219s 0.001s
im_detect: 2573/4024 0.219s 0.001s
im_detect: 2574/4024 0.219s 0.001s
im_detect: 2575/4024 0.219s 0.001s
im_detect: 2576/4024 0.219s 0.001s
im_detect: 2577/4024 0.219s 0.001s
im_detect: 2578/4024 0.219s 0.001s
im_detect: 2579/4024 0.219s 0.001s
im_detect: 2580/4024 0.219s 0.001s
im_detect: 2581/4024 0.219s 0.001s
im_detect: 2582/4024 0.219s 0.001s
im_detect: 2583/4024 0.219s 0.001s
im_detect: 2584/4024 0.219s 0.001s
im_detect: 2585/4024 0.219s 0.001s
im_detect: 2586/4024 0.219s 0.001s
im_detect: 2587/4024 0.219s 0.001s
im_detect: 2588/4024 0.219s 0.001s
im_detect: 2589/4024 0.219s 0.001s
im_detect: 2590/4024 0.219s 0.001s
im_detect: 2591/4024 0.219s 0.001s
im_detect: 2592/4024 0.219s 0.001s
im_detect: 2593/4024 0.219s 0.001s
im_detect: 2594/4024 0.219s 0.001s
im_detect: 2595/4024 0.219s 0.001s
im_detect: 2596/4024 0.219s 0.001s
im_detect: 2597/4024 0.219s 0.001s
im_detect: 2598/4024 0.219s 0.001s
im_detect: 2599/4024 0.219s 0.001s
im_detect: 2600/4024 0.219s 0.001s
im_detect: 2601/4024 0.219s 0.001s
im_detect: 2602/4024 0.219s 0.001s
im_detect: 2603/4024 0.219s 0.001s
im_detect: 2604/4024 0.219s 0.001s
im_detect: 2605/4024 0.219s 0.001s
im_detect: 2606/4024 0.219s 0.001s
im_detect: 2607/4024 0.219s 0.001s
im_detect: 2608/4024 0.219s 0.001s
im_detect: 2609/4024 0.219s 0.001s
im_detect: 2610/4024 0.219s 0.001s
im_detect: 2611/4024 0.219s 0.001s
im_detect: 2612/4024 0.219s 0.001s
im_detect: 2613/4024 0.219s 0.001s
im_detect: 2614/4024 0.219s 0.001s
im_detect: 2615/4024 0.219s 0.001s
im_detect: 2616/4024 0.219s 0.001s
im_detect: 2617/4024 0.219s 0.001s
im_detect: 2618/4024 0.219s 0.001s
im_detect: 2619/4024 0.219s 0.001s
im_detect: 2620/4024 0.219s 0.001s
im_detect: 2621/4024 0.219s 0.001s
im_detect: 2622/4024 0.219s 0.001s
im_detect: 2623/4024 0.219s 0.001s
im_detect: 2624/4024 0.219s 0.001s
im_detect: 2625/4024 0.219s 0.001s
im_detect: 2626/4024 0.219s 0.001s
im_detect: 2627/4024 0.219s 0.001s
im_detect: 2628/4024 0.219s 0.001s
im_detect: 2629/4024 0.219s 0.001s
im_detect: 2630/4024 0.219s 0.001s
im_detect: 2631/4024 0.219s 0.001s
im_detect: 2632/4024 0.219s 0.001s
im_detect: 2633/4024 0.219s 0.001s
im_detect: 2634/4024 0.219s 0.001s
im_detect: 2635/4024 0.219s 0.001s
im_detect: 2636/4024 0.219s 0.001s
im_detect: 2637/4024 0.219s 0.001s
im_detect: 2638/4024 0.219s 0.001s
im_detect: 2639/4024 0.219s 0.001s
im_detect: 2640/4024 0.219s 0.001s
im_detect: 2641/4024 0.219s 0.001s
im_detect: 2642/4024 0.219s 0.001s
im_detect: 2643/4024 0.219s 0.001s
im_detect: 2644/4024 0.219s 0.001s
im_detect: 2645/4024 0.219s 0.001s
im_detect: 2646/4024 0.219s 0.001s
im_detect: 2647/4024 0.219s 0.001s
im_detect: 2648/4024 0.219s 0.001s
im_detect: 2649/4024 0.219s 0.001s
im_detect: 2650/4024 0.219s 0.001s
im_detect: 2651/4024 0.219s 0.001s
im_detect: 2652/4024 0.219s 0.001s
im_detect: 2653/4024 0.219s 0.001s
im_detect: 2654/4024 0.219s 0.001s
im_detect: 2655/4024 0.219s 0.001s
im_detect: 2656/4024 0.219s 0.001s
im_detect: 2657/4024 0.219s 0.001s
im_detect: 2658/4024 0.219s 0.001s
im_detect: 2659/4024 0.219s 0.001s
im_detect: 2660/4024 0.219s 0.001s
im_detect: 2661/4024 0.219s 0.001s
im_detect: 2662/4024 0.219s 0.001s
im_detect: 2663/4024 0.219s 0.001s
im_detect: 2664/4024 0.219s 0.001s
im_detect: 2665/4024 0.219s 0.001s
im_detect: 2666/4024 0.219s 0.001s
im_detect: 2667/4024 0.219s 0.001s
im_detect: 2668/4024 0.219s 0.001s
im_detect: 2669/4024 0.219s 0.001s
im_detect: 2670/4024 0.219s 0.001s
im_detect: 2671/4024 0.219s 0.001s
im_detect: 2672/4024 0.219s 0.001s
im_detect: 2673/4024 0.219s 0.001s
im_detect: 2674/4024 0.219s 0.001s
im_detect: 2675/4024 0.219s 0.001s
im_detect: 2676/4024 0.219s 0.001s
im_detect: 2677/4024 0.219s 0.001s
im_detect: 2678/4024 0.219s 0.001s
im_detect: 2679/4024 0.219s 0.001s
im_detect: 2680/4024 0.219s 0.001s
im_detect: 2681/4024 0.219s 0.001s
im_detect: 2682/4024 0.219s 0.001s
im_detect: 2683/4024 0.219s 0.001s
im_detect: 2684/4024 0.219s 0.001s
im_detect: 2685/4024 0.219s 0.001s
im_detect: 2686/4024 0.219s 0.001s
im_detect: 2687/4024 0.219s 0.001s
im_detect: 2688/4024 0.219s 0.001s
im_detect: 2689/4024 0.219s 0.001s
im_detect: 2690/4024 0.219s 0.001s
im_detect: 2691/4024 0.219s 0.001s
im_detect: 2692/4024 0.219s 0.001s
im_detect: 2693/4024 0.219s 0.001s
im_detect: 2694/4024 0.219s 0.001s
im_detect: 2695/4024 0.219s 0.001s
im_detect: 2696/4024 0.219s 0.001s
im_detect: 2697/4024 0.219s 0.001s
im_detect: 2698/4024 0.219s 0.001s
im_detect: 2699/4024 0.219s 0.001s
im_detect: 2700/4024 0.219s 0.001s
im_detect: 2701/4024 0.219s 0.001s
im_detect: 2702/4024 0.219s 0.001s
im_detect: 2703/4024 0.219s 0.001s
im_detect: 2704/4024 0.219s 0.001s
im_detect: 2705/4024 0.219s 0.001s
im_detect: 2706/4024 0.219s 0.001s
im_detect: 2707/4024 0.219s 0.001s
im_detect: 2708/4024 0.219s 0.001s
im_detect: 2709/4024 0.219s 0.001s
im_detect: 2710/4024 0.219s 0.001s
im_detect: 2711/4024 0.219s 0.001s
im_detect: 2712/4024 0.219s 0.001s
im_detect: 2713/4024 0.219s 0.001s
im_detect: 2714/4024 0.219s 0.001s
im_detect: 2715/4024 0.219s 0.001s
im_detect: 2716/4024 0.219s 0.001s
im_detect: 2717/4024 0.219s 0.001s
im_detect: 2718/4024 0.219s 0.001s
im_detect: 2719/4024 0.219s 0.001s
im_detect: 2720/4024 0.219s 0.001s
im_detect: 2721/4024 0.219s 0.001s
im_detect: 2722/4024 0.219s 0.001s
im_detect: 2723/4024 0.219s 0.001s
im_detect: 2724/4024 0.219s 0.001s
im_detect: 2725/4024 0.219s 0.001s
im_detect: 2726/4024 0.219s 0.001s
im_detect: 2727/4024 0.219s 0.001s
im_detect: 2728/4024 0.219s 0.001s
im_detect: 2729/4024 0.219s 0.001s
im_detect: 2730/4024 0.219s 0.001s
im_detect: 2731/4024 0.219s 0.001s
im_detect: 2732/4024 0.219s 0.001s
im_detect: 2733/4024 0.219s 0.001s
im_detect: 2734/4024 0.219s 0.001s
im_detect: 2735/4024 0.219s 0.001s
im_detect: 2736/4024 0.219s 0.001s
im_detect: 2737/4024 0.219s 0.001s
im_detect: 2738/4024 0.219s 0.001s
im_detect: 2739/4024 0.219s 0.001s
im_detect: 2740/4024 0.219s 0.001s
im_detect: 2741/4024 0.219s 0.001s
im_detect: 2742/4024 0.219s 0.001s
im_detect: 2743/4024 0.219s 0.001s
im_detect: 2744/4024 0.219s 0.001s
im_detect: 2745/4024 0.219s 0.001s
im_detect: 2746/4024 0.219s 0.001s
im_detect: 2747/4024 0.219s 0.001s
im_detect: 2748/4024 0.219s 0.001s
im_detect: 2749/4024 0.219s 0.001s
im_detect: 2750/4024 0.219s 0.001s
im_detect: 2751/4024 0.219s 0.001s
im_detect: 2752/4024 0.219s 0.001s
im_detect: 2753/4024 0.219s 0.001s
im_detect: 2754/4024 0.219s 0.001s
im_detect: 2755/4024 0.219s 0.001s
im_detect: 2756/4024 0.219s 0.001s
im_detect: 2757/4024 0.219s 0.001s
im_detect: 2758/4024 0.219s 0.001s
im_detect: 2759/4024 0.219s 0.001s
im_detect: 2760/4024 0.219s 0.001s
im_detect: 2761/4024 0.219s 0.001s
im_detect: 2762/4024 0.219s 0.001s
im_detect: 2763/4024 0.219s 0.001s
im_detect: 2764/4024 0.219s 0.001s
im_detect: 2765/4024 0.219s 0.001s
im_detect: 2766/4024 0.219s 0.001s
im_detect: 2767/4024 0.219s 0.001s
im_detect: 2768/4024 0.219s 0.001s
im_detect: 2769/4024 0.219s 0.001s
im_detect: 2770/4024 0.219s 0.001s
im_detect: 2771/4024 0.219s 0.001s
im_detect: 2772/4024 0.219s 0.001s
im_detect: 2773/4024 0.219s 0.001s
im_detect: 2774/4024 0.219s 0.001s
im_detect: 2775/4024 0.219s 0.001s
im_detect: 2776/4024 0.219s 0.001s
im_detect: 2777/4024 0.219s 0.001s
im_detect: 2778/4024 0.219s 0.001s
im_detect: 2779/4024 0.219s 0.001s
im_detect: 2780/4024 0.219s 0.001s
im_detect: 2781/4024 0.219s 0.001s
im_detect: 2782/4024 0.219s 0.001s
im_detect: 2783/4024 0.219s 0.001s
im_detect: 2784/4024 0.219s 0.001s
im_detect: 2785/4024 0.219s 0.001s
im_detect: 2786/4024 0.219s 0.001s
im_detect: 2787/4024 0.219s 0.001s
im_detect: 2788/4024 0.219s 0.001s
im_detect: 2789/4024 0.219s 0.001s
im_detect: 2790/4024 0.219s 0.001s
im_detect: 2791/4024 0.219s 0.001s
im_detect: 2792/4024 0.219s 0.001s
im_detect: 2793/4024 0.219s 0.001s
im_detect: 2794/4024 0.219s 0.001s
im_detect: 2795/4024 0.219s 0.001s
im_detect: 2796/4024 0.219s 0.001s
im_detect: 2797/4024 0.219s 0.001s
im_detect: 2798/4024 0.219s 0.001s
im_detect: 2799/4024 0.219s 0.001s
im_detect: 2800/4024 0.219s 0.001s
im_detect: 2801/4024 0.219s 0.001s
im_detect: 2802/4024 0.219s 0.001s
im_detect: 2803/4024 0.219s 0.001s
im_detect: 2804/4024 0.219s 0.001s
im_detect: 2805/4024 0.219s 0.001s
im_detect: 2806/4024 0.219s 0.001s
im_detect: 2807/4024 0.219s 0.001s
im_detect: 2808/4024 0.219s 0.001s
im_detect: 2809/4024 0.219s 0.001s
im_detect: 2810/4024 0.219s 0.001s
im_detect: 2811/4024 0.219s 0.001s
im_detect: 2812/4024 0.219s 0.001s
im_detect: 2813/4024 0.219s 0.001s
im_detect: 2814/4024 0.219s 0.001s
im_detect: 2815/4024 0.219s 0.001s
im_detect: 2816/4024 0.219s 0.001s
im_detect: 2817/4024 0.219s 0.001s
im_detect: 2818/4024 0.219s 0.001s
im_detect: 2819/4024 0.219s 0.001s
im_detect: 2820/4024 0.219s 0.001s
im_detect: 2821/4024 0.219s 0.001s
im_detect: 2822/4024 0.219s 0.001s
im_detect: 2823/4024 0.219s 0.001s
im_detect: 2824/4024 0.219s 0.001s
im_detect: 2825/4024 0.219s 0.001s
im_detect: 2826/4024 0.219s 0.001s
im_detect: 2827/4024 0.219s 0.001s
im_detect: 2828/4024 0.219s 0.001s
im_detect: 2829/4024 0.219s 0.001s
im_detect: 2830/4024 0.219s 0.001s
im_detect: 2831/4024 0.219s 0.001s
im_detect: 2832/4024 0.219s 0.001s
im_detect: 2833/4024 0.219s 0.001s
im_detect: 2834/4024 0.219s 0.001s
im_detect: 2835/4024 0.219s 0.001s
im_detect: 2836/4024 0.219s 0.001s
im_detect: 2837/4024 0.219s 0.001s
im_detect: 2838/4024 0.219s 0.001s
im_detect: 2839/4024 0.219s 0.001s
im_detect: 2840/4024 0.219s 0.001s
im_detect: 2841/4024 0.219s 0.001s
im_detect: 2842/4024 0.219s 0.001s
im_detect: 2843/4024 0.219s 0.001s
im_detect: 2844/4024 0.219s 0.001s
im_detect: 2845/4024 0.219s 0.001s
im_detect: 2846/4024 0.219s 0.001s
im_detect: 2847/4024 0.219s 0.001s
im_detect: 2848/4024 0.219s 0.001s
im_detect: 2849/4024 0.219s 0.001s
im_detect: 2850/4024 0.219s 0.001s
im_detect: 2851/4024 0.219s 0.001s
im_detect: 2852/4024 0.219s 0.001s
im_detect: 2853/4024 0.219s 0.001s
im_detect: 2854/4024 0.219s 0.001s
im_detect: 2855/4024 0.219s 0.001s
im_detect: 2856/4024 0.219s 0.001s
im_detect: 2857/4024 0.219s 0.001s
im_detect: 2858/4024 0.219s 0.001s
im_detect: 2859/4024 0.219s 0.001s
im_detect: 2860/4024 0.219s 0.001s
im_detect: 2861/4024 0.219s 0.001s
im_detect: 2862/4024 0.219s 0.001s
im_detect: 2863/4024 0.219s 0.001s
im_detect: 2864/4024 0.219s 0.001s
im_detect: 2865/4024 0.219s 0.001s
im_detect: 2866/4024 0.219s 0.001s
im_detect: 2867/4024 0.219s 0.001s
im_detect: 2868/4024 0.219s 0.001s
im_detect: 2869/4024 0.219s 0.001s
im_detect: 2870/4024 0.219s 0.001s
im_detect: 2871/4024 0.219s 0.001s
im_detect: 2872/4024 0.219s 0.001s
im_detect: 2873/4024 0.219s 0.001s
im_detect: 2874/4024 0.219s 0.001s
im_detect: 2875/4024 0.219s 0.001s
im_detect: 2876/4024 0.219s 0.001s
im_detect: 2877/4024 0.219s 0.001s
im_detect: 2878/4024 0.219s 0.001s
im_detect: 2879/4024 0.219s 0.001s
im_detect: 2880/4024 0.219s 0.001s
im_detect: 2881/4024 0.219s 0.001s
im_detect: 2882/4024 0.219s 0.001s
im_detect: 2883/4024 0.219s 0.001s
im_detect: 2884/4024 0.219s 0.001s
im_detect: 2885/4024 0.219s 0.001s
im_detect: 2886/4024 0.219s 0.001s
im_detect: 2887/4024 0.219s 0.001s
im_detect: 2888/4024 0.219s 0.001s
im_detect: 2889/4024 0.219s 0.001s
im_detect: 2890/4024 0.219s 0.001s
im_detect: 2891/4024 0.219s 0.001s
im_detect: 2892/4024 0.219s 0.001s
im_detect: 2893/4024 0.219s 0.001s
im_detect: 2894/4024 0.219s 0.001s
im_detect: 2895/4024 0.219s 0.001s
im_detect: 2896/4024 0.219s 0.001s
im_detect: 2897/4024 0.219s 0.001s
im_detect: 2898/4024 0.219s 0.001s
im_detect: 2899/4024 0.219s 0.001s
im_detect: 2900/4024 0.219s 0.001s
im_detect: 2901/4024 0.219s 0.001s
im_detect: 2902/4024 0.219s 0.001s
im_detect: 2903/4024 0.219s 0.001s
im_detect: 2904/4024 0.219s 0.001s
im_detect: 2905/4024 0.219s 0.001s
im_detect: 2906/4024 0.219s 0.001s
im_detect: 2907/4024 0.219s 0.001s
im_detect: 2908/4024 0.219s 0.001s
im_detect: 2909/4024 0.219s 0.001s
im_detect: 2910/4024 0.219s 0.001s
im_detect: 2911/4024 0.219s 0.001s
im_detect: 2912/4024 0.219s 0.001s
im_detect: 2913/4024 0.219s 0.001s
im_detect: 2914/4024 0.219s 0.001s
im_detect: 2915/4024 0.219s 0.001s
im_detect: 2916/4024 0.219s 0.001s
im_detect: 2917/4024 0.219s 0.001s
im_detect: 2918/4024 0.219s 0.001s
im_detect: 2919/4024 0.219s 0.001s
im_detect: 2920/4024 0.219s 0.001s
im_detect: 2921/4024 0.219s 0.001s
im_detect: 2922/4024 0.219s 0.001s
im_detect: 2923/4024 0.219s 0.001s
im_detect: 2924/4024 0.219s 0.001s
im_detect: 2925/4024 0.219s 0.001s
im_detect: 2926/4024 0.219s 0.001s
im_detect: 2927/4024 0.219s 0.001s
im_detect: 2928/4024 0.219s 0.001s
im_detect: 2929/4024 0.219s 0.001s
im_detect: 2930/4024 0.219s 0.001s
im_detect: 2931/4024 0.219s 0.001s
im_detect: 2932/4024 0.219s 0.001s
im_detect: 2933/4024 0.219s 0.001s
im_detect: 2934/4024 0.219s 0.001s
im_detect: 2935/4024 0.219s 0.001s
im_detect: 2936/4024 0.219s 0.001s
im_detect: 2937/4024 0.219s 0.001s
im_detect: 2938/4024 0.219s 0.001s
im_detect: 2939/4024 0.219s 0.001s
im_detect: 2940/4024 0.219s 0.001s
im_detect: 2941/4024 0.219s 0.001s
im_detect: 2942/4024 0.219s 0.001s
im_detect: 2943/4024 0.219s 0.001s
im_detect: 2944/4024 0.219s 0.001s
im_detect: 2945/4024 0.219s 0.001s
im_detect: 2946/4024 0.219s 0.001s
im_detect: 2947/4024 0.219s 0.001s
im_detect: 2948/4024 0.219s 0.001s
im_detect: 2949/4024 0.219s 0.001s
im_detect: 2950/4024 0.219s 0.001s
im_detect: 2951/4024 0.219s 0.001s
im_detect: 2952/4024 0.219s 0.001s
im_detect: 2953/4024 0.219s 0.001s
im_detect: 2954/4024 0.219s 0.001s
im_detect: 2955/4024 0.219s 0.001s
im_detect: 2956/4024 0.219s 0.001s
im_detect: 2957/4024 0.219s 0.001s
im_detect: 2958/4024 0.219s 0.001s
im_detect: 2959/4024 0.219s 0.001s
im_detect: 2960/4024 0.219s 0.001s
im_detect: 2961/4024 0.219s 0.001s
im_detect: 2962/4024 0.219s 0.001s
im_detect: 2963/4024 0.219s 0.001s
im_detect: 2964/4024 0.219s 0.001s
im_detect: 2965/4024 0.219s 0.001s
im_detect: 2966/4024 0.219s 0.001s
im_detect: 2967/4024 0.219s 0.001s
im_detect: 2968/4024 0.219s 0.001s
im_detect: 2969/4024 0.219s 0.001s
im_detect: 2970/4024 0.219s 0.001s
im_detect: 2971/4024 0.219s 0.001s
im_detect: 2972/4024 0.219s 0.001s
im_detect: 2973/4024 0.219s 0.001s
im_detect: 2974/4024 0.219s 0.001s
im_detect: 2975/4024 0.219s 0.001s
im_detect: 2976/4024 0.219s 0.001s
im_detect: 2977/4024 0.219s 0.001s
im_detect: 2978/4024 0.219s 0.001s
im_detect: 2979/4024 0.219s 0.001s
im_detect: 2980/4024 0.219s 0.001s
im_detect: 2981/4024 0.219s 0.001s
im_detect: 2982/4024 0.219s 0.001s
im_detect: 2983/4024 0.219s 0.001s
im_detect: 2984/4024 0.219s 0.001s
im_detect: 2985/4024 0.219s 0.001s
im_detect: 2986/4024 0.219s 0.001s
im_detect: 2987/4024 0.219s 0.001s
im_detect: 2988/4024 0.219s 0.001s
im_detect: 2989/4024 0.219s 0.001s
im_detect: 2990/4024 0.219s 0.001s
im_detect: 2991/4024 0.219s 0.001s
im_detect: 2992/4024 0.219s 0.001s
im_detect: 2993/4024 0.219s 0.001s
im_detect: 2994/4024 0.219s 0.001s
im_detect: 2995/4024 0.219s 0.001s
im_detect: 2996/4024 0.219s 0.001s
im_detect: 2997/4024 0.219s 0.001s
im_detect: 2998/4024 0.219s 0.001s
im_detect: 2999/4024 0.219s 0.001s
im_detect: 3000/4024 0.219s 0.001s
im_detect: 3001/4024 0.219s 0.001s
im_detect: 3002/4024 0.219s 0.001s
im_detect: 3003/4024 0.219s 0.001s
im_detect: 3004/4024 0.220s 0.001s
im_detect: 3005/4024 0.220s 0.001s
im_detect: 3006/4024 0.220s 0.001s
im_detect: 3007/4024 0.220s 0.001s
im_detect: 3008/4024 0.220s 0.001s
im_detect: 3009/4024 0.220s 0.001s
im_detect: 3010/4024 0.220s 0.001s
im_detect: 3011/4024 0.220s 0.001s
im_detect: 3012/4024 0.220s 0.001s
im_detect: 3013/4024 0.220s 0.001s
im_detect: 3014/4024 0.220s 0.001s
im_detect: 3015/4024 0.220s 0.001s
im_detect: 3016/4024 0.220s 0.001s
im_detect: 3017/4024 0.220s 0.001s
im_detect: 3018/4024 0.220s 0.001s
im_detect: 3019/4024 0.220s 0.001s
im_detect: 3020/4024 0.220s 0.001s
im_detect: 3021/4024 0.220s 0.001s
im_detect: 3022/4024 0.220s 0.001s
im_detect: 3023/4024 0.220s 0.001s
im_detect: 3024/4024 0.220s 0.001s
im_detect: 3025/4024 0.220s 0.001s
im_detect: 3026/4024 0.220s 0.001s
im_detect: 3027/4024 0.220s 0.001s
im_detect: 3028/4024 0.220s 0.001s
im_detect: 3029/4024 0.220s 0.001s
im_detect: 3030/4024 0.220s 0.001s
im_detect: 3031/4024 0.220s 0.001s
im_detect: 3032/4024 0.220s 0.001s
im_detect: 3033/4024 0.220s 0.001s
im_detect: 3034/4024 0.220s 0.001s
im_detect: 3035/4024 0.220s 0.001s
im_detect: 3036/4024 0.220s 0.001s
im_detect: 3037/4024 0.220s 0.001s
im_detect: 3038/4024 0.220s 0.001s
im_detect: 3039/4024 0.220s 0.001s
im_detect: 3040/4024 0.220s 0.001s
im_detect: 3041/4024 0.220s 0.001s
im_detect: 3042/4024 0.220s 0.001s
im_detect: 3043/4024 0.220s 0.001s
im_detect: 3044/4024 0.220s 0.001s
im_detect: 3045/4024 0.220s 0.001s
im_detect: 3046/4024 0.220s 0.001s
im_detect: 3047/4024 0.220s 0.001s
im_detect: 3048/4024 0.220s 0.001s
im_detect: 3049/4024 0.220s 0.001s
im_detect: 3050/4024 0.220s 0.001s
im_detect: 3051/4024 0.220s 0.001s
im_detect: 3052/4024 0.220s 0.001s
im_detect: 3053/4024 0.220s 0.001s
im_detect: 3054/4024 0.220s 0.001s
im_detect: 3055/4024 0.220s 0.001s
im_detect: 3056/4024 0.220s 0.001s
im_detect: 3057/4024 0.220s 0.001s
im_detect: 3058/4024 0.220s 0.001s
im_detect: 3059/4024 0.220s 0.001s
im_detect: 3060/4024 0.220s 0.001s
im_detect: 3061/4024 0.220s 0.001s
im_detect: 3062/4024 0.220s 0.001s
im_detect: 3063/4024 0.220s 0.001s
im_detect: 3064/4024 0.220s 0.001s
im_detect: 3065/4024 0.220s 0.001s
im_detect: 3066/4024 0.220s 0.001s
im_detect: 3067/4024 0.220s 0.001s
im_detect: 3068/4024 0.220s 0.001s
im_detect: 3069/4024 0.220s 0.001s
im_detect: 3070/4024 0.220s 0.001s
im_detect: 3071/4024 0.220s 0.001s
im_detect: 3072/4024 0.220s 0.001s
im_detect: 3073/4024 0.220s 0.001s
im_detect: 3074/4024 0.220s 0.001s
im_detect: 3075/4024 0.220s 0.001s
im_detect: 3076/4024 0.220s 0.001s
im_detect: 3077/4024 0.220s 0.001s
im_detect: 3078/4024 0.220s 0.001s
im_detect: 3079/4024 0.220s 0.001s
im_detect: 3080/4024 0.220s 0.001s
im_detect: 3081/4024 0.220s 0.001s
im_detect: 3082/4024 0.220s 0.001s
im_detect: 3083/4024 0.220s 0.001s
im_detect: 3084/4024 0.220s 0.001s
im_detect: 3085/4024 0.220s 0.001s
im_detect: 3086/4024 0.220s 0.001s
im_detect: 3087/4024 0.220s 0.001s
im_detect: 3088/4024 0.220s 0.001s
im_detect: 3089/4024 0.220s 0.001s
im_detect: 3090/4024 0.220s 0.001s
im_detect: 3091/4024 0.220s 0.001s
im_detect: 3092/4024 0.220s 0.001s
im_detect: 3093/4024 0.220s 0.001s
im_detect: 3094/4024 0.220s 0.001s
im_detect: 3095/4024 0.220s 0.001s
im_detect: 3096/4024 0.220s 0.001s
im_detect: 3097/4024 0.220s 0.001s
im_detect: 3098/4024 0.220s 0.001s
im_detect: 3099/4024 0.220s 0.001s
im_detect: 3100/4024 0.220s 0.001s
im_detect: 3101/4024 0.220s 0.001s
im_detect: 3102/4024 0.220s 0.001s
im_detect: 3103/4024 0.220s 0.001s
im_detect: 3104/4024 0.220s 0.001s
im_detect: 3105/4024 0.220s 0.001s
im_detect: 3106/4024 0.220s 0.001s
im_detect: 3107/4024 0.220s 0.001s
im_detect: 3108/4024 0.220s 0.001s
im_detect: 3109/4024 0.220s 0.001s
im_detect: 3110/4024 0.220s 0.001s
im_detect: 3111/4024 0.220s 0.001s
im_detect: 3112/4024 0.220s 0.001s
im_detect: 3113/4024 0.220s 0.001s
im_detect: 3114/4024 0.220s 0.001s
im_detect: 3115/4024 0.220s 0.001s
im_detect: 3116/4024 0.220s 0.001s
im_detect: 3117/4024 0.220s 0.001s
im_detect: 3118/4024 0.220s 0.001s
im_detect: 3119/4024 0.220s 0.001s
im_detect: 3120/4024 0.220s 0.001s
im_detect: 3121/4024 0.220s 0.001s
im_detect: 3122/4024 0.220s 0.001s
im_detect: 3123/4024 0.220s 0.001s
im_detect: 3124/4024 0.220s 0.001s
im_detect: 3125/4024 0.220s 0.001s
im_detect: 3126/4024 0.220s 0.001s
im_detect: 3127/4024 0.220s 0.001s
im_detect: 3128/4024 0.220s 0.001s
im_detect: 3129/4024 0.220s 0.001s
im_detect: 3130/4024 0.220s 0.001s
im_detect: 3131/4024 0.220s 0.001s
im_detect: 3132/4024 0.220s 0.001s
im_detect: 3133/4024 0.220s 0.001s
im_detect: 3134/4024 0.220s 0.001s
im_detect: 3135/4024 0.220s 0.001s
im_detect: 3136/4024 0.220s 0.001s
im_detect: 3137/4024 0.220s 0.001s
im_detect: 3138/4024 0.220s 0.001s
im_detect: 3139/4024 0.220s 0.001s
im_detect: 3140/4024 0.220s 0.001s
im_detect: 3141/4024 0.220s 0.001s
im_detect: 3142/4024 0.220s 0.001s
im_detect: 3143/4024 0.220s 0.001s
im_detect: 3144/4024 0.220s 0.001s
im_detect: 3145/4024 0.220s 0.001s
im_detect: 3146/4024 0.220s 0.001s
im_detect: 3147/4024 0.220s 0.001s
im_detect: 3148/4024 0.220s 0.001s
im_detect: 3149/4024 0.220s 0.001s
im_detect: 3150/4024 0.220s 0.001s
im_detect: 3151/4024 0.220s 0.001s
im_detect: 3152/4024 0.220s 0.001s
im_detect: 3153/4024 0.220s 0.001s
im_detect: 3154/4024 0.220s 0.001s
im_detect: 3155/4024 0.220s 0.001s
im_detect: 3156/4024 0.220s 0.001s
im_detect: 3157/4024 0.220s 0.001s
im_detect: 3158/4024 0.220s 0.001s
im_detect: 3159/4024 0.220s 0.001s
im_detect: 3160/4024 0.220s 0.001s
im_detect: 3161/4024 0.220s 0.001s
im_detect: 3162/4024 0.220s 0.001s
im_detect: 3163/4024 0.220s 0.001s
im_detect: 3164/4024 0.220s 0.001s
im_detect: 3165/4024 0.220s 0.001s
im_detect: 3166/4024 0.220s 0.001s
im_detect: 3167/4024 0.220s 0.001s
im_detect: 3168/4024 0.220s 0.001s
im_detect: 3169/4024 0.220s 0.001s
im_detect: 3170/4024 0.220s 0.001s
im_detect: 3171/4024 0.220s 0.001s
im_detect: 3172/4024 0.220s 0.001s
im_detect: 3173/4024 0.220s 0.001s
im_detect: 3174/4024 0.220s 0.001s
im_detect: 3175/4024 0.220s 0.001s
im_detect: 3176/4024 0.220s 0.001s
im_detect: 3177/4024 0.220s 0.001s
im_detect: 3178/4024 0.220s 0.001s
im_detect: 3179/4024 0.220s 0.001s
im_detect: 3180/4024 0.220s 0.001s
im_detect: 3181/4024 0.220s 0.001s
im_detect: 3182/4024 0.220s 0.001s
im_detect: 3183/4024 0.220s 0.001s
im_detect: 3184/4024 0.220s 0.001s
im_detect: 3185/4024 0.220s 0.001s
im_detect: 3186/4024 0.220s 0.001s
im_detect: 3187/4024 0.220s 0.001s
im_detect: 3188/4024 0.220s 0.001s
im_detect: 3189/4024 0.220s 0.001s
im_detect: 3190/4024 0.220s 0.001s
im_detect: 3191/4024 0.220s 0.001s
im_detect: 3192/4024 0.220s 0.001s
im_detect: 3193/4024 0.220s 0.001s
im_detect: 3194/4024 0.220s 0.001s
im_detect: 3195/4024 0.220s 0.001s
im_detect: 3196/4024 0.220s 0.001s
im_detect: 3197/4024 0.220s 0.001s
im_detect: 3198/4024 0.220s 0.001s
im_detect: 3199/4024 0.220s 0.001s
im_detect: 3200/4024 0.220s 0.001s
im_detect: 3201/4024 0.220s 0.001s
im_detect: 3202/4024 0.220s 0.001s
im_detect: 3203/4024 0.220s 0.001s
im_detect: 3204/4024 0.220s 0.001s
im_detect: 3205/4024 0.220s 0.001s
im_detect: 3206/4024 0.220s 0.001s
im_detect: 3207/4024 0.220s 0.001s
im_detect: 3208/4024 0.220s 0.001s
im_detect: 3209/4024 0.220s 0.001s
im_detect: 3210/4024 0.220s 0.001s
im_detect: 3211/4024 0.220s 0.001s
im_detect: 3212/4024 0.220s 0.001s
im_detect: 3213/4024 0.220s 0.001s
im_detect: 3214/4024 0.220s 0.001s
im_detect: 3215/4024 0.220s 0.001s
im_detect: 3216/4024 0.220s 0.001s
im_detect: 3217/4024 0.220s 0.001s
im_detect: 3218/4024 0.220s 0.001s
im_detect: 3219/4024 0.220s 0.001s
im_detect: 3220/4024 0.220s 0.001s
im_detect: 3221/4024 0.220s 0.001s
im_detect: 3222/4024 0.220s 0.001s
im_detect: 3223/4024 0.220s 0.001s
im_detect: 3224/4024 0.220s 0.001s
im_detect: 3225/4024 0.220s 0.001s
im_detect: 3226/4024 0.220s 0.001s
im_detect: 3227/4024 0.220s 0.001s
im_detect: 3228/4024 0.220s 0.001s
im_detect: 3229/4024 0.220s 0.001s
im_detect: 3230/4024 0.220s 0.001s
im_detect: 3231/4024 0.220s 0.001s
im_detect: 3232/4024 0.220s 0.001s
im_detect: 3233/4024 0.220s 0.001s
im_detect: 3234/4024 0.220s 0.001s
im_detect: 3235/4024 0.220s 0.001s
im_detect: 3236/4024 0.220s 0.001s
im_detect: 3237/4024 0.220s 0.001s
im_detect: 3238/4024 0.220s 0.001s
im_detect: 3239/4024 0.220s 0.001s
im_detect: 3240/4024 0.220s 0.001s
im_detect: 3241/4024 0.220s 0.001s
im_detect: 3242/4024 0.220s 0.001s
im_detect: 3243/4024 0.220s 0.001s
im_detect: 3244/4024 0.220s 0.001s
im_detect: 3245/4024 0.220s 0.001s
im_detect: 3246/4024 0.220s 0.001s
im_detect: 3247/4024 0.220s 0.001s
im_detect: 3248/4024 0.220s 0.001s
im_detect: 3249/4024 0.220s 0.001s
im_detect: 3250/4024 0.220s 0.001s
im_detect: 3251/4024 0.220s 0.001s
im_detect: 3252/4024 0.220s 0.001s
im_detect: 3253/4024 0.220s 0.001s
im_detect: 3254/4024 0.220s 0.001s
im_detect: 3255/4024 0.220s 0.001s
im_detect: 3256/4024 0.220s 0.001s
im_detect: 3257/4024 0.220s 0.001s
im_detect: 3258/4024 0.220s 0.001s
im_detect: 3259/4024 0.220s 0.001s
im_detect: 3260/4024 0.220s 0.001s
im_detect: 3261/4024 0.220s 0.001s
im_detect: 3262/4024 0.220s 0.001s
im_detect: 3263/4024 0.220s 0.001s
im_detect: 3264/4024 0.220s 0.001s
im_detect: 3265/4024 0.220s 0.001s
im_detect: 3266/4024 0.220s 0.001s
im_detect: 3267/4024 0.220s 0.001s
im_detect: 3268/4024 0.220s 0.001s
im_detect: 3269/4024 0.220s 0.001s
im_detect: 3270/4024 0.220s 0.001s
im_detect: 3271/4024 0.220s 0.001s
im_detect: 3272/4024 0.220s 0.001s
im_detect: 3273/4024 0.220s 0.001s
im_detect: 3274/4024 0.220s 0.001s
im_detect: 3275/4024 0.220s 0.001s
im_detect: 3276/4024 0.220s 0.001s
im_detect: 3277/4024 0.220s 0.001s
im_detect: 3278/4024 0.220s 0.001s
im_detect: 3279/4024 0.220s 0.001s
im_detect: 3280/4024 0.220s 0.001s
im_detect: 3281/4024 0.220s 0.001s
im_detect: 3282/4024 0.220s 0.001s
im_detect: 3283/4024 0.220s 0.001s
im_detect: 3284/4024 0.220s 0.001s
im_detect: 3285/4024 0.220s 0.001s
im_detect: 3286/4024 0.220s 0.001s
im_detect: 3287/4024 0.220s 0.001s
im_detect: 3288/4024 0.220s 0.001s
im_detect: 3289/4024 0.220s 0.001s
im_detect: 3290/4024 0.220s 0.001s
im_detect: 3291/4024 0.220s 0.001s
im_detect: 3292/4024 0.220s 0.001s
im_detect: 3293/4024 0.220s 0.001s
im_detect: 3294/4024 0.220s 0.001s
im_detect: 3295/4024 0.220s 0.001s
im_detect: 3296/4024 0.220s 0.001s
im_detect: 3297/4024 0.220s 0.001s
im_detect: 3298/4024 0.220s 0.001s
im_detect: 3299/4024 0.220s 0.001s
im_detect: 3300/4024 0.220s 0.001s
im_detect: 3301/4024 0.220s 0.001s
im_detect: 3302/4024 0.220s 0.001s
im_detect: 3303/4024 0.220s 0.001s
im_detect: 3304/4024 0.220s 0.001s
im_detect: 3305/4024 0.220s 0.001s
im_detect: 3306/4024 0.220s 0.001s
im_detect: 3307/4024 0.220s 0.001s
im_detect: 3308/4024 0.220s 0.001s
im_detect: 3309/4024 0.220s 0.001s
im_detect: 3310/4024 0.220s 0.001s
im_detect: 3311/4024 0.220s 0.001s
im_detect: 3312/4024 0.220s 0.001s
im_detect: 3313/4024 0.220s 0.001s
im_detect: 3314/4024 0.220s 0.001s
im_detect: 3315/4024 0.220s 0.001s
im_detect: 3316/4024 0.220s 0.001s
im_detect: 3317/4024 0.220s 0.001s
im_detect: 3318/4024 0.220s 0.001s
im_detect: 3319/4024 0.220s 0.001s
im_detect: 3320/4024 0.220s 0.001s
im_detect: 3321/4024 0.220s 0.001s
im_detect: 3322/4024 0.220s 0.001s
im_detect: 3323/4024 0.220s 0.001s
im_detect: 3324/4024 0.220s 0.001s
im_detect: 3325/4024 0.220s 0.001s
im_detect: 3326/4024 0.220s 0.001s
im_detect: 3327/4024 0.220s 0.001s
im_detect: 3328/4024 0.220s 0.001s
im_detect: 3329/4024 0.220s 0.001s
im_detect: 3330/4024 0.220s 0.001s
im_detect: 3331/4024 0.220s 0.001s
im_detect: 3332/4024 0.220s 0.001s
im_detect: 3333/4024 0.220s 0.001s
im_detect: 3334/4024 0.220s 0.001s
im_detect: 3335/4024 0.220s 0.001s
im_detect: 3336/4024 0.220s 0.001s
im_detect: 3337/4024 0.220s 0.001s
im_detect: 3338/4024 0.220s 0.001s
im_detect: 3339/4024 0.220s 0.001s
im_detect: 3340/4024 0.220s 0.001s
im_detect: 3341/4024 0.220s 0.001s
im_detect: 3342/4024 0.220s 0.001s
im_detect: 3343/4024 0.220s 0.001s
im_detect: 3344/4024 0.220s 0.001s
im_detect: 3345/4024 0.220s 0.001s
im_detect: 3346/4024 0.220s 0.001s
im_detect: 3347/4024 0.220s 0.001s
im_detect: 3348/4024 0.220s 0.001s
im_detect: 3349/4024 0.220s 0.001s
im_detect: 3350/4024 0.220s 0.001s
im_detect: 3351/4024 0.220s 0.001s
im_detect: 3352/4024 0.220s 0.001s
im_detect: 3353/4024 0.220s 0.001s
im_detect: 3354/4024 0.220s 0.001s
im_detect: 3355/4024 0.220s 0.001s
im_detect: 3356/4024 0.220s 0.001s
im_detect: 3357/4024 0.220s 0.001s
im_detect: 3358/4024 0.220s 0.001s
im_detect: 3359/4024 0.220s 0.001s
im_detect: 3360/4024 0.220s 0.001s
im_detect: 3361/4024 0.220s 0.001s
im_detect: 3362/4024 0.220s 0.001s
im_detect: 3363/4024 0.220s 0.001s
im_detect: 3364/4024 0.220s 0.001s
im_detect: 3365/4024 0.220s 0.001s
im_detect: 3366/4024 0.220s 0.001s
im_detect: 3367/4024 0.220s 0.001s
im_detect: 3368/4024 0.220s 0.001s
im_detect: 3369/4024 0.220s 0.001s
im_detect: 3370/4024 0.220s 0.001s
im_detect: 3371/4024 0.220s 0.001s
im_detect: 3372/4024 0.220s 0.001s
im_detect: 3373/4024 0.220s 0.001s
im_detect: 3374/4024 0.220s 0.001s
im_detect: 3375/4024 0.220s 0.001s
im_detect: 3376/4024 0.220s 0.001s
im_detect: 3377/4024 0.220s 0.001s
im_detect: 3378/4024 0.220s 0.001s
im_detect: 3379/4024 0.220s 0.001s
im_detect: 3380/4024 0.220s 0.001s
im_detect: 3381/4024 0.220s 0.001s
im_detect: 3382/4024 0.220s 0.001s
im_detect: 3383/4024 0.220s 0.001s
im_detect: 3384/4024 0.220s 0.001s
im_detect: 3385/4024 0.220s 0.001s
im_detect: 3386/4024 0.220s 0.001s
im_detect: 3387/4024 0.220s 0.001s
im_detect: 3388/4024 0.220s 0.001s
im_detect: 3389/4024 0.220s 0.001s
im_detect: 3390/4024 0.220s 0.001s
im_detect: 3391/4024 0.220s 0.001s
im_detect: 3392/4024 0.220s 0.001s
im_detect: 3393/4024 0.220s 0.001s
im_detect: 3394/4024 0.220s 0.001s
im_detect: 3395/4024 0.220s 0.001s
im_detect: 3396/4024 0.220s 0.001s
im_detect: 3397/4024 0.220s 0.001s
im_detect: 3398/4024 0.220s 0.001s
im_detect: 3399/4024 0.220s 0.001s
im_detect: 3400/4024 0.220s 0.001s
im_detect: 3401/4024 0.220s 0.001s
im_detect: 3402/4024 0.220s 0.001s
im_detect: 3403/4024 0.220s 0.001s
im_detect: 3404/4024 0.220s 0.001s
im_detect: 3405/4024 0.220s 0.001s
im_detect: 3406/4024 0.220s 0.001s
im_detect: 3407/4024 0.220s 0.001s
im_detect: 3408/4024 0.220s 0.001s
im_detect: 3409/4024 0.220s 0.001s
im_detect: 3410/4024 0.220s 0.001s
im_detect: 3411/4024 0.220s 0.001s
im_detect: 3412/4024 0.220s 0.001s
im_detect: 3413/4024 0.220s 0.001s
im_detect: 3414/4024 0.220s 0.001s
im_detect: 3415/4024 0.220s 0.001s
im_detect: 3416/4024 0.220s 0.001s
im_detect: 3417/4024 0.220s 0.001s
im_detect: 3418/4024 0.220s 0.001s
im_detect: 3419/4024 0.220s 0.001s
im_detect: 3420/4024 0.220s 0.001s
im_detect: 3421/4024 0.220s 0.001s
im_detect: 3422/4024 0.220s 0.001s
im_detect: 3423/4024 0.220s 0.001s
im_detect: 3424/4024 0.220s 0.001s
im_detect: 3425/4024 0.220s 0.001s
im_detect: 3426/4024 0.220s 0.001s
im_detect: 3427/4024 0.220s 0.001s
im_detect: 3428/4024 0.220s 0.001s
im_detect: 3429/4024 0.220s 0.001s
im_detect: 3430/4024 0.220s 0.001s
im_detect: 3431/4024 0.220s 0.001s
im_detect: 3432/4024 0.220s 0.001s
im_detect: 3433/4024 0.220s 0.001s
im_detect: 3434/4024 0.220s 0.001s
im_detect: 3435/4024 0.220s 0.001s
im_detect: 3436/4024 0.220s 0.001s
im_detect: 3437/4024 0.220s 0.001s
im_detect: 3438/4024 0.220s 0.001s
im_detect: 3439/4024 0.220s 0.001s
im_detect: 3440/4024 0.220s 0.001s
im_detect: 3441/4024 0.220s 0.001s
im_detect: 3442/4024 0.220s 0.001s
im_detect: 3443/4024 0.220s 0.001s
im_detect: 3444/4024 0.220s 0.001s
im_detect: 3445/4024 0.220s 0.001s
im_detect: 3446/4024 0.220s 0.001s
im_detect: 3447/4024 0.220s 0.001s
im_detect: 3448/4024 0.220s 0.001s
im_detect: 3449/4024 0.220s 0.001s
im_detect: 3450/4024 0.220s 0.001s
im_detect: 3451/4024 0.220s 0.001s
im_detect: 3452/4024 0.220s 0.001s
im_detect: 3453/4024 0.220s 0.001s
im_detect: 3454/4024 0.220s 0.001s
im_detect: 3455/4024 0.220s 0.001s
im_detect: 3456/4024 0.220s 0.001s
im_detect: 3457/4024 0.220s 0.001s
im_detect: 3458/4024 0.220s 0.001s
im_detect: 3459/4024 0.220s 0.001s
im_detect: 3460/4024 0.220s 0.001s
im_detect: 3461/4024 0.220s 0.001s
im_detect: 3462/4024 0.220s 0.001s
im_detect: 3463/4024 0.220s 0.001s
im_detect: 3464/4024 0.220s 0.001s
im_detect: 3465/4024 0.220s 0.001s
im_detect: 3466/4024 0.220s 0.001s
im_detect: 3467/4024 0.220s 0.001s
im_detect: 3468/4024 0.220s 0.001s
im_detect: 3469/4024 0.220s 0.001s
im_detect: 3470/4024 0.220s 0.001s
im_detect: 3471/4024 0.220s 0.001s
im_detect: 3472/4024 0.220s 0.001s
im_detect: 3473/4024 0.220s 0.001s
im_detect: 3474/4024 0.220s 0.001s
im_detect: 3475/4024 0.220s 0.001s
im_detect: 3476/4024 0.220s 0.001s
im_detect: 3477/4024 0.220s 0.001s
im_detect: 3478/4024 0.220s 0.001s
im_detect: 3479/4024 0.220s 0.001s
im_detect: 3480/4024 0.220s 0.001s
im_detect: 3481/4024 0.220s 0.001s
im_detect: 3482/4024 0.220s 0.001s
im_detect: 3483/4024 0.220s 0.001s
im_detect: 3484/4024 0.220s 0.001s
im_detect: 3485/4024 0.220s 0.001s
im_detect: 3486/4024 0.220s 0.001s
im_detect: 3487/4024 0.220s 0.001s
im_detect: 3488/4024 0.220s 0.001s
im_detect: 3489/4024 0.220s 0.001s
im_detect: 3490/4024 0.220s 0.001s
im_detect: 3491/4024 0.220s 0.001s
im_detect: 3492/4024 0.220s 0.001s
im_detect: 3493/4024 0.220s 0.001s
im_detect: 3494/4024 0.220s 0.001s
im_detect: 3495/4024 0.220s 0.001s
im_detect: 3496/4024 0.220s 0.001s
im_detect: 3497/4024 0.220s 0.001s
im_detect: 3498/4024 0.220s 0.001s
im_detect: 3499/4024 0.220s 0.001s
im_detect: 3500/4024 0.220s 0.001s
im_detect: 3501/4024 0.220s 0.001s
im_detect: 3502/4024 0.220s 0.001s
im_detect: 3503/4024 0.220s 0.001s
im_detect: 3504/4024 0.220s 0.001s
im_detect: 3505/4024 0.220s 0.001s
im_detect: 3506/4024 0.220s 0.001s
im_detect: 3507/4024 0.220s 0.001s
im_detect: 3508/4024 0.220s 0.001s
im_detect: 3509/4024 0.220s 0.001s
im_detect: 3510/4024 0.220s 0.001s
im_detect: 3511/4024 0.220s 0.001s
im_detect: 3512/4024 0.220s 0.001s
im_detect: 3513/4024 0.220s 0.001s
im_detect: 3514/4024 0.220s 0.001s
im_detect: 3515/4024 0.220s 0.001s
im_detect: 3516/4024 0.220s 0.001s
im_detect: 3517/4024 0.220s 0.001s
im_detect: 3518/4024 0.220s 0.001s
im_detect: 3519/4024 0.220s 0.001s
im_detect: 3520/4024 0.220s 0.001s
im_detect: 3521/4024 0.220s 0.001s
im_detect: 3522/4024 0.220s 0.001s
im_detect: 3523/4024 0.220s 0.001s
im_detect: 3524/4024 0.220s 0.001s
im_detect: 3525/4024 0.220s 0.001s
im_detect: 3526/4024 0.220s 0.001s
im_detect: 3527/4024 0.220s 0.001s
im_detect: 3528/4024 0.220s 0.001s
im_detect: 3529/4024 0.220s 0.001s
im_detect: 3530/4024 0.220s 0.001s
im_detect: 3531/4024 0.220s 0.001s
im_detect: 3532/4024 0.220s 0.001s
im_detect: 3533/4024 0.220s 0.001s
im_detect: 3534/4024 0.220s 0.001s
im_detect: 3535/4024 0.220s 0.001s
im_detect: 3536/4024 0.220s 0.001s
im_detect: 3537/4024 0.220s 0.001s
im_detect: 3538/4024 0.220s 0.001s
im_detect: 3539/4024 0.220s 0.001s
im_detect: 3540/4024 0.220s 0.001s
im_detect: 3541/4024 0.220s 0.001s
im_detect: 3542/4024 0.220s 0.001s
im_detect: 3543/4024 0.220s 0.001s
im_detect: 3544/4024 0.220s 0.001s
im_detect: 3545/4024 0.220s 0.001s
im_detect: 3546/4024 0.220s 0.001s
im_detect: 3547/4024 0.220s 0.001s
im_detect: 3548/4024 0.220s 0.001s
im_detect: 3549/4024 0.220s 0.001s
im_detect: 3550/4024 0.220s 0.001s
im_detect: 3551/4024 0.220s 0.001s
im_detect: 3552/4024 0.220s 0.001s
im_detect: 3553/4024 0.220s 0.001s
im_detect: 3554/4024 0.220s 0.001s
im_detect: 3555/4024 0.220s 0.001s
im_detect: 3556/4024 0.220s 0.001s
im_detect: 3557/4024 0.220s 0.001s
im_detect: 3558/4024 0.220s 0.001s
im_detect: 3559/4024 0.220s 0.001s
im_detect: 3560/4024 0.220s 0.001s
im_detect: 3561/4024 0.220s 0.001s
im_detect: 3562/4024 0.220s 0.001s
im_detect: 3563/4024 0.220s 0.001s
im_detect: 3564/4024 0.220s 0.001s
im_detect: 3565/4024 0.220s 0.001s
im_detect: 3566/4024 0.220s 0.001s
im_detect: 3567/4024 0.220s 0.001s
im_detect: 3568/4024 0.220s 0.001s
im_detect: 3569/4024 0.220s 0.001s
im_detect: 3570/4024 0.220s 0.001s
im_detect: 3571/4024 0.220s 0.001s
im_detect: 3572/4024 0.220s 0.001s
im_detect: 3573/4024 0.220s 0.001s
im_detect: 3574/4024 0.220s 0.001s
im_detect: 3575/4024 0.220s 0.001s
im_detect: 3576/4024 0.220s 0.001s
im_detect: 3577/4024 0.220s 0.001s
im_detect: 3578/4024 0.220s 0.001s
im_detect: 3579/4024 0.220s 0.001s
im_detect: 3580/4024 0.220s 0.001s
im_detect: 3581/4024 0.220s 0.001s
im_detect: 3582/4024 0.220s 0.001s
im_detect: 3583/4024 0.220s 0.001s
im_detect: 3584/4024 0.220s 0.001s
im_detect: 3585/4024 0.220s 0.001s
im_detect: 3586/4024 0.220s 0.001s
im_detect: 3587/4024 0.220s 0.001s
im_detect: 3588/4024 0.220s 0.001s
im_detect: 3589/4024 0.220s 0.001s
im_detect: 3590/4024 0.220s 0.001s
im_detect: 3591/4024 0.220s 0.001s
im_detect: 3592/4024 0.220s 0.001s
im_detect: 3593/4024 0.220s 0.001s
im_detect: 3594/4024 0.220s 0.001s
im_detect: 3595/4024 0.220s 0.001s
im_detect: 3596/4024 0.220s 0.001s
im_detect: 3597/4024 0.220s 0.001s
im_detect: 3598/4024 0.220s 0.001s
im_detect: 3599/4024 0.220s 0.001s
im_detect: 3600/4024 0.220s 0.001s
im_detect: 3601/4024 0.220s 0.001s
im_detect: 3602/4024 0.220s 0.001s
im_detect: 3603/4024 0.220s 0.001s
im_detect: 3604/4024 0.220s 0.001s
im_detect: 3605/4024 0.220s 0.001s
im_detect: 3606/4024 0.220s 0.001s
im_detect: 3607/4024 0.220s 0.001s
im_detect: 3608/4024 0.220s 0.001s
im_detect: 3609/4024 0.220s 0.001s
im_detect: 3610/4024 0.220s 0.001s
im_detect: 3611/4024 0.220s 0.001s
im_detect: 3612/4024 0.220s 0.001s
im_detect: 3613/4024 0.220s 0.001s
im_detect: 3614/4024 0.220s 0.001s
im_detect: 3615/4024 0.220s 0.001s
im_detect: 3616/4024 0.220s 0.001s
im_detect: 3617/4024 0.220s 0.001s
im_detect: 3618/4024 0.220s 0.001s
im_detect: 3619/4024 0.220s 0.001s
im_detect: 3620/4024 0.220s 0.001s
im_detect: 3621/4024 0.220s 0.001s
im_detect: 3622/4024 0.220s 0.001s
im_detect: 3623/4024 0.220s 0.001s
im_detect: 3624/4024 0.220s 0.001s
im_detect: 3625/4024 0.220s 0.001s
im_detect: 3626/4024 0.220s 0.001s
im_detect: 3627/4024 0.220s 0.001s
im_detect: 3628/4024 0.220s 0.001s
im_detect: 3629/4024 0.220s 0.001s
im_detect: 3630/4024 0.220s 0.001s
im_detect: 3631/4024 0.220s 0.001s
im_detect: 3632/4024 0.220s 0.001s
im_detect: 3633/4024 0.220s 0.001s
im_detect: 3634/4024 0.220s 0.001s
im_detect: 3635/4024 0.220s 0.001s
im_detect: 3636/4024 0.220s 0.001s
im_detect: 3637/4024 0.220s 0.001s
im_detect: 3638/4024 0.220s 0.001s
im_detect: 3639/4024 0.220s 0.001s
im_detect: 3640/4024 0.220s 0.001s
im_detect: 3641/4024 0.220s 0.001s
im_detect: 3642/4024 0.220s 0.001s
im_detect: 3643/4024 0.220s 0.001s
im_detect: 3644/4024 0.220s 0.001s
im_detect: 3645/4024 0.220s 0.001s
im_detect: 3646/4024 0.220s 0.001s
im_detect: 3647/4024 0.220s 0.001s
im_detect: 3648/4024 0.220s 0.001s
im_detect: 3649/4024 0.220s 0.001s
im_detect: 3650/4024 0.220s 0.001s
im_detect: 3651/4024 0.220s 0.001s
im_detect: 3652/4024 0.220s 0.001s
im_detect: 3653/4024 0.220s 0.001s
im_detect: 3654/4024 0.220s 0.001s
im_detect: 3655/4024 0.220s 0.001s
im_detect: 3656/4024 0.220s 0.001s
im_detect: 3657/4024 0.220s 0.001s
im_detect: 3658/4024 0.220s 0.001s
im_detect: 3659/4024 0.220s 0.001s
im_detect: 3660/4024 0.220s 0.001s
im_detect: 3661/4024 0.220s 0.001s
im_detect: 3662/4024 0.220s 0.001s
im_detect: 3663/4024 0.220s 0.001s
im_detect: 3664/4024 0.220s 0.001s
im_detect: 3665/4024 0.220s 0.001s
im_detect: 3666/4024 0.220s 0.001s
im_detect: 3667/4024 0.220s 0.001s
im_detect: 3668/4024 0.220s 0.001s
im_detect: 3669/4024 0.220s 0.001s
im_detect: 3670/4024 0.220s 0.001s
im_detect: 3671/4024 0.220s 0.001s
im_detect: 3672/4024 0.220s 0.001s
im_detect: 3673/4024 0.220s 0.001s
im_detect: 3674/4024 0.220s 0.001s
im_detect: 3675/4024 0.220s 0.001s
im_detect: 3676/4024 0.220s 0.001s
im_detect: 3677/4024 0.220s 0.001s
im_detect: 3678/4024 0.220s 0.001s
im_detect: 3679/4024 0.220s 0.001s
im_detect: 3680/4024 0.220s 0.001s
im_detect: 3681/4024 0.220s 0.001s
im_detect: 3682/4024 0.220s 0.001s
im_detect: 3683/4024 0.220s 0.001s
im_detect: 3684/4024 0.220s 0.001s
im_detect: 3685/4024 0.220s 0.001s
im_detect: 3686/4024 0.220s 0.001s
im_detect: 3687/4024 0.220s 0.001s
im_detect: 3688/4024 0.220s 0.001s
im_detect: 3689/4024 0.220s 0.001s
im_detect: 3690/4024 0.220s 0.001s
im_detect: 3691/4024 0.220s 0.001s
im_detect: 3692/4024 0.220s 0.001s
im_detect: 3693/4024 0.220s 0.001s
im_detect: 3694/4024 0.220s 0.001s
im_detect: 3695/4024 0.220s 0.001s
im_detect: 3696/4024 0.220s 0.001s
im_detect: 3697/4024 0.220s 0.001s
im_detect: 3698/4024 0.220s 0.001s
im_detect: 3699/4024 0.220s 0.001s
im_detect: 3700/4024 0.220s 0.001s
im_detect: 3701/4024 0.220s 0.001s
im_detect: 3702/4024 0.220s 0.001s
im_detect: 3703/4024 0.220s 0.001s
im_detect: 3704/4024 0.220s 0.001s
im_detect: 3705/4024 0.220s 0.001s
im_detect: 3706/4024 0.220s 0.001s
im_detect: 3707/4024 0.220s 0.001s
im_detect: 3708/4024 0.220s 0.001s
im_detect: 3709/4024 0.220s 0.001s
im_detect: 3710/4024 0.220s 0.001s
im_detect: 3711/4024 0.220s 0.001s
im_detect: 3712/4024 0.220s 0.001s
im_detect: 3713/4024 0.220s 0.001s
im_detect: 3714/4024 0.220s 0.001s
im_detect: 3715/4024 0.220s 0.001s
im_detect: 3716/4024 0.220s 0.001s
im_detect: 3717/4024 0.220s 0.001s
im_detect: 3718/4024 0.220s 0.001s
im_detect: 3719/4024 0.220s 0.001s
im_detect: 3720/4024 0.220s 0.001s
im_detect: 3721/4024 0.220s 0.001s
im_detect: 3722/4024 0.220s 0.001s
im_detect: 3723/4024 0.220s 0.001s
im_detect: 3724/4024 0.220s 0.001s
im_detect: 3725/4024 0.220s 0.001s
im_detect: 3726/4024 0.220s 0.001s
im_detect: 3727/4024 0.220s 0.001s
im_detect: 3728/4024 0.220s 0.001s
im_detect: 3729/4024 0.220s 0.001s
im_detect: 3730/4024 0.220s 0.001s
im_detect: 3731/4024 0.220s 0.001s
im_detect: 3732/4024 0.220s 0.001s
im_detect: 3733/4024 0.220s 0.001s
im_detect: 3734/4024 0.220s 0.001s
im_detect: 3735/4024 0.220s 0.001s
im_detect: 3736/4024 0.220s 0.001s
im_detect: 3737/4024 0.220s 0.001s
im_detect: 3738/4024 0.220s 0.001s
im_detect: 3739/4024 0.220s 0.001s
im_detect: 3740/4024 0.220s 0.001s
im_detect: 3741/4024 0.220s 0.001s
im_detect: 3742/4024 0.220s 0.001s
im_detect: 3743/4024 0.220s 0.001s
im_detect: 3744/4024 0.220s 0.001s
im_detect: 3745/4024 0.220s 0.001s
im_detect: 3746/4024 0.220s 0.001s
im_detect: 3747/4024 0.220s 0.001s
im_detect: 3748/4024 0.220s 0.001s
im_detect: 3749/4024 0.220s 0.001s
im_detect: 3750/4024 0.220s 0.001s
im_detect: 3751/4024 0.220s 0.001s
im_detect: 3752/4024 0.220s 0.001s
im_detect: 3753/4024 0.220s 0.001s
im_detect: 3754/4024 0.220s 0.001s
im_detect: 3755/4024 0.220s 0.001s
im_detect: 3756/4024 0.220s 0.001s
im_detect: 3757/4024 0.220s 0.001s
im_detect: 3758/4024 0.220s 0.001s
im_detect: 3759/4024 0.220s 0.001s
im_detect: 3760/4024 0.220s 0.001s
im_detect: 3761/4024 0.220s 0.001s
im_detect: 3762/4024 0.220s 0.001s
im_detect: 3763/4024 0.220s 0.001s
im_detect: 3764/4024 0.220s 0.001s
im_detect: 3765/4024 0.220s 0.001s
im_detect: 3766/4024 0.220s 0.001s
im_detect: 3767/4024 0.220s 0.001s
im_detect: 3768/4024 0.220s 0.001s
im_detect: 3769/4024 0.220s 0.001s
im_detect: 3770/4024 0.220s 0.001s
im_detect: 3771/4024 0.220s 0.001s
im_detect: 3772/4024 0.220s 0.001s
im_detect: 3773/4024 0.220s 0.001s
im_detect: 3774/4024 0.220s 0.001s
im_detect: 3775/4024 0.220s 0.001s
im_detect: 3776/4024 0.220s 0.001s
im_detect: 3777/4024 0.220s 0.001s
im_detect: 3778/4024 0.220s 0.001s
im_detect: 3779/4024 0.220s 0.001s
im_detect: 3780/4024 0.220s 0.001s
im_detect: 3781/4024 0.220s 0.001s
im_detect: 3782/4024 0.220s 0.001s
im_detect: 3783/4024 0.220s 0.001s
im_detect: 3784/4024 0.220s 0.001s
im_detect: 3785/4024 0.220s 0.001s
im_detect: 3786/4024 0.220s 0.001s
im_detect: 3787/4024 0.220s 0.001s
im_detect: 3788/4024 0.220s 0.001s
im_detect: 3789/4024 0.220s 0.001s
im_detect: 3790/4024 0.220s 0.001s
im_detect: 3791/4024 0.220s 0.001s
im_detect: 3792/4024 0.220s 0.001s
im_detect: 3793/4024 0.220s 0.001s
im_detect: 3794/4024 0.220s 0.001s
im_detect: 3795/4024 0.220s 0.001s
im_detect: 3796/4024 0.220s 0.001s
im_detect: 3797/4024 0.220s 0.001s
im_detect: 3798/4024 0.220s 0.001s
im_detect: 3799/4024 0.220s 0.001s
im_detect: 3800/4024 0.220s 0.001s
im_detect: 3801/4024 0.220s 0.001s
im_detect: 3802/4024 0.220s 0.001s
im_detect: 3803/4024 0.220s 0.001s
im_detect: 3804/4024 0.220s 0.001s
im_detect: 3805/4024 0.220s 0.001s
im_detect: 3806/4024 0.220s 0.001s
im_detect: 3807/4024 0.220s 0.001s
im_detect: 3808/4024 0.220s 0.001s
im_detect: 3809/4024 0.220s 0.001s
im_detect: 3810/4024 0.220s 0.001s
im_detect: 3811/4024 0.220s 0.001s
im_detect: 3812/4024 0.220s 0.001s
im_detect: 3813/4024 0.220s 0.001s
im_detect: 3814/4024 0.220s 0.001s
im_detect: 3815/4024 0.220s 0.001s
im_detect: 3816/4024 0.220s 0.001s
im_detect: 3817/4024 0.220s 0.001s
im_detect: 3818/4024 0.220s 0.001s
im_detect: 3819/4024 0.220s 0.001s
im_detect: 3820/4024 0.220s 0.001s
im_detect: 3821/4024 0.220s 0.001s
im_detect: 3822/4024 0.220s 0.001s
im_detect: 3823/4024 0.220s 0.001s
im_detect: 3824/4024 0.220s 0.001s
im_detect: 3825/4024 0.220s 0.001s
im_detect: 3826/4024 0.220s 0.001s
im_detect: 3827/4024 0.220s 0.001s
im_detect: 3828/4024 0.220s 0.001s
im_detect: 3829/4024 0.220s 0.001s
im_detect: 3830/4024 0.220s 0.001s
im_detect: 3831/4024 0.220s 0.001s
im_detect: 3832/4024 0.220s 0.001s
im_detect: 3833/4024 0.220s 0.001s
im_detect: 3834/4024 0.220s 0.001s
im_detect: 3835/4024 0.220s 0.001s
im_detect: 3836/4024 0.220s 0.001s
im_detect: 3837/4024 0.220s 0.001s
im_detect: 3838/4024 0.220s 0.001s
im_detect: 3839/4024 0.220s 0.001s
im_detect: 3840/4024 0.220s 0.001s
im_detect: 3841/4024 0.220s 0.001s
im_detect: 3842/4024 0.220s 0.001s
im_detect: 3843/4024 0.220s 0.001s
im_detect: 3844/4024 0.220s 0.001s
im_detect: 3845/4024 0.220s 0.001s
im_detect: 3846/4024 0.220s 0.001s
im_detect: 3847/4024 0.220s 0.001s
im_detect: 3848/4024 0.220s 0.001s
im_detect: 3849/4024 0.220s 0.001s
im_detect: 3850/4024 0.220s 0.001s
im_detect: 3851/4024 0.220s 0.001s
im_detect: 3852/4024 0.220s 0.001s
im_detect: 3853/4024 0.220s 0.001s
im_detect: 3854/4024 0.220s 0.001s
im_detect: 3855/4024 0.220s 0.001s
im_detect: 3856/4024 0.220s 0.001s
im_detect: 3857/4024 0.220s 0.001s
im_detect: 3858/4024 0.220s 0.001s
im_detect: 3859/4024 0.220s 0.001s
im_detect: 3860/4024 0.220s 0.001s
im_detect: 3861/4024 0.220s 0.001s
im_detect: 3862/4024 0.220s 0.001s
im_detect: 3863/4024 0.220s 0.001s
im_detect: 3864/4024 0.220s 0.001s
im_detect: 3865/4024 0.220s 0.001s
im_detect: 3866/4024 0.220s 0.001s
im_detect: 3867/4024 0.220s 0.001s
im_detect: 3868/4024 0.220s 0.001s
im_detect: 3869/4024 0.220s 0.001s
im_detect: 3870/4024 0.220s 0.001s
im_detect: 3871/4024 0.220s 0.001s
im_detect: 3872/4024 0.220s 0.001s
im_detect: 3873/4024 0.220s 0.001s
im_detect: 3874/4024 0.220s 0.001s
im_detect: 3875/4024 0.220s 0.001s
im_detect: 3876/4024 0.220s 0.001s
im_detect: 3877/4024 0.220s 0.001s
im_detect: 3878/4024 0.220s 0.001s
im_detect: 3879/4024 0.220s 0.001s
im_detect: 3880/4024 0.220s 0.001s
im_detect: 3881/4024 0.220s 0.001s
im_detect: 3882/4024 0.220s 0.001s
im_detect: 3883/4024 0.220s 0.001s
im_detect: 3884/4024 0.220s 0.001s
im_detect: 3885/4024 0.220s 0.001s
im_detect: 3886/4024 0.220s 0.001s
im_detect: 3887/4024 0.220s 0.001s
im_detect: 3888/4024 0.220s 0.001s
im_detect: 3889/4024 0.220s 0.001s
im_detect: 3890/4024 0.220s 0.001s
im_detect: 3891/4024 0.220s 0.001s
im_detect: 3892/4024 0.220s 0.001s
im_detect: 3893/4024 0.220s 0.001s
im_detect: 3894/4024 0.220s 0.001s
im_detect: 3895/4024 0.220s 0.001s
im_detect: 3896/4024 0.220s 0.001s
im_detect: 3897/4024 0.220s 0.001s
im_detect: 3898/4024 0.220s 0.001s
im_detect: 3899/4024 0.220s 0.001s
im_detect: 3900/4024 0.220s 0.001s
im_detect: 3901/4024 0.220s 0.001s
im_detect: 3902/4024 0.220s 0.001s
im_detect: 3903/4024 0.220s 0.001s
im_detect: 3904/4024 0.220s 0.001s
im_detect: 3905/4024 0.220s 0.001s
im_detect: 3906/4024 0.220s 0.001s
im_detect: 3907/4024 0.220s 0.001s
im_detect: 3908/4024 0.220s 0.001s
im_detect: 3909/4024 0.220s 0.001s
im_detect: 3910/4024 0.220s 0.001s
im_detect: 3911/4024 0.220s 0.001s
im_detect: 3912/4024 0.220s 0.001s
im_detect: 3913/4024 0.220s 0.001s
im_detect: 3914/4024 0.220s 0.001s
im_detect: 3915/4024 0.220s 0.001s
im_detect: 3916/4024 0.220s 0.001s
im_detect: 3917/4024 0.220s 0.001s
im_detect: 3918/4024 0.220s 0.001s
im_detect: 3919/4024 0.220s 0.001s
im_detect: 3920/4024 0.220s 0.001s
im_detect: 3921/4024 0.220s 0.001s
im_detect: 3922/4024 0.220s 0.001s
im_detect: 3923/4024 0.220s 0.001s
im_detect: 3924/4024 0.220s 0.001s
im_detect: 3925/4024 0.220s 0.001s
im_detect: 3926/4024 0.220s 0.001s
im_detect: 3927/4024 0.220s 0.001s
im_detect: 3928/4024 0.220s 0.001s
im_detect: 3929/4024 0.220s 0.001s
im_detect: 3930/4024 0.220s 0.001s
im_detect: 3931/4024 0.220s 0.001s
im_detect: 3932/4024 0.220s 0.001s
im_detect: 3933/4024 0.220s 0.001s
im_detect: 3934/4024 0.220s 0.001s
im_detect: 3935/4024 0.220s 0.001s
im_detect: 3936/4024 0.220s 0.001s
im_detect: 3937/4024 0.220s 0.001s
im_detect: 3938/4024 0.220s 0.001s
im_detect: 3939/4024 0.220s 0.001s
im_detect: 3940/4024 0.220s 0.001s
im_detect: 3941/4024 0.220s 0.001s
im_detect: 3942/4024 0.220s 0.001s
im_detect: 3943/4024 0.220s 0.001s
im_detect: 3944/4024 0.220s 0.001s
im_detect: 3945/4024 0.220s 0.001s
im_detect: 3946/4024 0.220s 0.001s
im_detect: 3947/4024 0.220s 0.001s
im_detect: 3948/4024 0.220s 0.001s
im_detect: 3949/4024 0.220s 0.001s
im_detect: 3950/4024 0.220s 0.001s
im_detect: 3951/4024 0.220s 0.001s
im_detect: 3952/4024 0.220s 0.001s
im_detect: 3953/4024 0.220s 0.001s
im_detect: 3954/4024 0.220s 0.001s
im_detect: 3955/4024 0.220s 0.001s
im_detect: 3956/4024 0.220s 0.001s
im_detect: 3957/4024 0.220s 0.001s
im_detect: 3958/4024 0.220s 0.001s
im_detect: 3959/4024 0.220s 0.001s
im_detect: 3960/4024 0.220s 0.001s
im_detect: 3961/4024 0.220s 0.001s
im_detect: 3962/4024 0.220s 0.001s
im_detect: 3963/4024 0.220s 0.001s
im_detect: 3964/4024 0.220s 0.001s
im_detect: 3965/4024 0.220s 0.001s
im_detect: 3966/4024 0.220s 0.001s
im_detect: 3967/4024 0.220s 0.001s
im_detect: 3968/4024 0.220s 0.001s
im_detect: 3969/4024 0.220s 0.001s
im_detect: 3970/4024 0.220s 0.001s
im_detect: 3971/4024 0.220s 0.001s
im_detect: 3972/4024 0.220s 0.001s
im_detect: 3973/4024 0.220s 0.001s
im_detect: 3974/4024 0.220s 0.001s
im_detect: 3975/4024 0.220s 0.001s
im_detect: 3976/4024 0.220s 0.001s
im_detect: 3977/4024 0.221s 0.001s
im_detect: 3978/4024 0.220s 0.001s
im_detect: 3979/4024 0.220s 0.001s
im_detect: 3980/4024 0.220s 0.001s
im_detect: 3981/4024 0.220s 0.001s
im_detect: 3982/4024 0.220s 0.001s
im_detect: 3983/4024 0.220s 0.001s
im_detect: 3984/4024 0.220s 0.001s
im_detect: 3985/4024 0.220s 0.001s
im_detect: 3986/4024 0.220s 0.001s
im_detect: 3987/4024 0.220s 0.001s
im_detect: 3988/4024 0.220s 0.001s
im_detect: 3989/4024 0.220s 0.001s
im_detect: 3990/4024 0.220s 0.001s
im_detect: 3991/4024 0.220s 0.001s
im_detect: 3992/4024 0.220s 0.001s
im_detect: 3993/4024 0.220s 0.001s
im_detect: 3994/4024 0.220s 0.001s
im_detect: 3995/4024 0.220s 0.001s
im_detect: 3996/4024 0.220s 0.001s
im_detect: 3997/4024 0.220s 0.001s
im_detect: 3998/4024 0.220s 0.001s
im_detect: 3999/4024 0.220s 0.001s
im_detect: 4000/4024 0.220s 0.001s
im_detect: 4001/4024 0.220s 0.001s
im_detect: 4002/4024 0.220s 0.001s
im_detect: 4003/4024 0.220s 0.001s
im_detect: 4004/4024 0.220s 0.001s
im_detect: 4005/4024 0.220s 0.001s
im_detect: 4006/4024 0.220s 0.001s
im_detect: 4007/4024 0.220s 0.001s
im_detect: 4008/4024 0.220s 0.001s
im_detect: 4009/4024 0.220s 0.001s
im_detect: 4010/4024 0.221s 0.001s
im_detect: 4011/4024 0.221s 0.001s
im_detect: 4012/4024 0.221s 0.001s
im_detect: 4013/4024 0.221s 0.001s
im_detect: 4014/4024 0.221s 0.001s
im_detect: 4015/4024 0.221s 0.001s
im_detect: 4016/4024 0.221s 0.001s
im_detect: 4017/4024 0.221s 0.001s
im_detect: 4018/4024 0.221s 0.001s
im_detect: 4019/4024 0.221s 0.001s
im_detect: 4020/4024 0.221s 0.001s
im_detect: 4021/4024 0.221s 0.001s
im_detect: 4022/4024 0.221s 0.001s
im_detect: 4023/4024 0.221s 0.001s
im_detect: 4024/4024 0.221s 0.001s
Evaluating detections
Writing person VOC results file
VOC07 metric? Yes
[      0.       0.       0. ... 1229857. 1229858. 1229859.] [1.00e+00 2.00e+00 3.00e+00 ... 1.66e+03 1.66e+03 1.66e+03] 0.0
/home/neuiva1/sol/10_12/py-R-FCN/tools/../lib/datasets/voc_eval.py:197: RuntimeWarning: divide by zero encountered in divide
  rec = tp / float(npos)
AP for person = 1.0000
Mean AP = 1.0000
~~~~~~~~
Results:
1.000
1.000
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	15m47.237s
user	15m11.648s
sys	1m29.528s
+ ./tools/test_net.py --gpu 3 --def experiments/10_22/model_ohem/multi_test.prototxt --net output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_8000.caffemodel --imdb voc_0712_test --cfg experiments/10_22/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_8000.caffemodel', cfg_file='experiments/10_22/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=3, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/10_22/model_ohem/multi_test.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'DATA_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '10_22/model',
 'GPU_ID': 3,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/neuiva1/sol/10_12/py-R-FCN/models/pascal_voc',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/neuiva1/sol/10_12/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.55,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 20,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 20,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 2000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W1022 16:26:47.199932 27659 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W1022 16:26:47.199975 27659 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W1022 16:26:47.199978 27659 _caffe.cpp:125] Net('experiments/10_22/model_ohem/multi_test.prototxt', 1, weights='output/10_22/model/voc_0712_trainval/fpn_rfcn_ohem_iter_8000.caffemodel')
I1022 16:26:47.203567 27659 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/10_22/model_ohem/multi_test.prototxt
I1022 16:26:47.203619 27659 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W1022 16:26:47.203624 27659 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I1022 16:26:47.205755 27659 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b
I1022 16:26:47.206863 27659 layer_factory.hpp:77] Creating layer input
I1022 16:26:47.206876 27659 net.cpp:100] Creating Layer input
I1022 16:26:47.206881 27659 net.cpp:418] input -> data
I1022 16:26:47.206900 27659 net.cpp:418] input -> im_info
I1022 16:26:47.721933 27659 net.cpp:150] Setting up input
I1022 16:26:47.721976 27659 net.cpp:157] Top shape: 1 3 224 224 (150528)
I1022 16:26:47.721982 27659 net.cpp:157] Top shape: 1 3 (3)
I1022 16:26:47.721984 27659 net.cpp:165] Memory required for data: 602124
I1022 16:26:47.721992 27659 layer_factory.hpp:77] Creating layer conv1
I1022 16:26:47.722016 27659 net.cpp:100] Creating Layer conv1
I1022 16:26:47.722021 27659 net.cpp:444] conv1 <- data
I1022 16:26:47.722031 27659 net.cpp:418] conv1 -> conv1
I1022 16:26:48.431869 27659 net.cpp:150] Setting up conv1
I1022 16:26:48.431907 27659 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 16:26:48.431911 27659 net.cpp:165] Memory required for data: 3813388
I1022 16:26:48.431931 27659 layer_factory.hpp:77] Creating layer bn_conv1
I1022 16:26:48.431949 27659 net.cpp:100] Creating Layer bn_conv1
I1022 16:26:48.431954 27659 net.cpp:444] bn_conv1 <- conv1
I1022 16:26:48.431962 27659 net.cpp:405] bn_conv1 -> conv1 (in-place)
I1022 16:26:48.432310 27659 net.cpp:150] Setting up bn_conv1
I1022 16:26:48.432318 27659 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 16:26:48.432322 27659 net.cpp:165] Memory required for data: 7024652
I1022 16:26:48.432333 27659 layer_factory.hpp:77] Creating layer scale_conv1
I1022 16:26:48.432341 27659 net.cpp:100] Creating Layer scale_conv1
I1022 16:26:48.432344 27659 net.cpp:444] scale_conv1 <- conv1
I1022 16:26:48.432349 27659 net.cpp:405] scale_conv1 -> conv1 (in-place)
I1022 16:26:48.432411 27659 layer_factory.hpp:77] Creating layer scale_conv1
I1022 16:26:48.432641 27659 net.cpp:150] Setting up scale_conv1
I1022 16:26:48.432651 27659 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 16:26:48.432654 27659 net.cpp:165] Memory required for data: 10235916
I1022 16:26:48.432662 27659 layer_factory.hpp:77] Creating layer conv1_relu
I1022 16:26:48.432668 27659 net.cpp:100] Creating Layer conv1_relu
I1022 16:26:48.432674 27659 net.cpp:444] conv1_relu <- conv1
I1022 16:26:48.432678 27659 net.cpp:405] conv1_relu -> conv1 (in-place)
I1022 16:26:48.432898 27659 net.cpp:150] Setting up conv1_relu
I1022 16:26:48.432909 27659 net.cpp:157] Top shape: 1 64 112 112 (802816)
I1022 16:26:48.432911 27659 net.cpp:165] Memory required for data: 13447180
I1022 16:26:48.432915 27659 layer_factory.hpp:77] Creating layer pool1
I1022 16:26:48.432924 27659 net.cpp:100] Creating Layer pool1
I1022 16:26:48.432929 27659 net.cpp:444] pool1 <- conv1
I1022 16:26:48.432934 27659 net.cpp:418] pool1 -> pool1
I1022 16:26:48.432998 27659 net.cpp:150] Setting up pool1
I1022 16:26:48.433006 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.433008 27659 net.cpp:165] Memory required for data: 14249996
I1022 16:26:48.433012 27659 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I1022 16:26:48.433017 27659 net.cpp:100] Creating Layer pool1_pool1_0_split
I1022 16:26:48.433020 27659 net.cpp:444] pool1_pool1_0_split <- pool1
I1022 16:26:48.433025 27659 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1022 16:26:48.433032 27659 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1022 16:26:48.433084 27659 net.cpp:150] Setting up pool1_pool1_0_split
I1022 16:26:48.433090 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.433094 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.433097 27659 net.cpp:165] Memory required for data: 15855628
I1022 16:26:48.433100 27659 layer_factory.hpp:77] Creating layer res2a_branch1
I1022 16:26:48.433110 27659 net.cpp:100] Creating Layer res2a_branch1
I1022 16:26:48.433113 27659 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I1022 16:26:48.433118 27659 net.cpp:418] res2a_branch1 -> res2a_branch1
I1022 16:26:48.434723 27659 net.cpp:150] Setting up res2a_branch1
I1022 16:26:48.434736 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.434739 27659 net.cpp:165] Memory required for data: 19066892
I1022 16:26:48.434746 27659 layer_factory.hpp:77] Creating layer bn2a_branch1
I1022 16:26:48.434754 27659 net.cpp:100] Creating Layer bn2a_branch1
I1022 16:26:48.434758 27659 net.cpp:444] bn2a_branch1 <- res2a_branch1
I1022 16:26:48.434763 27659 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I1022 16:26:48.438987 27659 net.cpp:150] Setting up bn2a_branch1
I1022 16:26:48.439002 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.439005 27659 net.cpp:165] Memory required for data: 22278156
I1022 16:26:48.439018 27659 layer_factory.hpp:77] Creating layer scale2a_branch1
I1022 16:26:48.439025 27659 net.cpp:100] Creating Layer scale2a_branch1
I1022 16:26:48.439028 27659 net.cpp:444] scale2a_branch1 <- res2a_branch1
I1022 16:26:48.439034 27659 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I1022 16:26:48.439096 27659 layer_factory.hpp:77] Creating layer scale2a_branch1
I1022 16:26:48.439276 27659 net.cpp:150] Setting up scale2a_branch1
I1022 16:26:48.439283 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.439287 27659 net.cpp:165] Memory required for data: 25489420
I1022 16:26:48.439293 27659 layer_factory.hpp:77] Creating layer res2a_branch2a
I1022 16:26:48.439303 27659 net.cpp:100] Creating Layer res2a_branch2a
I1022 16:26:48.439308 27659 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I1022 16:26:48.439313 27659 net.cpp:418] res2a_branch2a -> res2a_branch2a
I1022 16:26:48.440943 27659 net.cpp:150] Setting up res2a_branch2a
I1022 16:26:48.440956 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.440959 27659 net.cpp:165] Memory required for data: 26292236
I1022 16:26:48.440969 27659 layer_factory.hpp:77] Creating layer bn2a_branch2a
I1022 16:26:48.440977 27659 net.cpp:100] Creating Layer bn2a_branch2a
I1022 16:26:48.440980 27659 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I1022 16:26:48.440986 27659 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I1022 16:26:48.441301 27659 net.cpp:150] Setting up bn2a_branch2a
I1022 16:26:48.441308 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.441311 27659 net.cpp:165] Memory required for data: 27095052
I1022 16:26:48.441321 27659 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1022 16:26:48.441329 27659 net.cpp:100] Creating Layer scale2a_branch2a
I1022 16:26:48.441331 27659 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I1022 16:26:48.441336 27659 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I1022 16:26:48.441395 27659 layer_factory.hpp:77] Creating layer scale2a_branch2a
I1022 16:26:48.441581 27659 net.cpp:150] Setting up scale2a_branch2a
I1022 16:26:48.441589 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.441592 27659 net.cpp:165] Memory required for data: 27897868
I1022 16:26:48.441598 27659 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I1022 16:26:48.441606 27659 net.cpp:100] Creating Layer res2a_branch2a_relu
I1022 16:26:48.441608 27659 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I1022 16:26:48.441613 27659 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I1022 16:26:48.441823 27659 net.cpp:150] Setting up res2a_branch2a_relu
I1022 16:26:48.441834 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.441838 27659 net.cpp:165] Memory required for data: 28700684
I1022 16:26:48.441840 27659 layer_factory.hpp:77] Creating layer res2a_branch2b
I1022 16:26:48.441848 27659 net.cpp:100] Creating Layer res2a_branch2b
I1022 16:26:48.441854 27659 net.cpp:444] res2a_branch2b <- res2a_branch2a
I1022 16:26:48.441859 27659 net.cpp:418] res2a_branch2b -> res2a_branch2b
I1022 16:26:48.453294 27659 net.cpp:150] Setting up res2a_branch2b
I1022 16:26:48.453310 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.453313 27659 net.cpp:165] Memory required for data: 29503500
I1022 16:26:48.453320 27659 layer_factory.hpp:77] Creating layer bn2a_branch2b
I1022 16:26:48.453328 27659 net.cpp:100] Creating Layer bn2a_branch2b
I1022 16:26:48.453332 27659 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I1022 16:26:48.453338 27659 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I1022 16:26:48.453682 27659 net.cpp:150] Setting up bn2a_branch2b
I1022 16:26:48.453691 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.453693 27659 net.cpp:165] Memory required for data: 30306316
I1022 16:26:48.453701 27659 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1022 16:26:48.453709 27659 net.cpp:100] Creating Layer scale2a_branch2b
I1022 16:26:48.453713 27659 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I1022 16:26:48.453718 27659 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I1022 16:26:48.453778 27659 layer_factory.hpp:77] Creating layer scale2a_branch2b
I1022 16:26:48.453970 27659 net.cpp:150] Setting up scale2a_branch2b
I1022 16:26:48.453979 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.453981 27659 net.cpp:165] Memory required for data: 31109132
I1022 16:26:48.453989 27659 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I1022 16:26:48.453994 27659 net.cpp:100] Creating Layer res2a_branch2b_relu
I1022 16:26:48.453999 27659 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I1022 16:26:48.454002 27659 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I1022 16:26:48.454874 27659 net.cpp:150] Setting up res2a_branch2b_relu
I1022 16:26:48.454887 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.454890 27659 net.cpp:165] Memory required for data: 31911948
I1022 16:26:48.454895 27659 layer_factory.hpp:77] Creating layer res2a_branch2c
I1022 16:26:48.454903 27659 net.cpp:100] Creating Layer res2a_branch2c
I1022 16:26:48.454907 27659 net.cpp:444] res2a_branch2c <- res2a_branch2b
I1022 16:26:48.454913 27659 net.cpp:418] res2a_branch2c -> res2a_branch2c
I1022 16:26:48.456540 27659 net.cpp:150] Setting up res2a_branch2c
I1022 16:26:48.456554 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.456557 27659 net.cpp:165] Memory required for data: 35123212
I1022 16:26:48.456563 27659 layer_factory.hpp:77] Creating layer bn2a_branch2c
I1022 16:26:48.456571 27659 net.cpp:100] Creating Layer bn2a_branch2c
I1022 16:26:48.456575 27659 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I1022 16:26:48.456581 27659 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I1022 16:26:48.456925 27659 net.cpp:150] Setting up bn2a_branch2c
I1022 16:26:48.456934 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.456938 27659 net.cpp:165] Memory required for data: 38334476
I1022 16:26:48.456945 27659 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1022 16:26:48.456953 27659 net.cpp:100] Creating Layer scale2a_branch2c
I1022 16:26:48.456955 27659 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I1022 16:26:48.456960 27659 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I1022 16:26:48.457026 27659 layer_factory.hpp:77] Creating layer scale2a_branch2c
I1022 16:26:48.457202 27659 net.cpp:150] Setting up scale2a_branch2c
I1022 16:26:48.457211 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.457214 27659 net.cpp:165] Memory required for data: 41545740
I1022 16:26:48.457221 27659 layer_factory.hpp:77] Creating layer res2a
I1022 16:26:48.457227 27659 net.cpp:100] Creating Layer res2a
I1022 16:26:48.457231 27659 net.cpp:444] res2a <- res2a_branch1
I1022 16:26:48.457235 27659 net.cpp:444] res2a <- res2a_branch2c
I1022 16:26:48.457240 27659 net.cpp:418] res2a -> res2a
I1022 16:26:48.457275 27659 net.cpp:150] Setting up res2a
I1022 16:26:48.457281 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.457285 27659 net.cpp:165] Memory required for data: 44757004
I1022 16:26:48.457288 27659 layer_factory.hpp:77] Creating layer res2a_relu
I1022 16:26:48.457293 27659 net.cpp:100] Creating Layer res2a_relu
I1022 16:26:48.457295 27659 net.cpp:444] res2a_relu <- res2a
I1022 16:26:48.457300 27659 net.cpp:405] res2a_relu -> res2a (in-place)
I1022 16:26:48.457514 27659 net.cpp:150] Setting up res2a_relu
I1022 16:26:48.457523 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.457526 27659 net.cpp:165] Memory required for data: 47968268
I1022 16:26:48.457530 27659 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I1022 16:26:48.457536 27659 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I1022 16:26:48.457541 27659 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I1022 16:26:48.457547 27659 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I1022 16:26:48.457554 27659 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I1022 16:26:48.457614 27659 net.cpp:150] Setting up res2a_res2a_relu_0_split
I1022 16:26:48.457620 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.457624 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.457628 27659 net.cpp:165] Memory required for data: 54390796
I1022 16:26:48.457630 27659 layer_factory.hpp:77] Creating layer res2b_branch2a
I1022 16:26:48.457638 27659 net.cpp:100] Creating Layer res2b_branch2a
I1022 16:26:48.457643 27659 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I1022 16:26:48.457649 27659 net.cpp:418] res2b_branch2a -> res2b_branch2a
I1022 16:26:48.459266 27659 net.cpp:150] Setting up res2b_branch2a
I1022 16:26:48.459280 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.459282 27659 net.cpp:165] Memory required for data: 55193612
I1022 16:26:48.459290 27659 layer_factory.hpp:77] Creating layer bn2b_branch2a
I1022 16:26:48.459296 27659 net.cpp:100] Creating Layer bn2b_branch2a
I1022 16:26:48.459300 27659 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I1022 16:26:48.459305 27659 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I1022 16:26:48.459641 27659 net.cpp:150] Setting up bn2b_branch2a
I1022 16:26:48.459650 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.459651 27659 net.cpp:165] Memory required for data: 55996428
I1022 16:26:48.459662 27659 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1022 16:26:48.459669 27659 net.cpp:100] Creating Layer scale2b_branch2a
I1022 16:26:48.459673 27659 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I1022 16:26:48.459677 27659 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I1022 16:26:48.459736 27659 layer_factory.hpp:77] Creating layer scale2b_branch2a
I1022 16:26:48.459933 27659 net.cpp:150] Setting up scale2b_branch2a
I1022 16:26:48.459942 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.459945 27659 net.cpp:165] Memory required for data: 56799244
I1022 16:26:48.459952 27659 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I1022 16:26:48.459959 27659 net.cpp:100] Creating Layer res2b_branch2a_relu
I1022 16:26:48.459962 27659 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I1022 16:26:48.459966 27659 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I1022 16:26:48.460199 27659 net.cpp:150] Setting up res2b_branch2a_relu
I1022 16:26:48.460209 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.460212 27659 net.cpp:165] Memory required for data: 57602060
I1022 16:26:48.460216 27659 layer_factory.hpp:77] Creating layer res2b_branch2b
I1022 16:26:48.460227 27659 net.cpp:100] Creating Layer res2b_branch2b
I1022 16:26:48.460232 27659 net.cpp:444] res2b_branch2b <- res2b_branch2a
I1022 16:26:48.460238 27659 net.cpp:418] res2b_branch2b -> res2b_branch2b
I1022 16:26:48.461990 27659 net.cpp:150] Setting up res2b_branch2b
I1022 16:26:48.462004 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.462007 27659 net.cpp:165] Memory required for data: 58404876
I1022 16:26:48.462013 27659 layer_factory.hpp:77] Creating layer bn2b_branch2b
I1022 16:26:48.462023 27659 net.cpp:100] Creating Layer bn2b_branch2b
I1022 16:26:48.462025 27659 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I1022 16:26:48.462031 27659 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I1022 16:26:48.462389 27659 net.cpp:150] Setting up bn2b_branch2b
I1022 16:26:48.462397 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.462400 27659 net.cpp:165] Memory required for data: 59207692
I1022 16:26:48.462409 27659 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1022 16:26:48.462414 27659 net.cpp:100] Creating Layer scale2b_branch2b
I1022 16:26:48.462417 27659 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I1022 16:26:48.462424 27659 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I1022 16:26:48.462491 27659 layer_factory.hpp:77] Creating layer scale2b_branch2b
I1022 16:26:48.462698 27659 net.cpp:150] Setting up scale2b_branch2b
I1022 16:26:48.462707 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.462709 27659 net.cpp:165] Memory required for data: 60010508
I1022 16:26:48.462715 27659 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I1022 16:26:48.462723 27659 net.cpp:100] Creating Layer res2b_branch2b_relu
I1022 16:26:48.462726 27659 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I1022 16:26:48.462730 27659 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I1022 16:26:48.463606 27659 net.cpp:150] Setting up res2b_branch2b_relu
I1022 16:26:48.463618 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.463621 27659 net.cpp:165] Memory required for data: 60813324
I1022 16:26:48.463625 27659 layer_factory.hpp:77] Creating layer res2b_branch2c
I1022 16:26:48.463641 27659 net.cpp:100] Creating Layer res2b_branch2c
I1022 16:26:48.463644 27659 net.cpp:444] res2b_branch2c <- res2b_branch2b
I1022 16:26:48.463650 27659 net.cpp:418] res2b_branch2c -> res2b_branch2c
I1022 16:26:48.465369 27659 net.cpp:150] Setting up res2b_branch2c
I1022 16:26:48.465382 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.465385 27659 net.cpp:165] Memory required for data: 64024588
I1022 16:26:48.465391 27659 layer_factory.hpp:77] Creating layer bn2b_branch2c
I1022 16:26:48.465400 27659 net.cpp:100] Creating Layer bn2b_branch2c
I1022 16:26:48.465404 27659 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I1022 16:26:48.465411 27659 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I1022 16:26:48.465751 27659 net.cpp:150] Setting up bn2b_branch2c
I1022 16:26:48.465759 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.465762 27659 net.cpp:165] Memory required for data: 67235852
I1022 16:26:48.465770 27659 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1022 16:26:48.465776 27659 net.cpp:100] Creating Layer scale2b_branch2c
I1022 16:26:48.465780 27659 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I1022 16:26:48.465785 27659 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I1022 16:26:48.465849 27659 layer_factory.hpp:77] Creating layer scale2b_branch2c
I1022 16:26:48.466042 27659 net.cpp:150] Setting up scale2b_branch2c
I1022 16:26:48.466048 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.466051 27659 net.cpp:165] Memory required for data: 70447116
I1022 16:26:48.466058 27659 layer_factory.hpp:77] Creating layer res2b
I1022 16:26:48.466063 27659 net.cpp:100] Creating Layer res2b
I1022 16:26:48.466065 27659 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I1022 16:26:48.466070 27659 net.cpp:444] res2b <- res2b_branch2c
I1022 16:26:48.466078 27659 net.cpp:418] res2b -> res2b
I1022 16:26:48.466114 27659 net.cpp:150] Setting up res2b
I1022 16:26:48.466118 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.466121 27659 net.cpp:165] Memory required for data: 73658380
I1022 16:26:48.466125 27659 layer_factory.hpp:77] Creating layer res2b_relu
I1022 16:26:48.466131 27659 net.cpp:100] Creating Layer res2b_relu
I1022 16:26:48.466135 27659 net.cpp:444] res2b_relu <- res2b
I1022 16:26:48.466140 27659 net.cpp:405] res2b_relu -> res2b (in-place)
I1022 16:26:48.466365 27659 net.cpp:150] Setting up res2b_relu
I1022 16:26:48.466372 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.466375 27659 net.cpp:165] Memory required for data: 76869644
I1022 16:26:48.466379 27659 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I1022 16:26:48.466384 27659 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I1022 16:26:48.466390 27659 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I1022 16:26:48.466395 27659 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I1022 16:26:48.466403 27659 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I1022 16:26:48.466467 27659 net.cpp:150] Setting up res2b_res2b_relu_0_split
I1022 16:26:48.466472 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.466476 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.466480 27659 net.cpp:165] Memory required for data: 83292172
I1022 16:26:48.466482 27659 layer_factory.hpp:77] Creating layer res2c_branch2a
I1022 16:26:48.466491 27659 net.cpp:100] Creating Layer res2c_branch2a
I1022 16:26:48.466495 27659 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I1022 16:26:48.466502 27659 net.cpp:418] res2c_branch2a -> res2c_branch2a
I1022 16:26:48.477201 27659 net.cpp:150] Setting up res2c_branch2a
I1022 16:26:48.477216 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.477219 27659 net.cpp:165] Memory required for data: 84094988
I1022 16:26:48.477226 27659 layer_factory.hpp:77] Creating layer bn2c_branch2a
I1022 16:26:48.477236 27659 net.cpp:100] Creating Layer bn2c_branch2a
I1022 16:26:48.477238 27659 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I1022 16:26:48.477244 27659 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I1022 16:26:48.477610 27659 net.cpp:150] Setting up bn2c_branch2a
I1022 16:26:48.477617 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.477620 27659 net.cpp:165] Memory required for data: 84897804
I1022 16:26:48.477628 27659 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1022 16:26:48.477636 27659 net.cpp:100] Creating Layer scale2c_branch2a
I1022 16:26:48.477639 27659 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I1022 16:26:48.477644 27659 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I1022 16:26:48.477708 27659 layer_factory.hpp:77] Creating layer scale2c_branch2a
I1022 16:26:48.477917 27659 net.cpp:150] Setting up scale2c_branch2a
I1022 16:26:48.477926 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.477928 27659 net.cpp:165] Memory required for data: 85700620
I1022 16:26:48.477933 27659 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I1022 16:26:48.477941 27659 net.cpp:100] Creating Layer res2c_branch2a_relu
I1022 16:26:48.477944 27659 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I1022 16:26:48.477952 27659 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I1022 16:26:48.478188 27659 net.cpp:150] Setting up res2c_branch2a_relu
I1022 16:26:48.478197 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.478200 27659 net.cpp:165] Memory required for data: 86503436
I1022 16:26:48.478204 27659 layer_factory.hpp:77] Creating layer res2c_branch2b
I1022 16:26:48.478216 27659 net.cpp:100] Creating Layer res2c_branch2b
I1022 16:26:48.478221 27659 net.cpp:444] res2c_branch2b <- res2c_branch2a
I1022 16:26:48.478227 27659 net.cpp:418] res2c_branch2b -> res2c_branch2b
I1022 16:26:48.480604 27659 net.cpp:150] Setting up res2c_branch2b
I1022 16:26:48.480639 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.480655 27659 net.cpp:165] Memory required for data: 87306252
I1022 16:26:48.480661 27659 layer_factory.hpp:77] Creating layer bn2c_branch2b
I1022 16:26:48.480677 27659 net.cpp:100] Creating Layer bn2c_branch2b
I1022 16:26:48.480681 27659 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I1022 16:26:48.480689 27659 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I1022 16:26:48.481067 27659 net.cpp:150] Setting up bn2c_branch2b
I1022 16:26:48.481077 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.481081 27659 net.cpp:165] Memory required for data: 88109068
I1022 16:26:48.481088 27659 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1022 16:26:48.481094 27659 net.cpp:100] Creating Layer scale2c_branch2b
I1022 16:26:48.481097 27659 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I1022 16:26:48.481104 27659 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I1022 16:26:48.481171 27659 layer_factory.hpp:77] Creating layer scale2c_branch2b
I1022 16:26:48.481384 27659 net.cpp:150] Setting up scale2c_branch2b
I1022 16:26:48.481390 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.481393 27659 net.cpp:165] Memory required for data: 88911884
I1022 16:26:48.481400 27659 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I1022 16:26:48.481408 27659 net.cpp:100] Creating Layer res2c_branch2b_relu
I1022 16:26:48.481413 27659 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I1022 16:26:48.481418 27659 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I1022 16:26:48.481657 27659 net.cpp:150] Setting up res2c_branch2b_relu
I1022 16:26:48.481665 27659 net.cpp:157] Top shape: 1 64 56 56 (200704)
I1022 16:26:48.481668 27659 net.cpp:165] Memory required for data: 89714700
I1022 16:26:48.481672 27659 layer_factory.hpp:77] Creating layer res2c_branch2c
I1022 16:26:48.481683 27659 net.cpp:100] Creating Layer res2c_branch2c
I1022 16:26:48.481688 27659 net.cpp:444] res2c_branch2c <- res2c_branch2b
I1022 16:26:48.481693 27659 net.cpp:418] res2c_branch2c -> res2c_branch2c
I1022 16:26:48.483424 27659 net.cpp:150] Setting up res2c_branch2c
I1022 16:26:48.483438 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.483441 27659 net.cpp:165] Memory required for data: 92925964
I1022 16:26:48.483448 27659 layer_factory.hpp:77] Creating layer bn2c_branch2c
I1022 16:26:48.483458 27659 net.cpp:100] Creating Layer bn2c_branch2c
I1022 16:26:48.483460 27659 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I1022 16:26:48.483467 27659 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I1022 16:26:48.483809 27659 net.cpp:150] Setting up bn2c_branch2c
I1022 16:26:48.483819 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.483821 27659 net.cpp:165] Memory required for data: 96137228
I1022 16:26:48.483836 27659 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1022 16:26:48.483845 27659 net.cpp:100] Creating Layer scale2c_branch2c
I1022 16:26:48.483849 27659 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I1022 16:26:48.483855 27659 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I1022 16:26:48.483918 27659 layer_factory.hpp:77] Creating layer scale2c_branch2c
I1022 16:26:48.484112 27659 net.cpp:150] Setting up scale2c_branch2c
I1022 16:26:48.484119 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.484122 27659 net.cpp:165] Memory required for data: 99348492
I1022 16:26:48.484128 27659 layer_factory.hpp:77] Creating layer res2c
I1022 16:26:48.484135 27659 net.cpp:100] Creating Layer res2c
I1022 16:26:48.484138 27659 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I1022 16:26:48.484143 27659 net.cpp:444] res2c <- res2c_branch2c
I1022 16:26:48.484150 27659 net.cpp:418] res2c -> res2c
I1022 16:26:48.484186 27659 net.cpp:150] Setting up res2c
I1022 16:26:48.484194 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.484196 27659 net.cpp:165] Memory required for data: 102559756
I1022 16:26:48.484200 27659 layer_factory.hpp:77] Creating layer res2c_relu
I1022 16:26:48.484205 27659 net.cpp:100] Creating Layer res2c_relu
I1022 16:26:48.484210 27659 net.cpp:444] res2c_relu <- res2c
I1022 16:26:48.484215 27659 net.cpp:405] res2c_relu -> res2c (in-place)
I1022 16:26:48.485110 27659 net.cpp:150] Setting up res2c_relu
I1022 16:26:48.485122 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.485126 27659 net.cpp:165] Memory required for data: 105771020
I1022 16:26:48.485129 27659 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I1022 16:26:48.485136 27659 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I1022 16:26:48.485139 27659 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I1022 16:26:48.485146 27659 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I1022 16:26:48.485154 27659 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I1022 16:26:48.485227 27659 net.cpp:150] Setting up res2c_res2c_relu_0_split
I1022 16:26:48.485234 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.485239 27659 net.cpp:157] Top shape: 1 256 56 56 (802816)
I1022 16:26:48.485242 27659 net.cpp:165] Memory required for data: 112193548
I1022 16:26:48.485245 27659 layer_factory.hpp:77] Creating layer res3a_branch1
I1022 16:26:48.485255 27659 net.cpp:100] Creating Layer res3a_branch1
I1022 16:26:48.485260 27659 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I1022 16:26:48.485267 27659 net.cpp:418] res3a_branch1 -> res3a_branch1
I1022 16:26:48.497093 27659 net.cpp:150] Setting up res3a_branch1
I1022 16:26:48.497108 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.497112 27659 net.cpp:165] Memory required for data: 113799180
I1022 16:26:48.497119 27659 layer_factory.hpp:77] Creating layer bn3a_branch1
I1022 16:26:48.497126 27659 net.cpp:100] Creating Layer bn3a_branch1
I1022 16:26:48.497130 27659 net.cpp:444] bn3a_branch1 <- res3a_branch1
I1022 16:26:48.497135 27659 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I1022 16:26:48.499328 27659 net.cpp:150] Setting up bn3a_branch1
I1022 16:26:48.499341 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.499344 27659 net.cpp:165] Memory required for data: 115404812
I1022 16:26:48.499353 27659 layer_factory.hpp:77] Creating layer scale3a_branch1
I1022 16:26:48.499363 27659 net.cpp:100] Creating Layer scale3a_branch1
I1022 16:26:48.499366 27659 net.cpp:444] scale3a_branch1 <- res3a_branch1
I1022 16:26:48.499374 27659 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I1022 16:26:48.499444 27659 layer_factory.hpp:77] Creating layer scale3a_branch1
I1022 16:26:48.499636 27659 net.cpp:150] Setting up scale3a_branch1
I1022 16:26:48.499644 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.499646 27659 net.cpp:165] Memory required for data: 117010444
I1022 16:26:48.499652 27659 layer_factory.hpp:77] Creating layer res3a_branch2a
I1022 16:26:48.499663 27659 net.cpp:100] Creating Layer res3a_branch2a
I1022 16:26:48.499670 27659 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I1022 16:26:48.499675 27659 net.cpp:418] res3a_branch2a -> res3a_branch2a
I1022 16:26:48.501488 27659 net.cpp:150] Setting up res3a_branch2a
I1022 16:26:48.501502 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.501505 27659 net.cpp:165] Memory required for data: 117411852
I1022 16:26:48.501511 27659 layer_factory.hpp:77] Creating layer bn3a_branch2a
I1022 16:26:48.501520 27659 net.cpp:100] Creating Layer bn3a_branch2a
I1022 16:26:48.501524 27659 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I1022 16:26:48.501531 27659 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I1022 16:26:48.501891 27659 net.cpp:150] Setting up bn3a_branch2a
I1022 16:26:48.501899 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.501902 27659 net.cpp:165] Memory required for data: 117813260
I1022 16:26:48.501910 27659 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1022 16:26:48.501919 27659 net.cpp:100] Creating Layer scale3a_branch2a
I1022 16:26:48.501922 27659 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I1022 16:26:48.501929 27659 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I1022 16:26:48.501992 27659 layer_factory.hpp:77] Creating layer scale3a_branch2a
I1022 16:26:48.502190 27659 net.cpp:150] Setting up scale3a_branch2a
I1022 16:26:48.502198 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.502202 27659 net.cpp:165] Memory required for data: 118214668
I1022 16:26:48.502207 27659 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I1022 16:26:48.502214 27659 net.cpp:100] Creating Layer res3a_branch2a_relu
I1022 16:26:48.502218 27659 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I1022 16:26:48.502223 27659 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I1022 16:26:48.503114 27659 net.cpp:150] Setting up res3a_branch2a_relu
I1022 16:26:48.503126 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.503129 27659 net.cpp:165] Memory required for data: 118616076
I1022 16:26:48.503134 27659 layer_factory.hpp:77] Creating layer res3a_branch2b
I1022 16:26:48.503144 27659 net.cpp:100] Creating Layer res3a_branch2b
I1022 16:26:48.503147 27659 net.cpp:444] res3a_branch2b <- res3a_branch2a
I1022 16:26:48.503154 27659 net.cpp:418] res3a_branch2b -> res3a_branch2b
I1022 16:26:48.505693 27659 net.cpp:150] Setting up res3a_branch2b
I1022 16:26:48.505708 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.505712 27659 net.cpp:165] Memory required for data: 119017484
I1022 16:26:48.505717 27659 layer_factory.hpp:77] Creating layer bn3a_branch2b
I1022 16:26:48.505725 27659 net.cpp:100] Creating Layer bn3a_branch2b
I1022 16:26:48.505728 27659 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I1022 16:26:48.505735 27659 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I1022 16:26:48.506103 27659 net.cpp:150] Setting up bn3a_branch2b
I1022 16:26:48.506112 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.506114 27659 net.cpp:165] Memory required for data: 119418892
I1022 16:26:48.506122 27659 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1022 16:26:48.506130 27659 net.cpp:100] Creating Layer scale3a_branch2b
I1022 16:26:48.506134 27659 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I1022 16:26:48.506140 27659 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I1022 16:26:48.506206 27659 layer_factory.hpp:77] Creating layer scale3a_branch2b
I1022 16:26:48.506402 27659 net.cpp:150] Setting up scale3a_branch2b
I1022 16:26:48.506409 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.506412 27659 net.cpp:165] Memory required for data: 119820300
I1022 16:26:48.506418 27659 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I1022 16:26:48.506425 27659 net.cpp:100] Creating Layer res3a_branch2b_relu
I1022 16:26:48.506429 27659 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I1022 16:26:48.506438 27659 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I1022 16:26:48.506667 27659 net.cpp:150] Setting up res3a_branch2b_relu
I1022 16:26:48.506677 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.506680 27659 net.cpp:165] Memory required for data: 120221708
I1022 16:26:48.506683 27659 layer_factory.hpp:77] Creating layer res3a_branch2c
I1022 16:26:48.506695 27659 net.cpp:100] Creating Layer res3a_branch2c
I1022 16:26:48.506700 27659 net.cpp:444] res3a_branch2c <- res3a_branch2b
I1022 16:26:48.506706 27659 net.cpp:418] res3a_branch2c -> res3a_branch2c
I1022 16:26:48.508515 27659 net.cpp:150] Setting up res3a_branch2c
I1022 16:26:48.508529 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.508533 27659 net.cpp:165] Memory required for data: 121827340
I1022 16:26:48.508538 27659 layer_factory.hpp:77] Creating layer bn3a_branch2c
I1022 16:26:48.508553 27659 net.cpp:100] Creating Layer bn3a_branch2c
I1022 16:26:48.508558 27659 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I1022 16:26:48.508563 27659 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I1022 16:26:48.508941 27659 net.cpp:150] Setting up bn3a_branch2c
I1022 16:26:48.508949 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.508952 27659 net.cpp:165] Memory required for data: 123432972
I1022 16:26:48.508961 27659 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1022 16:26:48.508970 27659 net.cpp:100] Creating Layer scale3a_branch2c
I1022 16:26:48.508973 27659 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I1022 16:26:48.508980 27659 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I1022 16:26:48.509057 27659 layer_factory.hpp:77] Creating layer scale3a_branch2c
I1022 16:26:48.509256 27659 net.cpp:150] Setting up scale3a_branch2c
I1022 16:26:48.509263 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.509266 27659 net.cpp:165] Memory required for data: 125038604
I1022 16:26:48.509272 27659 layer_factory.hpp:77] Creating layer res3a
I1022 16:26:48.509279 27659 net.cpp:100] Creating Layer res3a
I1022 16:26:48.509282 27659 net.cpp:444] res3a <- res3a_branch1
I1022 16:26:48.509286 27659 net.cpp:444] res3a <- res3a_branch2c
I1022 16:26:48.509290 27659 net.cpp:418] res3a -> res3a
I1022 16:26:48.509330 27659 net.cpp:150] Setting up res3a
I1022 16:26:48.509336 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.509340 27659 net.cpp:165] Memory required for data: 126644236
I1022 16:26:48.509342 27659 layer_factory.hpp:77] Creating layer res3a_relu
I1022 16:26:48.509347 27659 net.cpp:100] Creating Layer res3a_relu
I1022 16:26:48.509351 27659 net.cpp:444] res3a_relu <- res3a
I1022 16:26:48.509356 27659 net.cpp:405] res3a_relu -> res3a (in-place)
I1022 16:26:48.510257 27659 net.cpp:150] Setting up res3a_relu
I1022 16:26:48.510272 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.510274 27659 net.cpp:165] Memory required for data: 128249868
I1022 16:26:48.510277 27659 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I1022 16:26:48.510288 27659 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I1022 16:26:48.510291 27659 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I1022 16:26:48.510296 27659 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I1022 16:26:48.510303 27659 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I1022 16:26:48.510388 27659 net.cpp:150] Setting up res3a_res3a_relu_0_split
I1022 16:26:48.510398 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.510402 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.510406 27659 net.cpp:165] Memory required for data: 131461132
I1022 16:26:48.510409 27659 layer_factory.hpp:77] Creating layer res3b_branch2a
I1022 16:26:48.510417 27659 net.cpp:100] Creating Layer res3b_branch2a
I1022 16:26:48.510422 27659 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I1022 16:26:48.510427 27659 net.cpp:418] res3b_branch2a -> res3b_branch2a
I1022 16:26:48.518808 27659 net.cpp:150] Setting up res3b_branch2a
I1022 16:26:48.518824 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.518827 27659 net.cpp:165] Memory required for data: 131862540
I1022 16:26:48.518833 27659 layer_factory.hpp:77] Creating layer bn3b_branch2a
I1022 16:26:48.518843 27659 net.cpp:100] Creating Layer bn3b_branch2a
I1022 16:26:48.518847 27659 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I1022 16:26:48.518852 27659 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I1022 16:26:48.519214 27659 net.cpp:150] Setting up bn3b_branch2a
I1022 16:26:48.519222 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.519225 27659 net.cpp:165] Memory required for data: 132263948
I1022 16:26:48.519232 27659 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1022 16:26:48.519242 27659 net.cpp:100] Creating Layer scale3b_branch2a
I1022 16:26:48.519244 27659 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I1022 16:26:48.519249 27659 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I1022 16:26:48.519315 27659 layer_factory.hpp:77] Creating layer scale3b_branch2a
I1022 16:26:48.519517 27659 net.cpp:150] Setting up scale3b_branch2a
I1022 16:26:48.519526 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.519528 27659 net.cpp:165] Memory required for data: 132665356
I1022 16:26:48.519534 27659 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I1022 16:26:48.519543 27659 net.cpp:100] Creating Layer res3b_branch2a_relu
I1022 16:26:48.519547 27659 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I1022 16:26:48.519552 27659 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I1022 16:26:48.519788 27659 net.cpp:150] Setting up res3b_branch2a_relu
I1022 16:26:48.519800 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.519804 27659 net.cpp:165] Memory required for data: 133066764
I1022 16:26:48.519807 27659 layer_factory.hpp:77] Creating layer res3b_branch2b
I1022 16:26:48.519814 27659 net.cpp:100] Creating Layer res3b_branch2b
I1022 16:26:48.519819 27659 net.cpp:444] res3b_branch2b <- res3b_branch2a
I1022 16:26:48.519825 27659 net.cpp:418] res3b_branch2b -> res3b_branch2b
I1022 16:26:48.522326 27659 net.cpp:150] Setting up res3b_branch2b
I1022 16:26:48.522339 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.522343 27659 net.cpp:165] Memory required for data: 133468172
I1022 16:26:48.522349 27659 layer_factory.hpp:77] Creating layer bn3b_branch2b
I1022 16:26:48.522358 27659 net.cpp:100] Creating Layer bn3b_branch2b
I1022 16:26:48.522362 27659 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I1022 16:26:48.522369 27659 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I1022 16:26:48.522740 27659 net.cpp:150] Setting up bn3b_branch2b
I1022 16:26:48.522750 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.522753 27659 net.cpp:165] Memory required for data: 133869580
I1022 16:26:48.522761 27659 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1022 16:26:48.522768 27659 net.cpp:100] Creating Layer scale3b_branch2b
I1022 16:26:48.522771 27659 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I1022 16:26:48.522779 27659 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I1022 16:26:48.522848 27659 layer_factory.hpp:77] Creating layer scale3b_branch2b
I1022 16:26:48.523052 27659 net.cpp:150] Setting up scale3b_branch2b
I1022 16:26:48.523061 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.523063 27659 net.cpp:165] Memory required for data: 134270988
I1022 16:26:48.523069 27659 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I1022 16:26:48.523077 27659 net.cpp:100] Creating Layer res3b_branch2b_relu
I1022 16:26:48.523079 27659 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I1022 16:26:48.523084 27659 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I1022 16:26:48.523326 27659 net.cpp:150] Setting up res3b_branch2b_relu
I1022 16:26:48.523336 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.523339 27659 net.cpp:165] Memory required for data: 134672396
I1022 16:26:48.523342 27659 layer_factory.hpp:77] Creating layer res3b_branch2c
I1022 16:26:48.523352 27659 net.cpp:100] Creating Layer res3b_branch2c
I1022 16:26:48.523357 27659 net.cpp:444] res3b_branch2c <- res3b_branch2b
I1022 16:26:48.523365 27659 net.cpp:418] res3b_branch2c -> res3b_branch2c
I1022 16:26:48.525180 27659 net.cpp:150] Setting up res3b_branch2c
I1022 16:26:48.525197 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.525199 27659 net.cpp:165] Memory required for data: 136278028
I1022 16:26:48.525205 27659 layer_factory.hpp:77] Creating layer bn3b_branch2c
I1022 16:26:48.525213 27659 net.cpp:100] Creating Layer bn3b_branch2c
I1022 16:26:48.525216 27659 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I1022 16:26:48.525224 27659 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I1022 16:26:48.525595 27659 net.cpp:150] Setting up bn3b_branch2c
I1022 16:26:48.525602 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.525605 27659 net.cpp:165] Memory required for data: 137883660
I1022 16:26:48.525614 27659 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1022 16:26:48.525621 27659 net.cpp:100] Creating Layer scale3b_branch2c
I1022 16:26:48.525624 27659 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I1022 16:26:48.525630 27659 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I1022 16:26:48.525701 27659 layer_factory.hpp:77] Creating layer scale3b_branch2c
I1022 16:26:48.525902 27659 net.cpp:150] Setting up scale3b_branch2c
I1022 16:26:48.525909 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.525913 27659 net.cpp:165] Memory required for data: 139489292
I1022 16:26:48.525918 27659 layer_factory.hpp:77] Creating layer res3b
I1022 16:26:48.525928 27659 net.cpp:100] Creating Layer res3b
I1022 16:26:48.525931 27659 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I1022 16:26:48.525935 27659 net.cpp:444] res3b <- res3b_branch2c
I1022 16:26:48.525940 27659 net.cpp:418] res3b -> res3b
I1022 16:26:48.525979 27659 net.cpp:150] Setting up res3b
I1022 16:26:48.525986 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.525990 27659 net.cpp:165] Memory required for data: 141094924
I1022 16:26:48.525992 27659 layer_factory.hpp:77] Creating layer res3b_relu
I1022 16:26:48.525997 27659 net.cpp:100] Creating Layer res3b_relu
I1022 16:26:48.526001 27659 net.cpp:444] res3b_relu <- res3b
I1022 16:26:48.526005 27659 net.cpp:405] res3b_relu -> res3b (in-place)
I1022 16:26:48.526906 27659 net.cpp:150] Setting up res3b_relu
I1022 16:26:48.526919 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.526922 27659 net.cpp:165] Memory required for data: 142700556
I1022 16:26:48.526926 27659 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I1022 16:26:48.526935 27659 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I1022 16:26:48.526939 27659 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I1022 16:26:48.526947 27659 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I1022 16:26:48.526955 27659 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I1022 16:26:48.527035 27659 net.cpp:150] Setting up res3b_res3b_relu_0_split
I1022 16:26:48.527042 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.527046 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.527050 27659 net.cpp:165] Memory required for data: 145911820
I1022 16:26:48.527052 27659 layer_factory.hpp:77] Creating layer res3c_branch2a
I1022 16:26:48.527062 27659 net.cpp:100] Creating Layer res3c_branch2a
I1022 16:26:48.527067 27659 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I1022 16:26:48.527073 27659 net.cpp:418] res3c_branch2a -> res3c_branch2a
I1022 16:26:48.529198 27659 net.cpp:150] Setting up res3c_branch2a
I1022 16:26:48.529212 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.529217 27659 net.cpp:165] Memory required for data: 146313228
I1022 16:26:48.529222 27659 layer_factory.hpp:77] Creating layer bn3c_branch2a
I1022 16:26:48.529233 27659 net.cpp:100] Creating Layer bn3c_branch2a
I1022 16:26:48.529239 27659 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I1022 16:26:48.529247 27659 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I1022 16:26:48.529608 27659 net.cpp:150] Setting up bn3c_branch2a
I1022 16:26:48.529618 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.529620 27659 net.cpp:165] Memory required for data: 146714636
I1022 16:26:48.529628 27659 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1022 16:26:48.529634 27659 net.cpp:100] Creating Layer scale3c_branch2a
I1022 16:26:48.529637 27659 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I1022 16:26:48.529644 27659 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I1022 16:26:48.529711 27659 layer_factory.hpp:77] Creating layer scale3c_branch2a
I1022 16:26:48.529916 27659 net.cpp:150] Setting up scale3c_branch2a
I1022 16:26:48.529922 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.529925 27659 net.cpp:165] Memory required for data: 147116044
I1022 16:26:48.529932 27659 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I1022 16:26:48.529938 27659 net.cpp:100] Creating Layer res3c_branch2a_relu
I1022 16:26:48.529942 27659 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I1022 16:26:48.529947 27659 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I1022 16:26:48.530189 27659 net.cpp:150] Setting up res3c_branch2a_relu
I1022 16:26:48.530197 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.530200 27659 net.cpp:165] Memory required for data: 147517452
I1022 16:26:48.530205 27659 layer_factory.hpp:77] Creating layer res3c_branch2b
I1022 16:26:48.530213 27659 net.cpp:100] Creating Layer res3c_branch2b
I1022 16:26:48.530218 27659 net.cpp:444] res3c_branch2b <- res3c_branch2a
I1022 16:26:48.530227 27659 net.cpp:418] res3c_branch2b -> res3c_branch2b
I1022 16:26:48.538038 27659 net.cpp:150] Setting up res3c_branch2b
I1022 16:26:48.538053 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.538056 27659 net.cpp:165] Memory required for data: 147918860
I1022 16:26:48.538063 27659 layer_factory.hpp:77] Creating layer bn3c_branch2b
I1022 16:26:48.538074 27659 net.cpp:100] Creating Layer bn3c_branch2b
I1022 16:26:48.538076 27659 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I1022 16:26:48.538084 27659 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I1022 16:26:48.538465 27659 net.cpp:150] Setting up bn3c_branch2b
I1022 16:26:48.538472 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.538475 27659 net.cpp:165] Memory required for data: 148320268
I1022 16:26:48.538483 27659 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1022 16:26:48.538491 27659 net.cpp:100] Creating Layer scale3c_branch2b
I1022 16:26:48.538496 27659 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I1022 16:26:48.538502 27659 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I1022 16:26:48.538568 27659 layer_factory.hpp:77] Creating layer scale3c_branch2b
I1022 16:26:48.538772 27659 net.cpp:150] Setting up scale3c_branch2b
I1022 16:26:48.538780 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.538784 27659 net.cpp:165] Memory required for data: 148721676
I1022 16:26:48.538789 27659 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I1022 16:26:48.538799 27659 net.cpp:100] Creating Layer res3c_branch2b_relu
I1022 16:26:48.538802 27659 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I1022 16:26:48.538807 27659 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I1022 16:26:48.539054 27659 net.cpp:150] Setting up res3c_branch2b_relu
I1022 16:26:48.539064 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.539067 27659 net.cpp:165] Memory required for data: 149123084
I1022 16:26:48.539070 27659 layer_factory.hpp:77] Creating layer res3c_branch2c
I1022 16:26:48.539083 27659 net.cpp:100] Creating Layer res3c_branch2c
I1022 16:26:48.539088 27659 net.cpp:444] res3c_branch2c <- res3c_branch2b
I1022 16:26:48.539093 27659 net.cpp:418] res3c_branch2c -> res3c_branch2c
I1022 16:26:48.540941 27659 net.cpp:150] Setting up res3c_branch2c
I1022 16:26:48.540956 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.540958 27659 net.cpp:165] Memory required for data: 150728716
I1022 16:26:48.540966 27659 layer_factory.hpp:77] Creating layer bn3c_branch2c
I1022 16:26:48.540974 27659 net.cpp:100] Creating Layer bn3c_branch2c
I1022 16:26:48.540977 27659 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I1022 16:26:48.540984 27659 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I1022 16:26:48.541359 27659 net.cpp:150] Setting up bn3c_branch2c
I1022 16:26:48.541366 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.541369 27659 net.cpp:165] Memory required for data: 152334348
I1022 16:26:48.541378 27659 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1022 16:26:48.541385 27659 net.cpp:100] Creating Layer scale3c_branch2c
I1022 16:26:48.541389 27659 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I1022 16:26:48.541395 27659 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I1022 16:26:48.541467 27659 layer_factory.hpp:77] Creating layer scale3c_branch2c
I1022 16:26:48.541671 27659 net.cpp:150] Setting up scale3c_branch2c
I1022 16:26:48.541678 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.541682 27659 net.cpp:165] Memory required for data: 153939980
I1022 16:26:48.541687 27659 layer_factory.hpp:77] Creating layer res3c
I1022 16:26:48.541694 27659 net.cpp:100] Creating Layer res3c
I1022 16:26:48.541698 27659 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I1022 16:26:48.541702 27659 net.cpp:444] res3c <- res3c_branch2c
I1022 16:26:48.541707 27659 net.cpp:418] res3c -> res3c
I1022 16:26:48.541748 27659 net.cpp:150] Setting up res3c
I1022 16:26:48.541755 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.541757 27659 net.cpp:165] Memory required for data: 155545612
I1022 16:26:48.541760 27659 layer_factory.hpp:77] Creating layer res3c_relu
I1022 16:26:48.541765 27659 net.cpp:100] Creating Layer res3c_relu
I1022 16:26:48.541769 27659 net.cpp:444] res3c_relu <- res3c
I1022 16:26:48.541774 27659 net.cpp:405] res3c_relu -> res3c (in-place)
I1022 16:26:48.542011 27659 net.cpp:150] Setting up res3c_relu
I1022 16:26:48.542021 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.542023 27659 net.cpp:165] Memory required for data: 157151244
I1022 16:26:48.542027 27659 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I1022 16:26:48.542035 27659 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I1022 16:26:48.542040 27659 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I1022 16:26:48.542047 27659 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I1022 16:26:48.542055 27659 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I1022 16:26:48.542129 27659 net.cpp:150] Setting up res3c_res3c_relu_0_split
I1022 16:26:48.542136 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.542140 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.542143 27659 net.cpp:165] Memory required for data: 160362508
I1022 16:26:48.542146 27659 layer_factory.hpp:77] Creating layer res3d_branch2a
I1022 16:26:48.542158 27659 net.cpp:100] Creating Layer res3d_branch2a
I1022 16:26:48.542163 27659 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I1022 16:26:48.542168 27659 net.cpp:418] res3d_branch2a -> res3d_branch2a
I1022 16:26:48.545765 27659 net.cpp:150] Setting up res3d_branch2a
I1022 16:26:48.545779 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.545783 27659 net.cpp:165] Memory required for data: 160763916
I1022 16:26:48.545789 27659 layer_factory.hpp:77] Creating layer bn3d_branch2a
I1022 16:26:48.545800 27659 net.cpp:100] Creating Layer bn3d_branch2a
I1022 16:26:48.545806 27659 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I1022 16:26:48.545814 27659 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I1022 16:26:48.546186 27659 net.cpp:150] Setting up bn3d_branch2a
I1022 16:26:48.546195 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.546200 27659 net.cpp:165] Memory required for data: 161165324
I1022 16:26:48.546218 27659 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1022 16:26:48.546226 27659 net.cpp:100] Creating Layer scale3d_branch2a
I1022 16:26:48.546232 27659 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I1022 16:26:48.546241 27659 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I1022 16:26:48.546316 27659 layer_factory.hpp:77] Creating layer scale3d_branch2a
I1022 16:26:48.546525 27659 net.cpp:150] Setting up scale3d_branch2a
I1022 16:26:48.546532 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.546535 27659 net.cpp:165] Memory required for data: 161566732
I1022 16:26:48.546542 27659 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I1022 16:26:48.546547 27659 net.cpp:100] Creating Layer res3d_branch2a_relu
I1022 16:26:48.546552 27659 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I1022 16:26:48.546558 27659 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I1022 16:26:48.547477 27659 net.cpp:150] Setting up res3d_branch2a_relu
I1022 16:26:48.547490 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.547493 27659 net.cpp:165] Memory required for data: 161968140
I1022 16:26:48.547497 27659 layer_factory.hpp:77] Creating layer res3d_branch2b
I1022 16:26:48.547508 27659 net.cpp:100] Creating Layer res3d_branch2b
I1022 16:26:48.547511 27659 net.cpp:444] res3d_branch2b <- res3d_branch2a
I1022 16:26:48.547519 27659 net.cpp:418] res3d_branch2b -> res3d_branch2b
I1022 16:26:48.550809 27659 net.cpp:150] Setting up res3d_branch2b
I1022 16:26:48.550824 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.550827 27659 net.cpp:165] Memory required for data: 162369548
I1022 16:26:48.550833 27659 layer_factory.hpp:77] Creating layer bn3d_branch2b
I1022 16:26:48.550843 27659 net.cpp:100] Creating Layer bn3d_branch2b
I1022 16:26:48.550846 27659 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I1022 16:26:48.550853 27659 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I1022 16:26:48.551239 27659 net.cpp:150] Setting up bn3d_branch2b
I1022 16:26:48.551247 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.551250 27659 net.cpp:165] Memory required for data: 162770956
I1022 16:26:48.551259 27659 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1022 16:26:48.551267 27659 net.cpp:100] Creating Layer scale3d_branch2b
I1022 16:26:48.551270 27659 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I1022 16:26:48.551275 27659 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I1022 16:26:48.551344 27659 layer_factory.hpp:77] Creating layer scale3d_branch2b
I1022 16:26:48.551549 27659 net.cpp:150] Setting up scale3d_branch2b
I1022 16:26:48.551558 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.551560 27659 net.cpp:165] Memory required for data: 163172364
I1022 16:26:48.551566 27659 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I1022 16:26:48.551578 27659 net.cpp:100] Creating Layer res3d_branch2b_relu
I1022 16:26:48.551582 27659 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I1022 16:26:48.551586 27659 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I1022 16:26:48.551832 27659 net.cpp:150] Setting up res3d_branch2b_relu
I1022 16:26:48.551842 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.551846 27659 net.cpp:165] Memory required for data: 163573772
I1022 16:26:48.551849 27659 layer_factory.hpp:77] Creating layer res3d_branch2c
I1022 16:26:48.551859 27659 net.cpp:100] Creating Layer res3d_branch2c
I1022 16:26:48.551867 27659 net.cpp:444] res3d_branch2c <- res3d_branch2b
I1022 16:26:48.551872 27659 net.cpp:418] res3d_branch2c -> res3d_branch2c
I1022 16:26:48.553730 27659 net.cpp:150] Setting up res3d_branch2c
I1022 16:26:48.553745 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.553747 27659 net.cpp:165] Memory required for data: 165179404
I1022 16:26:48.553753 27659 layer_factory.hpp:77] Creating layer bn3d_branch2c
I1022 16:26:48.553762 27659 net.cpp:100] Creating Layer bn3d_branch2c
I1022 16:26:48.553766 27659 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I1022 16:26:48.553773 27659 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I1022 16:26:48.554147 27659 net.cpp:150] Setting up bn3d_branch2c
I1022 16:26:48.554153 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.554157 27659 net.cpp:165] Memory required for data: 166785036
I1022 16:26:48.554164 27659 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1022 16:26:48.554172 27659 net.cpp:100] Creating Layer scale3d_branch2c
I1022 16:26:48.554177 27659 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I1022 16:26:48.554180 27659 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I1022 16:26:48.554251 27659 layer_factory.hpp:77] Creating layer scale3d_branch2c
I1022 16:26:48.554457 27659 net.cpp:150] Setting up scale3d_branch2c
I1022 16:26:48.554464 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.554467 27659 net.cpp:165] Memory required for data: 168390668
I1022 16:26:48.554473 27659 layer_factory.hpp:77] Creating layer res3d
I1022 16:26:48.554483 27659 net.cpp:100] Creating Layer res3d
I1022 16:26:48.554486 27659 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I1022 16:26:48.554491 27659 net.cpp:444] res3d <- res3d_branch2c
I1022 16:26:48.554497 27659 net.cpp:418] res3d -> res3d
I1022 16:26:48.554538 27659 net.cpp:150] Setting up res3d
I1022 16:26:48.554545 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.554548 27659 net.cpp:165] Memory required for data: 169996300
I1022 16:26:48.554550 27659 layer_factory.hpp:77] Creating layer res3d_relu
I1022 16:26:48.554556 27659 net.cpp:100] Creating Layer res3d_relu
I1022 16:26:48.554559 27659 net.cpp:444] res3d_relu <- res3d
I1022 16:26:48.554563 27659 net.cpp:405] res3d_relu -> res3d (in-place)
I1022 16:26:48.554805 27659 net.cpp:150] Setting up res3d_relu
I1022 16:26:48.554816 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.554818 27659 net.cpp:165] Memory required for data: 171601932
I1022 16:26:48.554821 27659 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I1022 16:26:48.554829 27659 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I1022 16:26:48.554833 27659 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I1022 16:26:48.554839 27659 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I1022 16:26:48.554847 27659 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I1022 16:26:48.554854 27659 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_2
I1022 16:26:48.554953 27659 net.cpp:150] Setting up res3d_res3d_relu_0_split
I1022 16:26:48.554960 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.554963 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.554967 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.554970 27659 net.cpp:165] Memory required for data: 176418828
I1022 16:26:48.554973 27659 layer_factory.hpp:77] Creating layer res4a_branch1
I1022 16:26:48.554983 27659 net.cpp:100] Creating Layer res4a_branch1
I1022 16:26:48.554988 27659 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I1022 16:26:48.554996 27659 net.cpp:418] res4a_branch1 -> res4a_branch1
I1022 16:26:48.558890 27659 net.cpp:150] Setting up res4a_branch1
I1022 16:26:48.558904 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.558908 27659 net.cpp:165] Memory required for data: 177221644
I1022 16:26:48.558914 27659 layer_factory.hpp:77] Creating layer bn4a_branch1
I1022 16:26:48.558923 27659 net.cpp:100] Creating Layer bn4a_branch1
I1022 16:26:48.558928 27659 net.cpp:444] bn4a_branch1 <- res4a_branch1
I1022 16:26:48.558934 27659 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I1022 16:26:48.559366 27659 net.cpp:150] Setting up bn4a_branch1
I1022 16:26:48.559376 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.559379 27659 net.cpp:165] Memory required for data: 178024460
I1022 16:26:48.559387 27659 layer_factory.hpp:77] Creating layer scale4a_branch1
I1022 16:26:48.559393 27659 net.cpp:100] Creating Layer scale4a_branch1
I1022 16:26:48.559396 27659 net.cpp:444] scale4a_branch1 <- res4a_branch1
I1022 16:26:48.559402 27659 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I1022 16:26:48.559466 27659 layer_factory.hpp:77] Creating layer scale4a_branch1
I1022 16:26:48.559679 27659 net.cpp:150] Setting up scale4a_branch1
I1022 16:26:48.559686 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.559689 27659 net.cpp:165] Memory required for data: 178827276
I1022 16:26:48.559695 27659 layer_factory.hpp:77] Creating layer res4a_branch2a
I1022 16:26:48.559706 27659 net.cpp:100] Creating Layer res4a_branch2a
I1022 16:26:48.559712 27659 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I1022 16:26:48.559718 27659 net.cpp:418] res4a_branch2a -> res4a_branch2a
I1022 16:26:48.561597 27659 net.cpp:150] Setting up res4a_branch2a
I1022 16:26:48.561614 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.561616 27659 net.cpp:165] Memory required for data: 179027980
I1022 16:26:48.561622 27659 layer_factory.hpp:77] Creating layer bn4a_branch2a
I1022 16:26:48.561630 27659 net.cpp:100] Creating Layer bn4a_branch2a
I1022 16:26:48.561633 27659 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I1022 16:26:48.561640 27659 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I1022 16:26:48.562012 27659 net.cpp:150] Setting up bn4a_branch2a
I1022 16:26:48.562021 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.562023 27659 net.cpp:165] Memory required for data: 179228684
I1022 16:26:48.562031 27659 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1022 16:26:48.562039 27659 net.cpp:100] Creating Layer scale4a_branch2a
I1022 16:26:48.562042 27659 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I1022 16:26:48.562049 27659 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I1022 16:26:48.562122 27659 layer_factory.hpp:77] Creating layer scale4a_branch2a
I1022 16:26:48.562324 27659 net.cpp:150] Setting up scale4a_branch2a
I1022 16:26:48.562330 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.562333 27659 net.cpp:165] Memory required for data: 179429388
I1022 16:26:48.562340 27659 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I1022 16:26:48.562346 27659 net.cpp:100] Creating Layer res4a_branch2a_relu
I1022 16:26:48.562350 27659 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I1022 16:26:48.562355 27659 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I1022 16:26:48.563269 27659 net.cpp:150] Setting up res4a_branch2a_relu
I1022 16:26:48.563282 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.563284 27659 net.cpp:165] Memory required for data: 179630092
I1022 16:26:48.563288 27659 layer_factory.hpp:77] Creating layer res4a_branch2b
I1022 16:26:48.563299 27659 net.cpp:100] Creating Layer res4a_branch2b
I1022 16:26:48.563303 27659 net.cpp:444] res4a_branch2b <- res4a_branch2a
I1022 16:26:48.563311 27659 net.cpp:418] res4a_branch2b -> res4a_branch2b
I1022 16:26:48.575407 27659 net.cpp:150] Setting up res4a_branch2b
I1022 16:26:48.575420 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.575424 27659 net.cpp:165] Memory required for data: 179830796
I1022 16:26:48.575430 27659 layer_factory.hpp:77] Creating layer bn4a_branch2b
I1022 16:26:48.575440 27659 net.cpp:100] Creating Layer bn4a_branch2b
I1022 16:26:48.575444 27659 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I1022 16:26:48.575449 27659 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I1022 16:26:48.575834 27659 net.cpp:150] Setting up bn4a_branch2b
I1022 16:26:48.575841 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.575845 27659 net.cpp:165] Memory required for data: 180031500
I1022 16:26:48.575852 27659 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1022 16:26:48.575860 27659 net.cpp:100] Creating Layer scale4a_branch2b
I1022 16:26:48.575863 27659 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I1022 16:26:48.575868 27659 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I1022 16:26:48.575937 27659 layer_factory.hpp:77] Creating layer scale4a_branch2b
I1022 16:26:48.576138 27659 net.cpp:150] Setting up scale4a_branch2b
I1022 16:26:48.576146 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.576149 27659 net.cpp:165] Memory required for data: 180232204
I1022 16:26:48.576155 27659 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I1022 16:26:48.576162 27659 net.cpp:100] Creating Layer res4a_branch2b_relu
I1022 16:26:48.576166 27659 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I1022 16:26:48.576172 27659 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I1022 16:26:48.576427 27659 net.cpp:150] Setting up res4a_branch2b_relu
I1022 16:26:48.576437 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.576440 27659 net.cpp:165] Memory required for data: 180432908
I1022 16:26:48.576443 27659 layer_factory.hpp:77] Creating layer res4a_branch2c
I1022 16:26:48.576453 27659 net.cpp:100] Creating Layer res4a_branch2c
I1022 16:26:48.576457 27659 net.cpp:444] res4a_branch2c <- res4a_branch2b
I1022 16:26:48.576464 27659 net.cpp:418] res4a_branch2c -> res4a_branch2c
I1022 16:26:48.580315 27659 net.cpp:150] Setting up res4a_branch2c
I1022 16:26:48.580329 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.580332 27659 net.cpp:165] Memory required for data: 181235724
I1022 16:26:48.580338 27659 layer_factory.hpp:77] Creating layer bn4a_branch2c
I1022 16:26:48.580349 27659 net.cpp:100] Creating Layer bn4a_branch2c
I1022 16:26:48.580353 27659 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I1022 16:26:48.580360 27659 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I1022 16:26:48.580755 27659 net.cpp:150] Setting up bn4a_branch2c
I1022 16:26:48.580765 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.580767 27659 net.cpp:165] Memory required for data: 182038540
I1022 16:26:48.580775 27659 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1022 16:26:48.580786 27659 net.cpp:100] Creating Layer scale4a_branch2c
I1022 16:26:48.580790 27659 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I1022 16:26:48.580796 27659 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I1022 16:26:48.580860 27659 layer_factory.hpp:77] Creating layer scale4a_branch2c
I1022 16:26:48.581087 27659 net.cpp:150] Setting up scale4a_branch2c
I1022 16:26:48.581095 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.581097 27659 net.cpp:165] Memory required for data: 182841356
I1022 16:26:48.581104 27659 layer_factory.hpp:77] Creating layer res4a
I1022 16:26:48.581111 27659 net.cpp:100] Creating Layer res4a
I1022 16:26:48.581115 27659 net.cpp:444] res4a <- res4a_branch1
I1022 16:26:48.581120 27659 net.cpp:444] res4a <- res4a_branch2c
I1022 16:26:48.581125 27659 net.cpp:418] res4a -> res4a
I1022 16:26:48.581166 27659 net.cpp:150] Setting up res4a
I1022 16:26:48.581172 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.581176 27659 net.cpp:165] Memory required for data: 183644172
I1022 16:26:48.581178 27659 layer_factory.hpp:77] Creating layer res4a_relu
I1022 16:26:48.581183 27659 net.cpp:100] Creating Layer res4a_relu
I1022 16:26:48.581187 27659 net.cpp:444] res4a_relu <- res4a
I1022 16:26:48.581192 27659 net.cpp:405] res4a_relu -> res4a (in-place)
I1022 16:26:48.582101 27659 net.cpp:150] Setting up res4a_relu
I1022 16:26:48.582114 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.582118 27659 net.cpp:165] Memory required for data: 184446988
I1022 16:26:48.582120 27659 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I1022 16:26:48.582131 27659 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I1022 16:26:48.582135 27659 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I1022 16:26:48.582140 27659 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I1022 16:26:48.582147 27659 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I1022 16:26:48.582228 27659 net.cpp:150] Setting up res4a_res4a_relu_0_split
I1022 16:26:48.582238 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.582242 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.582244 27659 net.cpp:165] Memory required for data: 186052620
I1022 16:26:48.582247 27659 layer_factory.hpp:77] Creating layer res4b_branch2a
I1022 16:26:48.582268 27659 net.cpp:100] Creating Layer res4b_branch2a
I1022 16:26:48.582273 27659 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I1022 16:26:48.582279 27659 net.cpp:418] res4b_branch2a -> res4b_branch2a
I1022 16:26:48.584255 27659 net.cpp:150] Setting up res4b_branch2a
I1022 16:26:48.584270 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.584272 27659 net.cpp:165] Memory required for data: 186253324
I1022 16:26:48.584280 27659 layer_factory.hpp:77] Creating layer bn4b_branch2a
I1022 16:26:48.584286 27659 net.cpp:100] Creating Layer bn4b_branch2a
I1022 16:26:48.584290 27659 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I1022 16:26:48.584298 27659 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I1022 16:26:48.584689 27659 net.cpp:150] Setting up bn4b_branch2a
I1022 16:26:48.584698 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.584702 27659 net.cpp:165] Memory required for data: 186454028
I1022 16:26:48.584709 27659 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1022 16:26:48.584720 27659 net.cpp:100] Creating Layer scale4b_branch2a
I1022 16:26:48.584725 27659 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I1022 16:26:48.584730 27659 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I1022 16:26:48.584798 27659 layer_factory.hpp:77] Creating layer scale4b_branch2a
I1022 16:26:48.585016 27659 net.cpp:150] Setting up scale4b_branch2a
I1022 16:26:48.585023 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.585026 27659 net.cpp:165] Memory required for data: 186654732
I1022 16:26:48.585034 27659 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I1022 16:26:48.585041 27659 net.cpp:100] Creating Layer res4b_branch2a_relu
I1022 16:26:48.585047 27659 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I1022 16:26:48.585050 27659 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I1022 16:26:48.585963 27659 net.cpp:150] Setting up res4b_branch2a_relu
I1022 16:26:48.585975 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.585978 27659 net.cpp:165] Memory required for data: 186855436
I1022 16:26:48.585983 27659 layer_factory.hpp:77] Creating layer res4b_branch2b
I1022 16:26:48.585995 27659 net.cpp:100] Creating Layer res4b_branch2b
I1022 16:26:48.585999 27659 net.cpp:444] res4b_branch2b <- res4b_branch2a
I1022 16:26:48.586004 27659 net.cpp:418] res4b_branch2b -> res4b_branch2b
I1022 16:26:48.592790 27659 net.cpp:150] Setting up res4b_branch2b
I1022 16:26:48.592808 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.592810 27659 net.cpp:165] Memory required for data: 187056140
I1022 16:26:48.592818 27659 layer_factory.hpp:77] Creating layer bn4b_branch2b
I1022 16:26:48.592825 27659 net.cpp:100] Creating Layer bn4b_branch2b
I1022 16:26:48.592833 27659 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I1022 16:26:48.592839 27659 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I1022 16:26:48.593240 27659 net.cpp:150] Setting up bn4b_branch2b
I1022 16:26:48.593247 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.593250 27659 net.cpp:165] Memory required for data: 187256844
I1022 16:26:48.593258 27659 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1022 16:26:48.593266 27659 net.cpp:100] Creating Layer scale4b_branch2b
I1022 16:26:48.593271 27659 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I1022 16:26:48.593278 27659 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I1022 16:26:48.593350 27659 layer_factory.hpp:77] Creating layer scale4b_branch2b
I1022 16:26:48.593554 27659 net.cpp:150] Setting up scale4b_branch2b
I1022 16:26:48.593561 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.593564 27659 net.cpp:165] Memory required for data: 187457548
I1022 16:26:48.593570 27659 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I1022 16:26:48.593580 27659 net.cpp:100] Creating Layer res4b_branch2b_relu
I1022 16:26:48.593585 27659 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I1022 16:26:48.593590 27659 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I1022 16:26:48.593838 27659 net.cpp:150] Setting up res4b_branch2b_relu
I1022 16:26:48.593848 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.593852 27659 net.cpp:165] Memory required for data: 187658252
I1022 16:26:48.593855 27659 layer_factory.hpp:77] Creating layer res4b_branch2c
I1022 16:26:48.593864 27659 net.cpp:100] Creating Layer res4b_branch2c
I1022 16:26:48.593869 27659 net.cpp:444] res4b_branch2c <- res4b_branch2b
I1022 16:26:48.593876 27659 net.cpp:418] res4b_branch2c -> res4b_branch2c
I1022 16:26:48.599412 27659 net.cpp:150] Setting up res4b_branch2c
I1022 16:26:48.599427 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.599431 27659 net.cpp:165] Memory required for data: 188461068
I1022 16:26:48.599437 27659 layer_factory.hpp:77] Creating layer bn4b_branch2c
I1022 16:26:48.599447 27659 net.cpp:100] Creating Layer bn4b_branch2c
I1022 16:26:48.599450 27659 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I1022 16:26:48.599455 27659 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I1022 16:26:48.599850 27659 net.cpp:150] Setting up bn4b_branch2c
I1022 16:26:48.599858 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.599861 27659 net.cpp:165] Memory required for data: 189263884
I1022 16:26:48.599869 27659 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1022 16:26:48.599876 27659 net.cpp:100] Creating Layer scale4b_branch2c
I1022 16:26:48.599879 27659 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I1022 16:26:48.599886 27659 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I1022 16:26:48.599956 27659 layer_factory.hpp:77] Creating layer scale4b_branch2c
I1022 16:26:48.600178 27659 net.cpp:150] Setting up scale4b_branch2c
I1022 16:26:48.600185 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.600188 27659 net.cpp:165] Memory required for data: 190066700
I1022 16:26:48.600194 27659 layer_factory.hpp:77] Creating layer res4b
I1022 16:26:48.600200 27659 net.cpp:100] Creating Layer res4b
I1022 16:26:48.600203 27659 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I1022 16:26:48.600208 27659 net.cpp:444] res4b <- res4b_branch2c
I1022 16:26:48.600215 27659 net.cpp:418] res4b -> res4b
I1022 16:26:48.600256 27659 net.cpp:150] Setting up res4b
I1022 16:26:48.600263 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.600266 27659 net.cpp:165] Memory required for data: 190869516
I1022 16:26:48.600270 27659 layer_factory.hpp:77] Creating layer res4b_relu
I1022 16:26:48.600276 27659 net.cpp:100] Creating Layer res4b_relu
I1022 16:26:48.600282 27659 net.cpp:444] res4b_relu <- res4b
I1022 16:26:48.600286 27659 net.cpp:405] res4b_relu -> res4b (in-place)
I1022 16:26:48.600522 27659 net.cpp:150] Setting up res4b_relu
I1022 16:26:48.600533 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.600535 27659 net.cpp:165] Memory required for data: 191672332
I1022 16:26:48.600538 27659 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I1022 16:26:48.600546 27659 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I1022 16:26:48.600551 27659 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I1022 16:26:48.600558 27659 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I1022 16:26:48.600565 27659 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I1022 16:26:48.600661 27659 net.cpp:150] Setting up res4b_res4b_relu_0_split
I1022 16:26:48.600669 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.600673 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.600675 27659 net.cpp:165] Memory required for data: 193277964
I1022 16:26:48.600678 27659 layer_factory.hpp:77] Creating layer res4c_branch2a
I1022 16:26:48.600689 27659 net.cpp:100] Creating Layer res4c_branch2a
I1022 16:26:48.600694 27659 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I1022 16:26:48.600699 27659 net.cpp:418] res4c_branch2a -> res4c_branch2a
I1022 16:26:48.602706 27659 net.cpp:150] Setting up res4c_branch2a
I1022 16:26:48.602721 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.602726 27659 net.cpp:165] Memory required for data: 193478668
I1022 16:26:48.602732 27659 layer_factory.hpp:77] Creating layer bn4c_branch2a
I1022 16:26:48.602741 27659 net.cpp:100] Creating Layer bn4c_branch2a
I1022 16:26:48.602747 27659 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I1022 16:26:48.602754 27659 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I1022 16:26:48.603140 27659 net.cpp:150] Setting up bn4c_branch2a
I1022 16:26:48.603148 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.603152 27659 net.cpp:165] Memory required for data: 193679372
I1022 16:26:48.603159 27659 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1022 16:26:48.603169 27659 net.cpp:100] Creating Layer scale4c_branch2a
I1022 16:26:48.603174 27659 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I1022 16:26:48.603179 27659 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I1022 16:26:48.603248 27659 layer_factory.hpp:77] Creating layer scale4c_branch2a
I1022 16:26:48.603457 27659 net.cpp:150] Setting up scale4c_branch2a
I1022 16:26:48.603466 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.603468 27659 net.cpp:165] Memory required for data: 193880076
I1022 16:26:48.603474 27659 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I1022 16:26:48.603483 27659 net.cpp:100] Creating Layer res4c_branch2a_relu
I1022 16:26:48.603488 27659 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I1022 16:26:48.603493 27659 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I1022 16:26:48.603739 27659 net.cpp:150] Setting up res4c_branch2a_relu
I1022 16:26:48.603751 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.603754 27659 net.cpp:165] Memory required for data: 194080780
I1022 16:26:48.603757 27659 layer_factory.hpp:77] Creating layer res4c_branch2b
I1022 16:26:48.603766 27659 net.cpp:100] Creating Layer res4c_branch2b
I1022 16:26:48.603770 27659 net.cpp:444] res4c_branch2b <- res4c_branch2a
I1022 16:26:48.603775 27659 net.cpp:418] res4c_branch2b -> res4c_branch2b
I1022 16:26:48.608667 27659 net.cpp:150] Setting up res4c_branch2b
I1022 16:26:48.608682 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.608686 27659 net.cpp:165] Memory required for data: 194281484
I1022 16:26:48.608692 27659 layer_factory.hpp:77] Creating layer bn4c_branch2b
I1022 16:26:48.608702 27659 net.cpp:100] Creating Layer bn4c_branch2b
I1022 16:26:48.608706 27659 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I1022 16:26:48.608713 27659 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I1022 16:26:48.609112 27659 net.cpp:150] Setting up bn4c_branch2b
I1022 16:26:48.609122 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.609124 27659 net.cpp:165] Memory required for data: 194482188
I1022 16:26:48.609133 27659 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1022 16:26:48.609138 27659 net.cpp:100] Creating Layer scale4c_branch2b
I1022 16:26:48.609143 27659 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I1022 16:26:48.609148 27659 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I1022 16:26:48.609220 27659 layer_factory.hpp:77] Creating layer scale4c_branch2b
I1022 16:26:48.609429 27659 net.cpp:150] Setting up scale4c_branch2b
I1022 16:26:48.609437 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.609441 27659 net.cpp:165] Memory required for data: 194682892
I1022 16:26:48.609447 27659 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I1022 16:26:48.609454 27659 net.cpp:100] Creating Layer res4c_branch2b_relu
I1022 16:26:48.609458 27659 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I1022 16:26:48.609462 27659 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I1022 16:26:48.610399 27659 net.cpp:150] Setting up res4c_branch2b_relu
I1022 16:26:48.610416 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.610419 27659 net.cpp:165] Memory required for data: 194883596
I1022 16:26:48.610424 27659 layer_factory.hpp:77] Creating layer res4c_branch2c
I1022 16:26:48.610433 27659 net.cpp:100] Creating Layer res4c_branch2c
I1022 16:26:48.610437 27659 net.cpp:444] res4c_branch2c <- res4c_branch2b
I1022 16:26:48.610443 27659 net.cpp:418] res4c_branch2c -> res4c_branch2c
I1022 16:26:48.614334 27659 net.cpp:150] Setting up res4c_branch2c
I1022 16:26:48.614348 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.614351 27659 net.cpp:165] Memory required for data: 195686412
I1022 16:26:48.614358 27659 layer_factory.hpp:77] Creating layer bn4c_branch2c
I1022 16:26:48.614370 27659 net.cpp:100] Creating Layer bn4c_branch2c
I1022 16:26:48.614374 27659 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I1022 16:26:48.614379 27659 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I1022 16:26:48.614778 27659 net.cpp:150] Setting up bn4c_branch2c
I1022 16:26:48.614784 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.614787 27659 net.cpp:165] Memory required for data: 196489228
I1022 16:26:48.614795 27659 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1022 16:26:48.614802 27659 net.cpp:100] Creating Layer scale4c_branch2c
I1022 16:26:48.614805 27659 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I1022 16:26:48.614812 27659 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I1022 16:26:48.614879 27659 layer_factory.hpp:77] Creating layer scale4c_branch2c
I1022 16:26:48.615103 27659 net.cpp:150] Setting up scale4c_branch2c
I1022 16:26:48.615110 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.615113 27659 net.cpp:165] Memory required for data: 197292044
I1022 16:26:48.615119 27659 layer_factory.hpp:77] Creating layer res4c
I1022 16:26:48.615126 27659 net.cpp:100] Creating Layer res4c
I1022 16:26:48.615130 27659 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I1022 16:26:48.615134 27659 net.cpp:444] res4c <- res4c_branch2c
I1022 16:26:48.615141 27659 net.cpp:418] res4c -> res4c
I1022 16:26:48.615180 27659 net.cpp:150] Setting up res4c
I1022 16:26:48.615187 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.615191 27659 net.cpp:165] Memory required for data: 198094860
I1022 16:26:48.615195 27659 layer_factory.hpp:77] Creating layer res4c_relu
I1022 16:26:48.615201 27659 net.cpp:100] Creating Layer res4c_relu
I1022 16:26:48.615204 27659 net.cpp:444] res4c_relu <- res4c
I1022 16:26:48.615209 27659 net.cpp:405] res4c_relu -> res4c (in-place)
I1022 16:26:48.615447 27659 net.cpp:150] Setting up res4c_relu
I1022 16:26:48.615456 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.615459 27659 net.cpp:165] Memory required for data: 198897676
I1022 16:26:48.615463 27659 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I1022 16:26:48.615470 27659 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I1022 16:26:48.615476 27659 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I1022 16:26:48.615485 27659 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I1022 16:26:48.615494 27659 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I1022 16:26:48.615571 27659 net.cpp:150] Setting up res4c_res4c_relu_0_split
I1022 16:26:48.615578 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.615582 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.615584 27659 net.cpp:165] Memory required for data: 200503308
I1022 16:26:48.615587 27659 layer_factory.hpp:77] Creating layer res4d_branch2a
I1022 16:26:48.615597 27659 net.cpp:100] Creating Layer res4d_branch2a
I1022 16:26:48.615602 27659 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I1022 16:26:48.615608 27659 net.cpp:418] res4d_branch2a -> res4d_branch2a
I1022 16:26:48.617631 27659 net.cpp:150] Setting up res4d_branch2a
I1022 16:26:48.617646 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.617650 27659 net.cpp:165] Memory required for data: 200704012
I1022 16:26:48.617655 27659 layer_factory.hpp:77] Creating layer bn4d_branch2a
I1022 16:26:48.617664 27659 net.cpp:100] Creating Layer bn4d_branch2a
I1022 16:26:48.617668 27659 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I1022 16:26:48.617676 27659 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I1022 16:26:48.618067 27659 net.cpp:150] Setting up bn4d_branch2a
I1022 16:26:48.618075 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.618078 27659 net.cpp:165] Memory required for data: 200904716
I1022 16:26:48.618086 27659 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1022 16:26:48.618093 27659 net.cpp:100] Creating Layer scale4d_branch2a
I1022 16:26:48.618095 27659 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I1022 16:26:48.618103 27659 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I1022 16:26:48.618175 27659 layer_factory.hpp:77] Creating layer scale4d_branch2a
I1022 16:26:48.618388 27659 net.cpp:150] Setting up scale4d_branch2a
I1022 16:26:48.618396 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.618399 27659 net.cpp:165] Memory required for data: 201105420
I1022 16:26:48.618405 27659 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I1022 16:26:48.618412 27659 net.cpp:100] Creating Layer res4d_branch2a_relu
I1022 16:26:48.618415 27659 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I1022 16:26:48.618420 27659 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I1022 16:26:48.618662 27659 net.cpp:150] Setting up res4d_branch2a_relu
I1022 16:26:48.618671 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.618674 27659 net.cpp:165] Memory required for data: 201306124
I1022 16:26:48.618679 27659 layer_factory.hpp:77] Creating layer res4d_branch2b
I1022 16:26:48.618688 27659 net.cpp:100] Creating Layer res4d_branch2b
I1022 16:26:48.618693 27659 net.cpp:444] res4d_branch2b <- res4d_branch2a
I1022 16:26:48.618698 27659 net.cpp:418] res4d_branch2b -> res4d_branch2b
I1022 16:26:48.624543 27659 net.cpp:150] Setting up res4d_branch2b
I1022 16:26:48.624559 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.624563 27659 net.cpp:165] Memory required for data: 201506828
I1022 16:26:48.624569 27659 layer_factory.hpp:77] Creating layer bn4d_branch2b
I1022 16:26:48.624579 27659 net.cpp:100] Creating Layer bn4d_branch2b
I1022 16:26:48.624583 27659 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I1022 16:26:48.624588 27659 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I1022 16:26:48.625021 27659 net.cpp:150] Setting up bn4d_branch2b
I1022 16:26:48.625031 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.625035 27659 net.cpp:165] Memory required for data: 201707532
I1022 16:26:48.625042 27659 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1022 16:26:48.625048 27659 net.cpp:100] Creating Layer scale4d_branch2b
I1022 16:26:48.625052 27659 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I1022 16:26:48.625059 27659 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I1022 16:26:48.625142 27659 layer_factory.hpp:77] Creating layer scale4d_branch2b
I1022 16:26:48.625360 27659 net.cpp:150] Setting up scale4d_branch2b
I1022 16:26:48.625367 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.625370 27659 net.cpp:165] Memory required for data: 201908236
I1022 16:26:48.625376 27659 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I1022 16:26:48.625383 27659 net.cpp:100] Creating Layer res4d_branch2b_relu
I1022 16:26:48.625387 27659 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I1022 16:26:48.625393 27659 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I1022 16:26:48.626353 27659 net.cpp:150] Setting up res4d_branch2b_relu
I1022 16:26:48.626365 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.626368 27659 net.cpp:165] Memory required for data: 202108940
I1022 16:26:48.626372 27659 layer_factory.hpp:77] Creating layer res4d_branch2c
I1022 16:26:48.626384 27659 net.cpp:100] Creating Layer res4d_branch2c
I1022 16:26:48.626387 27659 net.cpp:444] res4d_branch2c <- res4d_branch2b
I1022 16:26:48.626395 27659 net.cpp:418] res4d_branch2c -> res4d_branch2c
I1022 16:26:48.630302 27659 net.cpp:150] Setting up res4d_branch2c
I1022 16:26:48.630316 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.630319 27659 net.cpp:165] Memory required for data: 202911756
I1022 16:26:48.630326 27659 layer_factory.hpp:77] Creating layer bn4d_branch2c
I1022 16:26:48.630336 27659 net.cpp:100] Creating Layer bn4d_branch2c
I1022 16:26:48.630339 27659 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I1022 16:26:48.630344 27659 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I1022 16:26:48.630751 27659 net.cpp:150] Setting up bn4d_branch2c
I1022 16:26:48.630759 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.630762 27659 net.cpp:165] Memory required for data: 203714572
I1022 16:26:48.630770 27659 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1022 16:26:48.630779 27659 net.cpp:100] Creating Layer scale4d_branch2c
I1022 16:26:48.630781 27659 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I1022 16:26:48.630789 27659 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I1022 16:26:48.630856 27659 layer_factory.hpp:77] Creating layer scale4d_branch2c
I1022 16:26:48.631084 27659 net.cpp:150] Setting up scale4d_branch2c
I1022 16:26:48.631091 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.631094 27659 net.cpp:165] Memory required for data: 204517388
I1022 16:26:48.631100 27659 layer_factory.hpp:77] Creating layer res4d
I1022 16:26:48.631111 27659 net.cpp:100] Creating Layer res4d
I1022 16:26:48.631115 27659 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I1022 16:26:48.631119 27659 net.cpp:444] res4d <- res4d_branch2c
I1022 16:26:48.631124 27659 net.cpp:418] res4d -> res4d
I1022 16:26:48.631168 27659 net.cpp:150] Setting up res4d
I1022 16:26:48.631175 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.631177 27659 net.cpp:165] Memory required for data: 205320204
I1022 16:26:48.631181 27659 layer_factory.hpp:77] Creating layer res4d_relu
I1022 16:26:48.631188 27659 net.cpp:100] Creating Layer res4d_relu
I1022 16:26:48.631191 27659 net.cpp:444] res4d_relu <- res4d
I1022 16:26:48.631197 27659 net.cpp:405] res4d_relu -> res4d (in-place)
I1022 16:26:48.631438 27659 net.cpp:150] Setting up res4d_relu
I1022 16:26:48.631448 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.631450 27659 net.cpp:165] Memory required for data: 206123020
I1022 16:26:48.631454 27659 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I1022 16:26:48.631460 27659 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I1022 16:26:48.631466 27659 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I1022 16:26:48.631474 27659 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I1022 16:26:48.631480 27659 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I1022 16:26:48.631559 27659 net.cpp:150] Setting up res4d_res4d_relu_0_split
I1022 16:26:48.631567 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.631570 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.631573 27659 net.cpp:165] Memory required for data: 207728652
I1022 16:26:48.631577 27659 layer_factory.hpp:77] Creating layer res4e_branch2a
I1022 16:26:48.631587 27659 net.cpp:100] Creating Layer res4e_branch2a
I1022 16:26:48.631592 27659 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I1022 16:26:48.631598 27659 net.cpp:418] res4e_branch2a -> res4e_branch2a
I1022 16:26:48.633639 27659 net.cpp:150] Setting up res4e_branch2a
I1022 16:26:48.633653 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.633656 27659 net.cpp:165] Memory required for data: 207929356
I1022 16:26:48.633662 27659 layer_factory.hpp:77] Creating layer bn4e_branch2a
I1022 16:26:48.633671 27659 net.cpp:100] Creating Layer bn4e_branch2a
I1022 16:26:48.633677 27659 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I1022 16:26:48.633683 27659 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I1022 16:26:48.634079 27659 net.cpp:150] Setting up bn4e_branch2a
I1022 16:26:48.634086 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.634089 27659 net.cpp:165] Memory required for data: 208130060
I1022 16:26:48.634097 27659 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1022 16:26:48.634104 27659 net.cpp:100] Creating Layer scale4e_branch2a
I1022 16:26:48.634106 27659 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I1022 16:26:48.634114 27659 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I1022 16:26:48.634186 27659 layer_factory.hpp:77] Creating layer scale4e_branch2a
I1022 16:26:48.634394 27659 net.cpp:150] Setting up scale4e_branch2a
I1022 16:26:48.634402 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.634405 27659 net.cpp:165] Memory required for data: 208330764
I1022 16:26:48.634411 27659 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I1022 16:26:48.634418 27659 net.cpp:100] Creating Layer res4e_branch2a_relu
I1022 16:26:48.634421 27659 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I1022 16:26:48.634429 27659 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I1022 16:26:48.634667 27659 net.cpp:150] Setting up res4e_branch2a_relu
I1022 16:26:48.634677 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.634680 27659 net.cpp:165] Memory required for data: 208531468
I1022 16:26:48.634685 27659 layer_factory.hpp:77] Creating layer res4e_branch2b
I1022 16:26:48.634693 27659 net.cpp:100] Creating Layer res4e_branch2b
I1022 16:26:48.634698 27659 net.cpp:444] res4e_branch2b <- res4e_branch2a
I1022 16:26:48.634706 27659 net.cpp:418] res4e_branch2b -> res4e_branch2b
I1022 16:26:48.645541 27659 net.cpp:150] Setting up res4e_branch2b
I1022 16:26:48.645555 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.645560 27659 net.cpp:165] Memory required for data: 208732172
I1022 16:26:48.645565 27659 layer_factory.hpp:77] Creating layer bn4e_branch2b
I1022 16:26:48.645575 27659 net.cpp:100] Creating Layer bn4e_branch2b
I1022 16:26:48.645579 27659 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I1022 16:26:48.645584 27659 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I1022 16:26:48.646011 27659 net.cpp:150] Setting up bn4e_branch2b
I1022 16:26:48.646021 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.646024 27659 net.cpp:165] Memory required for data: 208932876
I1022 16:26:48.646033 27659 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1022 16:26:48.646039 27659 net.cpp:100] Creating Layer scale4e_branch2b
I1022 16:26:48.646042 27659 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I1022 16:26:48.646047 27659 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I1022 16:26:48.646122 27659 layer_factory.hpp:77] Creating layer scale4e_branch2b
I1022 16:26:48.646340 27659 net.cpp:150] Setting up scale4e_branch2b
I1022 16:26:48.646348 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.646351 27659 net.cpp:165] Memory required for data: 209133580
I1022 16:26:48.646358 27659 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I1022 16:26:48.646368 27659 net.cpp:100] Creating Layer res4e_branch2b_relu
I1022 16:26:48.646373 27659 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I1022 16:26:48.646378 27659 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I1022 16:26:48.647493 27659 net.cpp:150] Setting up res4e_branch2b_relu
I1022 16:26:48.647506 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.647509 27659 net.cpp:165] Memory required for data: 209334284
I1022 16:26:48.647513 27659 layer_factory.hpp:77] Creating layer res4e_branch2c
I1022 16:26:48.647524 27659 net.cpp:100] Creating Layer res4e_branch2c
I1022 16:26:48.647528 27659 net.cpp:444] res4e_branch2c <- res4e_branch2b
I1022 16:26:48.647536 27659 net.cpp:418] res4e_branch2c -> res4e_branch2c
I1022 16:26:48.656023 27659 net.cpp:150] Setting up res4e_branch2c
I1022 16:26:48.656038 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.656041 27659 net.cpp:165] Memory required for data: 210137100
I1022 16:26:48.656049 27659 layer_factory.hpp:77] Creating layer bn4e_branch2c
I1022 16:26:48.656057 27659 net.cpp:100] Creating Layer bn4e_branch2c
I1022 16:26:48.656061 27659 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I1022 16:26:48.656069 27659 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I1022 16:26:48.656481 27659 net.cpp:150] Setting up bn4e_branch2c
I1022 16:26:48.656491 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.656492 27659 net.cpp:165] Memory required for data: 210939916
I1022 16:26:48.656500 27659 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1022 16:26:48.656509 27659 net.cpp:100] Creating Layer scale4e_branch2c
I1022 16:26:48.656512 27659 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I1022 16:26:48.656519 27659 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I1022 16:26:48.656587 27659 layer_factory.hpp:77] Creating layer scale4e_branch2c
I1022 16:26:48.656842 27659 net.cpp:150] Setting up scale4e_branch2c
I1022 16:26:48.656850 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.656853 27659 net.cpp:165] Memory required for data: 211742732
I1022 16:26:48.656860 27659 layer_factory.hpp:77] Creating layer res4e
I1022 16:26:48.656868 27659 net.cpp:100] Creating Layer res4e
I1022 16:26:48.656874 27659 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I1022 16:26:48.656879 27659 net.cpp:444] res4e <- res4e_branch2c
I1022 16:26:48.656884 27659 net.cpp:418] res4e -> res4e
I1022 16:26:48.656929 27659 net.cpp:150] Setting up res4e
I1022 16:26:48.656935 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.656939 27659 net.cpp:165] Memory required for data: 212545548
I1022 16:26:48.656941 27659 layer_factory.hpp:77] Creating layer res4e_relu
I1022 16:26:48.656946 27659 net.cpp:100] Creating Layer res4e_relu
I1022 16:26:48.656949 27659 net.cpp:444] res4e_relu <- res4e
I1022 16:26:48.656956 27659 net.cpp:405] res4e_relu -> res4e (in-place)
I1022 16:26:48.657194 27659 net.cpp:150] Setting up res4e_relu
I1022 16:26:48.657204 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.657207 27659 net.cpp:165] Memory required for data: 213348364
I1022 16:26:48.657210 27659 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I1022 16:26:48.657218 27659 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I1022 16:26:48.657223 27659 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I1022 16:26:48.657228 27659 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I1022 16:26:48.657235 27659 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I1022 16:26:48.657315 27659 net.cpp:150] Setting up res4e_res4e_relu_0_split
I1022 16:26:48.657325 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.657328 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.657330 27659 net.cpp:165] Memory required for data: 214953996
I1022 16:26:48.657333 27659 layer_factory.hpp:77] Creating layer res4f_branch2a
I1022 16:26:48.657341 27659 net.cpp:100] Creating Layer res4f_branch2a
I1022 16:26:48.657346 27659 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I1022 16:26:48.657353 27659 net.cpp:418] res4f_branch2a -> res4f_branch2a
I1022 16:26:48.659375 27659 net.cpp:150] Setting up res4f_branch2a
I1022 16:26:48.659389 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.659392 27659 net.cpp:165] Memory required for data: 215154700
I1022 16:26:48.659399 27659 layer_factory.hpp:77] Creating layer bn4f_branch2a
I1022 16:26:48.659407 27659 net.cpp:100] Creating Layer bn4f_branch2a
I1022 16:26:48.659411 27659 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I1022 16:26:48.659417 27659 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I1022 16:26:48.659818 27659 net.cpp:150] Setting up bn4f_branch2a
I1022 16:26:48.659826 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.659829 27659 net.cpp:165] Memory required for data: 215355404
I1022 16:26:48.659837 27659 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1022 16:26:48.659844 27659 net.cpp:100] Creating Layer scale4f_branch2a
I1022 16:26:48.659848 27659 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I1022 16:26:48.659853 27659 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I1022 16:26:48.659926 27659 layer_factory.hpp:77] Creating layer scale4f_branch2a
I1022 16:26:48.660140 27659 net.cpp:150] Setting up scale4f_branch2a
I1022 16:26:48.660148 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.660151 27659 net.cpp:165] Memory required for data: 215556108
I1022 16:26:48.660157 27659 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I1022 16:26:48.660166 27659 net.cpp:100] Creating Layer res4f_branch2a_relu
I1022 16:26:48.660168 27659 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I1022 16:26:48.660176 27659 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I1022 16:26:48.660414 27659 net.cpp:150] Setting up res4f_branch2a_relu
I1022 16:26:48.660424 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.660428 27659 net.cpp:165] Memory required for data: 215756812
I1022 16:26:48.660431 27659 layer_factory.hpp:77] Creating layer res4f_branch2b
I1022 16:26:48.660440 27659 net.cpp:100] Creating Layer res4f_branch2b
I1022 16:26:48.660445 27659 net.cpp:444] res4f_branch2b <- res4f_branch2a
I1022 16:26:48.660452 27659 net.cpp:418] res4f_branch2b -> res4f_branch2b
I1022 16:26:48.665424 27659 net.cpp:150] Setting up res4f_branch2b
I1022 16:26:48.665438 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.665442 27659 net.cpp:165] Memory required for data: 215957516
I1022 16:26:48.665448 27659 layer_factory.hpp:77] Creating layer bn4f_branch2b
I1022 16:26:48.665457 27659 net.cpp:100] Creating Layer bn4f_branch2b
I1022 16:26:48.665462 27659 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I1022 16:26:48.665468 27659 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I1022 16:26:48.665881 27659 net.cpp:150] Setting up bn4f_branch2b
I1022 16:26:48.665890 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.665892 27659 net.cpp:165] Memory required for data: 216158220
I1022 16:26:48.665900 27659 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1022 16:26:48.665910 27659 net.cpp:100] Creating Layer scale4f_branch2b
I1022 16:26:48.665912 27659 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I1022 16:26:48.665920 27659 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I1022 16:26:48.665992 27659 layer_factory.hpp:77] Creating layer scale4f_branch2b
I1022 16:26:48.666208 27659 net.cpp:150] Setting up scale4f_branch2b
I1022 16:26:48.666215 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.666218 27659 net.cpp:165] Memory required for data: 216358924
I1022 16:26:48.666224 27659 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I1022 16:26:48.666234 27659 net.cpp:100] Creating Layer res4f_branch2b_relu
I1022 16:26:48.666240 27659 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I1022 16:26:48.666245 27659 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I1022 16:26:48.666491 27659 net.cpp:150] Setting up res4f_branch2b_relu
I1022 16:26:48.666501 27659 net.cpp:157] Top shape: 1 256 14 14 (50176)
I1022 16:26:48.666504 27659 net.cpp:165] Memory required for data: 216559628
I1022 16:26:48.666508 27659 layer_factory.hpp:77] Creating layer res4f_branch2c
I1022 16:26:48.666517 27659 net.cpp:100] Creating Layer res4f_branch2c
I1022 16:26:48.666522 27659 net.cpp:444] res4f_branch2c <- res4f_branch2b
I1022 16:26:48.666529 27659 net.cpp:418] res4f_branch2c -> res4f_branch2c
I1022 16:26:48.673799 27659 net.cpp:150] Setting up res4f_branch2c
I1022 16:26:48.673815 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.673818 27659 net.cpp:165] Memory required for data: 217362444
I1022 16:26:48.673825 27659 layer_factory.hpp:77] Creating layer bn4f_branch2c
I1022 16:26:48.673835 27659 net.cpp:100] Creating Layer bn4f_branch2c
I1022 16:26:48.673838 27659 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I1022 16:26:48.673843 27659 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I1022 16:26:48.674263 27659 net.cpp:150] Setting up bn4f_branch2c
I1022 16:26:48.674271 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.674274 27659 net.cpp:165] Memory required for data: 218165260
I1022 16:26:48.674300 27659 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1022 16:26:48.674309 27659 net.cpp:100] Creating Layer scale4f_branch2c
I1022 16:26:48.674311 27659 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I1022 16:26:48.674316 27659 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I1022 16:26:48.674386 27659 layer_factory.hpp:77] Creating layer scale4f_branch2c
I1022 16:26:48.674623 27659 net.cpp:150] Setting up scale4f_branch2c
I1022 16:26:48.674630 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.674633 27659 net.cpp:165] Memory required for data: 218968076
I1022 16:26:48.674639 27659 layer_factory.hpp:77] Creating layer res4f
I1022 16:26:48.674648 27659 net.cpp:100] Creating Layer res4f
I1022 16:26:48.674650 27659 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I1022 16:26:48.674655 27659 net.cpp:444] res4f <- res4f_branch2c
I1022 16:26:48.674662 27659 net.cpp:418] res4f -> res4f
I1022 16:26:48.674706 27659 net.cpp:150] Setting up res4f
I1022 16:26:48.674713 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.674716 27659 net.cpp:165] Memory required for data: 219770892
I1022 16:26:48.674720 27659 layer_factory.hpp:77] Creating layer res4f_relu
I1022 16:26:48.674726 27659 net.cpp:100] Creating Layer res4f_relu
I1022 16:26:48.674729 27659 net.cpp:444] res4f_relu <- res4f
I1022 16:26:48.674734 27659 net.cpp:405] res4f_relu -> res4f (in-place)
I1022 16:26:48.675707 27659 net.cpp:150] Setting up res4f_relu
I1022 16:26:48.675722 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.675725 27659 net.cpp:165] Memory required for data: 220573708
I1022 16:26:48.675729 27659 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I1022 16:26:48.675735 27659 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I1022 16:26:48.675740 27659 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I1022 16:26:48.675747 27659 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I1022 16:26:48.675755 27659 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I1022 16:26:48.675760 27659 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I1022 16:26:48.675878 27659 net.cpp:150] Setting up res4f_res4f_relu_0_split
I1022 16:26:48.675884 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.675889 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.675894 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.675896 27659 net.cpp:165] Memory required for data: 222982156
I1022 16:26:48.675899 27659 layer_factory.hpp:77] Creating layer res5a_branch1
I1022 16:26:48.675909 27659 net.cpp:100] Creating Layer res5a_branch1
I1022 16:26:48.675914 27659 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I1022 16:26:48.675920 27659 net.cpp:418] res5a_branch1 -> res5a_branch1
I1022 16:26:48.683568 27659 net.cpp:150] Setting up res5a_branch1
I1022 16:26:48.683583 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.683585 27659 net.cpp:165] Memory required for data: 223383564
I1022 16:26:48.683593 27659 layer_factory.hpp:77] Creating layer bn5a_branch1
I1022 16:26:48.683603 27659 net.cpp:100] Creating Layer bn5a_branch1
I1022 16:26:48.683606 27659 net.cpp:444] bn5a_branch1 <- res5a_branch1
I1022 16:26:48.683614 27659 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I1022 16:26:48.684092 27659 net.cpp:150] Setting up bn5a_branch1
I1022 16:26:48.684100 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.684103 27659 net.cpp:165] Memory required for data: 223784972
I1022 16:26:48.684111 27659 layer_factory.hpp:77] Creating layer scale5a_branch1
I1022 16:26:48.684118 27659 net.cpp:100] Creating Layer scale5a_branch1
I1022 16:26:48.684120 27659 net.cpp:444] scale5a_branch1 <- res5a_branch1
I1022 16:26:48.684128 27659 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I1022 16:26:48.684200 27659 layer_factory.hpp:77] Creating layer scale5a_branch1
I1022 16:26:48.684439 27659 net.cpp:150] Setting up scale5a_branch1
I1022 16:26:48.684448 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.684450 27659 net.cpp:165] Memory required for data: 224186380
I1022 16:26:48.684456 27659 layer_factory.hpp:77] Creating layer res5a_branch2a
I1022 16:26:48.684466 27659 net.cpp:100] Creating Layer res5a_branch2a
I1022 16:26:48.684473 27659 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I1022 16:26:48.684478 27659 net.cpp:418] res5a_branch2a -> res5a_branch2a
I1022 16:26:48.694368 27659 net.cpp:150] Setting up res5a_branch2a
I1022 16:26:48.694383 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.694386 27659 net.cpp:165] Memory required for data: 224286732
I1022 16:26:48.694392 27659 layer_factory.hpp:77] Creating layer bn5a_branch2a
I1022 16:26:48.694402 27659 net.cpp:100] Creating Layer bn5a_branch2a
I1022 16:26:48.694406 27659 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I1022 16:26:48.694412 27659 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I1022 16:26:48.694839 27659 net.cpp:150] Setting up bn5a_branch2a
I1022 16:26:48.694847 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.694851 27659 net.cpp:165] Memory required for data: 224387084
I1022 16:26:48.694859 27659 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1022 16:26:48.694867 27659 net.cpp:100] Creating Layer scale5a_branch2a
I1022 16:26:48.694870 27659 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I1022 16:26:48.694875 27659 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I1022 16:26:48.694947 27659 layer_factory.hpp:77] Creating layer scale5a_branch2a
I1022 16:26:48.695183 27659 net.cpp:150] Setting up scale5a_branch2a
I1022 16:26:48.695190 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.695194 27659 net.cpp:165] Memory required for data: 224487436
I1022 16:26:48.695200 27659 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I1022 16:26:48.695206 27659 net.cpp:100] Creating Layer res5a_branch2a_relu
I1022 16:26:48.695210 27659 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I1022 16:26:48.695215 27659 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I1022 16:26:48.695456 27659 net.cpp:150] Setting up res5a_branch2a_relu
I1022 16:26:48.695466 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.695469 27659 net.cpp:165] Memory required for data: 224587788
I1022 16:26:48.695473 27659 layer_factory.hpp:77] Creating layer res5a_branch2b
I1022 16:26:48.695483 27659 net.cpp:100] Creating Layer res5a_branch2b
I1022 16:26:48.695488 27659 net.cpp:444] res5a_branch2b <- res5a_branch2a
I1022 16:26:48.695495 27659 net.cpp:418] res5a_branch2b -> res5a_branch2b
I1022 16:26:48.702342 27659 net.cpp:150] Setting up res5a_branch2b
I1022 16:26:48.702356 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.702359 27659 net.cpp:165] Memory required for data: 224688140
I1022 16:26:48.702364 27659 layer_factory.hpp:77] Creating layer bn5a_branch2b
I1022 16:26:48.702374 27659 net.cpp:100] Creating Layer bn5a_branch2b
I1022 16:26:48.702378 27659 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I1022 16:26:48.702385 27659 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I1022 16:26:48.702805 27659 net.cpp:150] Setting up bn5a_branch2b
I1022 16:26:48.702813 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.702816 27659 net.cpp:165] Memory required for data: 224788492
I1022 16:26:48.702824 27659 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1022 16:26:48.702832 27659 net.cpp:100] Creating Layer scale5a_branch2b
I1022 16:26:48.702836 27659 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I1022 16:26:48.702842 27659 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I1022 16:26:48.702911 27659 layer_factory.hpp:77] Creating layer scale5a_branch2b
I1022 16:26:48.703150 27659 net.cpp:150] Setting up scale5a_branch2b
I1022 16:26:48.703160 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.703161 27659 net.cpp:165] Memory required for data: 224888844
I1022 16:26:48.703167 27659 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I1022 16:26:48.703176 27659 net.cpp:100] Creating Layer res5a_branch2b_relu
I1022 16:26:48.703181 27659 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I1022 16:26:48.703186 27659 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I1022 16:26:48.703442 27659 net.cpp:150] Setting up res5a_branch2b_relu
I1022 16:26:48.703452 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.703456 27659 net.cpp:165] Memory required for data: 224989196
I1022 16:26:48.703459 27659 layer_factory.hpp:77] Creating layer res5a_branch2c
I1022 16:26:48.703470 27659 net.cpp:100] Creating Layer res5a_branch2c
I1022 16:26:48.703475 27659 net.cpp:444] res5a_branch2c <- res5a_branch2b
I1022 16:26:48.703481 27659 net.cpp:418] res5a_branch2c -> res5a_branch2c
I1022 16:26:48.708825 27659 net.cpp:150] Setting up res5a_branch2c
I1022 16:26:48.708838 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.708842 27659 net.cpp:165] Memory required for data: 225390604
I1022 16:26:48.708848 27659 layer_factory.hpp:77] Creating layer bn5a_branch2c
I1022 16:26:48.708858 27659 net.cpp:100] Creating Layer bn5a_branch2c
I1022 16:26:48.708861 27659 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I1022 16:26:48.708868 27659 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I1022 16:26:48.709303 27659 net.cpp:150] Setting up bn5a_branch2c
I1022 16:26:48.709311 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.709313 27659 net.cpp:165] Memory required for data: 225792012
I1022 16:26:48.709321 27659 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1022 16:26:48.709328 27659 net.cpp:100] Creating Layer scale5a_branch2c
I1022 16:26:48.709331 27659 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I1022 16:26:48.709338 27659 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I1022 16:26:48.709409 27659 layer_factory.hpp:77] Creating layer scale5a_branch2c
I1022 16:26:48.709652 27659 net.cpp:150] Setting up scale5a_branch2c
I1022 16:26:48.709661 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.709663 27659 net.cpp:165] Memory required for data: 226193420
I1022 16:26:48.709669 27659 layer_factory.hpp:77] Creating layer res5a
I1022 16:26:48.709677 27659 net.cpp:100] Creating Layer res5a
I1022 16:26:48.709681 27659 net.cpp:444] res5a <- res5a_branch1
I1022 16:26:48.709686 27659 net.cpp:444] res5a <- res5a_branch2c
I1022 16:26:48.709692 27659 net.cpp:418] res5a -> res5a
I1022 16:26:48.709735 27659 net.cpp:150] Setting up res5a
I1022 16:26:48.709743 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.709745 27659 net.cpp:165] Memory required for data: 226594828
I1022 16:26:48.709748 27659 layer_factory.hpp:77] Creating layer res5a_relu
I1022 16:26:48.709753 27659 net.cpp:100] Creating Layer res5a_relu
I1022 16:26:48.709756 27659 net.cpp:444] res5a_relu <- res5a
I1022 16:26:48.709764 27659 net.cpp:405] res5a_relu -> res5a (in-place)
I1022 16:26:48.710736 27659 net.cpp:150] Setting up res5a_relu
I1022 16:26:48.710749 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.710752 27659 net.cpp:165] Memory required for data: 226996236
I1022 16:26:48.710757 27659 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I1022 16:26:48.710765 27659 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I1022 16:26:48.710769 27659 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I1022 16:26:48.710775 27659 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I1022 16:26:48.710784 27659 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I1022 16:26:48.710873 27659 net.cpp:150] Setting up res5a_res5a_relu_0_split
I1022 16:26:48.710882 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.710886 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.710888 27659 net.cpp:165] Memory required for data: 227799052
I1022 16:26:48.710891 27659 layer_factory.hpp:77] Creating layer res5b_branch2a
I1022 16:26:48.710901 27659 net.cpp:100] Creating Layer res5b_branch2a
I1022 16:26:48.710906 27659 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I1022 16:26:48.710911 27659 net.cpp:418] res5b_branch2a -> res5b_branch2a
I1022 16:26:48.716243 27659 net.cpp:150] Setting up res5b_branch2a
I1022 16:26:48.716259 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.716262 27659 net.cpp:165] Memory required for data: 227899404
I1022 16:26:48.716269 27659 layer_factory.hpp:77] Creating layer bn5b_branch2a
I1022 16:26:48.716275 27659 net.cpp:100] Creating Layer bn5b_branch2a
I1022 16:26:48.716280 27659 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I1022 16:26:48.716287 27659 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I1022 16:26:48.716723 27659 net.cpp:150] Setting up bn5b_branch2a
I1022 16:26:48.716732 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.716734 27659 net.cpp:165] Memory required for data: 227999756
I1022 16:26:48.716754 27659 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1022 16:26:48.716763 27659 net.cpp:100] Creating Layer scale5b_branch2a
I1022 16:26:48.716768 27659 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I1022 16:26:48.716774 27659 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I1022 16:26:48.716845 27659 layer_factory.hpp:77] Creating layer scale5b_branch2a
I1022 16:26:48.717089 27659 net.cpp:150] Setting up scale5b_branch2a
I1022 16:26:48.717097 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.717100 27659 net.cpp:165] Memory required for data: 228100108
I1022 16:26:48.717106 27659 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I1022 16:26:48.717113 27659 net.cpp:100] Creating Layer res5b_branch2a_relu
I1022 16:26:48.717118 27659 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I1022 16:26:48.717123 27659 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I1022 16:26:48.717366 27659 net.cpp:150] Setting up res5b_branch2a_relu
I1022 16:26:48.717376 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.717380 27659 net.cpp:165] Memory required for data: 228200460
I1022 16:26:48.717383 27659 layer_factory.hpp:77] Creating layer res5b_branch2b
I1022 16:26:48.717393 27659 net.cpp:100] Creating Layer res5b_branch2b
I1022 16:26:48.717397 27659 net.cpp:444] res5b_branch2b <- res5b_branch2a
I1022 16:26:48.717402 27659 net.cpp:418] res5b_branch2b -> res5b_branch2b
I1022 16:26:48.724225 27659 net.cpp:150] Setting up res5b_branch2b
I1022 16:26:48.724239 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.724242 27659 net.cpp:165] Memory required for data: 228300812
I1022 16:26:48.724248 27659 layer_factory.hpp:77] Creating layer bn5b_branch2b
I1022 16:26:48.724258 27659 net.cpp:100] Creating Layer bn5b_branch2b
I1022 16:26:48.724262 27659 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I1022 16:26:48.724267 27659 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I1022 16:26:48.724709 27659 net.cpp:150] Setting up bn5b_branch2b
I1022 16:26:48.724719 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.724720 27659 net.cpp:165] Memory required for data: 228401164
I1022 16:26:48.724730 27659 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1022 16:26:48.724740 27659 net.cpp:100] Creating Layer scale5b_branch2b
I1022 16:26:48.724743 27659 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I1022 16:26:48.724748 27659 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I1022 16:26:48.724822 27659 layer_factory.hpp:77] Creating layer scale5b_branch2b
I1022 16:26:48.725061 27659 net.cpp:150] Setting up scale5b_branch2b
I1022 16:26:48.725069 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.725072 27659 net.cpp:165] Memory required for data: 228501516
I1022 16:26:48.725078 27659 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I1022 16:26:48.725086 27659 net.cpp:100] Creating Layer res5b_branch2b_relu
I1022 16:26:48.725090 27659 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I1022 16:26:48.725096 27659 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I1022 16:26:48.725352 27659 net.cpp:150] Setting up res5b_branch2b_relu
I1022 16:26:48.725361 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.725364 27659 net.cpp:165] Memory required for data: 228601868
I1022 16:26:48.725368 27659 layer_factory.hpp:77] Creating layer res5b_branch2c
I1022 16:26:48.725378 27659 net.cpp:100] Creating Layer res5b_branch2c
I1022 16:26:48.725381 27659 net.cpp:444] res5b_branch2c <- res5b_branch2b
I1022 16:26:48.725389 27659 net.cpp:418] res5b_branch2c -> res5b_branch2c
I1022 16:26:48.730727 27659 net.cpp:150] Setting up res5b_branch2c
I1022 16:26:48.730741 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.730744 27659 net.cpp:165] Memory required for data: 229003276
I1022 16:26:48.730751 27659 layer_factory.hpp:77] Creating layer bn5b_branch2c
I1022 16:26:48.730759 27659 net.cpp:100] Creating Layer bn5b_branch2c
I1022 16:26:48.730763 27659 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I1022 16:26:48.730770 27659 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I1022 16:26:48.731206 27659 net.cpp:150] Setting up bn5b_branch2c
I1022 16:26:48.731215 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.731217 27659 net.cpp:165] Memory required for data: 229404684
I1022 16:26:48.731225 27659 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1022 16:26:48.731235 27659 net.cpp:100] Creating Layer scale5b_branch2c
I1022 16:26:48.731238 27659 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I1022 16:26:48.731245 27659 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I1022 16:26:48.731318 27659 layer_factory.hpp:77] Creating layer scale5b_branch2c
I1022 16:26:48.731580 27659 net.cpp:150] Setting up scale5b_branch2c
I1022 16:26:48.731588 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.731591 27659 net.cpp:165] Memory required for data: 229806092
I1022 16:26:48.731598 27659 layer_factory.hpp:77] Creating layer res5b
I1022 16:26:48.731604 27659 net.cpp:100] Creating Layer res5b
I1022 16:26:48.731607 27659 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I1022 16:26:48.731612 27659 net.cpp:444] res5b <- res5b_branch2c
I1022 16:26:48.731617 27659 net.cpp:418] res5b -> res5b
I1022 16:26:48.731663 27659 net.cpp:150] Setting up res5b
I1022 16:26:48.731670 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.731674 27659 net.cpp:165] Memory required for data: 230207500
I1022 16:26:48.731678 27659 layer_factory.hpp:77] Creating layer res5b_relu
I1022 16:26:48.731683 27659 net.cpp:100] Creating Layer res5b_relu
I1022 16:26:48.731685 27659 net.cpp:444] res5b_relu <- res5b
I1022 16:26:48.731690 27659 net.cpp:405] res5b_relu -> res5b (in-place)
I1022 16:26:48.737098 27659 net.cpp:150] Setting up res5b_relu
I1022 16:26:48.737114 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.737118 27659 net.cpp:165] Memory required for data: 230608908
I1022 16:26:48.737121 27659 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I1022 16:26:48.737128 27659 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I1022 16:26:48.737134 27659 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I1022 16:26:48.737141 27659 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I1022 16:26:48.737149 27659 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I1022 16:26:48.737241 27659 net.cpp:150] Setting up res5b_res5b_relu_0_split
I1022 16:26:48.737248 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.737252 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.737255 27659 net.cpp:165] Memory required for data: 231411724
I1022 16:26:48.737258 27659 layer_factory.hpp:77] Creating layer res5c_branch2a
I1022 16:26:48.737268 27659 net.cpp:100] Creating Layer res5c_branch2a
I1022 16:26:48.737273 27659 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I1022 16:26:48.737280 27659 net.cpp:418] res5c_branch2a -> res5c_branch2a
I1022 16:26:48.742679 27659 net.cpp:150] Setting up res5c_branch2a
I1022 16:26:48.742694 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.742697 27659 net.cpp:165] Memory required for data: 231512076
I1022 16:26:48.742703 27659 layer_factory.hpp:77] Creating layer bn5c_branch2a
I1022 16:26:48.742712 27659 net.cpp:100] Creating Layer bn5c_branch2a
I1022 16:26:48.742717 27659 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I1022 16:26:48.742722 27659 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I1022 16:26:48.743173 27659 net.cpp:150] Setting up bn5c_branch2a
I1022 16:26:48.743181 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.743185 27659 net.cpp:165] Memory required for data: 231612428
I1022 16:26:48.743192 27659 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1022 16:26:48.743201 27659 net.cpp:100] Creating Layer scale5c_branch2a
I1022 16:26:48.743203 27659 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I1022 16:26:48.743211 27659 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I1022 16:26:48.743283 27659 layer_factory.hpp:77] Creating layer scale5c_branch2a
I1022 16:26:48.743533 27659 net.cpp:150] Setting up scale5c_branch2a
I1022 16:26:48.743541 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.743544 27659 net.cpp:165] Memory required for data: 231712780
I1022 16:26:48.743551 27659 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I1022 16:26:48.743559 27659 net.cpp:100] Creating Layer res5c_branch2a_relu
I1022 16:26:48.743562 27659 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I1022 16:26:48.743567 27659 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I1022 16:26:48.743814 27659 net.cpp:150] Setting up res5c_branch2a_relu
I1022 16:26:48.743824 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.743827 27659 net.cpp:165] Memory required for data: 231813132
I1022 16:26:48.743831 27659 layer_factory.hpp:77] Creating layer res5c_branch2b
I1022 16:26:48.743841 27659 net.cpp:100] Creating Layer res5c_branch2b
I1022 16:26:48.743849 27659 net.cpp:444] res5c_branch2b <- res5c_branch2a
I1022 16:26:48.743855 27659 net.cpp:418] res5c_branch2b -> res5c_branch2b
I1022 16:26:48.755173 27659 net.cpp:150] Setting up res5c_branch2b
I1022 16:26:48.755188 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.755192 27659 net.cpp:165] Memory required for data: 231913484
I1022 16:26:48.755198 27659 layer_factory.hpp:77] Creating layer bn5c_branch2b
I1022 16:26:48.755208 27659 net.cpp:100] Creating Layer bn5c_branch2b
I1022 16:26:48.755213 27659 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I1022 16:26:48.755220 27659 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I1022 16:26:48.755654 27659 net.cpp:150] Setting up bn5c_branch2b
I1022 16:26:48.755666 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.755668 27659 net.cpp:165] Memory required for data: 232013836
I1022 16:26:48.755676 27659 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1022 16:26:48.755682 27659 net.cpp:100] Creating Layer scale5c_branch2b
I1022 16:26:48.755686 27659 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I1022 16:26:48.755692 27659 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I1022 16:26:48.755764 27659 layer_factory.hpp:77] Creating layer scale5c_branch2b
I1022 16:26:48.756009 27659 net.cpp:150] Setting up scale5c_branch2b
I1022 16:26:48.756017 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.756021 27659 net.cpp:165] Memory required for data: 232114188
I1022 16:26:48.756026 27659 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I1022 16:26:48.756034 27659 net.cpp:100] Creating Layer res5c_branch2b_relu
I1022 16:26:48.756038 27659 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I1022 16:26:48.756044 27659 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I1022 16:26:48.756310 27659 net.cpp:150] Setting up res5c_branch2b_relu
I1022 16:26:48.756319 27659 net.cpp:157] Top shape: 1 512 7 7 (25088)
I1022 16:26:48.756323 27659 net.cpp:165] Memory required for data: 232214540
I1022 16:26:48.756326 27659 layer_factory.hpp:77] Creating layer res5c_branch2c
I1022 16:26:48.756336 27659 net.cpp:100] Creating Layer res5c_branch2c
I1022 16:26:48.756342 27659 net.cpp:444] res5c_branch2c <- res5c_branch2b
I1022 16:26:48.756350 27659 net.cpp:418] res5c_branch2c -> res5c_branch2c
I1022 16:26:48.761821 27659 net.cpp:150] Setting up res5c_branch2c
I1022 16:26:48.761835 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.761838 27659 net.cpp:165] Memory required for data: 232615948
I1022 16:26:48.761850 27659 layer_factory.hpp:77] Creating layer bn5c_branch2c
I1022 16:26:48.761859 27659 net.cpp:100] Creating Layer bn5c_branch2c
I1022 16:26:48.761863 27659 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I1022 16:26:48.761870 27659 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I1022 16:26:48.762318 27659 net.cpp:150] Setting up bn5c_branch2c
I1022 16:26:48.762326 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.762328 27659 net.cpp:165] Memory required for data: 233017356
I1022 16:26:48.762336 27659 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1022 16:26:48.762346 27659 net.cpp:100] Creating Layer scale5c_branch2c
I1022 16:26:48.762348 27659 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I1022 16:26:48.762353 27659 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I1022 16:26:48.762428 27659 layer_factory.hpp:77] Creating layer scale5c_branch2c
I1022 16:26:48.762681 27659 net.cpp:150] Setting up scale5c_branch2c
I1022 16:26:48.762688 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.762691 27659 net.cpp:165] Memory required for data: 233418764
I1022 16:26:48.762697 27659 layer_factory.hpp:77] Creating layer res5c
I1022 16:26:48.762706 27659 net.cpp:100] Creating Layer res5c
I1022 16:26:48.762709 27659 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I1022 16:26:48.762713 27659 net.cpp:444] res5c <- res5c_branch2c
I1022 16:26:48.762722 27659 net.cpp:418] res5c -> res5c
I1022 16:26:48.762769 27659 net.cpp:150] Setting up res5c
I1022 16:26:48.762776 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.762778 27659 net.cpp:165] Memory required for data: 233820172
I1022 16:26:48.762781 27659 layer_factory.hpp:77] Creating layer res5c_relu
I1022 16:26:48.762787 27659 net.cpp:100] Creating Layer res5c_relu
I1022 16:26:48.762790 27659 net.cpp:444] res5c_relu <- res5c
I1022 16:26:48.762794 27659 net.cpp:405] res5c_relu -> res5c (in-place)
I1022 16:26:48.763041 27659 net.cpp:150] Setting up res5c_relu
I1022 16:26:48.763051 27659 net.cpp:157] Top shape: 1 2048 7 7 (100352)
I1022 16:26:48.763053 27659 net.cpp:165] Memory required for data: 234221580
I1022 16:26:48.763057 27659 layer_factory.hpp:77] Creating layer upP4
I1022 16:26:48.763065 27659 net.cpp:100] Creating Layer upP4
I1022 16:26:48.763070 27659 net.cpp:444] upP4 <- res5c
I1022 16:26:48.763077 27659 net.cpp:418] upP4 -> upP4
I1022 16:26:48.765112 27659 net.cpp:150] Setting up upP4
I1022 16:26:48.765123 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.765126 27659 net.cpp:165] Memory required for data: 234622988
I1022 16:26:48.765131 27659 layer_factory.hpp:77] Creating layer newC4
I1022 16:26:48.765141 27659 net.cpp:100] Creating Layer newC4
I1022 16:26:48.765146 27659 net.cpp:444] newC4 <- res4f_res4f_relu_0_split_2
I1022 16:26:48.765154 27659 net.cpp:418] newC4 -> c4
I1022 16:26:48.775135 27659 net.cpp:150] Setting up newC4
I1022 16:26:48.775148 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.775151 27659 net.cpp:165] Memory required for data: 235024396
I1022 16:26:48.775159 27659 layer_factory.hpp:77] Creating layer eltwise_bnc4_bnp4
I1022 16:26:48.775169 27659 net.cpp:100] Creating Layer eltwise_bnc4_bnp4
I1022 16:26:48.775173 27659 net.cpp:444] eltwise_bnc4_bnp4 <- c4
I1022 16:26:48.775177 27659 net.cpp:444] eltwise_bnc4_bnp4 <- upP4
I1022 16:26:48.775187 27659 net.cpp:418] eltwise_bnc4_bnp4 -> skip_eltwise1
I1022 16:26:48.775254 27659 net.cpp:150] Setting up eltwise_bnc4_bnp4
I1022 16:26:48.775261 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.775264 27659 net.cpp:165] Memory required for data: 235425804
I1022 16:26:48.775269 27659 layer_factory.hpp:77] Creating layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 16:26:48.775274 27659 net.cpp:100] Creating Layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 16:26:48.775277 27659 net.cpp:444] skip_eltwise1_eltwise_bnc4_bnp4_0_split <- skip_eltwise1
I1022 16:26:48.775285 27659 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1022 16:26:48.775293 27659 net.cpp:418] skip_eltwise1_eltwise_bnc4_bnp4_0_split -> skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1022 16:26:48.775369 27659 net.cpp:150] Setting up skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 16:26:48.775375 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.775380 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.775383 27659 net.cpp:165] Memory required for data: 236228620
I1022 16:26:48.775387 27659 layer_factory.hpp:77] Creating layer bnp4_conv
I1022 16:26:48.775398 27659 net.cpp:100] Creating Layer bnp4_conv
I1022 16:26:48.775403 27659 net.cpp:444] bnp4_conv <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_0
I1022 16:26:48.775411 27659 net.cpp:418] bnp4_conv -> bnp4_conv
I1022 16:26:48.778095 27659 net.cpp:150] Setting up bnp4_conv
I1022 16:26:48.778108 27659 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:26:48.778111 27659 net.cpp:165] Memory required for data: 236328972
I1022 16:26:48.778118 27659 layer_factory.hpp:77] Creating layer bnp4_bn
I1022 16:26:48.778126 27659 net.cpp:100] Creating Layer bnp4_bn
I1022 16:26:48.778131 27659 net.cpp:444] bnp4_bn <- bnp4_conv
I1022 16:26:48.778137 27659 net.cpp:405] bnp4_bn -> bnp4_conv (in-place)
I1022 16:26:48.778568 27659 net.cpp:150] Setting up bnp4_bn
I1022 16:26:48.778575 27659 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:26:48.778578 27659 net.cpp:165] Memory required for data: 236429324
I1022 16:26:48.778585 27659 layer_factory.hpp:77] Creating layer bnp4_scale
I1022 16:26:48.778594 27659 net.cpp:100] Creating Layer bnp4_scale
I1022 16:26:48.778597 27659 net.cpp:444] bnp4_scale <- bnp4_conv
I1022 16:26:48.778604 27659 net.cpp:405] bnp4_scale -> bnp4_conv (in-place)
I1022 16:26:48.778678 27659 layer_factory.hpp:77] Creating layer bnp4_scale
I1022 16:26:48.778913 27659 net.cpp:150] Setting up bnp4_scale
I1022 16:26:48.778919 27659 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:26:48.778923 27659 net.cpp:165] Memory required for data: 236529676
I1022 16:26:48.778929 27659 layer_factory.hpp:77] Creating layer bnp4_ReLU
I1022 16:26:48.778939 27659 net.cpp:100] Creating Layer bnp4_ReLU
I1022 16:26:48.778944 27659 net.cpp:444] bnp4_ReLU <- bnp4_conv
I1022 16:26:48.778947 27659 net.cpp:405] bnp4_ReLU -> bnp4_conv (in-place)
I1022 16:26:48.779953 27659 net.cpp:150] Setting up bnp4_ReLU
I1022 16:26:48.779968 27659 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:26:48.779971 27659 net.cpp:165] Memory required for data: 236630028
I1022 16:26:48.779975 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_conv
I1022 16:26:48.779986 27659 net.cpp:100] Creating Layer bn_eltwise_1_1_conv
I1022 16:26:48.779990 27659 net.cpp:444] bn_eltwise_1_1_conv <- bnp4_conv
I1022 16:26:48.779996 27659 net.cpp:418] bn_eltwise_1_1_conv -> bn_eltwise_1_1_conv
I1022 16:26:48.784401 27659 net.cpp:150] Setting up bn_eltwise_1_1_conv
I1022 16:26:48.784415 27659 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:26:48.784418 27659 net.cpp:165] Memory required for data: 236730380
I1022 16:26:48.784425 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_bn
I1022 16:26:48.784432 27659 net.cpp:100] Creating Layer bn_eltwise_1_1_bn
I1022 16:26:48.784435 27659 net.cpp:444] bn_eltwise_1_1_bn <- bn_eltwise_1_1_conv
I1022 16:26:48.784441 27659 net.cpp:405] bn_eltwise_1_1_bn -> bn_eltwise_1_1_conv (in-place)
I1022 16:26:48.784893 27659 net.cpp:150] Setting up bn_eltwise_1_1_bn
I1022 16:26:48.784904 27659 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:26:48.784906 27659 net.cpp:165] Memory required for data: 236830732
I1022 16:26:48.784915 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1022 16:26:48.784921 27659 net.cpp:100] Creating Layer bn_eltwise_1_1_scale
I1022 16:26:48.784925 27659 net.cpp:444] bn_eltwise_1_1_scale <- bn_eltwise_1_1_conv
I1022 16:26:48.784931 27659 net.cpp:405] bn_eltwise_1_1_scale -> bn_eltwise_1_1_conv (in-place)
I1022 16:26:48.785018 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_scale
I1022 16:26:48.785250 27659 net.cpp:150] Setting up bn_eltwise_1_1_scale
I1022 16:26:48.785257 27659 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:26:48.785260 27659 net.cpp:165] Memory required for data: 236931084
I1022 16:26:48.785267 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_1_ReLU
I1022 16:26:48.785274 27659 net.cpp:100] Creating Layer bn_eltwise_1_1_ReLU
I1022 16:26:48.785279 27659 net.cpp:444] bn_eltwise_1_1_ReLU <- bn_eltwise_1_1_conv
I1022 16:26:48.785284 27659 net.cpp:405] bn_eltwise_1_1_ReLU -> bn_eltwise_1_1_conv (in-place)
I1022 16:26:48.785547 27659 net.cpp:150] Setting up bn_eltwise_1_1_ReLU
I1022 16:26:48.785557 27659 net.cpp:157] Top shape: 1 128 14 14 (25088)
I1022 16:26:48.785559 27659 net.cpp:165] Memory required for data: 237031436
I1022 16:26:48.785563 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_conv
I1022 16:26:48.785575 27659 net.cpp:100] Creating Layer bn_eltwise_1_2_conv
I1022 16:26:48.785581 27659 net.cpp:444] bn_eltwise_1_2_conv <- bn_eltwise_1_1_conv
I1022 16:26:48.785590 27659 net.cpp:418] bn_eltwise_1_2_conv -> bn_eltwise_1_2_conv
I1022 16:26:48.790184 27659 net.cpp:150] Setting up bn_eltwise_1_2_conv
I1022 16:26:48.790199 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.790202 27659 net.cpp:165] Memory required for data: 237432844
I1022 16:26:48.790208 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_bn
I1022 16:26:48.790218 27659 net.cpp:100] Creating Layer bn_eltwise_1_2_bn
I1022 16:26:48.790222 27659 net.cpp:444] bn_eltwise_1_2_bn <- bn_eltwise_1_2_conv
I1022 16:26:48.790230 27659 net.cpp:405] bn_eltwise_1_2_bn -> bn_eltwise_1_2_conv (in-place)
I1022 16:26:48.790673 27659 net.cpp:150] Setting up bn_eltwise_1_2_bn
I1022 16:26:48.790681 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.790684 27659 net.cpp:165] Memory required for data: 237834252
I1022 16:26:48.790693 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1022 16:26:48.790719 27659 net.cpp:100] Creating Layer bn_eltwise_1_2_scale
I1022 16:26:48.790721 27659 net.cpp:444] bn_eltwise_1_2_scale <- bn_eltwise_1_2_conv
I1022 16:26:48.790727 27659 net.cpp:405] bn_eltwise_1_2_scale -> bn_eltwise_1_2_conv (in-place)
I1022 16:26:48.790796 27659 layer_factory.hpp:77] Creating layer bn_eltwise_1_2_scale
I1022 16:26:48.791049 27659 net.cpp:150] Setting up bn_eltwise_1_2_scale
I1022 16:26:48.791059 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.791061 27659 net.cpp:165] Memory required for data: 238235660
I1022 16:26:48.791069 27659 layer_factory.hpp:77] Creating layer p3
I1022 16:26:48.791074 27659 net.cpp:100] Creating Layer p3
I1022 16:26:48.791079 27659 net.cpp:444] p3 <- bn_eltwise_1_2_conv
I1022 16:26:48.791085 27659 net.cpp:444] p3 <- skip_eltwise1_eltwise_bnc4_bnp4_0_split_1
I1022 16:26:48.791090 27659 net.cpp:418] p3 -> p3
I1022 16:26:48.791141 27659 net.cpp:150] Setting up p3
I1022 16:26:48.791148 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.791152 27659 net.cpp:165] Memory required for data: 238637068
I1022 16:26:48.791154 27659 layer_factory.hpp:77] Creating layer p3_relu
I1022 16:26:48.791159 27659 net.cpp:100] Creating Layer p3_relu
I1022 16:26:48.791162 27659 net.cpp:444] p3_relu <- p3
I1022 16:26:48.791169 27659 net.cpp:405] p3_relu -> p3 (in-place)
I1022 16:26:48.791424 27659 net.cpp:150] Setting up p3_relu
I1022 16:26:48.791435 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.791437 27659 net.cpp:165] Memory required for data: 239038476
I1022 16:26:48.791441 27659 layer_factory.hpp:77] Creating layer p3_p3_relu_0_split
I1022 16:26:48.791446 27659 net.cpp:100] Creating Layer p3_p3_relu_0_split
I1022 16:26:48.791450 27659 net.cpp:444] p3_p3_relu_0_split <- p3
I1022 16:26:48.791455 27659 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_0
I1022 16:26:48.791467 27659 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_1
I1022 16:26:48.791474 27659 net.cpp:418] p3_p3_relu_0_split -> p3_p3_relu_0_split_2
I1022 16:26:48.791589 27659 net.cpp:150] Setting up p3_p3_relu_0_split
I1022 16:26:48.791596 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.791600 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.791604 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.791606 27659 net.cpp:165] Memory required for data: 240242700
I1022 16:26:48.791610 27659 layer_factory.hpp:77] Creating layer newC3
I1022 16:26:48.791618 27659 net.cpp:100] Creating Layer newC3
I1022 16:26:48.791625 27659 net.cpp:444] newC3 <- res3d_res3d_relu_0_split_2
I1022 16:26:48.791632 27659 net.cpp:418] newC3 -> c3
I1022 16:26:48.798430 27659 net.cpp:150] Setting up newC3
I1022 16:26:48.798444 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.798447 27659 net.cpp:165] Memory required for data: 241848332
I1022 16:26:48.798455 27659 layer_factory.hpp:77] Creating layer upP3
I1022 16:26:48.798465 27659 net.cpp:100] Creating Layer upP3
I1022 16:26:48.798470 27659 net.cpp:444] upP3 <- p3_p3_relu_0_split_0
I1022 16:26:48.798477 27659 net.cpp:418] upP3 -> upP3
I1022 16:26:48.799327 27659 net.cpp:150] Setting up upP3
I1022 16:26:48.799337 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.799340 27659 net.cpp:165] Memory required for data: 243453964
I1022 16:26:48.799345 27659 layer_factory.hpp:77] Creating layer eltwise_bnc3_bnp3
I1022 16:26:48.799351 27659 net.cpp:100] Creating Layer eltwise_bnc3_bnp3
I1022 16:26:48.799355 27659 net.cpp:444] eltwise_bnc3_bnp3 <- c3
I1022 16:26:48.799360 27659 net.cpp:444] eltwise_bnc3_bnp3 <- upP3
I1022 16:26:48.799365 27659 net.cpp:418] eltwise_bnc3_bnp3 -> skip_eltwise2
I1022 16:26:48.799413 27659 net.cpp:150] Setting up eltwise_bnc3_bnp3
I1022 16:26:48.799420 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.799423 27659 net.cpp:165] Memory required for data: 245059596
I1022 16:26:48.799427 27659 layer_factory.hpp:77] Creating layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 16:26:48.799432 27659 net.cpp:100] Creating Layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 16:26:48.799435 27659 net.cpp:444] skip_eltwise2_eltwise_bnc3_bnp3_0_split <- skip_eltwise2
I1022 16:26:48.799443 27659 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1022 16:26:48.799448 27659 net.cpp:418] skip_eltwise2_eltwise_bnc3_bnp3_0_split -> skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1022 16:26:48.799525 27659 net.cpp:150] Setting up skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 16:26:48.799532 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.799536 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.799540 27659 net.cpp:165] Memory required for data: 248270860
I1022 16:26:48.799542 27659 layer_factory.hpp:77] Creating layer bnp3_conv
I1022 16:26:48.799552 27659 net.cpp:100] Creating Layer bnp3_conv
I1022 16:26:48.799557 27659 net.cpp:444] bnp3_conv <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_0
I1022 16:26:48.799566 27659 net.cpp:418] bnp3_conv -> bnp3_conv
I1022 16:26:48.802268 27659 net.cpp:150] Setting up bnp3_conv
I1022 16:26:48.802283 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.802285 27659 net.cpp:165] Memory required for data: 248672268
I1022 16:26:48.802291 27659 layer_factory.hpp:77] Creating layer bnp3_bn
I1022 16:26:48.802300 27659 net.cpp:100] Creating Layer bnp3_bn
I1022 16:26:48.802304 27659 net.cpp:444] bnp3_bn <- bnp3_conv
I1022 16:26:48.802311 27659 net.cpp:405] bnp3_bn -> bnp3_conv (in-place)
I1022 16:26:48.802769 27659 net.cpp:150] Setting up bnp3_bn
I1022 16:26:48.802778 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.802779 27659 net.cpp:165] Memory required for data: 249073676
I1022 16:26:48.802788 27659 layer_factory.hpp:77] Creating layer bnp3_scale
I1022 16:26:48.802796 27659 net.cpp:100] Creating Layer bnp3_scale
I1022 16:26:48.802799 27659 net.cpp:444] bnp3_scale <- bnp3_conv
I1022 16:26:48.802804 27659 net.cpp:405] bnp3_scale -> bnp3_conv (in-place)
I1022 16:26:48.802881 27659 layer_factory.hpp:77] Creating layer bnp3_scale
I1022 16:26:48.803131 27659 net.cpp:150] Setting up bnp3_scale
I1022 16:26:48.803139 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.803143 27659 net.cpp:165] Memory required for data: 249475084
I1022 16:26:48.803149 27659 layer_factory.hpp:77] Creating layer bnp3_ReLU
I1022 16:26:48.803159 27659 net.cpp:100] Creating Layer bnp3_ReLU
I1022 16:26:48.803164 27659 net.cpp:444] bnp3_ReLU <- bnp3_conv
I1022 16:26:48.803169 27659 net.cpp:405] bnp3_ReLU -> bnp3_conv (in-place)
I1022 16:26:48.810959 27659 net.cpp:150] Setting up bnp3_ReLU
I1022 16:26:48.810979 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.810983 27659 net.cpp:165] Memory required for data: 249876492
I1022 16:26:48.810987 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_conv
I1022 16:26:48.810999 27659 net.cpp:100] Creating Layer bn_eltwise_2_1_conv
I1022 16:26:48.811003 27659 net.cpp:444] bn_eltwise_2_1_conv <- bnp3_conv
I1022 16:26:48.811009 27659 net.cpp:418] bn_eltwise_2_1_conv -> bn_eltwise_2_1_conv
I1022 16:26:48.815340 27659 net.cpp:150] Setting up bn_eltwise_2_1_conv
I1022 16:26:48.815356 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.815359 27659 net.cpp:165] Memory required for data: 250277900
I1022 16:26:48.815366 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_bn
I1022 16:26:48.815373 27659 net.cpp:100] Creating Layer bn_eltwise_2_1_bn
I1022 16:26:48.815377 27659 net.cpp:444] bn_eltwise_2_1_bn <- bn_eltwise_2_1_conv
I1022 16:26:48.815384 27659 net.cpp:405] bn_eltwise_2_1_bn -> bn_eltwise_2_1_conv (in-place)
I1022 16:26:48.815847 27659 net.cpp:150] Setting up bn_eltwise_2_1_bn
I1022 16:26:48.815855 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.815860 27659 net.cpp:165] Memory required for data: 250679308
I1022 16:26:48.815867 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1022 16:26:48.815876 27659 net.cpp:100] Creating Layer bn_eltwise_2_1_scale
I1022 16:26:48.815878 27659 net.cpp:444] bn_eltwise_2_1_scale <- bn_eltwise_2_1_conv
I1022 16:26:48.815886 27659 net.cpp:405] bn_eltwise_2_1_scale -> bn_eltwise_2_1_conv (in-place)
I1022 16:26:48.815963 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_scale
I1022 16:26:48.816215 27659 net.cpp:150] Setting up bn_eltwise_2_1_scale
I1022 16:26:48.816222 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.816226 27659 net.cpp:165] Memory required for data: 251080716
I1022 16:26:48.816234 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_1_ReLU
I1022 16:26:48.816241 27659 net.cpp:100] Creating Layer bn_eltwise_2_1_ReLU
I1022 16:26:48.816244 27659 net.cpp:444] bn_eltwise_2_1_ReLU <- bn_eltwise_2_1_conv
I1022 16:26:48.816254 27659 net.cpp:405] bn_eltwise_2_1_ReLU -> bn_eltwise_2_1_conv (in-place)
I1022 16:26:48.816511 27659 net.cpp:150] Setting up bn_eltwise_2_1_ReLU
I1022 16:26:48.816520 27659 net.cpp:157] Top shape: 1 128 28 28 (100352)
I1022 16:26:48.816524 27659 net.cpp:165] Memory required for data: 251482124
I1022 16:26:48.816527 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_conv
I1022 16:26:48.816537 27659 net.cpp:100] Creating Layer bn_eltwise_2_2_conv
I1022 16:26:48.816541 27659 net.cpp:444] bn_eltwise_2_2_conv <- bn_eltwise_2_1_conv
I1022 16:26:48.816550 27659 net.cpp:418] bn_eltwise_2_2_conv -> bn_eltwise_2_2_conv
I1022 16:26:48.819310 27659 net.cpp:150] Setting up bn_eltwise_2_2_conv
I1022 16:26:48.819324 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.819327 27659 net.cpp:165] Memory required for data: 253087756
I1022 16:26:48.819334 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_bn
I1022 16:26:48.819344 27659 net.cpp:100] Creating Layer bn_eltwise_2_2_bn
I1022 16:26:48.819347 27659 net.cpp:444] bn_eltwise_2_2_bn <- bn_eltwise_2_2_conv
I1022 16:26:48.819352 27659 net.cpp:405] bn_eltwise_2_2_bn -> bn_eltwise_2_2_conv (in-place)
I1022 16:26:48.819813 27659 net.cpp:150] Setting up bn_eltwise_2_2_bn
I1022 16:26:48.819820 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.819823 27659 net.cpp:165] Memory required for data: 254693388
I1022 16:26:48.819831 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1022 16:26:48.819840 27659 net.cpp:100] Creating Layer bn_eltwise_2_2_scale
I1022 16:26:48.819844 27659 net.cpp:444] bn_eltwise_2_2_scale <- bn_eltwise_2_2_conv
I1022 16:26:48.819849 27659 net.cpp:405] bn_eltwise_2_2_scale -> bn_eltwise_2_2_conv (in-place)
I1022 16:26:48.819934 27659 layer_factory.hpp:77] Creating layer bn_eltwise_2_2_scale
I1022 16:26:48.820183 27659 net.cpp:150] Setting up bn_eltwise_2_2_scale
I1022 16:26:48.820199 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.820202 27659 net.cpp:165] Memory required for data: 256299020
I1022 16:26:48.820209 27659 layer_factory.hpp:77] Creating layer p2
I1022 16:26:48.820219 27659 net.cpp:100] Creating Layer p2
I1022 16:26:48.820225 27659 net.cpp:444] p2 <- skip_eltwise2_eltwise_bnc3_bnp3_0_split_1
I1022 16:26:48.820230 27659 net.cpp:444] p2 <- bn_eltwise_2_2_conv
I1022 16:26:48.820235 27659 net.cpp:418] p2 -> p2
I1022 16:26:48.820284 27659 net.cpp:150] Setting up p2
I1022 16:26:48.820292 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.820294 27659 net.cpp:165] Memory required for data: 257904652
I1022 16:26:48.820297 27659 layer_factory.hpp:77] Creating layer p2_relu
I1022 16:26:48.820302 27659 net.cpp:100] Creating Layer p2_relu
I1022 16:26:48.820307 27659 net.cpp:444] p2_relu <- p2
I1022 16:26:48.820312 27659 net.cpp:405] p2_relu -> p2 (in-place)
I1022 16:26:48.820561 27659 net.cpp:150] Setting up p2_relu
I1022 16:26:48.820571 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.820574 27659 net.cpp:165] Memory required for data: 259510284
I1022 16:26:48.820578 27659 layer_factory.hpp:77] Creating layer p2_p2_relu_0_split
I1022 16:26:48.820586 27659 net.cpp:100] Creating Layer p2_p2_relu_0_split
I1022 16:26:48.820590 27659 net.cpp:444] p2_p2_relu_0_split <- p2
I1022 16:26:48.820595 27659 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_0
I1022 16:26:48.820602 27659 net.cpp:418] p2_p2_relu_0_split -> p2_p2_relu_0_split_1
I1022 16:26:48.820705 27659 net.cpp:150] Setting up p2_p2_relu_0_split
I1022 16:26:48.820713 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.820719 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.820722 27659 net.cpp:165] Memory required for data: 262721548
I1022 16:26:48.820725 27659 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p2
I1022 16:26:48.820737 27659 net.cpp:100] Creating Layer rpn_conv/3x3_p2
I1022 16:26:48.820742 27659 net.cpp:444] rpn_conv/3x3_p2 <- p2_p2_relu_0_split_0
I1022 16:26:48.820750 27659 net.cpp:418] rpn_conv/3x3_p2 -> rpn/output_p2
I1022 16:26:48.853265 27659 net.cpp:150] Setting up rpn_conv/3x3_p2
I1022 16:26:48.853278 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.853282 27659 net.cpp:165] Memory required for data: 264327180
I1022 16:26:48.853289 27659 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p2
I1022 16:26:48.853298 27659 net.cpp:100] Creating Layer rpn_relu/3x3_p2
I1022 16:26:48.853302 27659 net.cpp:444] rpn_relu/3x3_p2 <- rpn/output_p2
I1022 16:26:48.853307 27659 net.cpp:405] rpn_relu/3x3_p2 -> rpn/output_p2 (in-place)
I1022 16:26:48.854332 27659 net.cpp:150] Setting up rpn_relu/3x3_p2
I1022 16:26:48.854349 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.854352 27659 net.cpp:165] Memory required for data: 265932812
I1022 16:26:48.854357 27659 layer_factory.hpp:77] Creating layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 16:26:48.854362 27659 net.cpp:100] Creating Layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 16:26:48.854367 27659 net.cpp:444] rpn/output_p2_rpn_relu/3x3_p2_0_split <- rpn/output_p2
I1022 16:26:48.854373 27659 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1022 16:26:48.854382 27659 net.cpp:418] rpn/output_p2_rpn_relu/3x3_p2_0_split -> rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1022 16:26:48.854477 27659 net.cpp:150] Setting up rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 16:26:48.854485 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.854490 27659 net.cpp:157] Top shape: 1 512 28 28 (401408)
I1022 16:26:48.854492 27659 net.cpp:165] Memory required for data: 269144076
I1022 16:26:48.854496 27659 layer_factory.hpp:77] Creating layer rpn_cls_score_p2
I1022 16:26:48.854507 27659 net.cpp:100] Creating Layer rpn_cls_score_p2
I1022 16:26:48.854512 27659 net.cpp:444] rpn_cls_score_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_0
I1022 16:26:48.854521 27659 net.cpp:418] rpn_cls_score_p2 -> rpn_cls_score_p2
I1022 16:26:48.857584 27659 net.cpp:150] Setting up rpn_cls_score_p2
I1022 16:26:48.857597 27659 net.cpp:157] Top shape: 1 22 28 28 (17248)
I1022 16:26:48.857600 27659 net.cpp:165] Memory required for data: 269213068
I1022 16:26:48.857609 27659 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p2
I1022 16:26:48.857620 27659 net.cpp:100] Creating Layer rpn_bbox_pred_p2
I1022 16:26:48.857625 27659 net.cpp:444] rpn_bbox_pred_p2 <- rpn/output_p2_rpn_relu/3x3_p2_0_split_1
I1022 16:26:48.857633 27659 net.cpp:418] rpn_bbox_pred_p2 -> rpn_bbox_pred_p2
I1022 16:26:48.860034 27659 net.cpp:150] Setting up rpn_bbox_pred_p2
I1022 16:26:48.860050 27659 net.cpp:157] Top shape: 1 44 28 28 (34496)
I1022 16:26:48.860054 27659 net.cpp:165] Memory required for data: 269351052
I1022 16:26:48.860061 27659 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p2
I1022 16:26:48.860070 27659 net.cpp:100] Creating Layer rpn_cls_score_reshape_p2
I1022 16:26:48.860074 27659 net.cpp:444] rpn_cls_score_reshape_p2 <- rpn_cls_score_p2
I1022 16:26:48.860082 27659 net.cpp:418] rpn_cls_score_reshape_p2 -> rpn_cls_score_reshape_p2
I1022 16:26:48.860141 27659 net.cpp:150] Setting up rpn_cls_score_reshape_p2
I1022 16:26:48.860148 27659 net.cpp:157] Top shape: 1 2 308 28 (17248)
I1022 16:26:48.860152 27659 net.cpp:165] Memory required for data: 269420044
I1022 16:26:48.860155 27659 layer_factory.hpp:77] Creating layer rpn_cls_prob_p2
I1022 16:26:48.860162 27659 net.cpp:100] Creating Layer rpn_cls_prob_p2
I1022 16:26:48.860165 27659 net.cpp:444] rpn_cls_prob_p2 <- rpn_cls_score_reshape_p2
I1022 16:26:48.860172 27659 net.cpp:418] rpn_cls_prob_p2 -> rpn_cls_prob_p2
I1022 16:26:48.860561 27659 net.cpp:150] Setting up rpn_cls_prob_p2
I1022 16:26:48.860570 27659 net.cpp:157] Top shape: 1 2 308 28 (17248)
I1022 16:26:48.860574 27659 net.cpp:165] Memory required for data: 269489036
I1022 16:26:48.860577 27659 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p2
I1022 16:26:48.860584 27659 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p2
I1022 16:26:48.860589 27659 net.cpp:444] rpn_cls_prob_reshape_p2 <- rpn_cls_prob_p2
I1022 16:26:48.860597 27659 net.cpp:418] rpn_cls_prob_reshape_p2 -> rpn_cls_prob_reshape_p2
I1022 16:26:48.860656 27659 net.cpp:150] Setting up rpn_cls_prob_reshape_p2
I1022 16:26:48.860663 27659 net.cpp:157] Top shape: 1 22 28 28 (17248)
I1022 16:26:48.860666 27659 net.cpp:165] Memory required for data: 269558028
I1022 16:26:48.860669 27659 layer_factory.hpp:77] Creating layer rpn_conv/3x3_p3
I1022 16:26:48.860680 27659 net.cpp:100] Creating Layer rpn_conv/3x3_p3
I1022 16:26:48.860685 27659 net.cpp:444] rpn_conv/3x3_p3 <- p3_p3_relu_0_split_1
I1022 16:26:48.860693 27659 net.cpp:418] rpn_conv/3x3_p3 -> rpn/output_p3
I1022 16:26:48.893882 27659 net.cpp:150] Setting up rpn_conv/3x3_p3
I1022 16:26:48.893898 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.893901 27659 net.cpp:165] Memory required for data: 269959436
I1022 16:26:48.893910 27659 layer_factory.hpp:77] Creating layer rpn_relu/3x3_p3
I1022 16:26:48.893918 27659 net.cpp:100] Creating Layer rpn_relu/3x3_p3
I1022 16:26:48.893921 27659 net.cpp:444] rpn_relu/3x3_p3 <- rpn/output_p3
I1022 16:26:48.893926 27659 net.cpp:405] rpn_relu/3x3_p3 -> rpn/output_p3 (in-place)
I1022 16:26:48.894191 27659 net.cpp:150] Setting up rpn_relu/3x3_p3
I1022 16:26:48.894201 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.894204 27659 net.cpp:165] Memory required for data: 270360844
I1022 16:26:48.894208 27659 layer_factory.hpp:77] Creating layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 16:26:48.894217 27659 net.cpp:100] Creating Layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 16:26:48.894222 27659 net.cpp:444] rpn/output_p3_rpn_relu/3x3_p3_0_split <- rpn/output_p3
I1022 16:26:48.894230 27659 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1022 16:26:48.894238 27659 net.cpp:418] rpn/output_p3_rpn_relu/3x3_p3_0_split -> rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1022 16:26:48.894346 27659 net.cpp:150] Setting up rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 16:26:48.894354 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.894357 27659 net.cpp:157] Top shape: 1 512 14 14 (100352)
I1022 16:26:48.894361 27659 net.cpp:165] Memory required for data: 271163660
I1022 16:26:48.894363 27659 layer_factory.hpp:77] Creating layer rpn_cls_score_p3
I1022 16:26:48.894376 27659 net.cpp:100] Creating Layer rpn_cls_score_p3
I1022 16:26:48.894381 27659 net.cpp:444] rpn_cls_score_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_0
I1022 16:26:48.894388 27659 net.cpp:418] rpn_cls_score_p3 -> rpn_cls_score_p3
I1022 16:26:48.896703 27659 net.cpp:150] Setting up rpn_cls_score_p3
I1022 16:26:48.896716 27659 net.cpp:157] Top shape: 1 22 14 14 (4312)
I1022 16:26:48.896719 27659 net.cpp:165] Memory required for data: 271180908
I1022 16:26:48.896726 27659 layer_factory.hpp:77] Creating layer rpn_bbox_pred_p3
I1022 16:26:48.896742 27659 net.cpp:100] Creating Layer rpn_bbox_pred_p3
I1022 16:26:48.896747 27659 net.cpp:444] rpn_bbox_pred_p3 <- rpn/output_p3_rpn_relu/3x3_p3_0_split_1
I1022 16:26:48.896757 27659 net.cpp:418] rpn_bbox_pred_p3 -> rpn_bbox_pred_p3
I1022 16:26:48.900305 27659 net.cpp:150] Setting up rpn_bbox_pred_p3
I1022 16:26:48.900319 27659 net.cpp:157] Top shape: 1 44 14 14 (8624)
I1022 16:26:48.900323 27659 net.cpp:165] Memory required for data: 271215404
I1022 16:26:48.900338 27659 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_p3
I1022 16:26:48.900348 27659 net.cpp:100] Creating Layer rpn_cls_score_reshape_p3
I1022 16:26:48.900352 27659 net.cpp:444] rpn_cls_score_reshape_p3 <- rpn_cls_score_p3
I1022 16:26:48.900359 27659 net.cpp:418] rpn_cls_score_reshape_p3 -> rpn_cls_score_reshape_p3
I1022 16:26:48.900421 27659 net.cpp:150] Setting up rpn_cls_score_reshape_p3
I1022 16:26:48.900429 27659 net.cpp:157] Top shape: 1 2 154 14 (4312)
I1022 16:26:48.900432 27659 net.cpp:165] Memory required for data: 271232652
I1022 16:26:48.900435 27659 layer_factory.hpp:77] Creating layer rpn_cls_prob_p3
I1022 16:26:48.900442 27659 net.cpp:100] Creating Layer rpn_cls_prob_p3
I1022 16:26:48.900445 27659 net.cpp:444] rpn_cls_prob_p3 <- rpn_cls_score_reshape_p3
I1022 16:26:48.900454 27659 net.cpp:418] rpn_cls_prob_p3 -> rpn_cls_prob_p3
I1022 16:26:48.900889 27659 net.cpp:150] Setting up rpn_cls_prob_p3
I1022 16:26:48.900900 27659 net.cpp:157] Top shape: 1 2 154 14 (4312)
I1022 16:26:48.900903 27659 net.cpp:165] Memory required for data: 271249900
I1022 16:26:48.900907 27659 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape_p3
I1022 16:26:48.900919 27659 net.cpp:100] Creating Layer rpn_cls_prob_reshape_p3
I1022 16:26:48.900923 27659 net.cpp:444] rpn_cls_prob_reshape_p3 <- rpn_cls_prob_p3
I1022 16:26:48.900930 27659 net.cpp:418] rpn_cls_prob_reshape_p3 -> rpn_cls_prob_reshape_p3
I1022 16:26:48.900992 27659 net.cpp:150] Setting up rpn_cls_prob_reshape_p3
I1022 16:26:48.901000 27659 net.cpp:157] Top shape: 1 22 14 14 (4312)
I1022 16:26:48.901002 27659 net.cpp:165] Memory required for data: 271267148
I1022 16:26:48.901005 27659 layer_factory.hpp:77] Creating layer proposal
I1022 16:26:48.901887 27659 net.cpp:100] Creating Layer proposal
I1022 16:26:48.901899 27659 net.cpp:444] proposal <- im_info
I1022 16:26:48.901906 27659 net.cpp:444] proposal <- rpn_bbox_pred_p2
I1022 16:26:48.901909 27659 net.cpp:444] proposal <- rpn_bbox_pred_p3
I1022 16:26:48.901913 27659 net.cpp:444] proposal <- rpn_cls_prob_reshape_p2
I1022 16:26:48.901917 27659 net.cpp:444] proposal <- rpn_cls_prob_reshape_p3
I1022 16:26:48.901924 27659 net.cpp:418] proposal -> rpn_rois_p2
I1022 16:26:48.901932 27659 net.cpp:418] proposal -> rpn_rois_p3
I1022 16:26:48.902865 27659 net.cpp:150] Setting up proposal
I1022 16:26:48.902878 27659 net.cpp:157] Top shape: 1 5 (5)
I1022 16:26:48.902884 27659 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 16:26:48.902885 27659 net.cpp:165] Memory required for data: 271267172
I1022 16:26:48.902894 27659 layer_factory.hpp:77] Creating layer rpn_rois_p2_proposal_0_split
I1022 16:26:48.902900 27659 net.cpp:100] Creating Layer rpn_rois_p2_proposal_0_split
I1022 16:26:48.902904 27659 net.cpp:444] rpn_rois_p2_proposal_0_split <- rpn_rois_p2
I1022 16:26:48.902910 27659 net.cpp:418] rpn_rois_p2_proposal_0_split -> rpn_rois_p2_proposal_0_split_0
I1022 16:26:48.902918 27659 net.cpp:418] rpn_rois_p2_proposal_0_split -> rpn_rois_p2_proposal_0_split_1
I1022 16:26:48.903002 27659 net.cpp:150] Setting up rpn_rois_p2_proposal_0_split
I1022 16:26:48.903008 27659 net.cpp:157] Top shape: 1 5 (5)
I1022 16:26:48.903012 27659 net.cpp:157] Top shape: 1 5 (5)
I1022 16:26:48.903014 27659 net.cpp:165] Memory required for data: 271267212
I1022 16:26:48.903017 27659 layer_factory.hpp:77] Creating layer rpn_rois_p3_proposal_1_split
I1022 16:26:48.903023 27659 net.cpp:100] Creating Layer rpn_rois_p3_proposal_1_split
I1022 16:26:48.903025 27659 net.cpp:444] rpn_rois_p3_proposal_1_split <- rpn_rois_p3
I1022 16:26:48.903031 27659 net.cpp:418] rpn_rois_p3_proposal_1_split -> rpn_rois_p3_proposal_1_split_0
I1022 16:26:48.903038 27659 net.cpp:418] rpn_rois_p3_proposal_1_split -> rpn_rois_p3_proposal_1_split_1
I1022 16:26:48.903120 27659 net.cpp:150] Setting up rpn_rois_p3_proposal_1_split
I1022 16:26:48.903127 27659 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 16:26:48.903131 27659 net.cpp:157] Top shape: 1 1 1 1 (1)
I1022 16:26:48.903134 27659 net.cpp:165] Memory required for data: 271267220
I1022 16:26:48.903137 27659 layer_factory.hpp:77] Creating layer conv_new_p2
I1022 16:26:48.903146 27659 net.cpp:100] Creating Layer conv_new_p2
I1022 16:26:48.903151 27659 net.cpp:444] conv_new_p2 <- p2_p2_relu_0_split_1
I1022 16:26:48.903156 27659 net.cpp:418] conv_new_p2 -> conv_new_p2
I1022 16:26:48.915591 27659 net.cpp:150] Setting up conv_new_p2
I1022 16:26:48.915606 27659 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 16:26:48.915609 27659 net.cpp:165] Memory required for data: 274478484
I1022 16:26:48.915621 27659 layer_factory.hpp:77] Creating layer conv_new_p2_relu
I1022 16:26:48.915629 27659 net.cpp:100] Creating Layer conv_new_p2_relu
I1022 16:26:48.915633 27659 net.cpp:444] conv_new_p2_relu <- conv_new_p2
I1022 16:26:48.915638 27659 net.cpp:405] conv_new_p2_relu -> conv_new_p2 (in-place)
I1022 16:26:48.916715 27659 net.cpp:150] Setting up conv_new_p2_relu
I1022 16:26:48.916730 27659 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 16:26:48.916733 27659 net.cpp:165] Memory required for data: 277689748
I1022 16:26:48.916745 27659 layer_factory.hpp:77] Creating layer conv_new_p2_conv_new_p2_relu_0_split
I1022 16:26:48.916752 27659 net.cpp:100] Creating Layer conv_new_p2_conv_new_p2_relu_0_split
I1022 16:26:48.916756 27659 net.cpp:444] conv_new_p2_conv_new_p2_relu_0_split <- conv_new_p2
I1022 16:26:48.916764 27659 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_0
I1022 16:26:48.916771 27659 net.cpp:418] conv_new_p2_conv_new_p2_relu_0_split -> conv_new_p2_conv_new_p2_relu_0_split_1
I1022 16:26:48.916868 27659 net.cpp:150] Setting up conv_new_p2_conv_new_p2_relu_0_split
I1022 16:26:48.916877 27659 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 16:26:48.916880 27659 net.cpp:157] Top shape: 1 1024 28 28 (802816)
I1022 16:26:48.916883 27659 net.cpp:165] Memory required for data: 284112276
I1022 16:26:48.916887 27659 layer_factory.hpp:77] Creating layer rfcn_cls_p2
I1022 16:26:48.916898 27659 net.cpp:100] Creating Layer rfcn_cls_p2
I1022 16:26:48.916903 27659 net.cpp:444] rfcn_cls_p2 <- conv_new_p2_conv_new_p2_relu_0_split_0
I1022 16:26:48.916910 27659 net.cpp:418] rfcn_cls_p2 -> rfcn_cls_p2
I1022 16:26:48.920392 27659 net.cpp:150] Setting up rfcn_cls_p2
I1022 16:26:48.920404 27659 net.cpp:157] Top shape: 1 98 28 28 (76832)
I1022 16:26:48.920408 27659 net.cpp:165] Memory required for data: 284419604
I1022 16:26:48.920423 27659 layer_factory.hpp:77] Creating layer rfcn_bbox_p2
I1022 16:26:48.920435 27659 net.cpp:100] Creating Layer rfcn_bbox_p2
I1022 16:26:48.920440 27659 net.cpp:444] rfcn_bbox_p2 <- conv_new_p2_conv_new_p2_relu_0_split_1
I1022 16:26:48.920449 27659 net.cpp:418] rfcn_bbox_p2 -> rfcn_bbox_p2
I1022 16:26:48.930611 27659 net.cpp:150] Setting up rfcn_bbox_p2
I1022 16:26:48.930626 27659 net.cpp:157] Top shape: 1 392 28 28 (307328)
I1022 16:26:48.930629 27659 net.cpp:165] Memory required for data: 285648916
I1022 16:26:48.930647 27659 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p2
I1022 16:26:48.930657 27659 net.cpp:100] Creating Layer psroipooled_cls_rois_p2
I1022 16:26:48.930662 27659 net.cpp:444] psroipooled_cls_rois_p2 <- rfcn_cls_p2
I1022 16:26:48.930667 27659 net.cpp:444] psroipooled_cls_rois_p2 <- rpn_rois_p2_proposal_0_split_0
I1022 16:26:48.930673 27659 net.cpp:418] psroipooled_cls_rois_p2 -> psroipooled_cls_rois_p2
I1022 16:26:48.930685 27659 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1022 16:26:48.930783 27659 net.cpp:150] Setting up psroipooled_cls_rois_p2
I1022 16:26:48.930790 27659 net.cpp:157] Top shape: 1 2 7 7 (98)
I1022 16:26:48.930794 27659 net.cpp:165] Memory required for data: 285649308
I1022 16:26:48.930797 27659 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p2
I1022 16:26:48.930806 27659 net.cpp:100] Creating Layer ave_cls_score_rois_p2
I1022 16:26:48.930811 27659 net.cpp:444] ave_cls_score_rois_p2 <- psroipooled_cls_rois_p2
I1022 16:26:48.930817 27659 net.cpp:418] ave_cls_score_rois_p2 -> cls_score_p2
I1022 16:26:48.931138 27659 net.cpp:150] Setting up ave_cls_score_rois_p2
I1022 16:26:48.931147 27659 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 16:26:48.931150 27659 net.cpp:165] Memory required for data: 285649316
I1022 16:26:48.931164 27659 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p2
I1022 16:26:48.931170 27659 net.cpp:100] Creating Layer psroipooled_loc_rois_p2
I1022 16:26:48.931174 27659 net.cpp:444] psroipooled_loc_rois_p2 <- rfcn_bbox_p2
I1022 16:26:48.931180 27659 net.cpp:444] psroipooled_loc_rois_p2 <- rpn_rois_p2_proposal_0_split_1
I1022 16:26:48.931186 27659 net.cpp:418] psroipooled_loc_rois_p2 -> psroipooled_loc_rois_p2
I1022 16:26:48.931193 27659 psroi_pooling_layer.cpp:26] Spatial scale: 0.125
I1022 16:26:48.931282 27659 net.cpp:150] Setting up psroipooled_loc_rois_p2
I1022 16:26:48.931289 27659 net.cpp:157] Top shape: 1 8 7 7 (392)
I1022 16:26:48.931293 27659 net.cpp:165] Memory required for data: 285650884
I1022 16:26:48.931295 27659 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p2
I1022 16:26:48.931300 27659 net.cpp:100] Creating Layer ave_bbox_pred_rois_p2
I1022 16:26:48.931306 27659 net.cpp:444] ave_bbox_pred_rois_p2 <- psroipooled_loc_rois_p2
I1022 16:26:48.931313 27659 net.cpp:418] ave_bbox_pred_rois_p2 -> bbox_pred_pre_p2
I1022 16:26:48.931607 27659 net.cpp:150] Setting up ave_bbox_pred_rois_p2
I1022 16:26:48.931617 27659 net.cpp:157] Top shape: 1 8 1 1 (8)
I1022 16:26:48.931620 27659 net.cpp:165] Memory required for data: 285650916
I1022 16:26:48.931633 27659 layer_factory.hpp:77] Creating layer conv_new_p3
I1022 16:26:48.931644 27659 net.cpp:100] Creating Layer conv_new_p3
I1022 16:26:48.931648 27659 net.cpp:444] conv_new_p3 <- p3_p3_relu_0_split_2
I1022 16:26:48.931658 27659 net.cpp:418] conv_new_p3 -> conv_new_p3
I1022 16:26:48.941568 27659 net.cpp:150] Setting up conv_new_p3
I1022 16:26:48.941582 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.941596 27659 net.cpp:165] Memory required for data: 286453732
I1022 16:26:48.941603 27659 layer_factory.hpp:77] Creating layer conv_new_p3_relu
I1022 16:26:48.941610 27659 net.cpp:100] Creating Layer conv_new_p3_relu
I1022 16:26:48.941614 27659 net.cpp:444] conv_new_p3_relu <- conv_new_p3
I1022 16:26:48.941622 27659 net.cpp:405] conv_new_p3_relu -> conv_new_p3 (in-place)
I1022 16:26:48.944463 27659 net.cpp:150] Setting up conv_new_p3_relu
I1022 16:26:48.944476 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.944491 27659 net.cpp:165] Memory required for data: 287256548
I1022 16:26:48.944495 27659 layer_factory.hpp:77] Creating layer conv_new_p3_conv_new_p3_relu_0_split
I1022 16:26:48.944504 27659 net.cpp:100] Creating Layer conv_new_p3_conv_new_p3_relu_0_split
I1022 16:26:48.944509 27659 net.cpp:444] conv_new_p3_conv_new_p3_relu_0_split <- conv_new_p3
I1022 16:26:48.944515 27659 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_0
I1022 16:26:48.944523 27659 net.cpp:418] conv_new_p3_conv_new_p3_relu_0_split -> conv_new_p3_conv_new_p3_relu_0_split_1
I1022 16:26:48.944659 27659 net.cpp:150] Setting up conv_new_p3_conv_new_p3_relu_0_split
I1022 16:26:48.944670 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.944674 27659 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I1022 16:26:48.944677 27659 net.cpp:165] Memory required for data: 288862180
I1022 16:26:48.944681 27659 layer_factory.hpp:77] Creating layer rfcn_cls_p3
I1022 16:26:48.944692 27659 net.cpp:100] Creating Layer rfcn_cls_p3
I1022 16:26:48.944699 27659 net.cpp:444] rfcn_cls_p3 <- conv_new_p3_conv_new_p3_relu_0_split_0
I1022 16:26:48.944705 27659 net.cpp:418] rfcn_cls_p3 -> rfcn_cls_p3
I1022 16:26:48.948014 27659 net.cpp:150] Setting up rfcn_cls_p3
I1022 16:26:48.948029 27659 net.cpp:157] Top shape: 1 98 14 14 (19208)
I1022 16:26:48.948042 27659 net.cpp:165] Memory required for data: 288939012
I1022 16:26:48.948050 27659 layer_factory.hpp:77] Creating layer rfcn_bbox_p3
I1022 16:26:48.948061 27659 net.cpp:100] Creating Layer rfcn_bbox_p3
I1022 16:26:48.948066 27659 net.cpp:444] rfcn_bbox_p3 <- conv_new_p3_conv_new_p3_relu_0_split_1
I1022 16:26:48.948074 27659 net.cpp:418] rfcn_bbox_p3 -> rfcn_bbox_p3
I1022 16:26:48.956671 27659 net.cpp:150] Setting up rfcn_bbox_p3
I1022 16:26:48.956687 27659 net.cpp:157] Top shape: 1 392 14 14 (76832)
I1022 16:26:48.956701 27659 net.cpp:165] Memory required for data: 289246340
I1022 16:26:48.956709 27659 layer_factory.hpp:77] Creating layer psroipooled_cls_rois_p3
I1022 16:26:48.956717 27659 net.cpp:100] Creating Layer psroipooled_cls_rois_p3
I1022 16:26:48.956720 27659 net.cpp:444] psroipooled_cls_rois_p3 <- rfcn_cls_p3
I1022 16:26:48.956725 27659 net.cpp:444] psroipooled_cls_rois_p3 <- rpn_rois_p3_proposal_1_split_0
I1022 16:26:48.956733 27659 net.cpp:418] psroipooled_cls_rois_p3 -> psroipooled_cls_rois_p3
I1022 16:26:48.956743 27659 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1022 16:26:48.956845 27659 net.cpp:150] Setting up psroipooled_cls_rois_p3
I1022 16:26:48.956854 27659 net.cpp:157] Top shape: 1 2 7 7 (98)
I1022 16:26:48.956857 27659 net.cpp:165] Memory required for data: 289246732
I1022 16:26:48.956861 27659 layer_factory.hpp:77] Creating layer ave_cls_score_rois_p3
I1022 16:26:48.956867 27659 net.cpp:100] Creating Layer ave_cls_score_rois_p3
I1022 16:26:48.956872 27659 net.cpp:444] ave_cls_score_rois_p3 <- psroipooled_cls_rois_p3
I1022 16:26:48.956881 27659 net.cpp:418] ave_cls_score_rois_p3 -> cls_score_p3
I1022 16:26:48.957208 27659 net.cpp:150] Setting up ave_cls_score_rois_p3
I1022 16:26:48.957217 27659 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 16:26:48.957221 27659 net.cpp:165] Memory required for data: 289246740
I1022 16:26:48.957233 27659 layer_factory.hpp:77] Creating layer psroipooled_loc_rois_p3
I1022 16:26:48.957239 27659 net.cpp:100] Creating Layer psroipooled_loc_rois_p3
I1022 16:26:48.957243 27659 net.cpp:444] psroipooled_loc_rois_p3 <- rfcn_bbox_p3
I1022 16:26:48.957248 27659 net.cpp:444] psroipooled_loc_rois_p3 <- rpn_rois_p3_proposal_1_split_1
I1022 16:26:48.957257 27659 net.cpp:418] psroipooled_loc_rois_p3 -> psroipooled_loc_rois_p3
I1022 16:26:48.957264 27659 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I1022 16:26:48.957353 27659 net.cpp:150] Setting up psroipooled_loc_rois_p3
I1022 16:26:48.957360 27659 net.cpp:157] Top shape: 1 8 7 7 (392)
I1022 16:26:48.957363 27659 net.cpp:165] Memory required for data: 289248308
I1022 16:26:48.957367 27659 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois_p3
I1022 16:26:48.957372 27659 net.cpp:100] Creating Layer ave_bbox_pred_rois_p3
I1022 16:26:48.957376 27659 net.cpp:444] ave_bbox_pred_rois_p3 <- psroipooled_loc_rois_p3
I1022 16:26:48.957383 27659 net.cpp:418] ave_bbox_pred_rois_p3 -> bbox_pred_pre_p3
I1022 16:26:48.957684 27659 net.cpp:150] Setting up ave_bbox_pred_rois_p3
I1022 16:26:48.957702 27659 net.cpp:157] Top shape: 1 8 1 1 (8)
I1022 16:26:48.957705 27659 net.cpp:165] Memory required for data: 289248340
I1022 16:26:48.957708 27659 layer_factory.hpp:77] Creating layer cls_prob_pre_p2
I1022 16:26:48.957715 27659 net.cpp:100] Creating Layer cls_prob_pre_p2
I1022 16:26:48.957718 27659 net.cpp:444] cls_prob_pre_p2 <- cls_score_p2
I1022 16:26:48.957726 27659 net.cpp:418] cls_prob_pre_p2 -> cls_prob_pre_p2
I1022 16:26:48.960449 27659 net.cpp:150] Setting up cls_prob_pre_p2
I1022 16:26:48.960464 27659 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 16:26:48.960469 27659 net.cpp:165] Memory required for data: 289248348
I1022 16:26:48.960480 27659 layer_factory.hpp:77] Creating layer cls_prob_pre_p3
I1022 16:26:48.960490 27659 net.cpp:100] Creating Layer cls_prob_pre_p3
I1022 16:26:48.960495 27659 net.cpp:444] cls_prob_pre_p3 <- cls_score_p3
I1022 16:26:48.960502 27659 net.cpp:418] cls_prob_pre_p3 -> cls_prob_pre_p3
I1022 16:26:48.960973 27659 net.cpp:150] Setting up cls_prob_pre_p3
I1022 16:26:48.960990 27659 net.cpp:157] Top shape: 1 2 1 1 (2)
I1022 16:26:48.960994 27659 net.cpp:165] Memory required for data: 289248356
I1022 16:26:48.960997 27659 layer_factory.hpp:77] Creating layer cls_prob_reshape_p2
I1022 16:26:48.961004 27659 net.cpp:100] Creating Layer cls_prob_reshape_p2
I1022 16:26:48.961007 27659 net.cpp:444] cls_prob_reshape_p2 <- cls_prob_pre_p2
I1022 16:26:48.961026 27659 net.cpp:418] cls_prob_reshape_p2 -> cls_prob_p2
I1022 16:26:48.961089 27659 net.cpp:150] Setting up cls_prob_reshape_p2
I1022 16:26:48.961097 27659 net.cpp:157] Top shape: 1 2 (2)
I1022 16:26:48.961099 27659 net.cpp:165] Memory required for data: 289248364
I1022 16:26:48.961102 27659 layer_factory.hpp:77] Creating layer cls_prob_reshape_p3
I1022 16:26:48.961109 27659 net.cpp:100] Creating Layer cls_prob_reshape_p3
I1022 16:26:48.961115 27659 net.cpp:444] cls_prob_reshape_p3 <- cls_prob_pre_p3
I1022 16:26:48.961119 27659 net.cpp:418] cls_prob_reshape_p3 -> cls_prob_p3
I1022 16:26:48.961170 27659 net.cpp:150] Setting up cls_prob_reshape_p3
I1022 16:26:48.961177 27659 net.cpp:157] Top shape: 1 2 (2)
I1022 16:26:48.961179 27659 net.cpp:165] Memory required for data: 289248372
I1022 16:26:48.961182 27659 layer_factory.hpp:77] Creating layer bbox_pred_reshape_p2
I1022 16:26:48.961189 27659 net.cpp:100] Creating Layer bbox_pred_reshape_p2
I1022 16:26:48.961191 27659 net.cpp:444] bbox_pred_reshape_p2 <- bbox_pred_pre_p2
I1022 16:26:48.961199 27659 net.cpp:418] bbox_pred_reshape_p2 -> bbox_pred_p2
I1022 16:26:48.961246 27659 net.cpp:150] Setting up bbox_pred_reshape_p2
I1022 16:26:48.961252 27659 net.cpp:157] Top shape: 1 8 (8)
I1022 16:26:48.961256 27659 net.cpp:165] Memory required for data: 289248404
I1022 16:26:48.961259 27659 layer_factory.hpp:77] Creating layer bbox_pred_reshape_p3
I1022 16:26:48.961266 27659 net.cpp:100] Creating Layer bbox_pred_reshape_p3
I1022 16:26:48.961271 27659 net.cpp:444] bbox_pred_reshape_p3 <- bbox_pred_pre_p3
I1022 16:26:48.961275 27659 net.cpp:418] bbox_pred_reshape_p3 -> bbox_pred_p3
I1022 16:26:48.961323 27659 net.cpp:150] Setting up bbox_pred_reshape_p3
I1022 16:26:48.961328 27659 net.cpp:157] Top shape: 1 8 (8)
I1022 16:26:48.961333 27659 net.cpp:165] Memory required for data: 289248436
I1022 16:26:48.961335 27659 net.cpp:228] bbox_pred_reshape_p3 does not need backward computation.
I1022 16:26:48.961338 27659 net.cpp:228] bbox_pred_reshape_p2 does not need backward computation.
I1022 16:26:48.961342 27659 net.cpp:228] cls_prob_reshape_p3 does not need backward computation.
I1022 16:26:48.961346 27659 net.cpp:228] cls_prob_reshape_p2 does not need backward computation.
I1022 16:26:48.961349 27659 net.cpp:228] cls_prob_pre_p3 does not need backward computation.
I1022 16:26:48.961352 27659 net.cpp:228] cls_prob_pre_p2 does not need backward computation.
I1022 16:26:48.961355 27659 net.cpp:228] ave_bbox_pred_rois_p3 does not need backward computation.
I1022 16:26:48.961366 27659 net.cpp:228] psroipooled_loc_rois_p3 does not need backward computation.
I1022 16:26:48.961370 27659 net.cpp:228] ave_cls_score_rois_p3 does not need backward computation.
I1022 16:26:48.961374 27659 net.cpp:228] psroipooled_cls_rois_p3 does not need backward computation.
I1022 16:26:48.961376 27659 net.cpp:228] rfcn_bbox_p3 does not need backward computation.
I1022 16:26:48.961380 27659 net.cpp:228] rfcn_cls_p3 does not need backward computation.
I1022 16:26:48.961385 27659 net.cpp:228] conv_new_p3_conv_new_p3_relu_0_split does not need backward computation.
I1022 16:26:48.961387 27659 net.cpp:228] conv_new_p3_relu does not need backward computation.
I1022 16:26:48.961390 27659 net.cpp:228] conv_new_p3 does not need backward computation.
I1022 16:26:48.961393 27659 net.cpp:228] ave_bbox_pred_rois_p2 does not need backward computation.
I1022 16:26:48.961397 27659 net.cpp:228] psroipooled_loc_rois_p2 does not need backward computation.
I1022 16:26:48.961400 27659 net.cpp:228] ave_cls_score_rois_p2 does not need backward computation.
I1022 16:26:48.961405 27659 net.cpp:228] psroipooled_cls_rois_p2 does not need backward computation.
I1022 16:26:48.961408 27659 net.cpp:228] rfcn_bbox_p2 does not need backward computation.
I1022 16:26:48.961412 27659 net.cpp:228] rfcn_cls_p2 does not need backward computation.
I1022 16:26:48.961416 27659 net.cpp:228] conv_new_p2_conv_new_p2_relu_0_split does not need backward computation.
I1022 16:26:48.961418 27659 net.cpp:228] conv_new_p2_relu does not need backward computation.
I1022 16:26:48.961421 27659 net.cpp:228] conv_new_p2 does not need backward computation.
I1022 16:26:48.961426 27659 net.cpp:228] rpn_rois_p3_proposal_1_split does not need backward computation.
I1022 16:26:48.961431 27659 net.cpp:228] rpn_rois_p2_proposal_0_split does not need backward computation.
I1022 16:26:48.961438 27659 net.cpp:228] proposal does not need backward computation.
I1022 16:26:48.961444 27659 net.cpp:228] rpn_cls_prob_reshape_p3 does not need backward computation.
I1022 16:26:48.961447 27659 net.cpp:228] rpn_cls_prob_p3 does not need backward computation.
I1022 16:26:48.961452 27659 net.cpp:228] rpn_cls_score_reshape_p3 does not need backward computation.
I1022 16:26:48.961454 27659 net.cpp:228] rpn_bbox_pred_p3 does not need backward computation.
I1022 16:26:48.961458 27659 net.cpp:228] rpn_cls_score_p3 does not need backward computation.
I1022 16:26:48.961462 27659 net.cpp:228] rpn/output_p3_rpn_relu/3x3_p3_0_split does not need backward computation.
I1022 16:26:48.961465 27659 net.cpp:228] rpn_relu/3x3_p3 does not need backward computation.
I1022 16:26:48.961468 27659 net.cpp:228] rpn_conv/3x3_p3 does not need backward computation.
I1022 16:26:48.961472 27659 net.cpp:228] rpn_cls_prob_reshape_p2 does not need backward computation.
I1022 16:26:48.961475 27659 net.cpp:228] rpn_cls_prob_p2 does not need backward computation.
I1022 16:26:48.961479 27659 net.cpp:228] rpn_cls_score_reshape_p2 does not need backward computation.
I1022 16:26:48.961484 27659 net.cpp:228] rpn_bbox_pred_p2 does not need backward computation.
I1022 16:26:48.961490 27659 net.cpp:228] rpn_cls_score_p2 does not need backward computation.
I1022 16:26:48.961494 27659 net.cpp:228] rpn/output_p2_rpn_relu/3x3_p2_0_split does not need backward computation.
I1022 16:26:48.961498 27659 net.cpp:228] rpn_relu/3x3_p2 does not need backward computation.
I1022 16:26:48.961501 27659 net.cpp:228] rpn_conv/3x3_p2 does not need backward computation.
I1022 16:26:48.961506 27659 net.cpp:228] p2_p2_relu_0_split does not need backward computation.
I1022 16:26:48.961510 27659 net.cpp:228] p2_relu does not need backward computation.
I1022 16:26:48.961514 27659 net.cpp:228] p2 does not need backward computation.
I1022 16:26:48.961519 27659 net.cpp:228] bn_eltwise_2_2_scale does not need backward computation.
I1022 16:26:48.961524 27659 net.cpp:228] bn_eltwise_2_2_bn does not need backward computation.
I1022 16:26:48.961527 27659 net.cpp:228] bn_eltwise_2_2_conv does not need backward computation.
I1022 16:26:48.961531 27659 net.cpp:228] bn_eltwise_2_1_ReLU does not need backward computation.
I1022 16:26:48.961535 27659 net.cpp:228] bn_eltwise_2_1_scale does not need backward computation.
I1022 16:26:48.961539 27659 net.cpp:228] bn_eltwise_2_1_bn does not need backward computation.
I1022 16:26:48.961541 27659 net.cpp:228] bn_eltwise_2_1_conv does not need backward computation.
I1022 16:26:48.961544 27659 net.cpp:228] bnp3_ReLU does not need backward computation.
I1022 16:26:48.961549 27659 net.cpp:228] bnp3_scale does not need backward computation.
I1022 16:26:48.961551 27659 net.cpp:228] bnp3_bn does not need backward computation.
I1022 16:26:48.961555 27659 net.cpp:228] bnp3_conv does not need backward computation.
I1022 16:26:48.961558 27659 net.cpp:228] skip_eltwise2_eltwise_bnc3_bnp3_0_split does not need backward computation.
I1022 16:26:48.961561 27659 net.cpp:228] eltwise_bnc3_bnp3 does not need backward computation.
I1022 16:26:48.961566 27659 net.cpp:228] upP3 does not need backward computation.
I1022 16:26:48.961570 27659 net.cpp:228] newC3 does not need backward computation.
I1022 16:26:48.961575 27659 net.cpp:228] p3_p3_relu_0_split does not need backward computation.
I1022 16:26:48.961578 27659 net.cpp:228] p3_relu does not need backward computation.
I1022 16:26:48.961581 27659 net.cpp:228] p3 does not need backward computation.
I1022 16:26:48.961586 27659 net.cpp:228] bn_eltwise_1_2_scale does not need backward computation.
I1022 16:26:48.961589 27659 net.cpp:228] bn_eltwise_1_2_bn does not need backward computation.
I1022 16:26:48.961592 27659 net.cpp:228] bn_eltwise_1_2_conv does not need backward computation.
I1022 16:26:48.961596 27659 net.cpp:228] bn_eltwise_1_1_ReLU does not need backward computation.
I1022 16:26:48.961601 27659 net.cpp:228] bn_eltwise_1_1_scale does not need backward computation.
I1022 16:26:48.961603 27659 net.cpp:228] bn_eltwise_1_1_bn does not need backward computation.
I1022 16:26:48.961606 27659 net.cpp:228] bn_eltwise_1_1_conv does not need backward computation.
I1022 16:26:48.961611 27659 net.cpp:228] bnp4_ReLU does not need backward computation.
I1022 16:26:48.961614 27659 net.cpp:228] bnp4_scale does not need backward computation.
I1022 16:26:48.961617 27659 net.cpp:228] bnp4_bn does not need backward computation.
I1022 16:26:48.961621 27659 net.cpp:228] bnp4_conv does not need backward computation.
I1022 16:26:48.961624 27659 net.cpp:228] skip_eltwise1_eltwise_bnc4_bnp4_0_split does not need backward computation.
I1022 16:26:48.961628 27659 net.cpp:228] eltwise_bnc4_bnp4 does not need backward computation.
I1022 16:26:48.961634 27659 net.cpp:228] newC4 does not need backward computation.
I1022 16:26:48.961638 27659 net.cpp:228] upP4 does not need backward computation.
I1022 16:26:48.961642 27659 net.cpp:228] res5c_relu does not need backward computation.
I1022 16:26:48.961645 27659 net.cpp:228] res5c does not need backward computation.
I1022 16:26:48.961649 27659 net.cpp:228] scale5c_branch2c does not need backward computation.
I1022 16:26:48.961653 27659 net.cpp:228] bn5c_branch2c does not need backward computation.
I1022 16:26:48.961657 27659 net.cpp:228] res5c_branch2c does not need backward computation.
I1022 16:26:48.961660 27659 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I1022 16:26:48.961663 27659 net.cpp:228] scale5c_branch2b does not need backward computation.
I1022 16:26:48.961666 27659 net.cpp:228] bn5c_branch2b does not need backward computation.
I1022 16:26:48.961670 27659 net.cpp:228] res5c_branch2b does not need backward computation.
I1022 16:26:48.961673 27659 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I1022 16:26:48.961676 27659 net.cpp:228] scale5c_branch2a does not need backward computation.
I1022 16:26:48.961680 27659 net.cpp:228] bn5c_branch2a does not need backward computation.
I1022 16:26:48.961683 27659 net.cpp:228] res5c_branch2a does not need backward computation.
I1022 16:26:48.961688 27659 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I1022 16:26:48.961691 27659 net.cpp:228] res5b_relu does not need backward computation.
I1022 16:26:48.961694 27659 net.cpp:228] res5b does not need backward computation.
I1022 16:26:48.961699 27659 net.cpp:228] scale5b_branch2c does not need backward computation.
I1022 16:26:48.961702 27659 net.cpp:228] bn5b_branch2c does not need backward computation.
I1022 16:26:48.961706 27659 net.cpp:228] res5b_branch2c does not need backward computation.
I1022 16:26:48.961709 27659 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I1022 16:26:48.961714 27659 net.cpp:228] scale5b_branch2b does not need backward computation.
I1022 16:26:48.961717 27659 net.cpp:228] bn5b_branch2b does not need backward computation.
I1022 16:26:48.961720 27659 net.cpp:228] res5b_branch2b does not need backward computation.
I1022 16:26:48.961724 27659 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I1022 16:26:48.961727 27659 net.cpp:228] scale5b_branch2a does not need backward computation.
I1022 16:26:48.961731 27659 net.cpp:228] bn5b_branch2a does not need backward computation.
I1022 16:26:48.961735 27659 net.cpp:228] res5b_branch2a does not need backward computation.
I1022 16:26:48.961738 27659 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I1022 16:26:48.961741 27659 net.cpp:228] res5a_relu does not need backward computation.
I1022 16:26:48.961745 27659 net.cpp:228] res5a does not need backward computation.
I1022 16:26:48.961750 27659 net.cpp:228] scale5a_branch2c does not need backward computation.
I1022 16:26:48.961753 27659 net.cpp:228] bn5a_branch2c does not need backward computation.
I1022 16:26:48.961757 27659 net.cpp:228] res5a_branch2c does not need backward computation.
I1022 16:26:48.961760 27659 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I1022 16:26:48.961763 27659 net.cpp:228] scale5a_branch2b does not need backward computation.
I1022 16:26:48.961766 27659 net.cpp:228] bn5a_branch2b does not need backward computation.
I1022 16:26:48.961771 27659 net.cpp:228] res5a_branch2b does not need backward computation.
I1022 16:26:48.961773 27659 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I1022 16:26:48.961777 27659 net.cpp:228] scale5a_branch2a does not need backward computation.
I1022 16:26:48.961781 27659 net.cpp:228] bn5a_branch2a does not need backward computation.
I1022 16:26:48.961784 27659 net.cpp:228] res5a_branch2a does not need backward computation.
I1022 16:26:48.961787 27659 net.cpp:228] scale5a_branch1 does not need backward computation.
I1022 16:26:48.961791 27659 net.cpp:228] bn5a_branch1 does not need backward computation.
I1022 16:26:48.961794 27659 net.cpp:228] res5a_branch1 does not need backward computation.
I1022 16:26:48.961798 27659 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I1022 16:26:48.961802 27659 net.cpp:228] res4f_relu does not need backward computation.
I1022 16:26:48.961805 27659 net.cpp:228] res4f does not need backward computation.
I1022 16:26:48.961809 27659 net.cpp:228] scale4f_branch2c does not need backward computation.
I1022 16:26:48.961813 27659 net.cpp:228] bn4f_branch2c does not need backward computation.
I1022 16:26:48.961817 27659 net.cpp:228] res4f_branch2c does not need backward computation.
I1022 16:26:48.961819 27659 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I1022 16:26:48.961823 27659 net.cpp:228] scale4f_branch2b does not need backward computation.
I1022 16:26:48.961827 27659 net.cpp:228] bn4f_branch2b does not need backward computation.
I1022 16:26:48.961829 27659 net.cpp:228] res4f_branch2b does not need backward computation.
I1022 16:26:48.961833 27659 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I1022 16:26:48.961838 27659 net.cpp:228] scale4f_branch2a does not need backward computation.
I1022 16:26:48.961840 27659 net.cpp:228] bn4f_branch2a does not need backward computation.
I1022 16:26:48.961843 27659 net.cpp:228] res4f_branch2a does not need backward computation.
I1022 16:26:48.961848 27659 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I1022 16:26:48.961851 27659 net.cpp:228] res4e_relu does not need backward computation.
I1022 16:26:48.961855 27659 net.cpp:228] res4e does not need backward computation.
I1022 16:26:48.961859 27659 net.cpp:228] scale4e_branch2c does not need backward computation.
I1022 16:26:48.961863 27659 net.cpp:228] bn4e_branch2c does not need backward computation.
I1022 16:26:48.961865 27659 net.cpp:228] res4e_branch2c does not need backward computation.
I1022 16:26:48.961869 27659 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I1022 16:26:48.961872 27659 net.cpp:228] scale4e_branch2b does not need backward computation.
I1022 16:26:48.961875 27659 net.cpp:228] bn4e_branch2b does not need backward computation.
I1022 16:26:48.961879 27659 net.cpp:228] res4e_branch2b does not need backward computation.
I1022 16:26:48.961882 27659 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I1022 16:26:48.961885 27659 net.cpp:228] scale4e_branch2a does not need backward computation.
I1022 16:26:48.961889 27659 net.cpp:228] bn4e_branch2a does not need backward computation.
I1022 16:26:48.961891 27659 net.cpp:228] res4e_branch2a does not need backward computation.
I1022 16:26:48.961895 27659 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I1022 16:26:48.961899 27659 net.cpp:228] res4d_relu does not need backward computation.
I1022 16:26:48.961902 27659 net.cpp:228] res4d does not need backward computation.
I1022 16:26:48.961906 27659 net.cpp:228] scale4d_branch2c does not need backward computation.
I1022 16:26:48.961910 27659 net.cpp:228] bn4d_branch2c does not need backward computation.
I1022 16:26:48.961913 27659 net.cpp:228] res4d_branch2c does not need backward computation.
I1022 16:26:48.961917 27659 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I1022 16:26:48.961920 27659 net.cpp:228] scale4d_branch2b does not need backward computation.
I1022 16:26:48.961925 27659 net.cpp:228] bn4d_branch2b does not need backward computation.
I1022 16:26:48.961927 27659 net.cpp:228] res4d_branch2b does not need backward computation.
I1022 16:26:48.961930 27659 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I1022 16:26:48.961935 27659 net.cpp:228] scale4d_branch2a does not need backward computation.
I1022 16:26:48.961938 27659 net.cpp:228] bn4d_branch2a does not need backward computation.
I1022 16:26:48.961941 27659 net.cpp:228] res4d_branch2a does not need backward computation.
I1022 16:26:48.961944 27659 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I1022 16:26:48.961948 27659 net.cpp:228] res4c_relu does not need backward computation.
I1022 16:26:48.961952 27659 net.cpp:228] res4c does not need backward computation.
I1022 16:26:48.961957 27659 net.cpp:228] scale4c_branch2c does not need backward computation.
I1022 16:26:48.961961 27659 net.cpp:228] bn4c_branch2c does not need backward computation.
I1022 16:26:48.961963 27659 net.cpp:228] res4c_branch2c does not need backward computation.
I1022 16:26:48.961969 27659 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I1022 16:26:48.961975 27659 net.cpp:228] scale4c_branch2b does not need backward computation.
I1022 16:26:48.961978 27659 net.cpp:228] bn4c_branch2b does not need backward computation.
I1022 16:26:48.961982 27659 net.cpp:228] res4c_branch2b does not need backward computation.
I1022 16:26:48.961984 27659 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I1022 16:26:48.961988 27659 net.cpp:228] scale4c_branch2a does not need backward computation.
I1022 16:26:48.961992 27659 net.cpp:228] bn4c_branch2a does not need backward computation.
I1022 16:26:48.961994 27659 net.cpp:228] res4c_branch2a does not need backward computation.
I1022 16:26:48.961998 27659 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I1022 16:26:48.962002 27659 net.cpp:228] res4b_relu does not need backward computation.
I1022 16:26:48.962005 27659 net.cpp:228] res4b does not need backward computation.
I1022 16:26:48.962009 27659 net.cpp:228] scale4b_branch2c does not need backward computation.
I1022 16:26:48.962013 27659 net.cpp:228] bn4b_branch2c does not need backward computation.
I1022 16:26:48.962016 27659 net.cpp:228] res4b_branch2c does not need backward computation.
I1022 16:26:48.962019 27659 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I1022 16:26:48.962023 27659 net.cpp:228] scale4b_branch2b does not need backward computation.
I1022 16:26:48.962026 27659 net.cpp:228] bn4b_branch2b does not need backward computation.
I1022 16:26:48.962029 27659 net.cpp:228] res4b_branch2b does not need backward computation.
I1022 16:26:48.962033 27659 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I1022 16:26:48.962036 27659 net.cpp:228] scale4b_branch2a does not need backward computation.
I1022 16:26:48.962040 27659 net.cpp:228] bn4b_branch2a does not need backward computation.
I1022 16:26:48.962044 27659 net.cpp:228] res4b_branch2a does not need backward computation.
I1022 16:26:48.962047 27659 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I1022 16:26:48.962050 27659 net.cpp:228] res4a_relu does not need backward computation.
I1022 16:26:48.962054 27659 net.cpp:228] res4a does not need backward computation.
I1022 16:26:48.962059 27659 net.cpp:228] scale4a_branch2c does not need backward computation.
I1022 16:26:48.962061 27659 net.cpp:228] bn4a_branch2c does not need backward computation.
I1022 16:26:48.962065 27659 net.cpp:228] res4a_branch2c does not need backward computation.
I1022 16:26:48.962069 27659 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I1022 16:26:48.962072 27659 net.cpp:228] scale4a_branch2b does not need backward computation.
I1022 16:26:48.962075 27659 net.cpp:228] bn4a_branch2b does not need backward computation.
I1022 16:26:48.962079 27659 net.cpp:228] res4a_branch2b does not need backward computation.
I1022 16:26:48.962082 27659 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I1022 16:26:48.962085 27659 net.cpp:228] scale4a_branch2a does not need backward computation.
I1022 16:26:48.962088 27659 net.cpp:228] bn4a_branch2a does not need backward computation.
I1022 16:26:48.962091 27659 net.cpp:228] res4a_branch2a does not need backward computation.
I1022 16:26:48.962095 27659 net.cpp:228] scale4a_branch1 does not need backward computation.
I1022 16:26:48.962098 27659 net.cpp:228] bn4a_branch1 does not need backward computation.
I1022 16:26:48.962102 27659 net.cpp:228] res4a_branch1 does not need backward computation.
I1022 16:26:48.962106 27659 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I1022 16:26:48.962110 27659 net.cpp:228] res3d_relu does not need backward computation.
I1022 16:26:48.962113 27659 net.cpp:228] res3d does not need backward computation.
I1022 16:26:48.962117 27659 net.cpp:228] scale3d_branch2c does not need backward computation.
I1022 16:26:48.962121 27659 net.cpp:228] bn3d_branch2c does not need backward computation.
I1022 16:26:48.962124 27659 net.cpp:228] res3d_branch2c does not need backward computation.
I1022 16:26:48.962128 27659 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I1022 16:26:48.962138 27659 net.cpp:228] scale3d_branch2b does not need backward computation.
I1022 16:26:48.962142 27659 net.cpp:228] bn3d_branch2b does not need backward computation.
I1022 16:26:48.962146 27659 net.cpp:228] res3d_branch2b does not need backward computation.
I1022 16:26:48.962149 27659 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I1022 16:26:48.962152 27659 net.cpp:228] scale3d_branch2a does not need backward computation.
I1022 16:26:48.962155 27659 net.cpp:228] bn3d_branch2a does not need backward computation.
I1022 16:26:48.962159 27659 net.cpp:228] res3d_branch2a does not need backward computation.
I1022 16:26:48.962162 27659 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I1022 16:26:48.962167 27659 net.cpp:228] res3c_relu does not need backward computation.
I1022 16:26:48.962169 27659 net.cpp:228] res3c does not need backward computation.
I1022 16:26:48.962174 27659 net.cpp:228] scale3c_branch2c does not need backward computation.
I1022 16:26:48.962182 27659 net.cpp:228] bn3c_branch2c does not need backward computation.
I1022 16:26:48.962184 27659 net.cpp:228] res3c_branch2c does not need backward computation.
I1022 16:26:48.962188 27659 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I1022 16:26:48.962191 27659 net.cpp:228] scale3c_branch2b does not need backward computation.
I1022 16:26:48.962194 27659 net.cpp:228] bn3c_branch2b does not need backward computation.
I1022 16:26:48.962198 27659 net.cpp:228] res3c_branch2b does not need backward computation.
I1022 16:26:48.962201 27659 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I1022 16:26:48.962205 27659 net.cpp:228] scale3c_branch2a does not need backward computation.
I1022 16:26:48.962208 27659 net.cpp:228] bn3c_branch2a does not need backward computation.
I1022 16:26:48.962211 27659 net.cpp:228] res3c_branch2a does not need backward computation.
I1022 16:26:48.962215 27659 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I1022 16:26:48.962219 27659 net.cpp:228] res3b_relu does not need backward computation.
I1022 16:26:48.962224 27659 net.cpp:228] res3b does not need backward computation.
I1022 16:26:48.962226 27659 net.cpp:228] scale3b_branch2c does not need backward computation.
I1022 16:26:48.962230 27659 net.cpp:228] bn3b_branch2c does not need backward computation.
I1022 16:26:48.962234 27659 net.cpp:228] res3b_branch2c does not need backward computation.
I1022 16:26:48.962237 27659 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I1022 16:26:48.962240 27659 net.cpp:228] scale3b_branch2b does not need backward computation.
I1022 16:26:48.962244 27659 net.cpp:228] bn3b_branch2b does not need backward computation.
I1022 16:26:48.962246 27659 net.cpp:228] res3b_branch2b does not need backward computation.
I1022 16:26:48.962249 27659 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I1022 16:26:48.962254 27659 net.cpp:228] scale3b_branch2a does not need backward computation.
I1022 16:26:48.962256 27659 net.cpp:228] bn3b_branch2a does not need backward computation.
I1022 16:26:48.962260 27659 net.cpp:228] res3b_branch2a does not need backward computation.
I1022 16:26:48.962263 27659 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I1022 16:26:48.962266 27659 net.cpp:228] res3a_relu does not need backward computation.
I1022 16:26:48.962270 27659 net.cpp:228] res3a does not need backward computation.
I1022 16:26:48.962275 27659 net.cpp:228] scale3a_branch2c does not need backward computation.
I1022 16:26:48.962278 27659 net.cpp:228] bn3a_branch2c does not need backward computation.
I1022 16:26:48.962282 27659 net.cpp:228] res3a_branch2c does not need backward computation.
I1022 16:26:48.962285 27659 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I1022 16:26:48.962290 27659 net.cpp:228] scale3a_branch2b does not need backward computation.
I1022 16:26:48.962292 27659 net.cpp:228] bn3a_branch2b does not need backward computation.
I1022 16:26:48.962296 27659 net.cpp:228] res3a_branch2b does not need backward computation.
I1022 16:26:48.962299 27659 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I1022 16:26:48.962303 27659 net.cpp:228] scale3a_branch2a does not need backward computation.
I1022 16:26:48.962306 27659 net.cpp:228] bn3a_branch2a does not need backward computation.
I1022 16:26:48.962309 27659 net.cpp:228] res3a_branch2a does not need backward computation.
I1022 16:26:48.962313 27659 net.cpp:228] scale3a_branch1 does not need backward computation.
I1022 16:26:48.962316 27659 net.cpp:228] bn3a_branch1 does not need backward computation.
I1022 16:26:48.962321 27659 net.cpp:228] res3a_branch1 does not need backward computation.
I1022 16:26:48.962323 27659 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I1022 16:26:48.962327 27659 net.cpp:228] res2c_relu does not need backward computation.
I1022 16:26:48.962330 27659 net.cpp:228] res2c does not need backward computation.
I1022 16:26:48.962337 27659 net.cpp:228] scale2c_branch2c does not need backward computation.
I1022 16:26:48.962339 27659 net.cpp:228] bn2c_branch2c does not need backward computation.
I1022 16:26:48.962342 27659 net.cpp:228] res2c_branch2c does not need backward computation.
I1022 16:26:48.962347 27659 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I1022 16:26:48.962358 27659 net.cpp:228] scale2c_branch2b does not need backward computation.
I1022 16:26:48.962361 27659 net.cpp:228] bn2c_branch2b does not need backward computation.
I1022 16:26:48.962364 27659 net.cpp:228] res2c_branch2b does not need backward computation.
I1022 16:26:48.962368 27659 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I1022 16:26:48.962371 27659 net.cpp:228] scale2c_branch2a does not need backward computation.
I1022 16:26:48.962374 27659 net.cpp:228] bn2c_branch2a does not need backward computation.
I1022 16:26:48.962378 27659 net.cpp:228] res2c_branch2a does not need backward computation.
I1022 16:26:48.962381 27659 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I1022 16:26:48.962384 27659 net.cpp:228] res2b_relu does not need backward computation.
I1022 16:26:48.962388 27659 net.cpp:228] res2b does not need backward computation.
I1022 16:26:48.962391 27659 net.cpp:228] scale2b_branch2c does not need backward computation.
I1022 16:26:48.962395 27659 net.cpp:228] bn2b_branch2c does not need backward computation.
I1022 16:26:48.962399 27659 net.cpp:228] res2b_branch2c does not need backward computation.
I1022 16:26:48.962401 27659 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I1022 16:26:48.962404 27659 net.cpp:228] scale2b_branch2b does not need backward computation.
I1022 16:26:48.962409 27659 net.cpp:228] bn2b_branch2b does not need backward computation.
I1022 16:26:48.962412 27659 net.cpp:228] res2b_branch2b does not need backward computation.
I1022 16:26:48.962415 27659 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I1022 16:26:48.962419 27659 net.cpp:228] scale2b_branch2a does not need backward computation.
I1022 16:26:48.962422 27659 net.cpp:228] bn2b_branch2a does not need backward computation.
I1022 16:26:48.962425 27659 net.cpp:228] res2b_branch2a does not need backward computation.
I1022 16:26:48.962429 27659 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I1022 16:26:48.962432 27659 net.cpp:228] res2a_relu does not need backward computation.
I1022 16:26:48.962435 27659 net.cpp:228] res2a does not need backward computation.
I1022 16:26:48.962440 27659 net.cpp:228] scale2a_branch2c does not need backward computation.
I1022 16:26:48.962442 27659 net.cpp:228] bn2a_branch2c does not need backward computation.
I1022 16:26:48.962445 27659 net.cpp:228] res2a_branch2c does not need backward computation.
I1022 16:26:48.962450 27659 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I1022 16:26:48.962452 27659 net.cpp:228] scale2a_branch2b does not need backward computation.
I1022 16:26:48.962463 27659 net.cpp:228] bn2a_branch2b does not need backward computation.
I1022 16:26:48.962466 27659 net.cpp:228] res2a_branch2b does not need backward computation.
I1022 16:26:48.962471 27659 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I1022 16:26:48.962474 27659 net.cpp:228] scale2a_branch2a does not need backward computation.
I1022 16:26:48.962477 27659 net.cpp:228] bn2a_branch2a does not need backward computation.
I1022 16:26:48.962481 27659 net.cpp:228] res2a_branch2a does not need backward computation.
I1022 16:26:48.962484 27659 net.cpp:228] scale2a_branch1 does not need backward computation.
I1022 16:26:48.962487 27659 net.cpp:228] bn2a_branch1 does not need backward computation.
I1022 16:26:48.962491 27659 net.cpp:228] res2a_branch1 does not need backward computation.
I1022 16:26:48.962494 27659 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I1022 16:26:48.962498 27659 net.cpp:228] pool1 does not need backward computation.
I1022 16:26:48.962502 27659 net.cpp:228] conv1_relu does not need backward computation.
I1022 16:26:48.962505 27659 net.cpp:228] scale_conv1 does not need backward computation.
I1022 16:26:48.962508 27659 net.cpp:228] bn_conv1 does not need backward computation.
I1022 16:26:48.962512 27659 net.cpp:228] conv1 does not need backward computation.
I1022 16:26:48.962515 27659 net.cpp:228] input does not need backward computation.
I1022 16:26:48.962518 27659 net.cpp:270] This network produces output bbox_pred_p2
I1022 16:26:48.962522 27659 net.cpp:270] This network produces output bbox_pred_p3
I1022 16:26:48.962525 27659 net.cpp:270] This network produces output cls_prob_p2
I1022 16:26:48.962529 27659 net.cpp:270] This network produces output cls_prob_p3
I1022 16:26:48.962715 27659 net.cpp:283] Network initialization done.
I1022 16:26:49.059947 27659 net.cpp:771] Ignoring source layer input-data
I1022 16:26:49.059968 27659 net.cpp:771] Ignoring source layer data_input-data_0_split
I1022 16:26:49.059986 27659 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I1022 16:26:49.059988 27659 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I1022 16:26:49.059990 27659 net.cpp:774] Copying source layer conv1
I1022 16:26:49.060008 27659 net.cpp:774] Copying source layer bn_conv1
I1022 16:26:49.060012 27659 net.cpp:774] Copying source layer scale_conv1
I1022 16:26:49.060016 27659 net.cpp:774] Copying source layer conv1_relu
I1022 16:26:49.060019 27659 net.cpp:774] Copying source layer pool1
I1022 16:26:49.060020 27659 net.cpp:774] Copying source layer pool1_pool1_0_split
I1022 16:26:49.060022 27659 net.cpp:774] Copying source layer res2a_branch1
I1022 16:26:49.060041 27659 net.cpp:774] Copying source layer bn2a_branch1
I1022 16:26:49.060047 27659 net.cpp:774] Copying source layer scale2a_branch1
I1022 16:26:49.060051 27659 net.cpp:774] Copying source layer res2a_branch2a
I1022 16:26:49.060060 27659 net.cpp:774] Copying source layer bn2a_branch2a
I1022 16:26:49.060067 27659 net.cpp:774] Copying source layer scale2a_branch2a
I1022 16:26:49.060071 27659 net.cpp:774] Copying source layer res2a_branch2a_relu
I1022 16:26:49.060075 27659 net.cpp:774] Copying source layer res2a_branch2b
I1022 16:26:49.060109 27659 net.cpp:774] Copying source layer bn2a_branch2b
I1022 16:26:49.060117 27659 net.cpp:774] Copying source layer scale2a_branch2b
I1022 16:26:49.060120 27659 net.cpp:774] Copying source layer res2a_branch2b_relu
I1022 16:26:49.060123 27659 net.cpp:774] Copying source layer res2a_branch2c
I1022 16:26:49.060142 27659 net.cpp:774] Copying source layer bn2a_branch2c
I1022 16:26:49.060149 27659 net.cpp:774] Copying source layer scale2a_branch2c
I1022 16:26:49.060153 27659 net.cpp:774] Copying source layer res2a
I1022 16:26:49.060156 27659 net.cpp:774] Copying source layer res2a_relu
I1022 16:26:49.060158 27659 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I1022 16:26:49.060161 27659 net.cpp:774] Copying source layer res2b_branch2a
I1022 16:26:49.060179 27659 net.cpp:774] Copying source layer bn2b_branch2a
I1022 16:26:49.060185 27659 net.cpp:774] Copying source layer scale2b_branch2a
I1022 16:26:49.060190 27659 net.cpp:774] Copying source layer res2b_branch2a_relu
I1022 16:26:49.060192 27659 net.cpp:774] Copying source layer res2b_branch2b
I1022 16:26:49.060226 27659 net.cpp:774] Copying source layer bn2b_branch2b
I1022 16:26:49.060232 27659 net.cpp:774] Copying source layer scale2b_branch2b
I1022 16:26:49.060237 27659 net.cpp:774] Copying source layer res2b_branch2b_relu
I1022 16:26:49.060240 27659 net.cpp:774] Copying source layer res2b_branch2c
I1022 16:26:49.060258 27659 net.cpp:774] Copying source layer bn2b_branch2c
I1022 16:26:49.060266 27659 net.cpp:774] Copying source layer scale2b_branch2c
I1022 16:26:49.060269 27659 net.cpp:774] Copying source layer res2b
I1022 16:26:49.060271 27659 net.cpp:774] Copying source layer res2b_relu
I1022 16:26:49.060273 27659 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I1022 16:26:49.060277 27659 net.cpp:774] Copying source layer res2c_branch2a
I1022 16:26:49.060295 27659 net.cpp:774] Copying source layer bn2c_branch2a
I1022 16:26:49.060302 27659 net.cpp:774] Copying source layer scale2c_branch2a
I1022 16:26:49.060305 27659 net.cpp:774] Copying source layer res2c_branch2a_relu
I1022 16:26:49.060308 27659 net.cpp:774] Copying source layer res2c_branch2b
I1022 16:26:49.060343 27659 net.cpp:774] Copying source layer bn2c_branch2b
I1022 16:26:49.060349 27659 net.cpp:774] Copying source layer scale2c_branch2b
I1022 16:26:49.060353 27659 net.cpp:774] Copying source layer res2c_branch2b_relu
I1022 16:26:49.060355 27659 net.cpp:774] Copying source layer res2c_branch2c
I1022 16:26:49.060374 27659 net.cpp:774] Copying source layer bn2c_branch2c
I1022 16:26:49.060380 27659 net.cpp:774] Copying source layer scale2c_branch2c
I1022 16:26:49.060384 27659 net.cpp:774] Copying source layer res2c
I1022 16:26:49.060387 27659 net.cpp:774] Copying source layer res2c_relu
I1022 16:26:49.060389 27659 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I1022 16:26:49.060392 27659 net.cpp:774] Copying source layer res3a_branch1
I1022 16:26:49.060495 27659 net.cpp:774] Copying source layer bn3a_branch1
I1022 16:26:49.060504 27659 net.cpp:774] Copying source layer scale3a_branch1
I1022 16:26:49.060509 27659 net.cpp:774] Copying source layer res3a_branch2a
I1022 16:26:49.060542 27659 net.cpp:774] Copying source layer bn3a_branch2a
I1022 16:26:49.060549 27659 net.cpp:774] Copying source layer scale3a_branch2a
I1022 16:26:49.060554 27659 net.cpp:774] Copying source layer res3a_branch2a_relu
I1022 16:26:49.060556 27659 net.cpp:774] Copying source layer res3a_branch2b
I1022 16:26:49.060726 27659 net.cpp:774] Copying source layer bn3a_branch2b
I1022 16:26:49.060734 27659 net.cpp:774] Copying source layer scale3a_branch2b
I1022 16:26:49.060739 27659 net.cpp:774] Copying source layer res3a_branch2b_relu
I1022 16:26:49.060741 27659 net.cpp:774] Copying source layer res3a_branch2c
I1022 16:26:49.060801 27659 net.cpp:774] Copying source layer bn3a_branch2c
I1022 16:26:49.060808 27659 net.cpp:774] Copying source layer scale3a_branch2c
I1022 16:26:49.060814 27659 net.cpp:774] Copying source layer res3a
I1022 16:26:49.060817 27659 net.cpp:774] Copying source layer res3a_relu
I1022 16:26:49.060819 27659 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I1022 16:26:49.060822 27659 net.cpp:774] Copying source layer res3b_branch2a
I1022 16:26:49.060880 27659 net.cpp:774] Copying source layer bn3b_branch2a
I1022 16:26:49.060887 27659 net.cpp:774] Copying source layer scale3b_branch2a
I1022 16:26:49.060891 27659 net.cpp:774] Copying source layer res3b_branch2a_relu
I1022 16:26:49.060894 27659 net.cpp:774] Copying source layer res3b_branch2b
I1022 16:26:49.061026 27659 net.cpp:774] Copying source layer bn3b_branch2b
I1022 16:26:49.061033 27659 net.cpp:774] Copying source layer scale3b_branch2b
I1022 16:26:49.061038 27659 net.cpp:774] Copying source layer res3b_branch2b_relu
I1022 16:26:49.061040 27659 net.cpp:774] Copying source layer res3b_branch2c
I1022 16:26:49.061110 27659 net.cpp:774] Copying source layer bn3b_branch2c
I1022 16:26:49.061118 27659 net.cpp:774] Copying source layer scale3b_branch2c
I1022 16:26:49.061123 27659 net.cpp:774] Copying source layer res3b
I1022 16:26:49.061125 27659 net.cpp:774] Copying source layer res3b_relu
I1022 16:26:49.061128 27659 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I1022 16:26:49.061131 27659 net.cpp:774] Copying source layer res3c_branch2a
I1022 16:26:49.061199 27659 net.cpp:774] Copying source layer bn3c_branch2a
I1022 16:26:49.061206 27659 net.cpp:774] Copying source layer scale3c_branch2a
I1022 16:26:49.061211 27659 net.cpp:774] Copying source layer res3c_branch2a_relu
I1022 16:26:49.061214 27659 net.cpp:774] Copying source layer res3c_branch2b
I1022 16:26:49.061337 27659 net.cpp:774] Copying source layer bn3c_branch2b
I1022 16:26:49.061344 27659 net.cpp:774] Copying source layer scale3c_branch2b
I1022 16:26:49.061348 27659 net.cpp:774] Copying source layer res3c_branch2b_relu
I1022 16:26:49.061352 27659 net.cpp:774] Copying source layer res3c_branch2c
I1022 16:26:49.061406 27659 net.cpp:774] Copying source layer bn3c_branch2c
I1022 16:26:49.061414 27659 net.cpp:774] Copying source layer scale3c_branch2c
I1022 16:26:49.061420 27659 net.cpp:774] Copying source layer res3c
I1022 16:26:49.061422 27659 net.cpp:774] Copying source layer res3c_relu
I1022 16:26:49.061425 27659 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I1022 16:26:49.061427 27659 net.cpp:774] Copying source layer res3d_branch2a
I1022 16:26:49.061484 27659 net.cpp:774] Copying source layer bn3d_branch2a
I1022 16:26:49.061491 27659 net.cpp:774] Copying source layer scale3d_branch2a
I1022 16:26:49.061496 27659 net.cpp:774] Copying source layer res3d_branch2a_relu
I1022 16:26:49.061498 27659 net.cpp:774] Copying source layer res3d_branch2b
I1022 16:26:49.061623 27659 net.cpp:774] Copying source layer bn3d_branch2b
I1022 16:26:49.061630 27659 net.cpp:774] Copying source layer scale3d_branch2b
I1022 16:26:49.061635 27659 net.cpp:774] Copying source layer res3d_branch2b_relu
I1022 16:26:49.061636 27659 net.cpp:774] Copying source layer res3d_branch2c
I1022 16:26:49.061693 27659 net.cpp:774] Copying source layer bn3d_branch2c
I1022 16:26:49.061702 27659 net.cpp:774] Copying source layer scale3d_branch2c
I1022 16:26:49.061707 27659 net.cpp:774] Copying source layer res3d
I1022 16:26:49.061708 27659 net.cpp:774] Copying source layer res3d_relu
I1022 16:26:49.061712 27659 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I1022 16:26:49.061713 27659 net.cpp:774] Copying source layer res4a_branch1
I1022 16:26:49.062108 27659 net.cpp:774] Copying source layer bn4a_branch1
I1022 16:26:49.062119 27659 net.cpp:774] Copying source layer scale4a_branch1
I1022 16:26:49.062124 27659 net.cpp:774] Copying source layer res4a_branch2a
I1022 16:26:49.062222 27659 net.cpp:774] Copying source layer bn4a_branch2a
I1022 16:26:49.062228 27659 net.cpp:774] Copying source layer scale4a_branch2a
I1022 16:26:49.062233 27659 net.cpp:774] Copying source layer res4a_branch2a_relu
I1022 16:26:49.062237 27659 net.cpp:774] Copying source layer res4a_branch2b
I1022 16:26:49.062734 27659 net.cpp:774] Copying source layer bn4a_branch2b
I1022 16:26:49.062741 27659 net.cpp:774] Copying source layer scale4a_branch2b
I1022 16:26:49.062762 27659 net.cpp:774] Copying source layer res4a_branch2b_relu
I1022 16:26:49.062764 27659 net.cpp:774] Copying source layer res4a_branch2c
I1022 16:26:49.062963 27659 net.cpp:774] Copying source layer bn4a_branch2c
I1022 16:26:49.062971 27659 net.cpp:774] Copying source layer scale4a_branch2c
I1022 16:26:49.062976 27659 net.cpp:774] Copying source layer res4a
I1022 16:26:49.062979 27659 net.cpp:774] Copying source layer res4a_relu
I1022 16:26:49.062983 27659 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I1022 16:26:49.062984 27659 net.cpp:774] Copying source layer res4b_branch2a
I1022 16:26:49.063184 27659 net.cpp:774] Copying source layer bn4b_branch2a
I1022 16:26:49.063192 27659 net.cpp:774] Copying source layer scale4b_branch2a
I1022 16:26:49.063196 27659 net.cpp:774] Copying source layer res4b_branch2a_relu
I1022 16:26:49.063199 27659 net.cpp:774] Copying source layer res4b_branch2b
I1022 16:26:49.063663 27659 net.cpp:774] Copying source layer bn4b_branch2b
I1022 16:26:49.063670 27659 net.cpp:774] Copying source layer scale4b_branch2b
I1022 16:26:49.063689 27659 net.cpp:774] Copying source layer res4b_branch2b_relu
I1022 16:26:49.063693 27659 net.cpp:774] Copying source layer res4b_branch2c
I1022 16:26:49.063885 27659 net.cpp:774] Copying source layer bn4b_branch2c
I1022 16:26:49.063894 27659 net.cpp:774] Copying source layer scale4b_branch2c
I1022 16:26:49.063899 27659 net.cpp:774] Copying source layer res4b
I1022 16:26:49.063901 27659 net.cpp:774] Copying source layer res4b_relu
I1022 16:26:49.063905 27659 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I1022 16:26:49.063907 27659 net.cpp:774] Copying source layer res4c_branch2a
I1022 16:26:49.064098 27659 net.cpp:774] Copying source layer bn4c_branch2a
I1022 16:26:49.064106 27659 net.cpp:774] Copying source layer scale4c_branch2a
I1022 16:26:49.064110 27659 net.cpp:774] Copying source layer res4c_branch2a_relu
I1022 16:26:49.064113 27659 net.cpp:774] Copying source layer res4c_branch2b
I1022 16:26:49.064554 27659 net.cpp:774] Copying source layer bn4c_branch2b
I1022 16:26:49.064563 27659 net.cpp:774] Copying source layer scale4c_branch2b
I1022 16:26:49.064582 27659 net.cpp:774] Copying source layer res4c_branch2b_relu
I1022 16:26:49.064585 27659 net.cpp:774] Copying source layer res4c_branch2c
I1022 16:26:49.064833 27659 net.cpp:774] Copying source layer bn4c_branch2c
I1022 16:26:49.064843 27659 net.cpp:774] Copying source layer scale4c_branch2c
I1022 16:26:49.064848 27659 net.cpp:774] Copying source layer res4c
I1022 16:26:49.064851 27659 net.cpp:774] Copying source layer res4c_relu
I1022 16:26:49.064854 27659 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I1022 16:26:49.064857 27659 net.cpp:774] Copying source layer res4d_branch2a
I1022 16:26:49.065086 27659 net.cpp:774] Copying source layer bn4d_branch2a
I1022 16:26:49.065095 27659 net.cpp:774] Copying source layer scale4d_branch2a
I1022 16:26:49.065100 27659 net.cpp:774] Copying source layer res4d_branch2a_relu
I1022 16:26:49.065102 27659 net.cpp:774] Copying source layer res4d_branch2b
I1022 16:26:49.065537 27659 net.cpp:774] Copying source layer bn4d_branch2b
I1022 16:26:49.065546 27659 net.cpp:774] Copying source layer scale4d_branch2b
I1022 16:26:49.065551 27659 net.cpp:774] Copying source layer res4d_branch2b_relu
I1022 16:26:49.065552 27659 net.cpp:774] Copying source layer res4d_branch2c
I1022 16:26:49.065749 27659 net.cpp:774] Copying source layer bn4d_branch2c
I1022 16:26:49.065758 27659 net.cpp:774] Copying source layer scale4d_branch2c
I1022 16:26:49.065764 27659 net.cpp:774] Copying source layer res4d
I1022 16:26:49.065766 27659 net.cpp:774] Copying source layer res4d_relu
I1022 16:26:49.065769 27659 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I1022 16:26:49.065773 27659 net.cpp:774] Copying source layer res4e_branch2a
I1022 16:26:49.065966 27659 net.cpp:774] Copying source layer bn4e_branch2a
I1022 16:26:49.065973 27659 net.cpp:774] Copying source layer scale4e_branch2a
I1022 16:26:49.065979 27659 net.cpp:774] Copying source layer res4e_branch2a_relu
I1022 16:26:49.065981 27659 net.cpp:774] Copying source layer res4e_branch2b
I1022 16:26:49.066431 27659 net.cpp:774] Copying source layer bn4e_branch2b
I1022 16:26:49.066439 27659 net.cpp:774] Copying source layer scale4e_branch2b
I1022 16:26:49.066443 27659 net.cpp:774] Copying source layer res4e_branch2b_relu
I1022 16:26:49.066447 27659 net.cpp:774] Copying source layer res4e_branch2c
I1022 16:26:49.066646 27659 net.cpp:774] Copying source layer bn4e_branch2c
I1022 16:26:49.066654 27659 net.cpp:774] Copying source layer scale4e_branch2c
I1022 16:26:49.066660 27659 net.cpp:774] Copying source layer res4e
I1022 16:26:49.066663 27659 net.cpp:774] Copying source layer res4e_relu
I1022 16:26:49.066666 27659 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I1022 16:26:49.066668 27659 net.cpp:774] Copying source layer res4f_branch2a
I1022 16:26:49.066864 27659 net.cpp:774] Copying source layer bn4f_branch2a
I1022 16:26:49.066871 27659 net.cpp:774] Copying source layer scale4f_branch2a
I1022 16:26:49.066876 27659 net.cpp:774] Copying source layer res4f_branch2a_relu
I1022 16:26:49.066879 27659 net.cpp:774] Copying source layer res4f_branch2b
I1022 16:26:49.067304 27659 net.cpp:774] Copying source layer bn4f_branch2b
I1022 16:26:49.067313 27659 net.cpp:774] Copying source layer scale4f_branch2b
I1022 16:26:49.067318 27659 net.cpp:774] Copying source layer res4f_branch2b_relu
I1022 16:26:49.067322 27659 net.cpp:774] Copying source layer res4f_branch2c
I1022 16:26:49.067512 27659 net.cpp:774] Copying source layer bn4f_branch2c
I1022 16:26:49.067522 27659 net.cpp:774] Copying source layer scale4f_branch2c
I1022 16:26:49.067528 27659 net.cpp:774] Copying source layer res4f
I1022 16:26:49.067530 27659 net.cpp:774] Copying source layer res4f_relu
I1022 16:26:49.067533 27659 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I1022 16:26:49.067536 27659 net.cpp:774] Copying source layer res5a_branch1
I1022 16:26:49.069123 27659 net.cpp:774] Copying source layer bn5a_branch1
I1022 16:26:49.069156 27659 net.cpp:774] Copying source layer scale5a_branch1
I1022 16:26:49.069178 27659 net.cpp:774] Copying source layer res5a_branch2a
I1022 16:26:49.069569 27659 net.cpp:774] Copying source layer bn5a_branch2a
I1022 16:26:49.069594 27659 net.cpp:774] Copying source layer scale5a_branch2a
I1022 16:26:49.069600 27659 net.cpp:774] Copying source layer res5a_branch2a_relu
I1022 16:26:49.069602 27659 net.cpp:774] Copying source layer res5a_branch2b
I1022 16:26:49.071336 27659 net.cpp:774] Copying source layer bn5a_branch2b
I1022 16:26:49.071347 27659 net.cpp:774] Copying source layer scale5a_branch2b
I1022 16:26:49.071369 27659 net.cpp:774] Copying source layer res5a_branch2b_relu
I1022 16:26:49.071372 27659 net.cpp:774] Copying source layer res5a_branch2c
I1022 16:26:49.072119 27659 net.cpp:774] Copying source layer bn5a_branch2c
I1022 16:26:49.072147 27659 net.cpp:774] Copying source layer scale5a_branch2c
I1022 16:26:49.072156 27659 net.cpp:774] Copying source layer res5a
I1022 16:26:49.072158 27659 net.cpp:774] Copying source layer res5a_relu
I1022 16:26:49.072162 27659 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I1022 16:26:49.072165 27659 net.cpp:774] Copying source layer res5b_branch2a
I1022 16:26:49.073000 27659 net.cpp:774] Copying source layer bn5b_branch2a
I1022 16:26:49.073010 27659 net.cpp:774] Copying source layer scale5b_branch2a
I1022 16:26:49.073031 27659 net.cpp:774] Copying source layer res5b_branch2a_relu
I1022 16:26:49.073034 27659 net.cpp:774] Copying source layer res5b_branch2b
I1022 16:26:49.074717 27659 net.cpp:774] Copying source layer bn5b_branch2b
I1022 16:26:49.074728 27659 net.cpp:774] Copying source layer scale5b_branch2b
I1022 16:26:49.074749 27659 net.cpp:774] Copying source layer res5b_branch2b_relu
I1022 16:26:49.074753 27659 net.cpp:774] Copying source layer res5b_branch2c
I1022 16:26:49.075500 27659 net.cpp:774] Copying source layer bn5b_branch2c
I1022 16:26:49.075526 27659 net.cpp:774] Copying source layer scale5b_branch2c
I1022 16:26:49.075534 27659 net.cpp:774] Copying source layer res5b
I1022 16:26:49.075536 27659 net.cpp:774] Copying source layer res5b_relu
I1022 16:26:49.075541 27659 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I1022 16:26:49.075543 27659 net.cpp:774] Copying source layer res5c_branch2a
I1022 16:26:49.076299 27659 net.cpp:774] Copying source layer bn5c_branch2a
I1022 16:26:49.076308 27659 net.cpp:774] Copying source layer scale5c_branch2a
I1022 16:26:49.076329 27659 net.cpp:774] Copying source layer res5c_branch2a_relu
I1022 16:26:49.076333 27659 net.cpp:774] Copying source layer res5c_branch2b
I1022 16:26:49.078088 27659 net.cpp:774] Copying source layer bn5c_branch2b
I1022 16:26:49.078102 27659 net.cpp:774] Copying source layer scale5c_branch2b
I1022 16:26:49.078125 27659 net.cpp:774] Copying source layer res5c_branch2b_relu
I1022 16:26:49.078126 27659 net.cpp:774] Copying source layer res5c_branch2c
I1022 16:26:49.078900 27659 net.cpp:774] Copying source layer bn5c_branch2c
I1022 16:26:49.078927 27659 net.cpp:774] Copying source layer scale5c_branch2c
I1022 16:26:49.078935 27659 net.cpp:774] Copying source layer res5c
I1022 16:26:49.078938 27659 net.cpp:774] Copying source layer res5c_relu
I1022 16:26:49.078940 27659 net.cpp:774] Copying source layer upP4
I1022 16:26:49.078971 27659 net.cpp:774] Copying source layer newC4
I1022 16:26:49.079380 27659 net.cpp:774] Copying source layer eltwise_bnc4_bnp4
I1022 16:26:49.079385 27659 net.cpp:774] Copying source layer skip_eltwise1_eltwise_bnc4_bnp4_0_split
I1022 16:26:49.079388 27659 net.cpp:774] Copying source layer bnp4_conv
I1022 16:26:49.079458 27659 net.cpp:774] Copying source layer bnp4_bn
I1022 16:26:49.079465 27659 net.cpp:774] Copying source layer bnp4_scale
I1022 16:26:49.079469 27659 net.cpp:774] Copying source layer bnp4_ReLU
I1022 16:26:49.079473 27659 net.cpp:774] Copying source layer bn_eltwise_1_1_conv
I1022 16:26:49.079591 27659 net.cpp:774] Copying source layer bn_eltwise_1_1_bn
I1022 16:26:49.079597 27659 net.cpp:774] Copying source layer bn_eltwise_1_1_scale
I1022 16:26:49.079602 27659 net.cpp:774] Copying source layer bn_eltwise_1_1_ReLU
I1022 16:26:49.079607 27659 net.cpp:774] Copying source layer bn_eltwise_1_2_conv
I1022 16:26:49.079663 27659 net.cpp:774] Copying source layer bn_eltwise_1_2_bn
I1022 16:26:49.079670 27659 net.cpp:774] Copying source layer bn_eltwise_1_2_scale
I1022 16:26:49.079675 27659 net.cpp:774] Copying source layer p3
I1022 16:26:49.079679 27659 net.cpp:774] Copying source layer p3_relu
I1022 16:26:49.079681 27659 net.cpp:774] Copying source layer p3_p3_relu_0_split
I1022 16:26:49.079684 27659 net.cpp:774] Copying source layer newC3
I1022 16:26:49.079902 27659 net.cpp:774] Copying source layer upP3
I1022 16:26:49.079916 27659 net.cpp:774] Copying source layer eltwise_bnc3_bnp3
I1022 16:26:49.079921 27659 net.cpp:774] Copying source layer skip_eltwise2_eltwise_bnc3_bnp3_0_split
I1022 16:26:49.079923 27659 net.cpp:774] Copying source layer bnp3_conv
I1022 16:26:49.079977 27659 net.cpp:774] Copying source layer bnp3_bn
I1022 16:26:49.079984 27659 net.cpp:774] Copying source layer bnp3_scale
I1022 16:26:49.079988 27659 net.cpp:774] Copying source layer bnp3_ReLU
I1022 16:26:49.079991 27659 net.cpp:774] Copying source layer bn_eltwise_2_1_conv
I1022 16:26:49.080106 27659 net.cpp:774] Copying source layer bn_eltwise_2_1_bn
I1022 16:26:49.080112 27659 net.cpp:774] Copying source layer bn_eltwise_2_1_scale
I1022 16:26:49.080117 27659 net.cpp:774] Copying source layer bn_eltwise_2_1_ReLU
I1022 16:26:49.080121 27659 net.cpp:774] Copying source layer bn_eltwise_2_2_conv
I1022 16:26:49.080176 27659 net.cpp:774] Copying source layer bn_eltwise_2_2_bn
I1022 16:26:49.080183 27659 net.cpp:774] Copying source layer bn_eltwise_2_2_scale
I1022 16:26:49.080188 27659 net.cpp:774] Copying source layer p2
I1022 16:26:49.080191 27659 net.cpp:774] Copying source layer p2_relu
I1022 16:26:49.080193 27659 net.cpp:774] Copying source layer p2_p2_relu_0_split
I1022 16:26:49.080196 27659 net.cpp:774] Copying source layer rpn_conv/3x3_p2
I1022 16:26:49.081949 27659 net.cpp:774] Copying source layer rpn_relu/3x3_p2
I1022 16:26:49.081959 27659 net.cpp:774] Copying source layer rpn/output_p2_rpn_relu/3x3_p2_0_split
I1022 16:26:49.081977 27659 net.cpp:774] Copying source layer rpn_cls_score_p2
I1022 16:26:49.081993 27659 net.cpp:771] Ignoring source layer rpn_cls_score_p2_rpn_cls_score_p2_0_split
I1022 16:26:49.081996 27659 net.cpp:774] Copying source layer rpn_bbox_pred_p2
I1022 16:26:49.082020 27659 net.cpp:771] Ignoring source layer rpn_bbox_pred_p2_rpn_bbox_pred_p2_0_split
I1022 16:26:49.082026 27659 net.cpp:774] Copying source layer rpn_cls_score_reshape_p2
I1022 16:26:49.082029 27659 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_p2_rpn_cls_score_reshape_p2_0_split
I1022 16:26:49.082031 27659 net.cpp:774] Copying source layer rpn_cls_prob_p2
I1022 16:26:49.082034 27659 net.cpp:774] Copying source layer rpn_cls_prob_reshape_p2
I1022 16:26:49.082036 27659 net.cpp:774] Copying source layer rpn_conv/3x3_p3
I1022 16:26:49.083792 27659 net.cpp:774] Copying source layer rpn_relu/3x3_p3
I1022 16:26:49.083801 27659 net.cpp:774] Copying source layer rpn/output_p3_rpn_relu/3x3_p3_0_split
I1022 16:26:49.083804 27659 net.cpp:774] Copying source layer rpn_cls_score_p3
I1022 16:26:49.083833 27659 net.cpp:771] Ignoring source layer rpn_cls_score_p3_rpn_cls_score_p3_0_split
I1022 16:26:49.083837 27659 net.cpp:774] Copying source layer rpn_bbox_pred_p3
I1022 16:26:49.083859 27659 net.cpp:771] Ignoring source layer rpn_bbox_pred_p3_rpn_bbox_pred_p3_0_split
I1022 16:26:49.083866 27659 net.cpp:774] Copying source layer rpn_cls_score_reshape_p3
I1022 16:26:49.083868 27659 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_p3_rpn_cls_score_reshape_p3_0_split
I1022 16:26:49.083871 27659 net.cpp:774] Copying source layer rpn_cls_prob_p3
I1022 16:26:49.083874 27659 net.cpp:774] Copying source layer rpn_cls_prob_reshape_p3
I1022 16:26:49.083878 27659 net.cpp:771] Ignoring source layer rpn-data
I1022 16:26:49.083879 27659 net.cpp:771] Ignoring source layer rpn_loss_cls_p2
I1022 16:26:49.083884 27659 net.cpp:771] Ignoring source layer rpn_loss_bbox_p2
I1022 16:26:49.083885 27659 net.cpp:771] Ignoring source layer rpn_loss_cls_p3
I1022 16:26:49.083889 27659 net.cpp:771] Ignoring source layer rpn_loss_bbox_p3
I1022 16:26:49.083890 27659 net.cpp:774] Copying source layer proposal
I1022 16:26:49.083894 27659 net.cpp:771] Ignoring source layer roi-data
I1022 16:26:49.083896 27659 net.cpp:771] Ignoring source layer rois_p2_roi-data_0_split
I1022 16:26:49.083899 27659 net.cpp:771] Ignoring source layer rois_p3_roi-data_1_split
I1022 16:26:49.083901 27659 net.cpp:771] Ignoring source layer labels_p2_roi-data_2_split
I1022 16:26:49.083904 27659 net.cpp:771] Ignoring source layer labels_p3_roi-data_3_split
I1022 16:26:49.083906 27659 net.cpp:771] Ignoring source layer bbox_targets_p2_roi-data_4_split
I1022 16:26:49.083909 27659 net.cpp:771] Ignoring source layer bbox_targets_p3_roi-data_5_split
I1022 16:26:49.083910 27659 net.cpp:771] Ignoring source layer bbox_inside_weights_p2_roi-data_6_split
I1022 16:26:49.083914 27659 net.cpp:771] Ignoring source layer bbox_inside_weights_p3_roi-data_7_split
I1022 16:26:49.083915 27659 net.cpp:774] Copying source layer conv_new_p2
I1022 16:26:49.084311 27659 net.cpp:774] Copying source layer conv_new_p2_relu
I1022 16:26:49.084316 27659 net.cpp:774] Copying source layer conv_new_p2_conv_new_p2_relu_0_split
I1022 16:26:49.084319 27659 net.cpp:774] Copying source layer rfcn_cls_p2
I1022 16:26:49.084415 27659 net.cpp:774] Copying source layer rfcn_bbox_p2
I1022 16:26:49.084761 27659 net.cpp:774] Copying source layer psroipooled_cls_rois_p2
I1022 16:26:49.084766 27659 net.cpp:774] Copying source layer ave_cls_score_rois_p2
I1022 16:26:49.084769 27659 net.cpp:771] Ignoring source layer cls_score_p2_ave_cls_score_rois_p2_0_split
I1022 16:26:49.084786 27659 net.cpp:774] Copying source layer psroipooled_loc_rois_p2
I1022 16:26:49.084789 27659 net.cpp:774] Copying source layer ave_bbox_pred_rois_p2
I1022 16:26:49.084791 27659 net.cpp:771] Ignoring source layer bbox_pred_p2_ave_bbox_pred_rois_p2_0_split
I1022 16:26:49.084796 27659 net.cpp:771] Ignoring source layer per_roi_loss_cls_p2
I1022 16:26:49.084800 27659 net.cpp:771] Ignoring source layer per_roi_loss_bbox_p2
I1022 16:26:49.084802 27659 net.cpp:771] Ignoring source layer per_roi_loss_p2
I1022 16:26:49.084805 27659 net.cpp:771] Ignoring source layer annotator_detector_p2
I1022 16:26:49.084808 27659 net.cpp:771] Ignoring source layer labels_ohem_p2_annotator_detector_p2_0_split
I1022 16:26:49.084810 27659 net.cpp:774] Copying source layer conv_new_p3
I1022 16:26:49.085240 27659 net.cpp:774] Copying source layer conv_new_p3_relu
I1022 16:26:49.085245 27659 net.cpp:774] Copying source layer conv_new_p3_conv_new_p3_relu_0_split
I1022 16:26:49.085247 27659 net.cpp:774] Copying source layer rfcn_cls_p3
I1022 16:26:49.085343 27659 net.cpp:774] Copying source layer rfcn_bbox_p3
I1022 16:26:49.085657 27659 net.cpp:774] Copying source layer psroipooled_cls_rois_p3
I1022 16:26:49.085661 27659 net.cpp:774] Copying source layer ave_cls_score_rois_p3
I1022 16:26:49.085664 27659 net.cpp:771] Ignoring source layer cls_score_p3_ave_cls_score_rois_p3_0_split
I1022 16:26:49.085666 27659 net.cpp:774] Copying source layer psroipooled_loc_rois_p3
I1022 16:26:49.085683 27659 net.cpp:774] Copying source layer ave_bbox_pred_rois_p3
I1022 16:26:49.085685 27659 net.cpp:771] Ignoring source layer bbox_pred_p3_ave_bbox_pred_rois_p3_0_split
I1022 16:26:49.085688 27659 net.cpp:771] Ignoring source layer per_roi_loss_cls_p3
I1022 16:26:49.085691 27659 net.cpp:771] Ignoring source layer per_roi_loss_bbox_p3
I1022 16:26:49.085693 27659 net.cpp:771] Ignoring source layer per_roi_loss_p3
I1022 16:26:49.085695 27659 net.cpp:771] Ignoring source layer annotator_detector_p3
I1022 16:26:49.085697 27659 net.cpp:771] Ignoring source layer labels_ohem_p3_annotator_detector_p3_0_split
I1022 16:26:49.085700 27659 net.cpp:771] Ignoring source layer loss_p2
I1022 16:26:49.085702 27659 net.cpp:771] Ignoring source layer loss_p3
I1022 16:26:49.085705 27659 net.cpp:771] Ignoring source layer accuarcy_p2
I1022 16:26:49.085707 27659 net.cpp:771] Ignoring source layer accuarcy_p3
I1022 16:26:49.085710 27659 net.cpp:771] Ignoring source layer loss_bbox_p2
I1022 16:26:49.085711 27659 net.cpp:771] Ignoring source layer loss_bbox_p3
I1022 16:26:49.085713 27659 net.cpp:771] Ignoring source layer silence
im_detect: 1/4024 1.098s 0.000s
im_detect: 2/4024 0.655s 0.000s
im_detect: 3/4024 0.504s 0.000s
im_detect: 4/4024 0.432s 0.000s
im_detect: 5/4024 0.390s 0.000s
im_detect: 6/4024 0.363s 0.001s
im_detect: 7/4024 0.343s 0.001s
im_detect: 8/4024 0.327s 0.000s
im_detect: 9/4024 0.316s 0.001s
im_detect: 10/4024 0.309s 0.001s
im_detect: 11/4024 0.304s 0.001s
im_detect: 12/4024 0.298s 0.001s
im_detect: 13/4024 0.291s 0.001s
im_detect: 14/4024 0.288s 0.001s
im_detect: 15/4024 0.284s 0.001s
im_detect: 16/4024 0.279s 0.001s
im_detect: 17/4024 0.276s 0.001s
im_detect: 18/4024 0.272s 0.001s
im_detect: 19/4024 0.270s 0.001s
im_detect: 20/4024 0.267s 0.001s
im_detect: 21/4024 0.264s 0.001s
im_detect: 22/4024 0.263s 0.001s
im_detect: 23/4024 0.261s 0.001s
im_detect: 24/4024 0.259s 0.001s
im_detect: 25/4024 0.258s 0.001s
im_detect: 26/4024 0.257s 0.001s
im_detect: 27/4024 0.255s 0.001s
im_detect: 28/4024 0.254s 0.001s
im_detect: 29/4024 0.253s 0.001s
im_detect: 30/4024 0.252s 0.001s
im_detect: 31/4024 0.251s 0.001s
im_detect: 32/4024 0.251s 0.001s
im_detect: 33/4024 0.250s 0.001s
im_detect: 34/4024 0.249s 0.001s
im_detect: 35/4024 0.248s 0.001s
im_detect: 36/4024 0.247s 0.001s
im_detect: 37/4024 0.246s 0.001s
im_detect: 38/4024 0.245s 0.001s
im_detect: 39/4024 0.244s 0.001s
im_detect: 40/4024 0.244s 0.001s
im_detect: 41/4024 0.243s 0.001s
im_detect: 42/4024 0.243s 0.001s
im_detect: 43/4024 0.242s 0.001s
im_detect: 44/4024 0.242s 0.001s
im_detect: 45/4024 0.242s 0.001s
im_detect: 46/4024 0.241s 0.001s
im_detect: 47/4024 0.241s 0.001s
im_detect: 48/4024 0.240s 0.001s
im_detect: 49/4024 0.240s 0.001s
im_detect: 50/4024 0.240s 0.001s
im_detect: 51/4024 0.240s 0.001s
im_detect: 52/4024 0.240s 0.001s
im_detect: 53/4024 0.239s 0.001s
im_detect: 54/4024 0.239s 0.001s
im_detect: 55/4024 0.239s 0.001s
im_detect: 56/4024 0.239s 0.001s
im_detect: 57/4024 0.238s 0.001s
im_detect: 58/4024 0.239s 0.001s
im_detect: 59/4024 0.238s 0.001s
im_detect: 60/4024 0.238s 0.001s
im_detect: 61/4024 0.238s 0.001s
im_detect: 62/4024 0.238s 0.001s
im_detect: 63/4024 0.238s 0.001s
im_detect: 64/4024 0.238s 0.001s
im_detect: 65/4024 0.238s 0.001s
im_detect: 66/4024 0.238s 0.001s
im_detect: 67/4024 0.238s 0.001s
im_detect: 68/4024 0.238s 0.001s
im_detect: 69/4024 0.237s 0.001s
im_detect: 70/4024 0.237s 0.001s
im_detect: 71/4024 0.237s 0.001s
im_detect: 72/4024 0.237s 0.001s
im_detect: 73/4024 0.237s 0.001s
im_detect: 74/4024 0.236s 0.001s
im_detect: 75/4024 0.236s 0.001s
im_detect: 76/4024 0.237s 0.001s
im_detect: 77/4024 0.236s 0.001s
im_detect: 78/4024 0.236s 0.001s
im_detect: 79/4024 0.236s 0.001s
im_detect: 80/4024 0.236s 0.001s
im_detect: 81/4024 0.236s 0.001s
im_detect: 82/4024 0.235s 0.001s
im_detect: 83/4024 0.235s 0.001s
im_detect: 84/4024 0.235s 0.001s
im_detect: 85/4024 0.235s 0.001s
im_detect: 86/4024 0.235s 0.001s
im_detect: 87/4024 0.235s 0.001s
im_detect: 88/4024 0.234s 0.001s
im_detect: 89/4024 0.234s 0.001s
im_detect: 90/4024 0.234s 0.001s
im_detect: 91/4024 0.234s 0.001s
im_detect: 92/4024 0.234s 0.001s
im_detect: 93/4024 0.234s 0.001s
im_detect: 94/4024 0.234s 0.001s
im_detect: 95/4024 0.234s 0.001s
im_detect: 96/4024 0.234s 0.001s
im_detect: 97/4024 0.234s 0.001s
im_detect: 98/4024 0.234s 0.001s
im_detect: 99/4024 0.234s 0.001s
im_detect: 100/4024 0.234s 0.001s
im_detect: 101/4024 0.234s 0.001s
im_detect: 102/4024 0.234s 0.001s
im_detect: 103/4024 0.233s 0.001s
im_detect: 104/4024 0.233s 0.001s
im_detect: 105/4024 0.233s 0.001s
im_detect: 106/4024 0.233s 0.001s
im_detect: 107/4024 0.233s 0.001s
im_detect: 108/4024 0.233s 0.001s
im_detect: 109/4024 0.232s 0.001s
im_detect: 110/4024 0.232s 0.001s
im_detect: 111/4024 0.232s 0.001s
im_detect: 112/4024 0.232s 0.001s
im_detect: 113/4024 0.232s 0.001s
im_detect: 114/4024 0.232s 0.001s
im_detect: 115/4024 0.232s 0.001s
im_detect: 116/4024 0.232s 0.001s
im_detect: 117/4024 0.232s 0.001s
im_detect: 118/4024 0.232s 0.001s
im_detect: 119/4024 0.232s 0.001s
im_detect: 120/4024 0.232s 0.001s
im_detect: 121/4024 0.232s 0.001s
im_detect: 122/4024 0.232s 0.001s
im_detect: 123/4024 0.232s 0.001s
im_detect: 124/4024 0.231s 0.001s
im_detect: 125/4024 0.231s 0.001s
im_detect: 126/4024 0.231s 0.001s
im_detect: 127/4024 0.231s 0.001s
im_detect: 128/4024 0.231s 0.001s
im_detect: 129/4024 0.231s 0.001s
im_detect: 130/4024 0.231s 0.001s
im_detect: 131/4024 0.231s 0.001s
im_detect: 132/4024 0.231s 0.001s
im_detect: 133/4024 0.231s 0.001s
im_detect: 134/4024 0.231s 0.001s
im_detect: 135/4024 0.231s 0.001s
im_detect: 136/4024 0.231s 0.001s
im_detect: 137/4024 0.231s 0.001s
im_detect: 138/4024 0.231s 0.001s
im_detect: 139/4024 0.231s 0.001s
im_detect: 140/4024 0.231s 0.001s
im_detect: 141/4024 0.231s 0.001s
im_detect: 142/4024 0.231s 0.001s
im_detect: 143/4024 0.231s 0.001s
im_detect: 144/4024 0.231s 0.001s
im_detect: 145/4024 0.231s 0.001s
im_detect: 146/4024 0.231s 0.001s
im_detect: 147/4024 0.231s 0.001s
im_detect: 148/4024 0.231s 0.001s
im_detect: 149/4024 0.231s 0.001s
im_detect: 150/4024 0.231s 0.001s
im_detect: 151/4024 0.231s 0.001s
im_detect: 152/4024 0.231s 0.001s
im_detect: 153/4024 0.231s 0.001s
im_detect: 154/4024 0.231s 0.001s
im_detect: 155/4024 0.231s 0.001s
im_detect: 156/4024 0.231s 0.001s
im_detect: 157/4024 0.231s 0.001s
im_detect: 158/4024 0.231s 0.001s
im_detect: 159/4024 0.231s 0.001s
im_detect: 160/4024 0.231s 0.001s
im_detect: 161/4024 0.231s 0.001s
im_detect: 162/4024 0.231s 0.001s
im_detect: 163/4024 0.231s 0.001s
im_detect: 164/4024 0.231s 0.001s
im_detect: 165/4024 0.230s 0.001s
im_detect: 166/4024 0.230s 0.001s
im_detect: 167/4024 0.230s 0.001s
im_detect: 168/4024 0.230s 0.001s
im_detect: 169/4024 0.230s 0.001s
im_detect: 170/4024 0.230s 0.001s
im_detect: 171/4024 0.231s 0.001s
im_detect: 172/4024 0.231s 0.001s
im_detect: 173/4024 0.231s 0.001s
im_detect: 174/4024 0.231s 0.001s
im_detect: 175/4024 0.231s 0.001s
im_detect: 176/4024 0.231s 0.001s
im_detect: 177/4024 0.231s 0.001s
im_detect: 178/4024 0.231s 0.001s
im_detect: 179/4024 0.230s 0.001s
im_detect: 180/4024 0.230s 0.001s
im_detect: 181/4024 0.230s 0.001s
im_detect: 182/4024 0.230s 0.001s
im_detect: 183/4024 0.230s 0.001s
im_detect: 184/4024 0.230s 0.001s
im_detect: 185/4024 0.229s 0.001s
im_detect: 186/4024 0.229s 0.001s
im_detect: 187/4024 0.229s 0.001s
im_detect: 188/4024 0.229s 0.001s
im_detect: 189/4024 0.229s 0.001s
im_detect: 190/4024 0.229s 0.001s
im_detect: 191/4024 0.229s 0.001s
im_detect: 192/4024 0.229s 0.001s
im_detect: 193/4024 0.229s 0.001s
im_detect: 194/4024 0.229s 0.001s
im_detect: 195/4024 0.228s 0.001s
im_detect: 196/4024 0.228s 0.001s
im_detect: 197/4024 0.228s 0.001s
im_detect: 198/4024 0.228s 0.001s
im_detect: 199/4024 0.228s 0.001s
im_detect: 200/4024 0.228s 0.001s
im_detect: 201/4024 0.228s 0.001s
im_detect: 202/4024 0.228s 0.001s
im_detect: 203/4024 0.228s 0.001s
im_detect: 204/4024 0.228s 0.001s
im_detect: 205/4024 0.228s 0.001s
im_detect: 206/4024 0.228s 0.001s
im_detect: 207/4024 0.228s 0.001s
im_detect: 208/4024 0.228s 0.001s
im_detect: 209/4024 0.228s 0.001s
im_detect: 210/4024 0.228s 0.001s
im_detect: 211/4024 0.228s 0.001s
im_detect: 212/4024 0.228s 0.001s
im_detect: 213/4024 0.228s 0.001s
im_detect: 214/4024 0.227s 0.001s
im_detect: 215/4024 0.227s 0.001s
im_detect: 216/4024 0.227s 0.001s
im_detect: 217/4024 0.227s 0.001s
im_detect: 218/4024 0.227s 0.001s
im_detect: 219/4024 0.227s 0.001s
im_detect: 220/4024 0.227s 0.001s
im_detect: 221/4024 0.227s 0.001s
im_detect: 222/4024 0.227s 0.001s
im_detect: 223/4024 0.227s 0.001s
im_detect: 224/4024 0.227s 0.001s
im_detect: 225/4024 0.227s 0.001s
im_detect: 226/4024 0.227s 0.001s
im_detect: 227/4024 0.227s 0.001s
im_detect: 228/4024 0.227s 0.001s
im_detect: 229/4024 0.227s 0.001s
im_detect: 230/4024 0.227s 0.001s
im_detect: 231/4024 0.227s 0.001s
im_detect: 232/4024 0.227s 0.001s
im_detect: 233/4024 0.227s 0.001s
im_detect: 234/4024 0.227s 0.001s
im_detect: 235/4024 0.227s 0.001s
im_detect: 236/4024 0.227s 0.001s
im_detect: 237/4024 0.226s 0.001s
im_detect: 238/4024 0.226s 0.001s
im_detect: 239/4024 0.226s 0.001s
im_detect: 240/4024 0.226s 0.001s
im_detect: 241/4024 0.226s 0.001s
im_detect: 242/4024 0.227s 0.001s
im_detect: 243/4024 0.227s 0.001s
im_detect: 244/4024 0.226s 0.001s
im_detect: 245/4024 0.226s 0.001s
im_detect: 246/4024 0.226s 0.001s
im_detect: 247/4024 0.226s 0.001s
im_detect: 248/4024 0.226s 0.001s
im_detect: 249/4024 0.226s 0.001s
im_detect: 250/4024 0.226s 0.001s
im_detect: 251/4024 0.226s 0.001s
im_detect: 252/4024 0.226s 0.001s
im_detect: 253/4024 0.226s 0.001s
im_detect: 254/4024 0.226s 0.001s
im_detect: 255/4024 0.226s 0.001s
im_detect: 256/4024 0.226s 0.001s
im_detect: 257/4024 0.226s 0.001s
im_detect: 258/4024 0.226s 0.001s
im_detect: 259/4024 0.226s 0.001s
im_detect: 260/4024 0.226s 0.001s
im_detect: 261/4024 0.226s 0.001s
im_detect: 262/4024 0.226s 0.001s
im_detect: 263/4024 0.226s 0.001s
im_detect: 264/4024 0.226s 0.001s
im_detect: 265/4024 0.226s 0.001s
im_detect: 266/4024 0.226s 0.001s
im_detect: 267/4024 0.226s 0.001s
im_detect: 268/4024 0.226s 0.001s
im_detect: 269/4024 0.226s 0.001s
im_detect: 270/4024 0.226s 0.001s
im_detect: 271/4024 0.226s 0.001s
im_detect: 272/4024 0.226s 0.001s
im_detect: 273/4024 0.226s 0.001s
im_detect: 274/4024 0.226s 0.001s
im_detect: 275/4024 0.226s 0.001s
im_detect: 276/4024 0.226s 0.001s
im_detect: 277/4024 0.226s 0.001s
im_detect: 278/4024 0.226s 0.001s
im_detect: 279/4024 0.226s 0.001s
im_detect: 280/4024 0.226s 0.001s
im_detect: 281/4024 0.226s 0.001s
im_detect: 282/4024 0.226s 0.001s
im_detect: 283/4024 0.226s 0.001s
im_detect: 284/4024 0.226s 0.001s
im_detect: 285/4024 0.226s 0.001s
im_detect: 286/4024 0.226s 0.001s
im_detect: 287/4024 0.226s 0.001s
im_detect: 288/4024 0.226s 0.001s
im_detect: 289/4024 0.226s 0.001s
im_detect: 290/4024 0.226s 0.001s
im_detect: 291/4024 0.226s 0.001s
im_detect: 292/4024 0.226s 0.001s
im_detect: 293/4024 0.225s 0.001s
im_detect: 294/4024 0.225s 0.001s
im_detect: 295/4024 0.225s 0.001s
im_detect: 296/4024 0.225s 0.001s
im_detect: 297/4024 0.225s 0.001s
im_detect: 298/4024 0.225s 0.001s
im_detect: 299/4024 0.225s 0.001s
im_detect: 300/4024 0.225s 0.001s
im_detect: 301/4024 0.225s 0.001s
im_detect: 302/4024 0.225s 0.001s
im_detect: 303/4024 0.225s 0.001s
im_detect: 304/4024 0.225s 0.001s
im_detect: 305/4024 0.225s 0.001s
im_detect: 306/4024 0.225s 0.001s
im_detect: 307/4024 0.224s 0.001s
im_detect: 308/4024 0.224s 0.001s
im_detect: 309/4024 0.224s 0.001s
im_detect: 310/4024 0.224s 0.001s
im_detect: 311/4024 0.224s 0.001s
im_detect: 312/4024 0.224s 0.001s
im_detect: 313/4024 0.224s 0.001s
im_detect: 314/4024 0.224s 0.001s
im_detect: 315/4024 0.224s 0.001s
im_detect: 316/4024 0.224s 0.001s
im_detect: 317/4024 0.224s 0.001s
im_detect: 318/4024 0.224s 0.001s
im_detect: 319/4024 0.224s 0.001s
im_detect: 320/4024 0.224s 0.001s
im_detect: 321/4024 0.224s 0.001s
im_detect: 322/4024 0.224s 0.001s
im_detect: 323/4024 0.224s 0.001s
im_detect: 324/4024 0.224s 0.001s
im_detect: 325/4024 0.224s 0.001s
im_detect: 326/4024 0.224s 0.001s
im_detect: 327/4024 0.224s 0.001s
im_detect: 328/4024 0.224s 0.001s
im_detect: 329/4024 0.224s 0.001s
im_detect: 330/4024 0.224s 0.001s
im_detect: 331/4024 0.224s 0.001s
im_detect: 332/4024 0.224s 0.001s
im_detect: 333/4024 0.224s 0.001s
im_detect: 334/4024 0.224s 0.001s
im_detect: 335/4024 0.224s 0.001s
im_detect: 336/4024 0.224s 0.001s
im_detect: 337/4024 0.224s 0.001s
im_detect: 338/4024 0.224s 0.001s
im_detect: 339/4024 0.224s 0.001s
im_detect: 340/4024 0.224s 0.001s
im_detect: 341/4024 0.224s 0.001s
im_detect: 342/4024 0.224s 0.001s
im_detect: 343/4024 0.224s 0.001s
im_detect: 344/4024 0.224s 0.001s
im_detect: 345/4024 0.224s 0.001s
im_detect: 346/4024 0.224s 0.001s
im_detect: 347/4024 0.224s 0.001s
im_detect: 348/4024 0.224s 0.001s
im_detect: 349/4024 0.224s 0.001s
im_detect: 350/4024 0.224s 0.001s
im_detect: 351/4024 0.224s 0.001s
im_detect: 352/4024 0.224s 0.001s
im_detect: 353/4024 0.224s 0.001s
im_detect: 354/4024 0.224s 0.001s
im_detect: 355/4024 0.224s 0.001s
im_detect: 356/4024 0.224s 0.001s
im_detect: 357/4024 0.224s 0.001s
im_detect: 358/4024 0.224s 0.001s
im_detect: 359/4024 0.224s 0.001s
im_detect: 360/4024 0.224s 0.001s
im_detect: 361/4024 0.224s 0.001s
im_detect: 362/4024 0.224s 0.001s
im_detect: 363/4024 0.224s 0.001s
im_detect: 364/4024 0.224s 0.001s
im_detect: 365/4024 0.224s 0.001s
im_detect: 366/4024 0.224s 0.001s
im_detect: 367/4024 0.224s 0.001s
im_detect: 368/4024 0.224s 0.001s
im_detect: 369/4024 0.224s 0.001s
im_detect: 370/4024 0.224s 0.001s
im_detect: 371/4024 0.224s 0.001s
im_detect: 372/4024 0.224s 0.001s
im_detect: 373/4024 0.224s 0.001s
im_detect: 374/4024 0.224s 0.001s
im_detect: 375/4024 0.224s 0.001s
im_detect: 376/4024 0.224s 0.001s
im_detect: 377/4024 0.224s 0.001s
im_detect: 378/4024 0.224s 0.001s
im_detect: 379/4024 0.224s 0.001s
im_detect: 380/4024 0.224s 0.001s
im_detect: 381/4024 0.224s 0.001s
im_detect: 382/4024 0.224s 0.001s
im_detect: 383/4024 0.224s 0.001s
im_detect: 384/4024 0.224s 0.001s
im_detect: 385/4024 0.224s 0.001s
im_detect: 386/4024 0.224s 0.001s
im_detect: 387/4024 0.224s 0.001s
im_detect: 388/4024 0.224s 0.001s
im_detect: 389/4024 0.224s 0.001s
im_detect: 390/4024 0.224s 0.001s
im_detect: 391/4024 0.224s 0.001s
im_detect: 392/4024 0.224s 0.001s
im_detect: 393/4024 0.224s 0.001s
im_detect: 394/4024 0.224s 0.001s
im_detect: 395/4024 0.224s 0.001s
im_detect: 396/4024 0.224s 0.001s
im_detect: 397/4024 0.224s 0.001s
im_detect: 398/4024 0.224s 0.001s
im_detect: 399/4024 0.224s 0.001s
im_detect: 400/4024 0.224s 0.001s
im_detect: 401/4024 0.224s 0.001s
im_detect: 402/4024 0.224s 0.001s
im_detect: 403/4024 0.224s 0.001s
im_detect: 404/4024 0.224s 0.001s
im_detect: 405/4024 0.224s 0.001s
im_detect: 406/4024 0.224s 0.001s
im_detect: 407/4024 0.224s 0.001s
im_detect: 408/4024 0.224s 0.001s
im_detect: 409/4024 0.224s 0.001s
im_detect: 410/4024 0.224s 0.001s
im_detect: 411/4024 0.224s 0.001s
im_detect: 412/4024 0.224s 0.001s
im_detect: 413/4024 0.224s 0.001s
im_detect: 414/4024 0.224s 0.001s
im_detect: 415/4024 0.224s 0.001s
im_detect: 416/4024 0.224s 0.001s
im_detect: 417/4024 0.224s 0.001s
im_detect: 418/4024 0.224s 0.001s
im_detect: 419/4024 0.224s 0.001s
im_detect: 420/4024 0.224s 0.001s
im_detect: 421/4024 0.224s 0.001s
im_detect: 422/4024 0.224s 0.001s
im_detect: 423/4024 0.224s 0.001s
im_detect: 424/4024 0.224s 0.001s
im_detect: 425/4024 0.224s 0.001s
im_detect: 426/4024 0.224s 0.001s
im_detect: 427/4024 0.224s 0.001s
im_detect: 428/4024 0.224s 0.001s
im_detect: 429/4024 0.224s 0.001s
im_detect: 430/4024 0.224s 0.001s
im_detect: 431/4024 0.224s 0.001s
im_detect: 432/4024 0.224s 0.001s
im_detect: 433/4024 0.224s 0.001s
im_detect: 434/4024 0.224s 0.001s
im_detect: 435/4024 0.224s 0.001s
im_detect: 436/4024 0.224s 0.001s
im_detect: 437/4024 0.224s 0.001s
im_detect: 438/4024 0.224s 0.001s
im_detect: 439/4024 0.225s 0.001s
im_detect: 440/4024 0.225s 0.001s
im_detect: 441/4024 0.225s 0.001s
im_detect: 442/4024 0.224s 0.001s
im_detect: 443/4024 0.225s 0.001s
im_detect: 444/4024 0.225s 0.001s
im_detect: 445/4024 0.225s 0.001s
im_detect: 446/4024 0.225s 0.001s
im_detect: 447/4024 0.225s 0.001s
im_detect: 448/4024 0.225s 0.001s
im_detect: 449/4024 0.225s 0.001s
im_detect: 450/4024 0.225s 0.001s
im_detect: 451/4024 0.225s 0.001s
im_detect: 452/4024 0.225s 0.001s
im_detect: 453/4024 0.225s 0.001s
im_detect: 454/4024 0.225s 0.001s
im_detect: 455/4024 0.225s 0.001s
im_detect: 456/4024 0.225s 0.001s
im_detect: 457/4024 0.225s 0.001s
im_detect: 458/4024 0.225s 0.001s
im_detect: 459/4024 0.225s 0.001s
im_detect: 460/4024 0.225s 0.001s
im_detect: 461/4024 0.225s 0.001s
im_detect: 462/4024 0.225s 0.001s
im_detect: 463/4024 0.225s 0.001s
im_detect: 464/4024 0.225s 0.001s
im_detect: 465/4024 0.225s 0.001s
im_detect: 466/4024 0.225s 0.001s
im_detect: 467/4024 0.225s 0.001s
im_detect: 468/4024 0.225s 0.001s
im_detect: 469/4024 0.225s 0.001s
im_detect: 470/4024 0.225s 0.001s
im_detect: 471/4024 0.225s 0.001s
im_detect: 472/4024 0.225s 0.001s
im_detect: 473/4024 0.225s 0.001s
im_detect: 474/4024 0.225s 0.001s
im_detect: 475/4024 0.225s 0.001s
im_detect: 476/4024 0.225s 0.001s
im_detect: 477/4024 0.225s 0.001s
im_detect: 478/4024 0.225s 0.001s
im_detect: 479/4024 0.225s 0.001s
im_detect: 480/4024 0.225s 0.001s
im_detect: 481/4024 0.225s 0.001s
im_detect: 482/4024 0.225s 0.001s
im_detect: 483/4024 0.225s 0.001s
im_detect: 484/4024 0.225s 0.001s
im_detect: 485/4024 0.225s 0.001s
im_detect: 486/4024 0.225s 0.001s
im_detect: 487/4024 0.225s 0.001s
im_detect: 488/4024 0.225s 0.001s
im_detect: 489/4024 0.225s 0.001s
im_detect: 490/4024 0.225s 0.001s
im_detect: 491/4024 0.225s 0.001s
im_detect: 492/4024 0.225s 0.001s
im_detect: 493/4024 0.225s 0.001s
im_detect: 494/4024 0.225s 0.001s
im_detect: 495/4024 0.225s 0.001s
im_detect: 496/4024 0.225s 0.001s
im_detect: 497/4024 0.225s 0.001s
im_detect: 498/4024 0.225s 0.001s
im_detect: 499/4024 0.225s 0.001s
im_detect: 500/4024 0.225s 0.001s
im_detect: 501/4024 0.225s 0.001s
im_detect: 502/4024 0.225s 0.001s
im_detect: 503/4024 0.225s 0.001s
im_detect: 504/4024 0.225s 0.001s
im_detect: 505/4024 0.225s 0.001s
im_detect: 506/4024 0.225s 0.001s
im_detect: 507/4024 0.225s 0.001s
im_detect: 508/4024 0.224s 0.001s
im_detect: 509/4024 0.225s 0.001s
im_detect: 510/4024 0.224s 0.001s
im_detect: 511/4024 0.224s 0.001s
im_detect: 512/4024 0.224s 0.001s
im_detect: 513/4024 0.225s 0.001s
im_detect: 514/4024 0.225s 0.001s
im_detect: 515/4024 0.225s 0.001s
im_detect: 516/4024 0.225s 0.001s
im_detect: 517/4024 0.225s 0.001s
im_detect: 518/4024 0.225s 0.001s
im_detect: 519/4024 0.225s 0.001s
im_detect: 520/4024 0.225s 0.001s
im_detect: 521/4024 0.225s 0.001s
im_detect: 522/4024 0.225s 0.001s
im_detect: 523/4024 0.225s 0.001s
im_detect: 524/4024 0.225s 0.001s
im_detect: 525/4024 0.225s 0.001s
im_detect: 526/4024 0.225s 0.001s
im_detect: 527/4024 0.225s 0.001s
im_detect: 528/4024 0.225s 0.001s
im_detect: 529/4024 0.225s 0.001s
im_detect: 530/4024 0.225s 0.001s
im_detect: 531/4024 0.225s 0.001s
im_detect: 532/4024 0.225s 0.001s
im_detect: 533/4024 0.225s 0.001s
im_detect: 534/4024 0.225s 0.001s
im_detect: 535/4024 0.225s 0.001s
im_detect: 536/4024 0.225s 0.001s
im_detect: 537/4024 0.225s 0.001s
im_detect: 538/4024 0.225s 0.001s
im_detect: 539/4024 0.225s 0.001s
im_detect: 540/4024 0.225s 0.001s
im_detect: 541/4024 0.225s 0.001s
im_detect: 542/4024 0.225s 0.001s
im_detect: 543/4024 0.225s 0.001s
im_detect: 544/4024 0.225s 0.001s
im_detect: 545/4024 0.225s 0.001s
im_detect: 546/4024 0.225s 0.001s
im_detect: 547/4024 0.225s 0.001s
im_detect: 548/4024 0.225s 0.001s
im_detect: 549/4024 0.225s 0.001s
im_detect: 550/4024 0.225s 0.001s
im_detect: 551/4024 0.225s 0.001s
im_detect: 552/4024 0.225s 0.001s
im_detect: 553/4024 0.225s 0.001s
im_detect: 554/4024 0.225s 0.001s
im_detect: 555/4024 0.225s 0.001s
im_detect: 556/4024 0.225s 0.001s
im_detect: 557/4024 0.225s 0.001s
im_detect: 558/4024 0.225s 0.001s
im_detect: 559/4024 0.225s 0.001s
im_detect: 560/4024 0.225s 0.001s
im_detect: 561/4024 0.225s 0.001s
im_detect: 562/4024 0.225s 0.001s
im_detect: 563/4024 0.225s 0.001s
im_detect: 564/4024 0.225s 0.001s
im_detect: 565/4024 0.225s 0.001s
im_detect: 566/4024 0.225s 0.001s
im_detect: 567/4024 0.225s 0.001s
im_detect: 568/4024 0.225s 0.001s
im_detect: 569/4024 0.225s 0.001s
im_detect: 570/4024 0.225s 0.001s
im_detect: 571/4024 0.225s 0.001s
im_detect: 572/4024 0.225s 0.001s
im_detect: 573/4024 0.225s 0.001s
im_detect: 574/4024 0.225s 0.001s
im_detect: 575/4024 0.225s 0.001s
im_detect: 576/4024 0.225s 0.001s
im_detect: 577/4024 0.225s 0.001s
im_detect: 578/4024 0.225s 0.001s
im_detect: 579/4024 0.225s 0.001s
im_detect: 580/4024 0.225s 0.001s
im_detect: 581/4024 0.225s 0.001s
im_detect: 582/4024 0.225s 0.001s
im_detect: 583/4024 0.225s 0.001s
im_detect: 584/4024 0.225s 0.001s
im_detect: 585/4024 0.225s 0.001s
im_detect: 586/4024 0.225s 0.001s
im_detect: 587/4024 0.225s 0.001s
im_detect: 588/4024 0.225s 0.001s
im_detect: 589/4024 0.225s 0.001s
im_detect: 590/4024 0.225s 0.001s
im_detect: 591/4024 0.225s 0.001s
im_detect: 592/4024 0.225s 0.001s
im_detect: 593/4024 0.225s 0.001s
im_detect: 594/4024 0.225s 0.001s
im_detect: 595/4024 0.225s 0.001s
im_detect: 596/4024 0.225s 0.001s
im_detect: 597/4024 0.225s 0.001s
im_detect: 598/4024 0.225s 0.001s
im_detect: 599/4024 0.225s 0.001s
im_detect: 600/4024 0.225s 0.001s
im_detect: 601/4024 0.225s 0.001s
im_detect: 602/4024 0.225s 0.001s
im_detect: 603/4024 0.225s 0.001s
im_detect: 604/4024 0.225s 0.001s
im_detect: 605/4024 0.225s 0.001s
im_detect: 606/4024 0.225s 0.001s
im_detect: 607/4024 0.225s 0.001s
im_detect: 608/4024 0.225s 0.001s
im_detect: 609/4024 0.225s 0.001s
im_detect: 610/4024 0.225s 0.001s
im_detect: 611/4024 0.225s 0.001s
im_detect: 612/4024 0.225s 0.001s
im_detect: 613/4024 0.225s 0.001s
im_detect: 614/4024 0.225s 0.001s
im_detect: 615/4024 0.225s 0.001s
im_detect: 616/4024 0.225s 0.001s
im_detect: 617/4024 0.225s 0.001s
im_detect: 618/4024 0.225s 0.001s
im_detect: 619/4024 0.225s 0.001s
im_detect: 620/4024 0.225s 0.001s
im_detect: 621/4024 0.225s 0.001s
im_detect: 622/4024 0.225s 0.001s
im_detect: 623/4024 0.225s 0.001s
im_detect: 624/4024 0.225s 0.001s
im_detect: 625/4024 0.225s 0.001s
im_detect: 626/4024 0.225s 0.001s
im_detect: 627/4024 0.225s 0.001s
im_detect: 628/4024 0.225s 0.001s
im_detect: 629/4024 0.225s 0.001s
im_detect: 630/4024 0.225s 0.001s
im_detect: 631/4024 0.225s 0.001s
im_detect: 632/4024 0.225s 0.001s
im_detect: 633/4024 0.225s 0.001s
im_detect: 634/4024 0.225s 0.001s
im_detect: 635/4024 0.225s 0.001s
im_detect: 636/4024 0.225s 0.001s
im_detect: 637/4024 0.225s 0.001s
im_detect: 638/4024 0.225s 0.001s
im_detect: 639/4024 0.225s 0.001s
im_detect: 640/4024 0.225s 0.001s
im_detect: 641/4024 0.225s 0.001s
im_detect: 642/4024 0.225s 0.001s
im_detect: 643/4024 0.225s 0.001s
im_detect: 644/4024 0.225s 0.001s
im_detect: 645/4024 0.225s 0.001s
im_detect: 646/4024 0.225s 0.001s
im_detect: 647/4024 0.225s 0.001s
im_detect: 648/4024 0.225s 0.001s
im_detect: 649/4024 0.225s 0.001s
im_detect: 650/4024 0.225s 0.001s
im_detect: 651/4024 0.225s 0.001s
im_detect: 652/4024 0.225s 0.001s
im_detect: 653/4024 0.225s 0.001s
im_detect: 654/4024 0.225s 0.001s
im_detect: 655/4024 0.225s 0.001s
im_detect: 656/4024 0.225s 0.001s
im_detect: 657/4024 0.225s 0.001s
im_detect: 658/4024 0.225s 0.001s
im_detect: 659/4024 0.225s 0.001s
im_detect: 660/4024 0.225s 0.001s
im_detect: 661/4024 0.225s 0.001s
im_detect: 662/4024 0.225s 0.001s
im_detect: 663/4024 0.225s 0.001s
im_detect: 664/4024 0.225s 0.001s
im_detect: 665/4024 0.225s 0.001s
im_detect: 666/4024 0.225s 0.001s
im_detect: 667/4024 0.225s 0.001s
im_detect: 668/4024 0.225s 0.001s
im_detect: 669/4024 0.225s 0.001s
im_detect: 670/4024 0.225s 0.001s
im_detect: 671/4024 0.225s 0.001s
im_detect: 672/4024 0.225s 0.001s
im_detect: 673/4024 0.225s 0.001s
im_detect: 674/4024 0.225s 0.001s
im_detect: 675/4024 0.225s 0.001s
im_detect: 676/4024 0.225s 0.001s
im_detect: 677/4024 0.225s 0.001s
im_detect: 678/4024 0.225s 0.001s
im_detect: 679/4024 0.225s 0.001s
im_detect: 680/4024 0.225s 0.001s
im_detect: 681/4024 0.225s 0.001s
im_detect: 682/4024 0.225s 0.001s
im_detect: 683/4024 0.225s 0.001s
im_detect: 684/4024 0.225s 0.001s
im_detect: 685/4024 0.225s 0.001s
im_detect: 686/4024 0.225s 0.001s
im_detect: 687/4024 0.225s 0.001s
im_detect: 688/4024 0.225s 0.001s
im_detect: 689/4024 0.225s 0.001s
im_detect: 690/4024 0.225s 0.001s
im_detect: 691/4024 0.225s 0.001s
im_detect: 692/4024 0.225s 0.001s
im_detect: 693/4024 0.225s 0.001s
im_detect: 694/4024 0.225s 0.001s
im_detect: 695/4024 0.225s 0.001s
im_detect: 696/4024 0.225s 0.001s
im_detect: 697/4024 0.225s 0.001s
im_detect: 698/4024 0.225s 0.001s
im_detect: 699/4024 0.225s 0.001s
im_detect: 700/4024 0.225s 0.001s
im_detect: 701/4024 0.225s 0.001s
im_detect: 702/4024 0.225s 0.001s
im_detect: 703/4024 0.225s 0.001s
im_detect: 704/4024 0.225s 0.001s
im_detect: 705/4024 0.225s 0.001s
im_detect: 706/4024 0.225s 0.001s
im_detect: 707/4024 0.225s 0.001s
im_detect: 708/4024 0.225s 0.001s
im_detect: 709/4024 0.225s 0.001s
im_detect: 710/4024 0.225s 0.001s
im_detect: 711/4024 0.225s 0.001s
im_detect: 712/4024 0.225s 0.001s
im_detect: 713/4024 0.225s 0.001s
im_detect: 714/4024 0.225s 0.001s
im_detect: 715/4024 0.225s 0.001s
im_detect: 716/4024 0.225s 0.001s
im_detect: 717/4024 0.225s 0.001s
im_detect: 718/4024 0.225s 0.001s
im_detect: 719/4024 0.225s 0.001s
im_detect: 720/4024 0.225s 0.001s
im_detect: 721/4024 0.225s 0.001s
im_detect: 722/4024 0.225s 0.001s
im_detect: 723/4024 0.225s 0.001s
im_detect: 724/4024 0.225s 0.001s
im_detect: 725/4024 0.225s 0.001s
im_detect: 726/4024 0.225s 0.001s
im_detect: 727/4024 0.225s 0.001s
im_detect: 728/4024 0.225s 0.001s
im_detect: 729/4024 0.225s 0.001s
im_detect: 730/4024 0.225s 0.001s
im_detect: 731/4024 0.225s 0.001s
im_detect: 732/4024 0.225s 0.001s
im_detect: 733/4024 0.225s 0.001s
im_detect: 734/4024 0.225s 0.001s
im_detect: 735/4024 0.225s 0.001s
im_detect: 736/4024 0.225s 0.001s
im_detect: 737/4024 0.225s 0.001s
im_detect: 738/4024 0.225s 0.001s
im_detect: 739/4024 0.225s 0.001s
im_detect: 740/4024 0.225s 0.001s
im_detect: 741/4024 0.225s 0.001s
im_detect: 742/4024 0.225s 0.001s
im_detect: 743/4024 0.225s 0.001s
im_detect: 744/4024 0.225s 0.001s
im_detect: 745/4024 0.225s 0.001s
im_detect: 746/4024 0.225s 0.001s
im_detect: 747/4024 0.225s 0.001s
im_detect: 748/4024 0.225s 0.001s
im_detect: 749/4024 0.225s 0.001s
im_detect: 750/4024 0.225s 0.001s
im_detect: 751/4024 0.225s 0.001s
im_detect: 752/4024 0.225s 0.001s
im_detect: 753/4024 0.225s 0.001s
im_detect: 754/4024 0.225s 0.001s
im_detect: 755/4024 0.225s 0.001s
im_detect: 756/4024 0.225s 0.001s
im_detect: 757/4024 0.225s 0.001s
im_detect: 758/4024 0.225s 0.001s
im_detect: 759/4024 0.225s 0.001s
im_detect: 760/4024 0.225s 0.001s
im_detect: 761/4024 0.225s 0.001s
im_detect: 762/4024 0.225s 0.001s
im_detect: 763/4024 0.225s 0.001s
im_detect: 764/4024 0.225s 0.001s
im_detect: 765/4024 0.225s 0.001s
im_detect: 766/4024 0.225s 0.001s
im_detect: 767/4024 0.225s 0.001s
im_detect: 768/4024 0.225s 0.001s
im_detect: 769/4024 0.225s 0.001s
im_detect: 770/4024 0.225s 0.001s
im_detect: 771/4024 0.225s 0.001s
im_detect: 772/4024 0.225s 0.001s
im_detect: 773/4024 0.225s 0.001s
im_detect: 774/4024 0.225s 0.001s
im_detect: 775/4024 0.225s 0.001s
im_detect: 776/4024 0.225s 0.001s
im_detect: 777/4024 0.225s 0.001s
im_detect: 778/4024 0.225s 0.001s
im_detect: 779/4024 0.225s 0.001s
im_detect: 780/4024 0.225s 0.001s
im_detect: 781/4024 0.225s 0.001s
im_detect: 782/4024 0.225s 0.001s
im_detect: 783/4024 0.225s 0.001s
im_detect: 784/4024 0.225s 0.001s
im_detect: 785/4024 0.225s 0.001s
im_detect: 786/4024 0.225s 0.001s
im_detect: 787/4024 0.225s 0.001s
im_detect: 788/4024 0.225s 0.001s
im_detect: 789/4024 0.225s 0.001s
im_detect: 790/4024 0.225s 0.001s
im_detect: 791/4024 0.225s 0.001s
im_detect: 792/4024 0.225s 0.001s
im_detect: 793/4024 0.225s 0.001s
im_detect: 794/4024 0.225s 0.001s
im_detect: 795/4024 0.225s 0.001s
im_detect: 796/4024 0.225s 0.001s
im_detect: 797/4024 0.225s 0.001s
im_detect: 798/4024 0.225s 0.001s
im_detect: 799/4024 0.225s 0.001s
im_detect: 800/4024 0.225s 0.001s
im_detect: 801/4024 0.225s 0.001s
im_detect: 802/4024 0.225s 0.001s
im_detect: 803/4024 0.225s 0.001s
im_detect: 804/4024 0.225s 0.001s
im_detect: 805/4024 0.225s 0.001s
im_detect: 806/4024 0.225s 0.001s
im_detect: 807/4024 0.225s 0.001s
im_detect: 808/4024 0.225s 0.001s
im_detect: 809/4024 0.225s 0.001s
im_detect: 810/4024 0.225s 0.001s
im_detect: 811/4024 0.225s 0.001s
im_detect: 812/4024 0.225s 0.001s
im_detect: 813/4024 0.225s 0.001s
im_detect: 814/4024 0.225s 0.001s
im_detect: 815/4024 0.225s 0.001s
im_detect: 816/4024 0.225s 0.001s
im_detect: 817/4024 0.225s 0.001s
im_detect: 818/4024 0.225s 0.001s
im_detect: 819/4024 0.225s 0.001s
im_detect: 820/4024 0.225s 0.001s
im_detect: 821/4024 0.225s 0.001s
im_detect: 822/4024 0.225s 0.001s
im_detect: 823/4024 0.225s 0.001s
im_detect: 824/4024 0.225s 0.001s
im_detect: 825/4024 0.225s 0.001s
im_detect: 826/4024 0.225s 0.001s
im_detect: 827/4024 0.225s 0.001s
im_detect: 828/4024 0.225s 0.001s
im_detect: 829/4024 0.225s 0.001s
im_detect: 830/4024 0.225s 0.001s
im_detect: 831/4024 0.225s 0.001s
im_detect: 832/4024 0.225s 0.001s
im_detect: 833/4024 0.225s 0.001s
im_detect: 834/4024 0.225s 0.001s
im_detect: 835/4024 0.225s 0.001s
im_detect: 836/4024 0.225s 0.001s
im_detect: 837/4024 0.225s 0.001s
im_detect: 838/4024 0.225s 0.001s
im_detect: 839/4024 0.225s 0.001s
im_detect: 840/4024 0.225s 0.001s
im_detect: 841/4024 0.225s 0.001s
im_detect: 842/4024 0.225s 0.001s
im_detect: 843/4024 0.225s 0.001s
im_detect: 844/4024 0.225s 0.001s
im_detect: 845/4024 0.225s 0.001s
im_detect: 846/4024 0.225s 0.001s
im_detect: 847/4024 0.225s 0.001s
im_detect: 848/4024 0.225s 0.001s
im_detect: 849/4024 0.225s 0.001s
im_detect: 850/4024 0.225s 0.001s
im_detect: 851/4024 0.225s 0.001s
im_detect: 852/4024 0.225s 0.001s
im_detect: 853/4024 0.225s 0.001s
im_detect: 854/4024 0.225s 0.001s
im_detect: 855/4024 0.225s 0.001s
im_detect: 856/4024 0.225s 0.001s
im_detect: 857/4024 0.225s 0.001s
im_detect: 858/4024 0.225s 0.001s
im_detect: 859/4024 0.225s 0.001s
im_detect: 860/4024 0.225s 0.001s
im_detect: 861/4024 0.225s 0.001s
im_detect: 862/4024 0.225s 0.001s
im_detect: 863/4024 0.225s 0.001s
im_detect: 864/4024 0.225s 0.001s
im_detect: 865/4024 0.225s 0.001s
im_detect: 866/4024 0.225s 0.001s
im_detect: 867/4024 0.225s 0.001s
im_detect: 868/4024 0.225s 0.001s
im_detect: 869/4024 0.225s 0.001s
im_detect: 870/4024 0.225s 0.001s
im_detect: 871/4024 0.225s 0.001s
im_detect: 872/4024 0.225s 0.001s
im_detect: 873/4024 0.225s 0.001s
im_detect: 874/4024 0.225s 0.001s
im_detect: 875/4024 0.225s 0.001s
im_detect: 876/4024 0.225s 0.001s
im_detect: 877/4024 0.225s 0.001s
im_detect: 878/4024 0.225s 0.001s
im_detect: 879/4024 0.225s 0.001s
im_detect: 880/4024 0.225s 0.001s
im_detect: 881/4024 0.225s 0.001s
im_detect: 882/4024 0.225s 0.001s
im_detect: 883/4024 0.225s 0.001s
im_detect: 884/4024 0.225s 0.001s
im_detect: 885/4024 0.225s 0.001s
im_detect: 886/4024 0.225s 0.001s
im_detect: 887/4024 0.225s 0.001s
im_detect: 888/4024 0.225s 0.001s
im_detect: 889/4024 0.225s 0.001s
im_detect: 890/4024 0.225s 0.001s
im_detect: 891/4024 0.225s 0.001s
im_detect: 892/4024 0.225s 0.001s
im_detect: 893/4024 0.225s 0.001s
im_detect: 894/4024 0.225s 0.001s
im_detect: 895/4024 0.225s 0.001s
im_detect: 896/4024 0.225s 0.001s
im_detect: 897/4024 0.225s 0.001s
im_detect: 898/4024 0.225s 0.001s
im_detect: 899/4024 0.225s 0.001s
im_detect: 900/4024 0.225s 0.001s
im_detect: 901/4024 0.225s 0.001s
im_detect: 902/4024 0.225s 0.001s
im_detect: 903/4024 0.225s 0.001s
im_detect: 904/4024 0.225s 0.001s
im_detect: 905/4024 0.225s 0.001s
im_detect: 906/4024 0.225s 0.001s
im_detect: 907/4024 0.225s 0.001s
im_detect: 908/4024 0.225s 0.001s
im_detect: 909/4024 0.225s 0.001s
im_detect: 910/4024 0.225s 0.001s
im_detect: 911/4024 0.225s 0.001s
im_detect: 912/4024 0.225s 0.001s
im_detect: 913/4024 0.225s 0.001s
im_detect: 914/4024 0.225s 0.001s
im_detect: 915/4024 0.225s 0.001s
im_detect: 916/4024 0.225s 0.001s
im_detect: 917/4024 0.225s 0.001s
im_detect: 918/4024 0.225s 0.001s
im_detect: 919/4024 0.225s 0.001s
im_detect: 920/4024 0.225s 0.001s
im_detect: 921/4024 0.225s 0.001s
im_detect: 922/4024 0.225s 0.001s
im_detect: 923/4024 0.225s 0.001s
im_detect: 924/4024 0.225s 0.001s
im_detect: 925/4024 0.225s 0.001s
im_detect: 926/4024 0.225s 0.001s
im_detect: 927/4024 0.225s 0.001s
im_detect: 928/4024 0.225s 0.001s
im_detect: 929/4024 0.225s 0.001s
im_detect: 930/4024 0.225s 0.001s
im_detect: 931/4024 0.225s 0.001s
im_detect: 932/4024 0.225s 0.001s
im_detect: 933/4024 0.225s 0.001s
im_detect: 934/4024 0.225s 0.001s
im_detect: 935/4024 0.225s 0.001s
im_detect: 936/4024 0.225s 0.001s
im_detect: 937/4024 0.225s 0.001s
im_detect: 938/4024 0.225s 0.001s
im_detect: 939/4024 0.225s 0.001s
im_detect: 940/4024 0.225s 0.001s
im_detect: 941/4024 0.225s 0.001s
im_detect: 942/4024 0.225s 0.001s
im_detect: 943/4024 0.225s 0.001s
im_detect: 944/4024 0.225s 0.001s
im_detect: 945/4024 0.225s 0.001s
im_detect: 946/4024 0.225s 0.001s
im_detect: 947/4024 0.225s 0.001s
im_detect: 948/4024 0.225s 0.001s
im_detect: 949/4024 0.225s 0.001s
im_detect: 950/4024 0.225s 0.001s
im_detect: 951/4024 0.225s 0.001s
im_detect: 952/4024 0.225s 0.001s
im_detect: 953/4024 0.225s 0.001s
im_detect: 954/4024 0.225s 0.001s
im_detect: 955/4024 0.225s 0.001s
im_detect: 956/4024 0.225s 0.001s
im_detect: 957/4024 0.225s 0.001s
im_detect: 958/4024 0.225s 0.001s
im_detect: 959/4024 0.225s 0.001s
im_detect: 960/4024 0.225s 0.001s
im_detect: 961/4024 0.225s 0.001s
im_detect: 962/4024 0.225s 0.001s
im_detect: 963/4024 0.225s 0.001s
im_detect: 964/4024 0.225s 0.001s
im_detect: 965/4024 0.225s 0.001s
im_detect: 966/4024 0.225s 0.001s
im_detect: 967/4024 0.225s 0.001s
im_detect: 968/4024 0.225s 0.001s
im_detect: 969/4024 0.225s 0.001s
im_detect: 970/4024 0.225s 0.001s
im_detect: 971/4024 0.225s 0.001s
im_detect: 972/4024 0.225s 0.001s
im_detect: 973/4024 0.225s 0.001s
im_detect: 974/4024 0.225s 0.001s
im_detect: 975/4024 0.225s 0.001s
im_detect: 976/4024 0.225s 0.001s
im_detect: 977/4024 0.225s 0.001s
im_detect: 978/4024 0.225s 0.001s
im_detect: 979/4024 0.225s 0.001s
im_detect: 980/4024 0.225s 0.001s
im_detect: 981/4024 0.225s 0.001s
im_detect: 982/4024 0.225s 0.001s
im_detect: 983/4024 0.225s 0.001s
im_detect: 984/4024 0.225s 0.001s
im_detect: 985/4024 0.225s 0.001s
im_detect: 986/4024 0.225s 0.001s
im_detect: 987/4024 0.225s 0.001s
im_detect: 988/4024 0.225s 0.001s
im_detect: 989/4024 0.225s 0.001s
im_detect: 990/4024 0.225s 0.001s
im_detect: 991/4024 0.225s 0.001s
im_detect: 992/4024 0.225s 0.001s
im_detect: 993/4024 0.225s 0.001s
im_detect: 994/4024 0.225s 0.001s
im_detect: 995/4024 0.225s 0.001s
im_detect: 996/4024 0.225s 0.001s
im_detect: 997/4024 0.225s 0.001s
im_detect: 998/4024 0.225s 0.001s
im_detect: 999/4024 0.226s 0.001s
im_detect: 1000/4024 0.226s 0.001s
im_detect: 1001/4024 0.226s 0.001s
im_detect: 1002/4024 0.226s 0.001s
im_detect: 1003/4024 0.226s 0.001s
im_detect: 1004/4024 0.226s 0.001s
im_detect: 1005/4024 0.226s 0.001s
im_detect: 1006/4024 0.226s 0.001s
im_detect: 1007/4024 0.226s 0.001s
im_detect: 1008/4024 0.226s 0.001s
im_detect: 1009/4024 0.225s 0.001s
im_detect: 1010/4024 0.225s 0.001s
im_detect: 1011/4024 0.225s 0.001s
im_detect: 1012/4024 0.225s 0.001s
im_detect: 1013/4024 0.225s 0.001s
im_detect: 1014/4024 0.225s 0.001s
im_detect: 1015/4024 0.225s 0.001s
im_detect: 1016/4024 0.225s 0.001s
im_detect: 1017/4024 0.225s 0.001s
im_detect: 1018/4024 0.225s 0.001s
im_detect: 1019/4024 0.225s 0.001s
im_detect: 1020/4024 0.225s 0.001s
im_detect: 1021/4024 0.225s 0.001s
im_detect: 1022/4024 0.225s 0.001s
im_detect: 1023/4024 0.225s 0.001s
im_detect: 1024/4024 0.225s 0.001s
im_detect: 1025/4024 0.225s 0.001s
im_detect: 1026/4024 0.225s 0.001s
im_detect: 1027/4024 0.225s 0.001s
im_detect: 1028/4024 0.225s 0.001s
im_detect: 1029/4024 0.225s 0.001s
im_detect: 1030/4024 0.225s 0.001s
im_detect: 1031/4024 0.225s 0.001s
im_detect: 1032/4024 0.225s 0.001s
im_detect: 1033/4024 0.225s 0.001s
im_detect: 1034/4024 0.225s 0.001s
im_detect: 1035/4024 0.225s 0.001s
im_detect: 1036/4024 0.225s 0.001s
im_detect: 1037/4024 0.225s 0.001s
im_detect: 1038/4024 0.225s 0.001s
im_detect: 1039/4024 0.225s 0.001s
im_detect: 1040/4024 0.225s 0.001s
im_detect: 1041/4024 0.225s 0.001s
im_detect: 1042/4024 0.225s 0.001s
im_detect: 1043/4024 0.225s 0.001s
im_detect: 1044/4024 0.225s 0.001s
im_detect: 1045/4024 0.225s 0.001s
im_detect: 1046/4024 0.225s 0.001s
im_detect: 1047/4024 0.225s 0.001s
im_detect: 1048/4024 0.225s 0.001s
im_detect: 1049/4024 0.225s 0.001s
im_detect: 1050/4024 0.225s 0.001s
im_detect: 1051/4024 0.225s 0.001s
im_detect: 1052/4024 0.225s 0.001s
im_detect: 1053/4024 0.225s 0.001s
im_detect: 1054/4024 0.225s 0.001s
im_detect: 1055/4024 0.225s 0.001s
im_detect: 1056/4024 0.225s 0.001s
im_detect: 1057/4024 0.225s 0.001s
im_detect: 1058/4024 0.225s 0.001s
im_detect: 1059/4024 0.225s 0.001s
im_detect: 1060/4024 0.225s 0.001s
im_detect: 1061/4024 0.225s 0.001s
im_detect: 1062/4024 0.225s 0.001s
im_detect: 1063/4024 0.225s 0.001s
im_detect: 1064/4024 0.225s 0.001s
im_detect: 1065/4024 0.225s 0.001s
im_detect: 1066/4024 0.225s 0.001s
im_detect: 1067/4024 0.225s 0.001s
im_detect: 1068/4024 0.225s 0.001s
im_detect: 1069/4024 0.225s 0.001s
im_detect: 1070/4024 0.225s 0.001s
im_detect: 1071/4024 0.225s 0.001s
im_detect: 1072/4024 0.225s 0.001s
im_detect: 1073/4024 0.225s 0.001s
im_detect: 1074/4024 0.225s 0.001s
im_detect: 1075/4024 0.225s 0.001s
im_detect: 1076/4024 0.225s 0.001s
im_detect: 1077/4024 0.225s 0.001s
im_detect: 1078/4024 0.225s 0.001s
im_detect: 1079/4024 0.225s 0.001s
im_detect: 1080/4024 0.225s 0.001s
im_detect: 1081/4024 0.225s 0.001s
im_detect: 1082/4024 0.225s 0.001s
im_detect: 1083/4024 0.225s 0.001s
im_detect: 1084/4024 0.225s 0.001s
im_detect: 1085/4024 0.225s 0.001s
im_detect: 1086/4024 0.225s 0.001s
im_detect: 1087/4024 0.225s 0.001s
im_detect: 1088/4024 0.225s 0.001s
im_detect: 1089/4024 0.225s 0.001s
im_detect: 1090/4024 0.225s 0.001s
im_detect: 1091/4024 0.225s 0.001s
im_detect: 1092/4024 0.225s 0.001s
im_detect: 1093/4024 0.225s 0.001s
im_detect: 1094/4024 0.225s 0.001s
im_detect: 1095/4024 0.225s 0.001s
im_detect: 1096/4024 0.225s 0.001s
im_detect: 1097/4024 0.225s 0.001s
im_detect: 1098/4024 0.225s 0.001s
im_detect: 1099/4024 0.225s 0.001s
im_detect: 1100/4024 0.225s 0.001s
im_detect: 1101/4024 0.225s 0.001s
im_detect: 1102/4024 0.225s 0.001s
im_detect: 1103/4024 0.225s 0.001s
im_detect: 1104/4024 0.225s 0.001s
im_detect: 1105/4024 0.225s 0.001s
im_detect: 1106/4024 0.225s 0.001s
im_detect: 1107/4024 0.225s 0.001s
im_detect: 1108/4024 0.225s 0.001s
im_detect: 1109/4024 0.225s 0.001s
im_detect: 1110/4024 0.225s 0.001s
im_detect: 1111/4024 0.225s 0.001s
im_detect: 1112/4024 0.225s 0.001s
im_detect: 1113/4024 0.225s 0.001s
im_detect: 1114/4024 0.225s 0.001s
im_detect: 1115/4024 0.225s 0.001s
im_detect: 1116/4024 0.225s 0.001s
im_detect: 1117/4024 0.225s 0.001s
im_detect: 1118/4024 0.225s 0.001s
im_detect: 1119/4024 0.225s 0.001s
im_detect: 1120/4024 0.225s 0.001s
im_detect: 1121/4024 0.225s 0.001s
im_detect: 1122/4024 0.225s 0.001s
im_detect: 1123/4024 0.225s 0.001s
im_detect: 1124/4024 0.225s 0.001s
im_detect: 1125/4024 0.225s 0.001s
im_detect: 1126/4024 0.225s 0.001s
im_detect: 1127/4024 0.225s 0.001s
im_detect: 1128/4024 0.225s 0.001s
im_detect: 1129/4024 0.225s 0.001s
im_detect: 1130/4024 0.225s 0.001s
im_detect: 1131/4024 0.225s 0.001s
im_detect: 1132/4024 0.225s 0.001s
im_detect: 1133/4024 0.225s 0.001s
im_detect: 1134/4024 0.225s 0.001s
im_detect: 1135/4024 0.225s 0.001s
im_detect: 1136/4024 0.225s 0.001s
im_detect: 1137/4024 0.225s 0.001s
im_detect: 1138/4024 0.225s 0.001s
im_detect: 1139/4024 0.225s 0.001s
im_detect: 1140/4024 0.225s 0.001s
im_detect: 1141/4024 0.225s 0.001s
im_detect: 1142/4024 0.225s 0.001s
im_detect: 1143/4024 0.225s 0.001s
im_detect: 1144/4024 0.225s 0.001s
im_detect: 1145/4024 0.225s 0.001s
im_detect: 1146/4024 0.225s 0.001s
im_detect: 1147/4024 0.225s 0.001s
im_detect: 1148/4024 0.225s 0.001s
im_detect: 1149/4024 0.225s 0.001s
im_detect: 1150/4024 0.225s 0.001s
im_detect: 1151/4024 0.225s 0.001s
im_detect: 1152/4024 0.225s 0.001s
im_detect: 1153/4024 0.225s 0.001s
im_detect: 1154/4024 0.225s 0.001s
im_detect: 1155/4024 0.225s 0.001s
im_detect: 1156/4024 0.225s 0.001s
im_detect: 1157/4024 0.225s 0.001s
im_detect: 1158/4024 0.225s 0.001s
im_detect: 1159/4024 0.225s 0.001s
im_detect: 1160/4024 0.225s 0.001s
im_detect: 1161/4024 0.225s 0.001s
im_detect: 1162/4024 0.225s 0.001s
im_detect: 1163/4024 0.225s 0.001s
im_detect: 1164/4024 0.225s 0.001s
im_detect: 1165/4024 0.225s 0.001s
im_detect: 1166/4024 0.225s 0.001s
im_detect: 1167/4024 0.225s 0.001s
im_detect: 1168/4024 0.225s 0.001s
im_detect: 1169/4024 0.225s 0.001s
im_detect: 1170/4024 0.225s 0.001s
im_detect: 1171/4024 0.225s 0.001s
im_detect: 1172/4024 0.225s 0.001s
im_detect: 1173/4024 0.225s 0.001s
im_detect: 1174/4024 0.225s 0.001s
im_detect: 1175/4024 0.225s 0.001s
im_detect: 1176/4024 0.225s 0.001s
im_detect: 1177/4024 0.225s 0.001s
im_detect: 1178/4024 0.225s 0.001s
im_detect: 1179/4024 0.225s 0.001s
im_detect: 1180/4024 0.225s 0.001s
im_detect: 1181/4024 0.225s 0.001s
im_detect: 1182/4024 0.225s 0.001s
im_detect: 1183/4024 0.225s 0.001s
im_detect: 1184/4024 0.225s 0.001s
im_detect: 1185/4024 0.225s 0.001s
im_detect: 1186/4024 0.225s 0.001s
im_detect: 1187/4024 0.225s 0.001s
im_detect: 1188/4024 0.225s 0.001s
im_detect: 1189/4024 0.225s 0.001s
im_detect: 1190/4024 0.225s 0.001s
im_detect: 1191/4024 0.225s 0.001s
im_detect: 1192/4024 0.225s 0.001s
im_detect: 1193/4024 0.225s 0.001s
im_detect: 1194/4024 0.225s 0.001s
im_detect: 1195/4024 0.225s 0.001s
im_detect: 1196/4024 0.225s 0.001s
im_detect: 1197/4024 0.225s 0.001s
im_detect: 1198/4024 0.225s 0.001s
im_detect: 1199/4024 0.225s 0.001s
im_detect: 1200/4024 0.225s 0.001s
im_detect: 1201/4024 0.225s 0.001s
im_detect: 1202/4024 0.225s 0.001s
im_detect: 1203/4024 0.225s 0.001s
im_detect: 1204/4024 0.225s 0.001s
im_detect: 1205/4024 0.225s 0.001s
im_detect: 1206/4024 0.225s 0.001s
im_detect: 1207/4024 0.225s 0.001s
im_detect: 1208/4024 0.225s 0.001s
im_detect: 1209/4024 0.225s 0.001s
im_detect: 1210/4024 0.225s 0.001s
im_detect: 1211/4024 0.225s 0.001s
im_detect: 1212/4024 0.225s 0.001s
im_detect: 1213/4024 0.225s 0.001s
im_detect: 1214/4024 0.225s 0.001s
im_detect: 1215/4024 0.225s 0.001s
im_detect: 1216/4024 0.225s 0.001s
im_detect: 1217/4024 0.225s 0.001s
im_detect: 1218/4024 0.225s 0.001s
im_detect: 1219/4024 0.225s 0.001s
im_detect: 1220/4024 0.225s 0.001s
im_detect: 1221/4024 0.225s 0.001s
im_detect: 1222/4024 0.225s 0.001s
im_detect: 1223/4024 0.225s 0.001s
im_detect: 1224/4024 0.225s 0.001s
im_detect: 1225/4024 0.225s 0.001s
im_detect: 1226/4024 0.225s 0.001s
im_detect: 1227/4024 0.225s 0.001s
im_detect: 1228/4024 0.225s 0.001s
im_detect: 1229/4024 0.225s 0.001s
im_detect: 1230/4024 0.225s 0.001s
im_detect: 1231/4024 0.225s 0.001s
im_detect: 1232/4024 0.225s 0.001s
im_detect: 1233/4024 0.225s 0.001s
im_detect: 1234/4024 0.225s 0.001s
im_detect: 1235/4024 0.225s 0.001s
im_detect: 1236/4024 0.225s 0.001s
im_detect: 1237/4024 0.225s 0.001s
im_detect: 1238/4024 0.225s 0.001s
im_detect: 1239/4024 0.225s 0.001s
im_detect: 1240/4024 0.225s 0.001s
im_detect: 1241/4024 0.225s 0.001s
im_detect: 1242/4024 0.225s 0.001s
im_detect: 1243/4024 0.225s 0.001s
im_detect: 1244/4024 0.225s 0.001s
im_detect: 1245/4024 0.225s 0.001s
im_detect: 1246/4024 0.225s 0.001s
im_detect: 1247/4024 0.225s 0.001s
im_detect: 1248/4024 0.225s 0.001s
im_detect: 1249/4024 0.225s 0.001s
im_detect: 1250/4024 0.225s 0.001s
im_detect: 1251/4024 0.225s 0.001s
im_detect: 1252/4024 0.225s 0.001s
im_detect: 1253/4024 0.225s 0.001s
im_detect: 1254/4024 0.225s 0.001s
im_detect: 1255/4024 0.225s 0.001s
im_detect: 1256/4024 0.225s 0.001s
im_detect: 1257/4024 0.225s 0.001s
im_detect: 1258/4024 0.225s 0.001s
im_detect: 1259/4024 0.225s 0.001s
im_detect: 1260/4024 0.225s 0.001s
im_detect: 1261/4024 0.225s 0.001s
im_detect: 1262/4024 0.225s 0.001s
im_detect: 1263/4024 0.225s 0.001s
im_detect: 1264/4024 0.225s 0.001s
im_detect: 1265/4024 0.225s 0.001s
im_detect: 1266/4024 0.225s 0.001s
im_detect: 1267/4024 0.225s 0.001s
im_detect: 1268/4024 0.225s 0.001s
im_detect: 1269/4024 0.225s 0.001s
im_detect: 1270/4024 0.225s 0.001s
im_detect: 1271/4024 0.225s 0.001s
im_detect: 1272/4024 0.225s 0.001s
im_detect: 1273/4024 0.225s 0.001s
im_detect: 1274/4024 0.225s 0.001s
im_detect: 1275/4024 0.225s 0.001s
im_detect: 1276/4024 0.225s 0.001s
im_detect: 1277/4024 0.225s 0.001s
im_detect: 1278/4024 0.225s 0.001s
im_detect: 1279/4024 0.225s 0.001s
im_detect: 1280/4024 0.225s 0.001s
im_detect: 1281/4024 0.225s 0.001s
im_detect: 1282/4024 0.225s 0.001s
im_detect: 1283/4024 0.225s 0.001s
im_detect: 1284/4024 0.225s 0.001s
im_detect: 1285/4024 0.225s 0.001s
im_detect: 1286/4024 0.225s 0.001s
im_detect: 1287/4024 0.225s 0.001s
im_detect: 1288/4024 0.225s 0.001s
im_detect: 1289/4024 0.225s 0.001s
im_detect: 1290/4024 0.225s 0.001s
im_detect: 1291/4024 0.225s 0.001s
im_detect: 1292/4024 0.225s 0.001s
im_detect: 1293/4024 0.225s 0.001s
im_detect: 1294/4024 0.225s 0.001s
im_detect: 1295/4024 0.225s 0.001s
im_detect: 1296/4024 0.225s 0.001s
im_detect: 1297/4024 0.225s 0.001s
im_detect: 1298/4024 0.225s 0.001s
im_detect: 1299/4024 0.225s 0.001s
im_detect: 1300/4024 0.225s 0.001s
im_detect: 1301/4024 0.225s 0.001s
im_detect: 1302/4024 0.225s 0.001s
im_detect: 1303/4024 0.225s 0.001s
im_detect: 1304/4024 0.225s 0.001s
im_detect: 1305/4024 0.225s 0.001s
im_detect: 1306/4024 0.225s 0.001s
im_detect: 1307/4024 0.225s 0.001s
im_detect: 1308/4024 0.225s 0.001s
im_detect: 1309/4024 0.225s 0.001s
im_detect: 1310/4024 0.225s 0.001s
im_detect: 1311/4024 0.225s 0.001s
im_detect: 1312/4024 0.225s 0.001s
im_detect: 1313/4024 0.225s 0.001s
im_detect: 1314/4024 0.225s 0.001s
im_detect: 1315/4024 0.225s 0.001s
im_detect: 1316/4024 0.225s 0.001s
im_detect: 1317/4024 0.225s 0.001s
im_detect: 1318/4024 0.225s 0.001s
im_detect: 1319/4024 0.225s 0.001s
im_detect: 1320/4024 0.225s 0.001s
im_detect: 1321/4024 0.225s 0.001s
im_detect: 1322/4024 0.225s 0.001s
im_detect: 1323/4024 0.225s 0.001s
im_detect: 1324/4024 0.225s 0.001s
im_detect: 1325/4024 0.225s 0.001s
im_detect: 1326/4024 0.225s 0.001s
im_detect: 1327/4024 0.225s 0.001s
im_detect: 1328/4024 0.225s 0.001s
im_detect: 1329/4024 0.225s 0.001s
im_detect: 1330/4024 0.225s 0.001s
im_detect: 1331/4024 0.225s 0.001s
im_detect: 1332/4024 0.225s 0.001s
im_detect: 1333/4024 0.225s 0.001s
im_detect: 1334/4024 0.225s 0.001s
im_detect: 1335/4024 0.225s 0.001s
im_detect: 1336/4024 0.225s 0.001s
im_detect: 1337/4024 0.225s 0.001s
im_detect: 1338/4024 0.225s 0.001s
im_detect: 1339/4024 0.225s 0.001s
im_detect: 1340/4024 0.225s 0.001s
im_detect: 1341/4024 0.225s 0.001s
im_detect: 1342/4024 0.225s 0.001s
im_detect: 1343/4024 0.225s 0.001s
im_detect: 1344/4024 0.225s 0.001s
im_detect: 1345/4024 0.225s 0.001s
im_detect: 1346/4024 0.225s 0.001s
im_detect: 1347/4024 0.225s 0.001s
im_detect: 1348/4024 0.225s 0.001s
im_detect: 1349/4024 0.225s 0.001s
im_detect: 1350/4024 0.225s 0.001s
im_detect: 1351/4024 0.225s 0.001s
im_detect: 1352/4024 0.225s 0.001s
im_detect: 1353/4024 0.225s 0.001s
im_detect: 1354/4024 0.225s 0.001s
im_detect: 1355/4024 0.225s 0.001s
im_detect: 1356/4024 0.225s 0.001s
im_detect: 1357/4024 0.225s 0.001s
im_detect: 1358/4024 0.225s 0.001s
im_detect: 1359/4024 0.225s 0.001s
im_detect: 1360/4024 0.225s 0.001s
im_detect: 1361/4024 0.225s 0.001s
im_detect: 1362/4024 0.225s 0.001s
im_detect: 1363/4024 0.225s 0.001s
im_detect: 1364/4024 0.225s 0.001s
im_detect: 1365/4024 0.225s 0.001s
im_detect: 1366/4024 0.225s 0.001s
im_detect: 1367/4024 0.225s 0.001s
im_detect: 1368/4024 0.225s 0.001s
im_detect: 1369/4024 0.225s 0.001s
im_detect: 1370/4024 0.225s 0.001s
im_detect: 1371/4024 0.225s 0.001s
im_detect: 1372/4024 0.225s 0.001s
im_detect: 1373/4024 0.225s 0.001s
im_detect: 1374/4024 0.225s 0.001s
im_detect: 1375/4024 0.225s 0.001s
im_detect: 1376/4024 0.225s 0.001s
im_detect: 1377/4024 0.225s 0.001s
im_detect: 1378/4024 0.225s 0.001s
im_detect: 1379/4024 0.225s 0.001s
im_detect: 1380/4024 0.225s 0.001s
im_detect: 1381/4024 0.225s 0.001s
im_detect: 1382/4024 0.225s 0.001s
im_detect: 1383/4024 0.225s 0.001s
im_detect: 1384/4024 0.225s 0.001s
im_detect: 1385/4024 0.225s 0.001s
im_detect: 1386/4024 0.225s 0.001s
im_detect: 1387/4024 0.225s 0.001s
im_detect: 1388/4024 0.225s 0.001s
im_detect: 1389/4024 0.225s 0.001s
im_detect: 1390/4024 0.225s 0.001s
im_detect: 1391/4024 0.225s 0.001s
im_detect: 1392/4024 0.225s 0.001s
im_detect: 1393/4024 0.225s 0.001s
im_detect: 1394/4024 0.225s 0.001s
im_detect: 1395/4024 0.225s 0.001s
im_detect: 1396/4024 0.225s 0.001s
im_detect: 1397/4024 0.225s 0.001s
im_detect: 1398/4024 0.225s 0.001s
im_detect: 1399/4024 0.225s 0.001s
im_detect: 1400/4024 0.225s 0.001s
im_detect: 1401/4024 0.225s 0.001s
im_detect: 1402/4024 0.225s 0.001s
im_detect: 1403/4024 0.225s 0.001s
im_detect: 1404/4024 0.225s 0.001s
im_detect: 1405/4024 0.225s 0.001s
im_detect: 1406/4024 0.225s 0.001s
im_detect: 1407/4024 0.225s 0.001s
im_detect: 1408/4024 0.225s 0.001s
im_detect: 1409/4024 0.225s 0.001s
im_detect: 1410/4024 0.225s 0.001s
im_detect: 1411/4024 0.225s 0.001s
im_detect: 1412/4024 0.225s 0.001s
im_detect: 1413/4024 0.225s 0.001s
im_detect: 1414/4024 0.225s 0.001s
im_detect: 1415/4024 0.225s 0.001s
im_detect: 1416/4024 0.225s 0.001s
im_detect: 1417/4024 0.225s 0.001s
im_detect: 1418/4024 0.225s 0.001s
im_detect: 1419/4024 0.225s 0.001s
im_detect: 1420/4024 0.225s 0.001s
im_detect: 1421/4024 0.225s 0.001s
im_detect: 1422/4024 0.225s 0.001s
im_detect: 1423/4024 0.225s 0.001s
im_detect: 1424/4024 0.225s 0.001s
im_detect: 1425/4024 0.225s 0.001s
im_detect: 1426/4024 0.225s 0.001s
im_detect: 1427/4024 0.225s 0.001s
im_detect: 1428/4024 0.225s 0.001s
im_detect: 1429/4024 0.225s 0.001s
im_detect: 1430/4024 0.225s 0.001s
im_detect: 1431/4024 0.225s 0.001s
im_detect: 1432/4024 0.225s 0.001s
im_detect: 1433/4024 0.225s 0.001s
im_detect: 1434/4024 0.225s 0.001s
im_detect: 1435/4024 0.225s 0.001s
im_detect: 1436/4024 0.225s 0.001s
im_detect: 1437/4024 0.225s 0.001s
im_detect: 1438/4024 0.225s 0.001s
im_detect: 1439/4024 0.225s 0.001s
im_detect: 1440/4024 0.225s 0.001s
im_detect: 1441/4024 0.225s 0.001s
im_detect: 1442/4024 0.225s 0.001s
im_detect: 1443/4024 0.225s 0.001s
im_detect: 1444/4024 0.225s 0.001s
im_detect: 1445/4024 0.225s 0.001s
im_detect: 1446/4024 0.225s 0.001s
im_detect: 1447/4024 0.225s 0.001s
im_detect: 1448/4024 0.225s 0.001s
im_detect: 1449/4024 0.225s 0.001s
im_detect: 1450/4024 0.225s 0.001s
im_detect: 1451/4024 0.225s 0.001s
im_detect: 1452/4024 0.225s 0.001s
im_detect: 1453/4024 0.225s 0.001s
im_detect: 1454/4024 0.225s 0.001s
im_detect: 1455/4024 0.225s 0.001s
im_detect: 1456/4024 0.225s 0.001s
im_detect: 1457/4024 0.225s 0.001s
im_detect: 1458/4024 0.225s 0.001s
im_detect: 1459/4024 0.225s 0.001s
im_detect: 1460/4024 0.225s 0.001s
im_detect: 1461/4024 0.225s 0.001s
im_detect: 1462/4024 0.225s 0.001s
im_detect: 1463/4024 0.225s 0.001s
im_detect: 1464/4024 0.225s 0.001s
im_detect: 1465/4024 0.225s 0.001s
im_detect: 1466/4024 0.225s 0.001s
im_detect: 1467/4024 0.225s 0.001s
im_detect: 1468/4024 0.225s 0.001s
im_detect: 1469/4024 0.225s 0.001s
im_detect: 1470/4024 0.225s 0.001s
im_detect: 1471/4024 0.225s 0.001s
im_detect: 1472/4024 0.225s 0.001s
im_detect: 1473/4024 0.225s 0.001s
im_detect: 1474/4024 0.225s 0.001s
im_detect: 1475/4024 0.225s 0.001s
im_detect: 1476/4024 0.225s 0.001s
im_detect: 1477/4024 0.225s 0.001s
im_detect: 1478/4024 0.225s 0.001s
im_detect: 1479/4024 0.225s 0.001s
im_detect: 1480/4024 0.225s 0.001s
im_detect: 1481/4024 0.225s 0.001s
im_detect: 1482/4024 0.225s 0.001s
im_detect: 1483/4024 0.225s 0.001s
im_detect: 1484/4024 0.225s 0.001s
im_detect: 1485/4024 0.225s 0.001s
im_detect: 1486/4024 0.225s 0.001s
im_detect: 1487/4024 0.225s 0.001s
im_detect: 1488/4024 0.225s 0.001s
im_detect: 1489/4024 0.225s 0.001s
im_detect: 1490/4024 0.225s 0.001s
im_detect: 1491/4024 0.225s 0.001s
im_detect: 1492/4024 0.225s 0.001s
im_detect: 1493/4024 0.225s 0.001s
im_detect: 1494/4024 0.225s 0.001s
im_detect: 1495/4024 0.225s 0.001s
im_detect: 1496/4024 0.225s 0.001s
im_detect: 1497/4024 0.225s 0.001s
im_detect: 1498/4024 0.225s 0.001s
im_detect: 1499/4024 0.225s 0.001s
im_detect: 1500/4024 0.225s 0.001s
im_detect: 1501/4024 0.225s 0.001s
im_detect: 1502/4024 0.225s 0.001s
im_detect: 1503/4024 0.225s 0.001s
im_detect: 1504/4024 0.225s 0.001s
im_detect: 1505/4024 0.225s 0.001s
im_detect: 1506/4024 0.225s 0.001s
im_detect: 1507/4024 0.225s 0.001s
im_detect: 1508/4024 0.225s 0.001s
im_detect: 1509/4024 0.225s 0.001s
im_detect: 1510/4024 0.225s 0.001s
im_detect: 1511/4024 0.225s 0.001s
im_detect: 1512/4024 0.225s 0.001s
im_detect: 1513/4024 0.225s 0.001s
im_detect: 1514/4024 0.225s 0.001s
im_detect: 1515/4024 0.225s 0.001s
im_detect: 1516/4024 0.225s 0.001s
im_detect: 1517/4024 0.225s 0.001s
im_detect: 1518/4024 0.225s 0.001s
im_detect: 1519/4024 0.225s 0.001s
im_detect: 1520/4024 0.225s 0.001s
im_detect: 1521/4024 0.225s 0.001s
im_detect: 1522/4024 0.225s 0.001s
im_detect: 1523/4024 0.225s 0.001s
im_detect: 1524/4024 0.225s 0.001s
im_detect: 1525/4024 0.225s 0.001s
im_detect: 1526/4024 0.225s 0.001s
im_detect: 1527/4024 0.225s 0.001s
im_detect: 1528/4024 0.225s 0.001s
im_detect: 1529/4024 0.225s 0.001s
im_detect: 1530/4024 0.225s 0.001s
im_detect: 1531/4024 0.225s 0.001s
im_detect: 1532/4024 0.225s 0.001s
im_detect: 1533/4024 0.225s 0.001s
im_detect: 1534/4024 0.225s 0.001s
im_detect: 1535/4024 0.225s 0.001s
im_detect: 1536/4024 0.225s 0.001s
im_detect: 1537/4024 0.225s 0.001s
im_detect: 1538/4024 0.225s 0.001s
im_detect: 1539/4024 0.225s 0.001s
im_detect: 1540/4024 0.225s 0.001s
im_detect: 1541/4024 0.225s 0.001s
im_detect: 1542/4024 0.225s 0.001s
im_detect: 1543/4024 0.225s 0.001s
im_detect: 1544/4024 0.225s 0.001s
im_detect: 1545/4024 0.225s 0.001s
im_detect: 1546/4024 0.225s 0.001s
im_detect: 1547/4024 0.225s 0.001s
im_detect: 1548/4024 0.225s 0.001s
im_detect: 1549/4024 0.225s 0.001s
im_detect: 1550/4024 0.225s 0.001s
im_detect: 1551/4024 0.225s 0.001s
im_detect: 1552/4024 0.225s 0.001s
im_detect: 1553/4024 0.225s 0.001s
im_detect: 1554/4024 0.225s 0.001s
im_detect: 1555/4024 0.225s 0.001s
im_detect: 1556/4024 0.225s 0.001s
im_detect: 1557/4024 0.225s 0.001s
im_detect: 1558/4024 0.225s 0.001s
im_detect: 1559/4024 0.225s 0.001s
im_detect: 1560/4024 0.225s 0.001s
im_detect: 1561/4024 0.225s 0.001s
im_detect: 1562/4024 0.225s 0.001s
im_detect: 1563/4024 0.225s 0.001s
im_detect: 1564/4024 0.225s 0.001s
im_detect: 1565/4024 0.225s 0.001s
im_detect: 1566/4024 0.225s 0.001s
im_detect: 1567/4024 0.225s 0.001s
im_detect: 1568/4024 0.225s 0.001s
im_detect: 1569/4024 0.225s 0.001s
im_detect: 1570/4024 0.225s 0.001s
im_detect: 1571/4024 0.225s 0.001s
im_detect: 1572/4024 0.225s 0.001s
im_detect: 1573/4024 0.225s 0.001s
im_detect: 1574/4024 0.225s 0.001s
im_detect: 1575/4024 0.225s 0.001s
im_detect: 1576/4024 0.225s 0.001s
im_detect: 1577/4024 0.225s 0.001s
im_detect: 1578/4024 0.225s 0.001s
im_detect: 1579/4024 0.225s 0.001s
im_detect: 1580/4024 0.225s 0.001s
im_detect: 1581/4024 0.225s 0.001s
im_detect: 1582/4024 0.225s 0.001s
im_detect: 1583/4024 0.225s 0.001s
im_detect: 1584/4024 0.225s 0.001s
im_detect: 1585/4024 0.225s 0.001s
im_detect: 1586/4024 0.225s 0.001s
im_detect: 1587/4024 0.225s 0.001s
im_detect: 1588/4024 0.225s 0.001s
im_detect: 1589/4024 0.225s 0.001s
im_detect: 1590/4024 0.225s 0.001s
im_detect: 1591/4024 0.225s 0.001s
im_detect: 1592/4024 0.225s 0.001s
im_detect: 1593/4024 0.225s 0.001s
im_detect: 1594/4024 0.225s 0.001s
im_detect: 1595/4024 0.225s 0.001s
im_detect: 1596/4024 0.225s 0.001s
im_detect: 1597/4024 0.225s 0.001s
im_detect: 1598/4024 0.225s 0.001s
im_detect: 1599/4024 0.225s 0.001s
im_detect: 1600/4024 0.225s 0.001s
im_detect: 1601/4024 0.225s 0.001s
im_detect: 1602/4024 0.225s 0.001s
im_detect: 1603/4024 0.225s 0.001s
im_detect: 1604/4024 0.225s 0.001s
im_detect: 1605/4024 0.225s 0.001s
im_detect: 1606/4024 0.225s 0.001s
im_detect: 1607/4024 0.225s 0.001s
im_detect: 1608/4024 0.225s 0.001s
im_detect: 1609/4024 0.225s 0.001s
im_detect: 1610/4024 0.225s 0.001s
im_detect: 1611/4024 0.225s 0.001s
im_detect: 1612/4024 0.225s 0.001s
im_detect: 1613/4024 0.225s 0.001s
im_detect: 1614/4024 0.225s 0.001s
im_detect: 1615/4024 0.225s 0.001s
im_detect: 1616/4024 0.225s 0.001s
im_detect: 1617/4024 0.225s 0.001s
im_detect: 1618/4024 0.225s 0.001s
im_detect: 1619/4024 0.225s 0.001s
im_detect: 1620/4024 0.225s 0.001s
im_detect: 1621/4024 0.225s 0.001s
im_detect: 1622/4024 0.225s 0.001s
im_detect: 1623/4024 0.225s 0.001s
im_detect: 1624/4024 0.225s 0.001s
im_detect: 1625/4024 0.225s 0.001s
im_detect: 1626/4024 0.225s 0.001s
im_detect: 1627/4024 0.225s 0.001s
im_detect: 1628/4024 0.225s 0.001s
im_detect: 1629/4024 0.225s 0.001s
im_detect: 1630/4024 0.225s 0.001s
im_detect: 1631/4024 0.225s 0.001s
im_detect: 1632/4024 0.225s 0.001s
im_detect: 1633/4024 0.225s 0.001s
im_detect: 1634/4024 0.225s 0.001s
im_detect: 1635/4024 0.225s 0.001s
im_detect: 1636/4024 0.225s 0.001s
im_detect: 1637/4024 0.225s 0.001s
im_detect: 1638/4024 0.225s 0.001s
im_detect: 1639/4024 0.225s 0.001s
im_detect: 1640/4024 0.225s 0.001s
im_detect: 1641/4024 0.225s 0.001s
im_detect: 1642/4024 0.225s 0.001s
im_detect: 1643/4024 0.225s 0.001s
im_detect: 1644/4024 0.225s 0.001s
im_detect: 1645/4024 0.225s 0.001s
im_detect: 1646/4024 0.225s 0.001s
im_detect: 1647/4024 0.225s 0.001s
im_detect: 1648/4024 0.225s 0.001s
im_detect: 1649/4024 0.225s 0.001s
im_detect: 1650/4024 0.225s 0.001s
im_detect: 1651/4024 0.225s 0.001s
im_detect: 1652/4024 0.225s 0.001s
im_detect: 1653/4024 0.225s 0.001s
im_detect: 1654/4024 0.225s 0.001s
im_detect: 1655/4024 0.225s 0.001s
im_detect: 1656/4024 0.225s 0.001s
im_detect: 1657/4024 0.225s 0.001s
im_detect: 1658/4024 0.225s 0.001s
im_detect: 1659/4024 0.225s 0.001s
im_detect: 1660/4024 0.225s 0.001s
im_detect: 1661/4024 0.225s 0.001s
im_detect: 1662/4024 0.225s 0.001s
im_detect: 1663/4024 0.225s 0.001s
im_detect: 1664/4024 0.225s 0.001s
im_detect: 1665/4024 0.225s 0.001s
im_detect: 1666/4024 0.225s 0.001s
im_detect: 1667/4024 0.225s 0.001s
im_detect: 1668/4024 0.225s 0.001s
im_detect: 1669/4024 0.225s 0.001s
im_detect: 1670/4024 0.225s 0.001s
im_detect: 1671/4024 0.225s 0.001s
im_detect: 1672/4024 0.225s 0.001s
im_detect: 1673/4024 0.225s 0.001s
im_detect: 1674/4024 0.225s 0.001s
im_detect: 1675/4024 0.225s 0.001s
im_detect: 1676/4024 0.225s 0.001s
im_detect: 1677/4024 0.225s 0.001s
im_detect: 1678/4024 0.225s 0.001s
im_detect: 1679/4024 0.225s 0.001s
im_detect: 1680/4024 0.225s 0.001s
im_detect: 1681/4024 0.225s 0.001s
im_detect: 1682/4024 0.225s 0.001s
im_detect: 1683/4024 0.225s 0.001s
im_detect: 1684/4024 0.225s 0.001s
im_detect: 1685/4024 0.225s 0.001s
im_detect: 1686/4024 0.225s 0.001s
im_detect: 1687/4024 0.225s 0.001s
im_detect: 1688/4024 0.225s 0.001s
im_detect: 1689/4024 0.225s 0.001s
im_detect: 1690/4024 0.225s 0.001s
im_detect: 1691/4024 0.225s 0.001s
im_detect: 1692/4024 0.225s 0.001s
im_detect: 1693/4024 0.225s 0.001s
im_detect: 1694/4024 0.225s 0.001s
im_detect: 1695/4024 0.225s 0.001s
im_detect: 1696/4024 0.225s 0.001s
im_detect: 1697/4024 0.225s 0.001s
im_detect: 1698/4024 0.225s 0.001s
im_detect: 1699/4024 0.225s 0.001s
im_detect: 1700/4024 0.225s 0.001s
im_detect: 1701/4024 0.225s 0.001s
im_detect: 1702/4024 0.225s 0.001s
im_detect: 1703/4024 0.225s 0.001s
im_detect: 1704/4024 0.225s 0.001s
im_detect: 1705/4024 0.225s 0.001s
im_detect: 1706/4024 0.225s 0.001s
im_detect: 1707/4024 0.225s 0.001s
im_detect: 1708/4024 0.225s 0.001s
im_detect: 1709/4024 0.225s 0.001s
im_detect: 1710/4024 0.225s 0.001s
im_detect: 1711/4024 0.225s 0.001s
im_detect: 1712/4024 0.225s 0.001s
im_detect: 1713/4024 0.225s 0.001s
im_detect: 1714/4024 0.225s 0.001s
im_detect: 1715/4024 0.225s 0.001s
im_detect: 1716/4024 0.225s 0.001s
im_detect: 1717/4024 0.225s 0.001s
im_detect: 1718/4024 0.225s 0.001s
im_detect: 1719/4024 0.225s 0.001s
im_detect: 1720/4024 0.225s 0.001s
im_detect: 1721/4024 0.225s 0.001s
im_detect: 1722/4024 0.225s 0.001s
im_detect: 1723/4024 0.225s 0.001s
im_detect: 1724/4024 0.225s 0.001s
im_detect: 1725/4024 0.225s 0.001s
im_detect: 1726/4024 0.225s 0.001s
im_detect: 1727/4024 0.225s 0.001s
im_detect: 1728/4024 0.225s 0.001s
im_detect: 1729/4024 0.225s 0.001s
im_detect: 1730/4024 0.225s 0.001s
im_detect: 1731/4024 0.225s 0.001s
im_detect: 1732/4024 0.225s 0.001s
im_detect: 1733/4024 0.225s 0.001s
im_detect: 1734/4024 0.225s 0.001s
im_detect: 1735/4024 0.225s 0.001s
im_detect: 1736/4024 0.225s 0.001s
im_detect: 1737/4024 0.225s 0.001s
im_detect: 1738/4024 0.225s 0.001s
im_detect: 1739/4024 0.225s 0.001s
im_detect: 1740/4024 0.225s 0.001s
im_detect: 1741/4024 0.225s 0.001s
im_detect: 1742/4024 0.225s 0.001s
im_detect: 1743/4024 0.225s 0.001s
im_detect: 1744/4024 0.225s 0.001s
im_detect: 1745/4024 0.225s 0.001s
im_detect: 1746/4024 0.225s 0.001s
im_detect: 1747/4024 0.225s 0.001s
im_detect: 1748/4024 0.225s 0.001s
im_detect: 1749/4024 0.225s 0.001s
im_detect: 1750/4024 0.225s 0.001s
im_detect: 1751/4024 0.225s 0.001s
im_detect: 1752/4024 0.225s 0.001s
im_detect: 1753/4024 0.225s 0.001s
im_detect: 1754/4024 0.225s 0.001s
im_detect: 1755/4024 0.225s 0.001s
im_detect: 1756/4024 0.225s 0.001s
im_detect: 1757/4024 0.225s 0.001s
im_detect: 1758/4024 0.225s 0.001s
im_detect: 1759/4024 0.225s 0.001s
im_detect: 1760/4024 0.225s 0.001s
im_detect: 1761/4024 0.225s 0.001s
im_detect: 1762/4024 0.225s 0.001s
im_detect: 1763/4024 0.225s 0.001s
im_detect: 1764/4024 0.225s 0.001s
im_detect: 1765/4024 0.225s 0.001s
im_detect: 1766/4024 0.225s 0.001s
im_detect: 1767/4024 0.225s 0.001s
im_detect: 1768/4024 0.225s 0.001s
im_detect: 1769/4024 0.225s 0.001s
im_detect: 1770/4024 0.225s 0.001s
im_detect: 1771/4024 0.225s 0.001s
im_detect: 1772/4024 0.225s 0.001s
im_detect: 1773/4024 0.225s 0.001s
im_detect: 1774/4024 0.225s 0.001s
im_detect: 1775/4024 0.225s 0.001s
im_detect: 1776/4024 0.225s 0.001s
im_detect: 1777/4024 0.225s 0.001s
im_detect: 1778/4024 0.225s 0.001s
im_detect: 1779/4024 0.225s 0.001s
im_detect: 1780/4024 0.225s 0.001s
im_detect: 1781/4024 0.225s 0.001s
im_detect: 1782/4024 0.225s 0.001s
im_detect: 1783/4024 0.225s 0.001s
im_detect: 1784/4024 0.225s 0.001s
im_detect: 1785/4024 0.225s 0.001s
im_detect: 1786/4024 0.225s 0.001s
im_detect: 1787/4024 0.225s 0.001s
im_detect: 1788/4024 0.225s 0.001s
im_detect: 1789/4024 0.225s 0.001s
im_detect: 1790/4024 0.225s 0.001s
im_detect: 1791/4024 0.225s 0.001s
im_detect: 1792/4024 0.225s 0.001s
im_detect: 1793/4024 0.225s 0.001s
im_detect: 1794/4024 0.225s 0.001s
im_detect: 1795/4024 0.225s 0.001s
im_detect: 1796/4024 0.225s 0.001s
im_detect: 1797/4024 0.225s 0.001s
im_detect: 1798/4024 0.225s 0.001s
im_detect: 1799/4024 0.225s 0.001s
im_detect: 1800/4024 0.225s 0.001s
im_detect: 1801/4024 0.225s 0.001s
im_detect: 1802/4024 0.225s 0.001s
im_detect: 1803/4024 0.225s 0.001s
im_detect: 1804/4024 0.225s 0.001s
im_detect: 1805/4024 0.225s 0.001s
im_detect: 1806/4024 0.225s 0.001s
im_detect: 1807/4024 0.225s 0.001s
im_detect: 1808/4024 0.225s 0.001s
im_detect: 1809/4024 0.225s 0.001s
im_detect: 1810/4024 0.225s 0.001s
im_detect: 1811/4024 0.225s 0.001s
im_detect: 1812/4024 0.225s 0.001s
im_detect: 1813/4024 0.225s 0.001s
im_detect: 1814/4024 0.225s 0.001s
im_detect: 1815/4024 0.225s 0.001s
im_detect: 1816/4024 0.225s 0.001s
im_detect: 1817/4024 0.225s 0.001s
im_detect: 1818/4024 0.225s 0.001s
im_detect: 1819/4024 0.225s 0.001s
im_detect: 1820/4024 0.225s 0.001s
im_detect: 1821/4024 0.225s 0.001s
im_detect: 1822/4024 0.225s 0.001s
im_detect: 1823/4024 0.225s 0.001s
im_detect: 1824/4024 0.225s 0.001s
im_detect: 1825/4024 0.225s 0.001s
im_detect: 1826/4024 0.225s 0.001s
im_detect: 1827/4024 0.225s 0.001s
im_detect: 1828/4024 0.225s 0.001s
im_detect: 1829/4024 0.225s 0.001s
im_detect: 1830/4024 0.225s 0.001s
im_detect: 1831/4024 0.225s 0.001s
im_detect: 1832/4024 0.225s 0.001s
im_detect: 1833/4024 0.225s 0.001s
im_detect: 1834/4024 0.225s 0.001s
im_detect: 1835/4024 0.225s 0.001s
im_detect: 1836/4024 0.225s 0.001s
im_detect: 1837/4024 0.225s 0.001s
im_detect: 1838/4024 0.225s 0.001s
im_detect: 1839/4024 0.225s 0.001s
im_detect: 1840/4024 0.225s 0.001s
im_detect: 1841/4024 0.225s 0.001s
im_detect: 1842/4024 0.225s 0.001s
im_detect: 1843/4024 0.225s 0.001s
im_detect: 1844/4024 0.225s 0.001s
im_detect: 1845/4024 0.225s 0.001s
im_detect: 1846/4024 0.225s 0.001s
im_detect: 1847/4024 0.225s 0.001s
im_detect: 1848/4024 0.225s 0.001s
im_detect: 1849/4024 0.225s 0.001s
im_detect: 1850/4024 0.225s 0.001s
im_detect: 1851/4024 0.225s 0.001s
im_detect: 1852/4024 0.225s 0.001s
im_detect: 1853/4024 0.225s 0.001s
im_detect: 1854/4024 0.225s 0.001s
im_detect: 1855/4024 0.225s 0.001s
im_detect: 1856/4024 0.225s 0.001s
im_detect: 1857/4024 0.225s 0.001s
im_detect: 1858/4024 0.225s 0.001s
im_detect: 1859/4024 0.225s 0.001s
im_detect: 1860/4024 0.225s 0.001s
im_detect: 1861/4024 0.225s 0.001s
im_detect: 1862/4024 0.225s 0.001s
im_detect: 1863/4024 0.225s 0.001s
im_detect: 1864/4024 0.225s 0.001s
im_detect: 1865/4024 0.225s 0.001s
im_detect: 1866/4024 0.225s 0.001s
im_detect: 1867/4024 0.225s 0.001s
im_detect: 1868/4024 0.225s 0.001s
im_detect: 1869/4024 0.225s 0.001s
im_detect: 1870/4024 0.225s 0.001s
im_detect: 1871/4024 0.224s 0.001s
im_detect: 1872/4024 0.224s 0.001s
im_detect: 1873/4024 0.224s 0.001s
im_detect: 1874/4024 0.224s 0.001s
im_detect: 1875/4024 0.224s 0.001s
im_detect: 1876/4024 0.224s 0.001s
im_detect: 1877/4024 0.224s 0.001s
im_detect: 1878/4024 0.224s 0.001s
im_detect: 1879/4024 0.224s 0.001s
im_detect: 1880/4024 0.224s 0.001s
im_detect: 1881/4024 0.224s 0.001s
im_detect: 1882/4024 0.224s 0.001s
im_detect: 1883/4024 0.224s 0.001s
im_detect: 1884/4024 0.224s 0.001s
im_detect: 1885/4024 0.224s 0.001s
im_detect: 1886/4024 0.224s 0.001s
im_detect: 1887/4024 0.224s 0.001s
im_detect: 1888/4024 0.224s 0.001s
im_detect: 1889/4024 0.224s 0.001s
im_detect: 1890/4024 0.224s 0.001s
im_detect: 1891/4024 0.224s 0.001s
im_detect: 1892/4024 0.224s 0.001s
im_detect: 1893/4024 0.224s 0.001s
im_detect: 1894/4024 0.224s 0.001s
im_detect: 1895/4024 0.224s 0.001s
im_detect: 1896/4024 0.224s 0.001s
im_detect: 1897/4024 0.224s 0.001s
im_detect: 1898/4024 0.224s 0.001s
im_detect: 1899/4024 0.224s 0.001s
im_detect: 1900/4024 0.224s 0.001s
im_detect: 1901/4024 0.224s 0.001s
im_detect: 1902/4024 0.224s 0.001s
im_detect: 1903/4024 0.224s 0.001s
im_detect: 1904/4024 0.224s 0.001s
im_detect: 1905/4024 0.224s 0.001s
im_detect: 1906/4024 0.224s 0.001s
im_detect: 1907/4024 0.224s 0.001s
im_detect: 1908/4024 0.224s 0.001s
im_detect: 1909/4024 0.224s 0.001s
im_detect: 1910/4024 0.224s 0.001s
im_detect: 1911/4024 0.224s 0.001s
im_detect: 1912/4024 0.224s 0.001s
im_detect: 1913/4024 0.224s 0.001s
im_detect: 1914/4024 0.224s 0.001s
im_detect: 1915/4024 0.224s 0.001s
im_detect: 1916/4024 0.224s 0.001s
im_detect: 1917/4024 0.224s 0.001s
im_detect: 1918/4024 0.224s 0.001s
im_detect: 1919/4024 0.224s 0.001s
im_detect: 1920/4024 0.224s 0.001s
im_detect: 1921/4024 0.224s 0.001s
im_detect: 1922/4024 0.224s 0.001s
im_detect: 1923/4024 0.224s 0.001s
im_detect: 1924/4024 0.224s 0.001s
im_detect: 1925/4024 0.224s 0.001s
im_detect: 1926/4024 0.224s 0.001s
im_detect: 1927/4024 0.224s 0.001s
im_detect: 1928/4024 0.224s 0.001s
im_detect: 1929/4024 0.224s 0.001s
im_detect: 1930/4024 0.224s 0.001s
im_detect: 1931/4024 0.224s 0.001s
im_detect: 1932/4024 0.224s 0.001s
im_detect: 1933/4024 0.224s 0.001s
im_detect: 1934/4024 0.224s 0.001s
im_detect: 1935/4024 0.224s 0.001s
im_detect: 1936/4024 0.224s 0.001s
im_detect: 1937/4024 0.224s 0.001s
im_detect: 1938/4024 0.224s 0.001s
im_detect: 1939/4024 0.224s 0.001s
im_detect: 1940/4024 0.224s 0.001s
im_detect: 1941/4024 0.224s 0.001s
im_detect: 1942/4024 0.224s 0.001s
im_detect: 1943/4024 0.224s 0.001s
im_detect: 1944/4024 0.224s 0.001s
im_detect: 1945/4024 0.224s 0.001s
im_detect: 1946/4024 0.224s 0.001s
im_detect: 1947/4024 0.224s 0.001s
im_detect: 1948/4024 0.224s 0.001s
im_detect: 1949/4024 0.224s 0.001s
im_detect: 1950/4024 0.224s 0.001s
im_detect: 1951/4024 0.224s 0.001s
im_detect: 1952/4024 0.224s 0.001s
im_detect: 1953/4024 0.224s 0.001s
im_detect: 1954/4024 0.224s 0.001s
im_detect: 1955/4024 0.224s 0.001s
im_detect: 1956/4024 0.224s 0.001s
im_detect: 1957/4024 0.224s 0.001s
im_detect: 1958/4024 0.224s 0.001s
im_detect: 1959/4024 0.224s 0.001s
im_detect: 1960/4024 0.224s 0.001s
im_detect: 1961/4024 0.224s 0.001s
im_detect: 1962/4024 0.224s 0.001s
im_detect: 1963/4024 0.224s 0.001s
im_detect: 1964/4024 0.224s 0.001s
im_detect: 1965/4024 0.224s 0.001s
im_detect: 1966/4024 0.224s 0.001s
im_detect: 1967/4024 0.224s 0.001s
im_detect: 1968/4024 0.224s 0.001s
im_detect: 1969/4024 0.224s 0.001s
im_detect: 1970/4024 0.224s 0.001s
im_detect: 1971/4024 0.224s 0.001s
im_detect: 1972/4024 0.224s 0.001s
im_detect: 1973/4024 0.224s 0.001s
im_detect: 1974/4024 0.224s 0.001s
im_detect: 1975/4024 0.224s 0.001s
im_detect: 1976/4024 0.224s 0.001s
im_detect: 1977/4024 0.224s 0.001s
im_detect: 1978/4024 0.224s 0.001s
im_detect: 1979/4024 0.224s 0.001s
im_detect: 1980/4024 0.224s 0.001s
im_detect: 1981/4024 0.224s 0.001s
im_detect: 1982/4024 0.224s 0.001s
im_detect: 1983/4024 0.224s 0.001s
im_detect: 1984/4024 0.224s 0.001s
im_detect: 1985/4024 0.224s 0.001s
im_detect: 1986/4024 0.224s 0.001s
im_detect: 1987/4024 0.224s 0.001s
im_detect: 1988/4024 0.224s 0.001s
im_detect: 1989/4024 0.224s 0.001s
im_detect: 1990/4024 0.224s 0.001s
im_detect: 1991/4024 0.224s 0.001s
im_detect: 1992/4024 0.224s 0.001s
im_detect: 1993/4024 0.224s 0.001s
im_detect: 1994/4024 0.224s 0.001s
im_detect: 1995/4024 0.224s 0.001s
im_detect: 1996/4024 0.224s 0.001s
im_detect: 1997/4024 0.224s 0.001s
im_detect: 1998/4024 0.224s 0.001s
im_detect: 1999/4024 0.224s 0.001s
im_detect: 2000/4024 0.224s 0.001s
im_detect: 2001/4024 0.224s 0.001s
im_detect: 2002/4024 0.224s 0.001s
im_detect: 2003/4024 0.224s 0.001s
im_detect: 2004/4024 0.224s 0.001s
im_detect: 2005/4024 0.224s 0.001s
im_detect: 2006/4024 0.224s 0.001s
im_detect: 2007/4024 0.224s 0.001s
im_detect: 2008/4024 0.224s 0.001s
im_detect: 2009/4024 0.224s 0.001s
im_detect: 2010/4024 0.224s 0.001s
im_detect: 2011/4024 0.224s 0.001s
im_detect: 2012/4024 0.224s 0.001s
im_detect: 2013/4024 0.224s 0.001s
im_detect: 2014/4024 0.224s 0.001s
im_detect: 2015/4024 0.224s 0.001s
im_detect: 2016/4024 0.224s 0.001s
im_detect: 2017/4024 0.224s 0.001s
im_detect: 2018/4024 0.224s 0.001s
im_detect: 2019/4024 0.224s 0.001s
im_detect: 2020/4024 0.224s 0.001s
im_detect: 2021/4024 0.224s 0.001s
im_detect: 2022/4024 0.224s 0.001s
im_detect: 2023/4024 0.224s 0.001s
im_detect: 2024/4024 0.224s 0.001s
im_detect: 2025/4024 0.224s 0.001s
im_detect: 2026/4024 0.224s 0.001s
im_detect: 2027/4024 0.224s 0.001s
im_detect: 2028/4024 0.224s 0.001s
im_detect: 2029/4024 0.224s 0.001s
im_detect: 2030/4024 0.224s 0.001s
im_detect: 2031/4024 0.224s 0.001s
im_detect: 2032/4024 0.224s 0.001s
im_detect: 2033/4024 0.224s 0.001s
im_detect: 2034/4024 0.224s 0.001s
im_detect: 2035/4024 0.224s 0.001s
im_detect: 2036/4024 0.224s 0.001s
im_detect: 2037/4024 0.224s 0.001s
im_detect: 2038/4024 0.224s 0.001s
im_detect: 2039/4024 0.224s 0.001s
im_detect: 2040/4024 0.224s 0.001s
im_detect: 2041/4024 0.224s 0.001s
im_detect: 2042/4024 0.224s 0.001s
im_detect: 2043/4024 0.224s 0.001s
im_detect: 2044/4024 0.224s 0.001s
im_detect: 2045/4024 0.224s 0.001s
im_detect: 2046/4024 0.224s 0.001s
im_detect: 2047/4024 0.224s 0.001s
im_detect: 2048/4024 0.224s 0.001s
im_detect: 2049/4024 0.224s 0.001s
im_detect: 2050/4024 0.224s 0.001s
im_detect: 2051/4024 0.224s 0.001s
im_detect: 2052/4024 0.224s 0.001s
im_detect: 2053/4024 0.224s 0.001s
im_detect: 2054/4024 0.224s 0.001s
im_detect: 2055/4024 0.224s 0.001s
im_detect: 2056/4024 0.224s 0.001s
im_detect: 2057/4024 0.224s 0.001s
im_detect: 2058/4024 0.224s 0.001s
im_detect: 2059/4024 0.224s 0.001s
im_detect: 2060/4024 0.224s 0.001s
im_detect: 2061/4024 0.224s 0.001s
im_detect: 2062/4024 0.224s 0.001s
im_detect: 2063/4024 0.224s 0.001s
im_detect: 2064/4024 0.224s 0.001s
im_detect: 2065/4024 0.224s 0.001s
im_detect: 2066/4024 0.224s 0.001s
im_detect: 2067/4024 0.224s 0.001s
im_detect: 2068/4024 0.224s 0.001s
im_detect: 2069/4024 0.224s 0.001s
im_detect: 2070/4024 0.224s 0.001s
im_detect: 2071/4024 0.224s 0.001s
im_detect: 2072/4024 0.224s 0.001s
im_detect: 2073/4024 0.224s 0.001s
im_detect: 2074/4024 0.224s 0.001s
im_detect: 2075/4024 0.224s 0.001s
im_detect: 2076/4024 0.224s 0.001s
im_detect: 2077/4024 0.224s 0.001s
im_detect: 2078/4024 0.224s 0.001s
im_detect: 2079/4024 0.224s 0.001s
im_detect: 2080/4024 0.224s 0.001s
im_detect: 2081/4024 0.224s 0.001s
im_detect: 2082/4024 0.224s 0.001s
im_detect: 2083/4024 0.224s 0.001s
im_detect: 2084/4024 0.224s 0.001s
im_detect: 2085/4024 0.224s 0.001s
im_detect: 2086/4024 0.224s 0.001s
im_detect: 2087/4024 0.224s 0.001s
im_detect: 2088/4024 0.224s 0.001s
im_detect: 2089/4024 0.224s 0.001s
im_detect: 2090/4024 0.224s 0.001s
im_detect: 2091/4024 0.224s 0.001s
im_detect: 2092/4024 0.224s 0.001s
im_detect: 2093/4024 0.224s 0.001s
im_detect: 2094/4024 0.224s 0.001s
im_detect: 2095/4024 0.224s 0.001s
im_detect: 2096/4024 0.224s 0.001s
im_detect: 2097/4024 0.224s 0.001s
im_detect: 2098/4024 0.224s 0.001s
im_detect: 2099/4024 0.224s 0.001s
im_detect: 2100/4024 0.224s 0.001s
im_detect: 2101/4024 0.224s 0.001s
im_detect: 2102/4024 0.224s 0.001s
im_detect: 2103/4024 0.224s 0.001s
im_detect: 2104/4024 0.224s 0.001s
im_detect: 2105/4024 0.224s 0.001s
im_detect: 2106/4024 0.224s 0.001s
im_detect: 2107/4024 0.224s 0.001s
im_detect: 2108/4024 0.224s 0.001s
im_detect: 2109/4024 0.224s 0.001s
im_detect: 2110/4024 0.224s 0.001s
im_detect: 2111/4024 0.224s 0.001s
im_detect: 2112/4024 0.224s 0.001s
im_detect: 2113/4024 0.224s 0.001s
im_detect: 2114/4024 0.224s 0.001s
im_detect: 2115/4024 0.224s 0.001s
im_detect: 2116/4024 0.224s 0.001s
im_detect: 2117/4024 0.224s 0.001s
im_detect: 2118/4024 0.224s 0.001s
im_detect: 2119/4024 0.224s 0.001s
im_detect: 2120/4024 0.224s 0.001s
im_detect: 2121/4024 0.224s 0.001s
im_detect: 2122/4024 0.224s 0.001s
im_detect: 2123/4024 0.224s 0.001s
im_detect: 2124/4024 0.224s 0.001s
im_detect: 2125/4024 0.224s 0.001s
im_detect: 2126/4024 0.224s 0.001s
im_detect: 2127/4024 0.224s 0.001s
im_detect: 2128/4024 0.224s 0.001s
im_detect: 2129/4024 0.224s 0.001s
im_detect: 2130/4024 0.224s 0.001s
im_detect: 2131/4024 0.224s 0.001s
im_detect: 2132/4024 0.224s 0.001s
im_detect: 2133/4024 0.224s 0.001s
im_detect: 2134/4024 0.224s 0.001s
im_detect: 2135/4024 0.224s 0.001s
im_detect: 2136/4024 0.224s 0.001s
im_detect: 2137/4024 0.224s 0.001s
im_detect: 2138/4024 0.224s 0.001s
im_detect: 2139/4024 0.224s 0.001s
im_detect: 2140/4024 0.224s 0.001s
im_detect: 2141/4024 0.224s 0.001s
im_detect: 2142/4024 0.224s 0.001s
im_detect: 2143/4024 0.224s 0.001s
im_detect: 2144/4024 0.224s 0.001s
im_detect: 2145/4024 0.224s 0.001s
im_detect: 2146/4024 0.224s 0.001s
im_detect: 2147/4024 0.224s 0.001s
im_detect: 2148/4024 0.224s 0.001s
im_detect: 2149/4024 0.224s 0.001s
im_detect: 2150/4024 0.224s 0.001s
im_detect: 2151/4024 0.224s 0.001s
im_detect: 2152/4024 0.224s 0.001s
im_detect: 2153/4024 0.224s 0.001s
im_detect: 2154/4024 0.224s 0.001s
im_detect: 2155/4024 0.224s 0.001s
im_detect: 2156/4024 0.224s 0.001s
im_detect: 2157/4024 0.224s 0.001s
im_detect: 2158/4024 0.224s 0.001s
im_detect: 2159/4024 0.224s 0.001s
im_detect: 2160/4024 0.224s 0.001s
im_detect: 2161/4024 0.224s 0.001s
im_detect: 2162/4024 0.224s 0.001s
im_detect: 2163/4024 0.224s 0.001s
im_detect: 2164/4024 0.224s 0.001s
im_detect: 2165/4024 0.224s 0.001s
im_detect: 2166/4024 0.224s 0.001s
im_detect: 2167/4024 0.224s 0.001s
im_detect: 2168/4024 0.224s 0.001s
im_detect: 2169/4024 0.224s 0.001s
im_detect: 2170/4024 0.224s 0.001s
im_detect: 2171/4024 0.224s 0.001s
im_detect: 2172/4024 0.224s 0.001s
im_detect: 2173/4024 0.224s 0.001s
im_detect: 2174/4024 0.224s 0.001s
im_detect: 2175/4024 0.224s 0.001s
im_detect: 2176/4024 0.224s 0.001s
im_detect: 2177/4024 0.224s 0.001s
im_detect: 2178/4024 0.224s 0.001s
im_detect: 2179/4024 0.224s 0.001s
im_detect: 2180/4024 0.224s 0.001s
im_detect: 2181/4024 0.224s 0.001s
im_detect: 2182/4024 0.224s 0.001s
im_detect: 2183/4024 0.224s 0.001s
im_detect: 2184/4024 0.224s 0.001s
im_detect: 2185/4024 0.224s 0.001s
im_detect: 2186/4024 0.224s 0.001s
im_detect: 2187/4024 0.224s 0.001s
im_detect: 2188/4024 0.224s 0.001s
im_detect: 2189/4024 0.224s 0.001s
im_detect: 2190/4024 0.224s 0.001s
im_detect: 2191/4024 0.224s 0.001s
im_detect: 2192/4024 0.224s 0.001s
im_detect: 2193/4024 0.224s 0.001s
im_detect: 2194/4024 0.224s 0.001s
im_detect: 2195/4024 0.224s 0.001s
im_detect: 2196/4024 0.224s 0.001s
im_detect: 2197/4024 0.224s 0.001s
im_detect: 2198/4024 0.224s 0.001s
im_detect: 2199/4024 0.224s 0.001s
im_detect: 2200/4024 0.224s 0.001s
im_detect: 2201/4024 0.224s 0.001s
im_detect: 2202/4024 0.224s 0.001s
im_detect: 2203/4024 0.224s 0.001s
im_detect: 2204/4024 0.224s 0.001s
im_detect: 2205/4024 0.224s 0.001s
im_detect: 2206/4024 0.224s 0.001s
im_detect: 2207/4024 0.224s 0.001s
im_detect: 2208/4024 0.224s 0.001s
im_detect: 2209/4024 0.224s 0.001s
im_detect: 2210/4024 0.224s 0.001s
im_detect: 2211/4024 0.224s 0.001s
im_detect: 2212/4024 0.224s 0.001s
im_detect: 2213/4024 0.224s 0.001s
im_detect: 2214/4024 0.224s 0.001s
im_detect: 2215/4024 0.224s 0.001s
im_detect: 2216/4024 0.224s 0.001s
im_detect: 2217/4024 0.224s 0.001s
im_detect: 2218/4024 0.224s 0.001s
im_detect: 2219/4024 0.224s 0.001s
im_detect: 2220/4024 0.224s 0.001s
im_detect: 2221/4024 0.224s 0.001s
im_detect: 2222/4024 0.224s 0.001s
im_detect: 2223/4024 0.224s 0.001s
im_detect: 2224/4024 0.224s 0.001s
im_detect: 2225/4024 0.224s 0.001s
im_detect: 2226/4024 0.224s 0.001s
im_detect: 2227/4024 0.224s 0.001s
im_detect: 2228/4024 0.224s 0.001s
im_detect: 2229/4024 0.224s 0.001s
im_detect: 2230/4024 0.224s 0.001s
im_detect: 2231/4024 0.224s 0.001s
im_detect: 2232/4024 0.224s 0.001s
im_detect: 2233/4024 0.224s 0.001s
im_detect: 2234/4024 0.224s 0.001s
im_detect: 2235/4024 0.224s 0.001s
im_detect: 2236/4024 0.224s 0.001s
im_detect: 2237/4024 0.224s 0.001s
im_detect: 2238/4024 0.224s 0.001s
im_detect: 2239/4024 0.223s 0.001s
im_detect: 2240/4024 0.223s 0.001s
im_detect: 2241/4024 0.223s 0.001s
im_detect: 2242/4024 0.224s 0.001s
im_detect: 2243/4024 0.224s 0.001s
im_detect: 2244/4024 0.223s 0.001s
im_detect: 2245/4024 0.223s 0.001s
im_detect: 2246/4024 0.224s 0.001s
im_detect: 2247/4024 0.223s 0.001s
im_detect: 2248/4024 0.223s 0.001s
im_detect: 2249/4024 0.223s 0.001s
im_detect: 2250/4024 0.223s 0.001s
im_detect: 2251/4024 0.223s 0.001s
im_detect: 2252/4024 0.223s 0.001s
im_detect: 2253/4024 0.223s 0.001s
im_detect: 2254/4024 0.223s 0.001s
im_detect: 2255/4024 0.223s 0.001s
im_detect: 2256/4024 0.223s 0.001s
im_detect: 2257/4024 0.223s 0.001s
im_detect: 2258/4024 0.223s 0.001s
im_detect: 2259/4024 0.223s 0.001s
im_detect: 2260/4024 0.223s 0.001s
im_detect: 2261/4024 0.223s 0.001s
im_detect: 2262/4024 0.223s 0.001s
im_detect: 2263/4024 0.223s 0.001s
im_detect: 2264/4024 0.223s 0.001s
im_detect: 2265/4024 0.223s 0.001s
im_detect: 2266/4024 0.223s 0.001s
im_detect: 2267/4024 0.223s 0.001s
im_detect: 2268/4024 0.223s 0.001s
im_detect: 2269/4024 0.223s 0.001s
im_detect: 2270/4024 0.223s 0.001s
im_detect: 2271/4024 0.223s 0.001s
im_detect: 2272/4024 0.223s 0.001s
im_detect: 2273/4024 0.223s 0.001s
im_detect: 2274/4024 0.223s 0.001s
im_detect: 2275/4024 0.223s 0.001s
im_detect: 2276/4024 0.223s 0.001s
im_detect: 2277/4024 0.223s 0.001s
im_detect: 2278/4024 0.223s 0.001s
im_detect: 2279/4024 0.223s 0.001s
im_detect: 2280/4024 0.223s 0.001s
im_detect: 2281/4024 0.223s 0.001s
im_detect: 2282/4024 0.223s 0.001s
im_detect: 2283/4024 0.223s 0.001s
im_detect: 2284/4024 0.223s 0.001s
im_detect: 2285/4024 0.223s 0.001s
im_detect: 2286/4024 0.223s 0.001s
im_detect: 2287/4024 0.223s 0.001s
im_detect: 2288/4024 0.223s 0.001s
im_detect: 2289/4024 0.223s 0.001s
im_detect: 2290/4024 0.223s 0.001s
im_detect: 2291/4024 0.223s 0.001s
im_detect: 2292/4024 0.223s 0.001s
im_detect: 2293/4024 0.223s 0.001s
im_detect: 2294/4024 0.223s 0.001s
im_detect: 2295/4024 0.223s 0.001s
im_detect: 2296/4024 0.223s 0.001s
im_detect: 2297/4024 0.223s 0.001s
im_detect: 2298/4024 0.223s 0.001s
im_detect: 2299/4024 0.223s 0.001s
im_detect: 2300/4024 0.223s 0.001s
im_detect: 2301/4024 0.223s 0.001s
im_detect: 2302/4024 0.223s 0.001s
im_detect: 2303/4024 0.223s 0.001s
im_detect: 2304/4024 0.223s 0.001s
im_detect: 2305/4024 0.223s 0.001s
im_detect: 2306/4024 0.223s 0.001s
im_detect: 2307/4024 0.223s 0.001s
im_detect: 2308/4024 0.223s 0.001s
im_detect: 2309/4024 0.223s 0.001s
im_detect: 2310/4024 0.223s 0.001s
im_detect: 2311/4024 0.223s 0.001s
im_detect: 2312/4024 0.223s 0.001s
im_detect: 2313/4024 0.223s 0.001s
im_detect: 2314/4024 0.223s 0.001s
im_detect: 2315/4024 0.223s 0.001s
im_detect: 2316/4024 0.223s 0.001s
im_detect: 2317/4024 0.223s 0.001s
im_detect: 2318/4024 0.223s 0.001s
im_detect: 2319/4024 0.223s 0.001s
im_detect: 2320/4024 0.223s 0.001s
im_detect: 2321/4024 0.223s 0.001s
im_detect: 2322/4024 0.223s 0.001s
im_detect: 2323/4024 0.223s 0.001s
im_detect: 2324/4024 0.223s 0.001s
im_detect: 2325/4024 0.223s 0.001s
im_detect: 2326/4024 0.223s 0.001s
im_detect: 2327/4024 0.223s 0.001s
im_detect: 2328/4024 0.223s 0.001s
im_detect: 2329/4024 0.223s 0.001s
im_detect: 2330/4024 0.223s 0.001s
im_detect: 2331/4024 0.223s 0.001s
im_detect: 2332/4024 0.223s 0.001s
im_detect: 2333/4024 0.223s 0.001s
im_detect: 2334/4024 0.223s 0.001s
im_detect: 2335/4024 0.223s 0.001s
im_detect: 2336/4024 0.223s 0.001s
im_detect: 2337/4024 0.223s 0.001s
im_detect: 2338/4024 0.223s 0.001s
im_detect: 2339/4024 0.223s 0.001s
im_detect: 2340/4024 0.223s 0.001s
im_detect: 2341/4024 0.223s 0.001s
im_detect: 2342/4024 0.223s 0.001s
im_detect: 2343/4024 0.223s 0.001s
im_detect: 2344/4024 0.223s 0.001s
im_detect: 2345/4024 0.223s 0.001s
im_detect: 2346/4024 0.223s 0.001s
im_detect: 2347/4024 0.223s 0.001s
im_detect: 2348/4024 0.223s 0.001s
im_detect: 2349/4024 0.223s 0.001s
im_detect: 2350/4024 0.223s 0.001s
im_detect: 2351/4024 0.223s 0.001s
im_detect: 2352/4024 0.223s 0.001s
im_detect: 2353/4024 0.223s 0.001s
im_detect: 2354/4024 0.223s 0.001s
im_detect: 2355/4024 0.223s 0.001s
im_detect: 2356/4024 0.223s 0.001s
im_detect: 2357/4024 0.223s 0.001s
im_detect: 2358/4024 0.223s 0.001s
im_detect: 2359/4024 0.223s 0.001s
im_detect: 2360/4024 0.223s 0.001s
im_detect: 2361/4024 0.223s 0.001s
im_detect: 2362/4024 0.223s 0.001s
im_detect: 2363/4024 0.223s 0.001s
im_detect: 2364/4024 0.223s 0.001s
im_detect: 2365/4024 0.223s 0.001s
im_detect: 2366/4024 0.223s 0.001s
im_detect: 2367/4024 0.223s 0.001s
im_detect: 2368/4024 0.223s 0.001s
im_detect: 2369/4024 0.223s 0.001s
im_detect: 2370/4024 0.223s 0.001s
im_detect: 2371/4024 0.223s 0.001s
im_detect: 2372/4024 0.223s 0.001s
im_detect: 2373/4024 0.223s 0.001s
im_detect: 2374/4024 0.223s 0.001s
im_detect: 2375/4024 0.223s 0.001s
im_detect: 2376/4024 0.223s 0.001s
im_detect: 2377/4024 0.223s 0.001s
im_detect: 2378/4024 0.223s 0.001s
im_detect: 2379/4024 0.223s 0.001s
im_detect: 2380/4024 0.223s 0.001s
im_detect: 2381/4024 0.223s 0.001s
im_detect: 2382/4024 0.223s 0.001s
im_detect: 2383/4024 0.223s 0.001s
im_detect: 2384/4024 0.223s 0.001s
im_detect: 2385/4024 0.223s 0.001s
im_detect: 2386/4024 0.223s 0.001s
im_detect: 2387/4024 0.223s 0.001s
im_detect: 2388/4024 0.223s 0.001s
im_detect: 2389/4024 0.223s 0.001s
im_detect: 2390/4024 0.223s 0.001s
im_detect: 2391/4024 0.223s 0.001s
im_detect: 2392/4024 0.223s 0.001s
im_detect: 2393/4024 0.223s 0.001s
im_detect: 2394/4024 0.223s 0.001s
im_detect: 2395/4024 0.223s 0.001s
im_detect: 2396/4024 0.223s 0.001s
im_detect: 2397/4024 0.223s 0.001s
im_detect: 2398/4024 0.223s 0.001s
im_detect: 2399/4024 0.223s 0.001s
im_detect: 2400/4024 0.223s 0.001s
im_detect: 2401/4024 0.223s 0.001s
im_detect: 2402/4024 0.223s 0.001s
im_detect: 2403/4024 0.223s 0.001s
im_detect: 2404/4024 0.223s 0.001s
im_detect: 2405/4024 0.223s 0.001s
im_detect: 2406/4024 0.223s 0.001s
im_detect: 2407/4024 0.223s 0.001s
im_detect: 2408/4024 0.223s 0.001s
im_detect: 2409/4024 0.223s 0.001s
im_detect: 2410/4024 0.223s 0.001s
im_detect: 2411/4024 0.223s 0.001s
im_detect: 2412/4024 0.223s 0.001s
im_detect: 2413/4024 0.223s 0.001s
im_detect: 2414/4024 0.223s 0.001s
im_detect: 2415/4024 0.223s 0.001s
im_detect: 2416/4024 0.223s 0.001s
im_detect: 2417/4024 0.223s 0.001s
im_detect: 2418/4024 0.223s 0.001s
im_detect: 2419/4024 0.223s 0.001s
im_detect: 2420/4024 0.223s 0.001s
im_detect: 2421/4024 0.223s 0.001s
im_detect: 2422/4024 0.223s 0.001s
im_detect: 2423/4024 0.223s 0.001s
im_detect: 2424/4024 0.223s 0.001s
im_detect: 2425/4024 0.223s 0.001s
im_detect: 2426/4024 0.223s 0.001s
im_detect: 2427/4024 0.223s 0.001s
im_detect: 2428/4024 0.223s 0.001s
im_detect: 2429/4024 0.223s 0.001s
im_detect: 2430/4024 0.223s 0.001s
im_detect: 2431/4024 0.223s 0.001s
im_detect: 2432/4024 0.223s 0.001s
im_detect: 2433/4024 0.223s 0.001s
im_detect: 2434/4024 0.223s 0.001s
im_detect: 2435/4024 0.223s 0.001s
im_detect: 2436/4024 0.223s 0.001s
im_detect: 2437/4024 0.223s 0.001s
im_detect: 2438/4024 0.223s 0.001s
im_detect: 2439/4024 0.223s 0.001s
im_detect: 2440/4024 0.223s 0.001s
im_detect: 2441/4024 0.223s 0.001s
im_detect: 2442/4024 0.223s 0.001s
im_detect: 2443/4024 0.223s 0.001s
im_detect: 2444/4024 0.223s 0.001s
im_detect: 2445/4024 0.223s 0.001s
im_detect: 2446/4024 0.223s 0.001s
im_detect: 2447/4024 0.223s 0.001s
im_detect: 2448/4024 0.223s 0.001s
im_detect: 2449/4024 0.223s 0.001s
im_detect: 2450/4024 0.223s 0.001s
im_detect: 2451/4024 0.223s 0.001s
im_detect: 2452/4024 0.223s 0.001s
im_detect: 2453/4024 0.223s 0.001s
im_detect: 2454/4024 0.223s 0.001s
im_detect: 2455/4024 0.223s 0.001s
im_detect: 2456/4024 0.223s 0.001s
im_detect: 2457/4024 0.223s 0.001s
im_detect: 2458/4024 0.223s 0.001s
im_detect: 2459/4024 0.223s 0.001s
im_detect: 2460/4024 0.223s 0.001s
im_detect: 2461/4024 0.223s 0.001s
im_detect: 2462/4024 0.223s 0.001s
im_detect: 2463/4024 0.223s 0.001s
im_detect: 2464/4024 0.223s 0.001s
im_detect: 2465/4024 0.223s 0.001s
im_detect: 2466/4024 0.223s 0.001s
im_detect: 2467/4024 0.223s 0.001s
im_detect: 2468/4024 0.223s 0.001s
im_detect: 2469/4024 0.223s 0.001s
im_detect: 2470/4024 0.223s 0.001s
im_detect: 2471/4024 0.223s 0.001s
im_detect: 2472/4024 0.223s 0.001s
im_detect: 2473/4024 0.223s 0.001s
im_detect: 2474/4024 0.223s 0.001s
im_detect: 2475/4024 0.223s 0.001s
im_detect: 2476/4024 0.223s 0.001s
im_detect: 2477/4024 0.223s 0.001s
im_detect: 2478/4024 0.223s 0.001s
im_detect: 2479/4024 0.223s 0.001s
im_detect: 2480/4024 0.222s 0.001s
im_detect: 2481/4024 0.222s 0.001s
im_detect: 2482/4024 0.222s 0.001s
im_detect: 2483/4024 0.222s 0.001s
im_detect: 2484/4024 0.222s 0.001s
im_detect: 2485/4024 0.222s 0.001s
im_detect: 2486/4024 0.222s 0.001s
im_detect: 2487/4024 0.222s 0.001s
im_detect: 2488/4024 0.222s 0.001s
im_detect: 2489/4024 0.222s 0.001s
im_detect: 2490/4024 0.222s 0.001s
im_detect: 2491/4024 0.222s 0.001s
im_detect: 2492/4024 0.222s 0.001s
im_detect: 2493/4024 0.222s 0.001s
im_detect: 2494/4024 0.222s 0.001s
im_detect: 2495/4024 0.222s 0.001s
im_detect: 2496/4024 0.222s 0.001s
im_detect: 2497/4024 0.222s 0.001s
im_detect: 2498/4024 0.222s 0.001s
im_detect: 2499/4024 0.222s 0.001s
im_detect: 2500/4024 0.222s 0.001s
im_detect: 2501/4024 0.222s 0.001s
im_detect: 2502/4024 0.222s 0.001s
im_detect: 2503/4024 0.222s 0.001s
im_detect: 2504/4024 0.222s 0.001s
im_detect: 2505/4024 0.222s 0.001s
im_detect: 2506/4024 0.222s 0.001s
im_detect: 2507/4024 0.222s 0.001s
im_detect: 2508/4024 0.222s 0.001s
im_detect: 2509/4024 0.222s 0.001s
im_detect: 2510/4024 0.222s 0.001s
im_detect: 2511/4024 0.222s 0.001s
im_detect: 2512/4024 0.222s 0.001s
im_detect: 2513/4024 0.222s 0.001s
im_detect: 2514/4024 0.222s 0.001s
im_detect: 2515/4024 0.222s 0.001s
im_detect: 2516/4024 0.222s 0.001s
im_detect: 2517/4024 0.222s 0.001s
im_detect: 2518/4024 0.222s 0.001s
im_detect: 2519/4024 0.222s 0.001s
im_detect: 2520/4024 0.222s 0.001s
im_detect: 2521/4024 0.222s 0.001s
im_detect: 2522/4024 0.222s 0.001s
im_detect: 2523/4024 0.222s 0.001s
im_detect: 2524/4024 0.222s 0.001s
im_detect: 2525/4024 0.222s 0.001s
im_detect: 2526/4024 0.222s 0.001s
im_detect: 2527/4024 0.222s 0.001s
im_detect: 2528/4024 0.222s 0.001s
im_detect: 2529/4024 0.222s 0.001s
im_detect: 2530/4024 0.222s 0.001s
im_detect: 2531/4024 0.222s 0.001s
im_detect: 2532/4024 0.222s 0.001s
im_detect: 2533/4024 0.222s 0.001s
im_detect: 2534/4024 0.222s 0.001s
im_detect: 2535/4024 0.222s 0.001s
im_detect: 2536/4024 0.222s 0.001s
im_detect: 2537/4024 0.222s 0.001s
im_detect: 2538/4024 0.222s 0.001s
im_detect: 2539/4024 0.222s 0.001s
im_detect: 2540/4024 0.222s 0.001s
im_detect: 2541/4024 0.222s 0.001s
im_detect: 2542/4024 0.222s 0.001s
im_detect: 2543/4024 0.222s 0.001s
im_detect: 2544/4024 0.222s 0.001s
im_detect: 2545/4024 0.222s 0.001s
im_detect: 2546/4024 0.222s 0.001s
im_detect: 2547/4024 0.222s 0.001s
im_detect: 2548/4024 0.222s 0.001s
im_detect: 2549/4024 0.222s 0.001s
im_detect: 2550/4024 0.222s 0.001s
im_detect: 2551/4024 0.222s 0.001s
im_detect: 2552/4024 0.222s 0.001s
im_detect: 2553/4024 0.222s 0.001s
im_detect: 2554/4024 0.222s 0.001s
im_detect: 2555/4024 0.222s 0.001s
im_detect: 2556/4024 0.222s 0.001s
im_detect: 2557/4024 0.222s 0.001s
im_detect: 2558/4024 0.222s 0.001s
im_detect: 2559/4024 0.222s 0.001s
im_detect: 2560/4024 0.222s 0.001s
im_detect: 2561/4024 0.222s 0.001s
im_detect: 2562/4024 0.222s 0.001s
im_detect: 2563/4024 0.222s 0.001s
im_detect: 2564/4024 0.222s 0.001s
im_detect: 2565/4024 0.222s 0.001s
im_detect: 2566/4024 0.222s 0.001s
im_detect: 2567/4024 0.222s 0.001s
im_detect: 2568/4024 0.222s 0.001s
im_detect: 2569/4024 0.222s 0.001s
im_detect: 2570/4024 0.222s 0.001s
im_detect: 2571/4024 0.222s 0.001s
im_detect: 2572/4024 0.222s 0.001s
im_detect: 2573/4024 0.222s 0.001s
im_detect: 2574/4024 0.222s 0.001s
im_detect: 2575/4024 0.222s 0.001s
im_detect: 2576/4024 0.222s 0.001s
im_detect: 2577/4024 0.222s 0.001s
im_detect: 2578/4024 0.222s 0.001s
im_detect: 2579/4024 0.222s 0.001s
im_detect: 2580/4024 0.222s 0.001s
im_detect: 2581/4024 0.222s 0.001s
im_detect: 2582/4024 0.222s 0.001s
im_detect: 2583/4024 0.222s 0.001s
im_detect: 2584/4024 0.222s 0.001s
im_detect: 2585/4024 0.222s 0.001s
im_detect: 2586/4024 0.222s 0.001s
im_detect: 2587/4024 0.222s 0.001s
im_detect: 2588/4024 0.222s 0.001s
im_detect: 2589/4024 0.222s 0.001s
im_detect: 2590/4024 0.222s 0.001s
im_detect: 2591/4024 0.222s 0.001s
im_detect: 2592/4024 0.222s 0.001s
im_detect: 2593/4024 0.222s 0.001s
im_detect: 2594/4024 0.222s 0.001s
im_detect: 2595/4024 0.222s 0.001s
im_detect: 2596/4024 0.222s 0.001s
im_detect: 2597/4024 0.222s 0.001s
im_detect: 2598/4024 0.222s 0.001s
im_detect: 2599/4024 0.222s 0.001s
im_detect: 2600/4024 0.222s 0.001s
im_detect: 2601/4024 0.222s 0.001s
im_detect: 2602/4024 0.222s 0.001s
im_detect: 2603/4024 0.222s 0.001s
im_detect: 2604/4024 0.222s 0.001s
im_detect: 2605/4024 0.222s 0.001s
im_detect: 2606/4024 0.222s 0.001s
im_detect: 2607/4024 0.222s 0.001s
im_detect: 2608/4024 0.222s 0.001s
im_detect: 2609/4024 0.222s 0.001s
im_detect: 2610/4024 0.222s 0.001s
im_detect: 2611/4024 0.222s 0.001s
im_detect: 2612/4024 0.222s 0.001s
im_detect: 2613/4024 0.222s 0.001s
im_detect: 2614/4024 0.222s 0.001s
im_detect: 2615/4024 0.222s 0.001s
im_detect: 2616/4024 0.222s 0.001s
im_detect: 2617/4024 0.222s 0.001s
im_detect: 2618/4024 0.222s 0.001s
im_detect: 2619/4024 0.221s 0.001s
im_detect: 2620/4024 0.221s 0.001s
im_detect: 2621/4024 0.221s 0.001s
im_detect: 2622/4024 0.221s 0.001s
im_detect: 2623/4024 0.221s 0.001s
im_detect: 2624/4024 0.221s 0.001s
im_detect: 2625/4024 0.221s 0.001s
im_detect: 2626/4024 0.221s 0.001s
im_detect: 2627/4024 0.221s 0.001s
im_detect: 2628/4024 0.221s 0.001s
im_detect: 2629/4024 0.221s 0.001s
im_detect: 2630/4024 0.221s 0.001s
im_detect: 2631/4024 0.221s 0.001s
im_detect: 2632/4024 0.221s 0.001s
im_detect: 2633/4024 0.221s 0.001s
im_detect: 2634/4024 0.221s 0.001s
im_detect: 2635/4024 0.221s 0.001s
im_detect: 2636/4024 0.221s 0.001s
im_detect: 2637/4024 0.221s 0.001s
im_detect: 2638/4024 0.221s 0.001s
im_detect: 2639/4024 0.221s 0.001s
im_detect: 2640/4024 0.221s 0.001s
im_detect: 2641/4024 0.221s 0.001s
im_detect: 2642/4024 0.221s 0.001s
im_detect: 2643/4024 0.221s 0.001s
im_detect: 2644/4024 0.221s 0.001s
im_detect: 2645/4024 0.221s 0.001s
im_detect: 2646/4024 0.221s 0.001s
im_detect: 2647/4024 0.221s 0.001s
im_detect: 2648/4024 0.221s 0.001s
im_detect: 2649/4024 0.221s 0.001s
im_detect: 2650/4024 0.221s 0.001s
im_detect: 2651/4024 0.221s 0.001s
im_detect: 2652/4024 0.221s 0.001s
im_detect: 2653/4024 0.221s 0.001s
im_detect: 2654/4024 0.221s 0.001s
im_detect: 2655/4024 0.221s 0.001s
im_detect: 2656/4024 0.221s 0.001s
im_detect: 2657/4024 0.221s 0.001s
im_detect: 2658/4024 0.221s 0.001s
im_detect: 2659/4024 0.221s 0.001s
im_detect: 2660/4024 0.221s 0.001s
im_detect: 2661/4024 0.221s 0.001s
im_detect: 2662/4024 0.221s 0.001s
im_detect: 2663/4024 0.221s 0.001s
im_detect: 2664/4024 0.221s 0.001s
im_detect: 2665/4024 0.221s 0.001s
im_detect: 2666/4024 0.221s 0.001s
im_detect: 2667/4024 0.221s 0.001s
im_detect: 2668/4024 0.221s 0.001s
im_detect: 2669/4024 0.221s 0.001s
im_detect: 2670/4024 0.221s 0.001s
im_detect: 2671/4024 0.221s 0.001s
im_detect: 2672/4024 0.221s 0.001s
im_detect: 2673/4024 0.221s 0.001s
im_detect: 2674/4024 0.221s 0.001s
im_detect: 2675/4024 0.221s 0.001s
im_detect: 2676/4024 0.221s 0.001s
im_detect: 2677/4024 0.221s 0.001s
im_detect: 2678/4024 0.221s 0.001s
im_detect: 2679/4024 0.221s 0.001s
im_detect: 2680/4024 0.221s 0.001s
im_detect: 2681/4024 0.221s 0.001s
im_detect: 2682/4024 0.221s 0.001s
im_detect: 2683/4024 0.221s 0.001s
im_detect: 2684/4024 0.221s 0.001s
im_detect: 2685/4024 0.221s 0.001s
im_detect: 2686/4024 0.221s 0.001s
im_detect: 2687/4024 0.221s 0.001s
im_detect: 2688/4024 0.221s 0.001s
im_detect: 2689/4024 0.221s 0.001s
im_detect: 2690/4024 0.221s 0.001s
im_detect: 2691/4024 0.221s 0.001s
im_detect: 2692/4024 0.221s 0.001s
im_detect: 2693/4024 0.221s 0.001s
im_detect: 2694/4024 0.221s 0.001s
im_detect: 2695/4024 0.221s 0.001s
im_detect: 2696/4024 0.221s 0.001s
im_detect: 2697/4024 0.221s 0.001s
im_detect: 2698/4024 0.221s 0.001s
im_detect: 2699/4024 0.221s 0.001s
im_detect: 2700/4024 0.221s 0.001s
im_detect: 2701/4024 0.221s 0.001s
im_detect: 2702/4024 0.221s 0.001s
im_detect: 2703/4024 0.221s 0.001s
im_detect: 2704/4024 0.221s 0.001s
im_detect: 2705/4024 0.221s 0.001s
im_detect: 2706/4024 0.221s 0.001s
im_detect: 2707/4024 0.221s 0.001s
im_detect: 2708/4024 0.221s 0.001s
im_detect: 2709/4024 0.221s 0.001s
im_detect: 2710/4024 0.221s 0.001s
im_detect: 2711/4024 0.221s 0.001s
im_detect: 2712/4024 0.221s 0.001s
im_detect: 2713/4024 0.221s 0.001s
im_detect: 2714/4024 0.221s 0.001s
im_detect: 2715/4024 0.221s 0.001s
im_detect: 2716/4024 0.221s 0.001s
im_detect: 2717/4024 0.221s 0.001s
im_detect: 2718/4024 0.221s 0.001s
im_detect: 2719/4024 0.221s 0.001s
im_detect: 2720/4024 0.221s 0.001s
im_detect: 2721/4024 0.221s 0.001s
im_detect: 2722/4024 0.221s 0.001s
im_detect: 2723/4024 0.221s 0.001s
im_detect: 2724/4024 0.221s 0.001s
im_detect: 2725/4024 0.221s 0.001s
im_detect: 2726/4024 0.221s 0.001s
im_detect: 2727/4024 0.221s 0.001s
im_detect: 2728/4024 0.221s 0.001s
im_detect: 2729/4024 0.221s 0.001s
im_detect: 2730/4024 0.221s 0.001s
im_detect: 2731/4024 0.221s 0.001s
im_detect: 2732/4024 0.221s 0.001s
im_detect: 2733/4024 0.221s 0.001s
im_detect: 2734/4024 0.221s 0.001s
im_detect: 2735/4024 0.221s 0.001s
im_detect: 2736/4024 0.221s 0.001s
im_detect: 2737/4024 0.221s 0.001s
im_detect: 2738/4024 0.221s 0.001s
im_detect: 2739/4024 0.221s 0.001s
im_detect: 2740/4024 0.221s 0.001s
im_detect: 2741/4024 0.221s 0.001s
im_detect: 2742/4024 0.221s 0.001s
im_detect: 2743/4024 0.221s 0.001s
im_detect: 2744/4024 0.221s 0.001s
im_detect: 2745/4024 0.221s 0.001s
im_detect: 2746/4024 0.221s 0.001s
im_detect: 2747/4024 0.221s 0.001s
im_detect: 2748/4024 0.221s 0.001s
im_detect: 2749/4024 0.221s 0.001s
im_detect: 2750/4024 0.221s 0.001s
im_detect: 2751/4024 0.221s 0.001s
im_detect: 2752/4024 0.221s 0.001s
im_detect: 2753/4024 0.221s 0.001s
im_detect: 2754/4024 0.221s 0.001s
im_detect: 2755/4024 0.221s 0.001s
im_detect: 2756/4024 0.221s 0.001s
im_detect: 2757/4024 0.221s 0.001s
im_detect: 2758/4024 0.221s 0.001s
im_detect: 2759/4024 0.221s 0.001s
im_detect: 2760/4024 0.221s 0.001s
im_detect: 2761/4024 0.221s 0.001s
im_detect: 2762/4024 0.221s 0.001s
im_detect: 2763/4024 0.221s 0.001s
im_detect: 2764/4024 0.221s 0.001s
im_detect: 2765/4024 0.221s 0.001s
im_detect: 2766/4024 0.221s 0.001s
im_detect: 2767/4024 0.221s 0.001s
im_detect: 2768/4024 0.221s 0.001s
im_detect: 2769/4024 0.221s 0.001s
im_detect: 2770/4024 0.221s 0.001s
im_detect: 2771/4024 0.221s 0.001s
im_detect: 2772/4024 0.221s 0.001s
im_detect: 2773/4024 0.221s 0.001s
im_detect: 2774/4024 0.221s 0.001s
im_detect: 2775/4024 0.221s 0.001s
im_detect: 2776/4024 0.221s 0.001s
im_detect: 2777/4024 0.221s 0.001s
im_detect: 2778/4024 0.221s 0.001s
im_detect: 2779/4024 0.221s 0.001s
im_detect: 2780/4024 0.221s 0.001s
im_detect: 2781/4024 0.221s 0.001s
im_detect: 2782/4024 0.221s 0.001s
im_detect: 2783/4024 0.221s 0.001s
im_detect: 2784/4024 0.221s 0.001s
im_detect: 2785/4024 0.221s 0.001s
im_detect: 2786/4024 0.221s 0.001s
im_detect: 2787/4024 0.221s 0.001s
im_detect: 2788/4024 0.221s 0.001s
im_detect: 2789/4024 0.221s 0.001s
im_detect: 2790/4024 0.221s 0.001s
im_detect: 2791/4024 0.221s 0.001s
im_detect: 2792/4024 0.221s 0.001s
im_detect: 2793/4024 0.221s 0.001s
im_detect: 2794/4024 0.221s 0.001s
im_detect: 2795/4024 0.221s 0.001s
im_detect: 2796/4024 0.221s 0.001s
im_detect: 2797/4024 0.221s 0.001s
im_detect: 2798/4024 0.221s 0.001s
im_detect: 2799/4024 0.221s 0.001s
im_detect: 2800/4024 0.221s 0.001s
im_detect: 2801/4024 0.221s 0.001s
im_detect: 2802/4024 0.221s 0.001s
im_detect: 2803/4024 0.221s 0.001s
im_detect: 2804/4024 0.221s 0.001s
im_detect: 2805/4024 0.221s 0.001s
im_detect: 2806/4024 0.221s 0.001s
im_detect: 2807/4024 0.221s 0.001s
im_detect: 2808/4024 0.221s 0.001s
im_detect: 2809/4024 0.221s 0.001s
im_detect: 2810/4024 0.221s 0.001s
im_detect: 2811/4024 0.221s 0.001s
im_detect: 2812/4024 0.221s 0.001s
im_detect: 2813/4024 0.221s 0.001s
im_detect: 2814/4024 0.221s 0.001s
im_detect: 2815/4024 0.221s 0.001s
im_detect: 2816/4024 0.221s 0.001s
im_detect: 2817/4024 0.221s 0.001s
im_detect: 2818/4024 0.221s 0.001s
im_detect: 2819/4024 0.221s 0.001s
im_detect: 2820/4024 0.221s 0.001s
im_detect: 2821/4024 0.221s 0.001s
im_detect: 2822/4024 0.221s 0.001s
im_detect: 2823/4024 0.221s 0.001s
im_detect: 2824/4024 0.221s 0.001s
im_detect: 2825/4024 0.221s 0.001s
im_detect: 2826/4024 0.221s 0.001s
im_detect: 2827/4024 0.221s 0.001s
im_detect: 2828/4024 0.221s 0.001s
im_detect: 2829/4024 0.221s 0.001s
im_detect: 2830/4024 0.221s 0.001s
im_detect: 2831/4024 0.221s 0.001s
im_detect: 2832/4024 0.221s 0.001s
im_detect: 2833/4024 0.221s 0.001s
im_detect: 2834/4024 0.221s 0.001s
im_detect: 2835/4024 0.221s 0.001s
im_detect: 2836/4024 0.221s 0.001s
im_detect: 2837/4024 0.221s 0.001s
im_detect: 2838/4024 0.221s 0.001s
im_detect: 2839/4024 0.221s 0.001s
im_detect: 2840/4024 0.221s 0.001s
im_detect: 2841/4024 0.221s 0.001s
im_detect: 2842/4024 0.221s 0.001s
im_detect: 2843/4024 0.221s 0.001s
im_detect: 2844/4024 0.221s 0.001s
im_detect: 2845/4024 0.221s 0.001s
im_detect: 2846/4024 0.221s 0.001s
im_detect: 2847/4024 0.221s 0.001s
im_detect: 2848/4024 0.221s 0.001s
im_detect: 2849/4024 0.221s 0.001s
im_detect: 2850/4024 0.221s 0.001s
im_detect: 2851/4024 0.221s 0.001s
im_detect: 2852/4024 0.221s 0.001s
im_detect: 2853/4024 0.221s 0.001s
im_detect: 2854/4024 0.221s 0.001s
im_detect: 2855/4024 0.221s 0.001s
im_detect: 2856/4024 0.221s 0.001s
im_detect: 2857/4024 0.221s 0.001s
im_detect: 2858/4024 0.221s 0.001s
im_detect: 2859/4024 0.221s 0.001s
im_detect: 2860/4024 0.221s 0.001s
im_detect: 2861/4024 0.221s 0.001s
im_detect: 2862/4024 0.221s 0.001s
im_detect: 2863/4024 0.221s 0.001s
im_detect: 2864/4024 0.221s 0.001s
im_detect: 2865/4024 0.221s 0.001s
im_detect: 2866/4024 0.221s 0.001s
im_detect: 2867/4024 0.221s 0.001s
im_detect: 2868/4024 0.221s 0.001s
im_detect: 2869/4024 0.221s 0.001s
im_detect: 2870/4024 0.221s 0.001s
im_detect: 2871/4024 0.221s 0.001s
im_detect: 2872/4024 0.221s 0.001s
im_detect: 2873/4024 0.221s 0.001s
im_detect: 2874/4024 0.221s 0.001s
im_detect: 2875/4024 0.221s 0.001s
im_detect: 2876/4024 0.221s 0.001s
im_detect: 2877/4024 0.221s 0.001s
im_detect: 2878/4024 0.221s 0.001s
im_detect: 2879/4024 0.221s 0.001s
im_detect: 2880/4024 0.221s 0.001s
im_detect: 2881/4024 0.221s 0.001s
im_detect: 2882/4024 0.221s 0.001s
im_detect: 2883/4024 0.221s 0.001s
im_detect: 2884/4024 0.221s 0.001s
im_detect: 2885/4024 0.221s 0.001s
im_detect: 2886/4024 0.221s 0.001s
im_detect: 2887/4024 0.221s 0.001s
im_detect: 2888/4024 0.221s 0.001s
im_detect: 2889/4024 0.221s 0.001s
im_detect: 2890/4024 0.221s 0.001s
im_detect: 2891/4024 0.221s 0.001s
im_detect: 2892/4024 0.221s 0.001s
im_detect: 2893/4024 0.221s 0.001s
im_detect: 2894/4024 0.221s 0.001s
im_detect: 2895/4024 0.221s 0.001s
im_detect: 2896/4024 0.221s 0.001s
im_detect: 2897/4024 0.221s 0.001s
im_detect: 2898/4024 0.221s 0.001s
im_detect: 2899/4024 0.221s 0.001s
im_detect: 2900/4024 0.221s 0.001s
im_detect: 2901/4024 0.221s 0.001s
im_detect: 2902/4024 0.221s 0.001s
im_detect: 2903/4024 0.221s 0.001s
im_detect: 2904/4024 0.221s 0.001s
im_detect: 2905/4024 0.221s 0.001s
im_detect: 2906/4024 0.221s 0.001s
im_detect: 2907/4024 0.221s 0.001s
im_detect: 2908/4024 0.221s 0.001s
im_detect: 2909/4024 0.221s 0.001s
im_detect: 2910/4024 0.221s 0.001s
im_detect: 2911/4024 0.221s 0.001s
im_detect: 2912/4024 0.221s 0.001s
im_detect: 2913/4024 0.221s 0.001s
im_detect: 2914/4024 0.221s 0.001s
im_detect: 2915/4024 0.221s 0.001s
im_detect: 2916/4024 0.221s 0.001s
im_detect: 2917/4024 0.221s 0.001s
im_detect: 2918/4024 0.221s 0.001s
im_detect: 2919/4024 0.221s 0.001s
im_detect: 2920/4024 0.221s 0.001s
im_detect: 2921/4024 0.221s 0.001s
im_detect: 2922/4024 0.221s 0.001s
im_detect: 2923/4024 0.221s 0.001s
im_detect: 2924/4024 0.221s 0.001s
im_detect: 2925/4024 0.221s 0.001s
im_detect: 2926/4024 0.221s 0.001s
im_detect: 2927/4024 0.221s 0.001s
im_detect: 2928/4024 0.221s 0.001s
im_detect: 2929/4024 0.221s 0.001s
im_detect: 2930/4024 0.221s 0.001s
im_detect: 2931/4024 0.221s 0.001s
im_detect: 2932/4024 0.221s 0.001s
im_detect: 2933/4024 0.221s 0.001s
im_detect: 2934/4024 0.221s 0.001s
im_detect: 2935/4024 0.221s 0.001s
im_detect: 2936/4024 0.221s 0.001s
im_detect: 2937/4024 0.221s 0.001s
im_detect: 2938/4024 0.221s 0.001s
im_detect: 2939/4024 0.221s 0.001s
im_detect: 2940/4024 0.221s 0.001s
im_detect: 2941/4024 0.221s 0.001s
im_detect: 2942/4024 0.221s 0.001s
im_detect: 2943/4024 0.221s 0.001s
im_detect: 2944/4024 0.221s 0.001s
im_detect: 2945/4024 0.221s 0.001s
im_detect: 2946/4024 0.221s 0.001s
im_detect: 2947/4024 0.221s 0.001s
im_detect: 2948/4024 0.221s 0.001s
im_detect: 2949/4024 0.221s 0.001s
im_detect: 2950/4024 0.221s 0.001s
im_detect: 2951/4024 0.221s 0.001s
im_detect: 2952/4024 0.221s 0.001s
im_detect: 2953/4024 0.221s 0.001s
im_detect: 2954/4024 0.221s 0.001s
im_detect: 2955/4024 0.221s 0.001s
im_detect: 2956/4024 0.221s 0.001s
im_detect: 2957/4024 0.221s 0.001s
im_detect: 2958/4024 0.221s 0.001s
im_detect: 2959/4024 0.221s 0.001s
im_detect: 2960/4024 0.221s 0.001s
im_detect: 2961/4024 0.221s 0.001s
im_detect: 2962/4024 0.221s 0.001s
im_detect: 2963/4024 0.221s 0.001s
im_detect: 2964/4024 0.221s 0.001s
im_detect: 2965/4024 0.221s 0.001s
im_detect: 2966/4024 0.221s 0.001s
im_detect: 2967/4024 0.221s 0.001s
im_detect: 2968/4024 0.221s 0.001s
im_detect: 2969/4024 0.221s 0.001s
im_detect: 2970/4024 0.221s 0.001s
im_detect: 2971/4024 0.221s 0.001s
im_detect: 2972/4024 0.221s 0.001s
im_detect: 2973/4024 0.221s 0.001s
im_detect: 2974/4024 0.221s 0.001s
im_detect: 2975/4024 0.221s 0.001s
im_detect: 2976/4024 0.221s 0.001s
im_detect: 2977/4024 0.221s 0.001s
im_detect: 2978/4024 0.221s 0.001s
im_detect: 2979/4024 0.221s 0.001s
im_detect: 2980/4024 0.221s 0.001s
im_detect: 2981/4024 0.221s 0.001s
im_detect: 2982/4024 0.221s 0.001s
im_detect: 2983/4024 0.221s 0.001s
im_detect: 2984/4024 0.221s 0.001s
im_detect: 2985/4024 0.221s 0.001s
im_detect: 2986/4024 0.221s 0.001s
im_detect: 2987/4024 0.221s 0.001s
im_detect: 2988/4024 0.221s 0.001s
im_detect: 2989/4024 0.221s 0.001s
im_detect: 2990/4024 0.221s 0.001s
im_detect: 2991/4024 0.221s 0.001s
im_detect: 2992/4024 0.221s 0.001s
im_detect: 2993/4024 0.221s 0.001s
im_detect: 2994/4024 0.221s 0.001s
im_detect: 2995/4024 0.221s 0.001s
im_detect: 2996/4024 0.221s 0.001s
im_detect: 2997/4024 0.221s 0.001s
im_detect: 2998/4024 0.221s 0.001s
im_detect: 2999/4024 0.221s 0.001s
im_detect: 3000/4024 0.221s 0.001s
im_detect: 3001/4024 0.221s 0.001s
im_detect: 3002/4024 0.221s 0.001s
im_detect: 3003/4024 0.221s 0.001s
im_detect: 3004/4024 0.221s 0.001s
im_detect: 3005/4024 0.221s 0.001s
im_detect: 3006/4024 0.221s 0.001s
im_detect: 3007/4024 0.221s 0.001s
im_detect: 3008/4024 0.221s 0.001s
im_detect: 3009/4024 0.221s 0.001s
im_detect: 3010/4024 0.221s 0.001s
im_detect: 3011/4024 0.221s 0.001s
im_detect: 3012/4024 0.221s 0.001s
im_detect: 3013/4024 0.221s 0.001s
im_detect: 3014/4024 0.221s 0.001s
im_detect: 3015/4024 0.221s 0.001s
im_detect: 3016/4024 0.221s 0.001s
im_detect: 3017/4024 0.221s 0.001s
im_detect: 3018/4024 0.221s 0.001s
im_detect: 3019/4024 0.221s 0.001s
im_detect: 3020/4024 0.221s 0.001s
im_detect: 3021/4024 0.221s 0.001s
im_detect: 3022/4024 0.221s 0.001s
im_detect: 3023/4024 0.221s 0.001s
im_detect: 3024/4024 0.221s 0.001s
im_detect: 3025/4024 0.221s 0.001s
im_detect: 3026/4024 0.221s 0.001s
im_detect: 3027/4024 0.221s 0.001s
im_detect: 3028/4024 0.221s 0.001s
im_detect: 3029/4024 0.221s 0.001s
im_detect: 3030/4024 0.221s 0.001s
im_detect: 3031/4024 0.221s 0.001s
im_detect: 3032/4024 0.221s 0.001s
im_detect: 3033/4024 0.221s 0.001s
im_detect: 3034/4024 0.221s 0.001s
im_detect: 3035/4024 0.221s 0.001s
im_detect: 3036/4024 0.221s 0.001s
im_detect: 3037/4024 0.221s 0.001s
im_detect: 3038/4024 0.221s 0.001s
im_detect: 3039/4024 0.221s 0.001s
im_detect: 3040/4024 0.221s 0.001s
im_detect: 3041/4024 0.221s 0.001s
im_detect: 3042/4024 0.221s 0.001s
im_detect: 3043/4024 0.221s 0.001s
im_detect: 3044/4024 0.221s 0.001s
im_detect: 3045/4024 0.221s 0.001s
im_detect: 3046/4024 0.221s 0.001s
im_detect: 3047/4024 0.221s 0.001s
im_detect: 3048/4024 0.221s 0.001s
im_detect: 3049/4024 0.221s 0.001s
im_detect: 3050/4024 0.221s 0.001s
im_detect: 3051/4024 0.221s 0.001s
im_detect: 3052/4024 0.221s 0.001s
im_detect: 3053/4024 0.221s 0.001s
im_detect: 3054/4024 0.221s 0.001s
im_detect: 3055/4024 0.221s 0.001s
im_detect: 3056/4024 0.221s 0.001s
im_detect: 3057/4024 0.221s 0.001s
im_detect: 3058/4024 0.221s 0.001s
im_detect: 3059/4024 0.221s 0.001s
im_detect: 3060/4024 0.221s 0.001s
im_detect: 3061/4024 0.221s 0.001s
im_detect: 3062/4024 0.221s 0.001s
im_detect: 3063/4024 0.221s 0.001s
im_detect: 3064/4024 0.221s 0.001s
im_detect: 3065/4024 0.221s 0.001s
im_detect: 3066/4024 0.221s 0.001s
im_detect: 3067/4024 0.221s 0.001s
im_detect: 3068/4024 0.221s 0.001s
im_detect: 3069/4024 0.221s 0.001s
im_detect: 3070/4024 0.221s 0.001s
im_detect: 3071/4024 0.221s 0.001s
im_detect: 3072/4024 0.221s 0.001s
im_detect: 3073/4024 0.221s 0.001s
im_detect: 3074/4024 0.221s 0.001s
im_detect: 3075/4024 0.221s 0.001s
im_detect: 3076/4024 0.221s 0.001s
im_detect: 3077/4024 0.221s 0.001s
im_detect: 3078/4024 0.221s 0.001s
im_detect: 3079/4024 0.221s 0.001s
im_detect: 3080/4024 0.221s 0.001s
im_detect: 3081/4024 0.221s 0.001s
im_detect: 3082/4024 0.221s 0.001s
im_detect: 3083/4024 0.221s 0.001s
im_detect: 3084/4024 0.221s 0.001s
im_detect: 3085/4024 0.221s 0.001s
im_detect: 3086/4024 0.221s 0.001s
im_detect: 3087/4024 0.221s 0.001s
im_detect: 3088/4024 0.221s 0.001s
im_detect: 3089/4024 0.221s 0.001s
im_detect: 3090/4024 0.221s 0.001s
im_detect: 3091/4024 0.221s 0.001s
im_detect: 3092/4024 0.221s 0.001s
im_detect: 3093/4024 0.221s 0.001s
im_detect: 3094/4024 0.221s 0.001s
im_detect: 3095/4024 0.221s 0.001s
im_detect: 3096/4024 0.221s 0.001s
im_detect: 3097/4024 0.221s 0.001s
im_detect: 3098/4024 0.221s 0.001s
im_detect: 3099/4024 0.221s 0.001s
im_detect: 3100/4024 0.221s 0.001s
im_detect: 3101/4024 0.221s 0.001s
im_detect: 3102/4024 0.221s 0.001s
im_detect: 3103/4024 0.221s 0.001s
im_detect: 3104/4024 0.221s 0.001s
im_detect: 3105/4024 0.221s 0.001s
im_detect: 3106/4024 0.221s 0.001s
im_detect: 3107/4024 0.221s 0.001s
im_detect: 3108/4024 0.221s 0.001s
im_detect: 3109/4024 0.221s 0.001s
im_detect: 3110/4024 0.221s 0.001s
im_detect: 3111/4024 0.221s 0.001s
im_detect: 3112/4024 0.221s 0.001s
im_detect: 3113/4024 0.221s 0.001s
im_detect: 3114/4024 0.221s 0.001s
im_detect: 3115/4024 0.221s 0.001s
im_detect: 3116/4024 0.221s 0.001s
im_detect: 3117/4024 0.221s 0.001s
im_detect: 3118/4024 0.221s 0.001s
im_detect: 3119/4024 0.221s 0.001s
im_detect: 3120/4024 0.221s 0.001s
im_detect: 3121/4024 0.221s 0.001s
im_detect: 3122/4024 0.221s 0.001s
im_detect: 3123/4024 0.221s 0.001s
im_detect: 3124/4024 0.221s 0.001s
im_detect: 3125/4024 0.221s 0.001s
im_detect: 3126/4024 0.221s 0.001s
im_detect: 3127/4024 0.221s 0.001s
im_detect: 3128/4024 0.221s 0.001s
im_detect: 3129/4024 0.221s 0.001s
im_detect: 3130/4024 0.221s 0.001s
im_detect: 3131/4024 0.221s 0.001s
im_detect: 3132/4024 0.221s 0.001s
im_detect: 3133/4024 0.221s 0.001s
im_detect: 3134/4024 0.221s 0.001s
im_detect: 3135/4024 0.221s 0.001s
im_detect: 3136/4024 0.221s 0.001s
im_detect: 3137/4024 0.221s 0.001s
im_detect: 3138/4024 0.221s 0.001s
im_detect: 3139/4024 0.221s 0.001s
im_detect: 3140/4024 0.221s 0.001s
im_detect: 3141/4024 0.221s 0.001s
im_detect: 3142/4024 0.221s 0.001s
im_detect: 3143/4024 0.221s 0.001s
im_detect: 3144/4024 0.221s 0.001s
im_detect: 3145/4024 0.221s 0.001s
im_detect: 3146/4024 0.221s 0.001s
im_detect: 3147/4024 0.221s 0.001s
im_detect: 3148/4024 0.221s 0.001s
im_detect: 3149/4024 0.221s 0.001s
im_detect: 3150/4024 0.221s 0.001s
im_detect: 3151/4024 0.221s 0.001s
im_detect: 3152/4024 0.221s 0.001s
im_detect: 3153/4024 0.221s 0.001s
im_detect: 3154/4024 0.221s 0.001s
im_detect: 3155/4024 0.221s 0.001s
im_detect: 3156/4024 0.221s 0.001s
im_detect: 3157/4024 0.221s 0.001s
im_detect: 3158/4024 0.221s 0.001s
im_detect: 3159/4024 0.221s 0.001s
im_detect: 3160/4024 0.221s 0.001s
im_detect: 3161/4024 0.221s 0.001s
im_detect: 3162/4024 0.221s 0.001s
im_detect: 3163/4024 0.221s 0.001s
im_detect: 3164/4024 0.221s 0.001s
im_detect: 3165/4024 0.221s 0.001s
im_detect: 3166/4024 0.221s 0.001s
im_detect: 3167/4024 0.221s 0.001s
im_detect: 3168/4024 0.221s 0.001s
im_detect: 3169/4024 0.221s 0.001s
im_detect: 3170/4024 0.221s 0.001s
im_detect: 3171/4024 0.221s 0.001s
im_detect: 3172/4024 0.221s 0.001s
im_detect: 3173/4024 0.221s 0.001s
im_detect: 3174/4024 0.221s 0.001s
im_detect: 3175/4024 0.221s 0.001s
im_detect: 3176/4024 0.221s 0.001s
im_detect: 3177/4024 0.221s 0.001s
im_detect: 3178/4024 0.221s 0.001s
im_detect: 3179/4024 0.221s 0.001s
im_detect: 3180/4024 0.221s 0.001s
im_detect: 3181/4024 0.221s 0.001s
im_detect: 3182/4024 0.221s 0.001s
im_detect: 3183/4024 0.221s 0.001s
im_detect: 3184/4024 0.221s 0.001s
im_detect: 3185/4024 0.221s 0.001s
im_detect: 3186/4024 0.221s 0.001s
im_detect: 3187/4024 0.221s 0.001s
im_detect: 3188/4024 0.221s 0.001s
im_detect: 3189/4024 0.221s 0.001s
im_detect: 3190/4024 0.221s 0.001s
im_detect: 3191/4024 0.221s 0.001s
im_detect: 3192/4024 0.221s 0.001s
im_detect: 3193/4024 0.221s 0.001s
im_detect: 3194/4024 0.221s 0.001s
im_detect: 3195/4024 0.221s 0.001s
im_detect: 3196/4024 0.221s 0.001s
im_detect: 3197/4024 0.221s 0.001s
im_detect: 3198/4024 0.221s 0.001s
im_detect: 3199/4024 0.221s 0.001s
im_detect: 3200/4024 0.221s 0.001s
im_detect: 3201/4024 0.221s 0.001s
im_detect: 3202/4024 0.221s 0.001s
im_detect: 3203/4024 0.221s 0.001s
im_detect: 3204/4024 0.221s 0.001s
im_detect: 3205/4024 0.221s 0.001s
im_detect: 3206/4024 0.221s 0.001s
im_detect: 3207/4024 0.221s 0.001s
im_detect: 3208/4024 0.221s 0.001s
im_detect: 3209/4024 0.221s 0.001s
im_detect: 3210/4024 0.221s 0.001s
im_detect: 3211/4024 0.221s 0.001s
im_detect: 3212/4024 0.221s 0.001s
im_detect: 3213/4024 0.221s 0.001s
im_detect: 3214/4024 0.221s 0.001s
im_detect: 3215/4024 0.221s 0.001s
im_detect: 3216/4024 0.221s 0.001s
im_detect: 3217/4024 0.221s 0.001s
im_detect: 3218/4024 0.221s 0.001s
im_detect: 3219/4024 0.221s 0.001s
im_detect: 3220/4024 0.221s 0.001s
im_detect: 3221/4024 0.221s 0.001s
im_detect: 3222/4024 0.221s 0.001s
im_detect: 3223/4024 0.221s 0.001s
im_detect: 3224/4024 0.221s 0.001s
im_detect: 3225/4024 0.221s 0.001s
im_detect: 3226/4024 0.221s 0.001s
im_detect: 3227/4024 0.221s 0.001s
im_detect: 3228/4024 0.221s 0.001s
im_detect: 3229/4024 0.221s 0.001s
im_detect: 3230/4024 0.221s 0.001s
im_detect: 3231/4024 0.221s 0.001s
im_detect: 3232/4024 0.221s 0.001s
im_detect: 3233/4024 0.221s 0.001s
im_detect: 3234/4024 0.221s 0.001s
im_detect: 3235/4024 0.221s 0.001s
im_detect: 3236/4024 0.221s 0.001s
im_detect: 3237/4024 0.221s 0.001s
im_detect: 3238/4024 0.221s 0.001s
im_detect: 3239/4024 0.221s 0.001s
im_detect: 3240/4024 0.221s 0.001s
im_detect: 3241/4024 0.221s 0.001s
im_detect: 3242/4024 0.221s 0.001s
im_detect: 3243/4024 0.221s 0.001s
im_detect: 3244/4024 0.221s 0.001s
im_detect: 3245/4024 0.221s 0.001s
im_detect: 3246/4024 0.221s 0.001s
im_detect: 3247/4024 0.221s 0.001s
im_detect: 3248/4024 0.221s 0.001s
im_detect: 3249/4024 0.221s 0.001s
im_detect: 3250/4024 0.221s 0.001s
im_detect: 3251/4024 0.221s 0.001s
im_detect: 3252/4024 0.221s 0.001s
im_detect: 3253/4024 0.221s 0.001s
im_detect: 3254/4024 0.221s 0.001s
im_detect: 3255/4024 0.221s 0.001s
im_detect: 3256/4024 0.221s 0.001s
im_detect: 3257/4024 0.221s 0.001s
im_detect: 3258/4024 0.221s 0.001s
im_detect: 3259/4024 0.221s 0.001s
im_detect: 3260/4024 0.221s 0.001s
im_detect: 3261/4024 0.221s 0.001s
im_detect: 3262/4024 0.221s 0.001s
im_detect: 3263/4024 0.221s 0.001s
im_detect: 3264/4024 0.221s 0.001s
im_detect: 3265/4024 0.221s 0.001s
im_detect: 3266/4024 0.221s 0.001s
im_detect: 3267/4024 0.221s 0.001s
im_detect: 3268/4024 0.221s 0.001s
im_detect: 3269/4024 0.221s 0.001s
im_detect: 3270/4024 0.221s 0.001s
im_detect: 3271/4024 0.221s 0.001s
im_detect: 3272/4024 0.221s 0.001s
im_detect: 3273/4024 0.221s 0.001s
im_detect: 3274/4024 0.221s 0.001s
im_detect: 3275/4024 0.221s 0.001s
im_detect: 3276/4024 0.221s 0.001s
im_detect: 3277/4024 0.221s 0.001s
im_detect: 3278/4024 0.221s 0.001s
im_detect: 3279/4024 0.221s 0.001s
im_detect: 3280/4024 0.221s 0.001s
im_detect: 3281/4024 0.221s 0.001s
im_detect: 3282/4024 0.221s 0.001s
im_detect: 3283/4024 0.221s 0.001s
im_detect: 3284/4024 0.221s 0.001s
im_detect: 3285/4024 0.221s 0.001s
im_detect: 3286/4024 0.221s 0.001s
im_detect: 3287/4024 0.221s 0.001s
im_detect: 3288/4024 0.221s 0.001s
im_detect: 3289/4024 0.221s 0.001s
im_detect: 3290/4024 0.221s 0.001s
im_detect: 3291/4024 0.221s 0.001s
im_detect: 3292/4024 0.221s 0.001s
im_detect: 3293/4024 0.221s 0.001s
im_detect: 3294/4024 0.221s 0.001s
im_detect: 3295/4024 0.221s 0.001s
im_detect: 3296/4024 0.221s 0.001s
im_detect: 3297/4024 0.221s 0.001s
im_detect: 3298/4024 0.221s 0.001s
im_detect: 3299/4024 0.221s 0.001s
im_detect: 3300/4024 0.221s 0.001s
im_detect: 3301/4024 0.221s 0.001s
im_detect: 3302/4024 0.221s 0.001s
im_detect: 3303/4024 0.221s 0.001s
im_detect: 3304/4024 0.221s 0.001s
im_detect: 3305/4024 0.221s 0.001s
im_detect: 3306/4024 0.221s 0.001s
im_detect: 3307/4024 0.221s 0.001s
im_detect: 3308/4024 0.221s 0.001s
im_detect: 3309/4024 0.221s 0.001s
im_detect: 3310/4024 0.221s 0.001s
im_detect: 3311/4024 0.221s 0.001s
im_detect: 3312/4024 0.221s 0.001s
im_detect: 3313/4024 0.221s 0.001s
im_detect: 3314/4024 0.221s 0.001s
im_detect: 3315/4024 0.221s 0.001s
im_detect: 3316/4024 0.221s 0.001s
im_detect: 3317/4024 0.221s 0.001s
im_detect: 3318/4024 0.221s 0.001s
im_detect: 3319/4024 0.221s 0.001s
im_detect: 3320/4024 0.221s 0.001s
im_detect: 3321/4024 0.221s 0.001s
im_detect: 3322/4024 0.221s 0.001s
im_detect: 3323/4024 0.221s 0.001s
im_detect: 3324/4024 0.221s 0.001s
im_detect: 3325/4024 0.221s 0.001s
im_detect: 3326/4024 0.221s 0.001s
im_detect: 3327/4024 0.221s 0.001s
im_detect: 3328/4024 0.221s 0.001s
im_detect: 3329/4024 0.221s 0.001s
im_detect: 3330/4024 0.221s 0.001s
im_detect: 3331/4024 0.221s 0.001s
im_detect: 3332/4024 0.221s 0.001s
im_detect: 3333/4024 0.221s 0.001s
im_detect: 3334/4024 0.221s 0.001s
im_detect: 3335/4024 0.221s 0.001s
im_detect: 3336/4024 0.221s 0.001s
im_detect: 3337/4024 0.221s 0.001s
im_detect: 3338/4024 0.221s 0.001s
im_detect: 3339/4024 0.221s 0.001s
im_detect: 3340/4024 0.221s 0.001s
im_detect: 3341/4024 0.221s 0.001s
im_detect: 3342/4024 0.221s 0.001s
im_detect: 3343/4024 0.221s 0.001s
im_detect: 3344/4024 0.221s 0.001s
im_detect: 3345/4024 0.221s 0.001s
im_detect: 3346/4024 0.221s 0.001s
im_detect: 3347/4024 0.221s 0.001s
im_detect: 3348/4024 0.221s 0.001s
im_detect: 3349/4024 0.221s 0.001s
im_detect: 3350/4024 0.221s 0.001s
im_detect: 3351/4024 0.221s 0.001s
im_detect: 3352/4024 0.221s 0.001s
im_detect: 3353/4024 0.221s 0.001s
im_detect: 3354/4024 0.221s 0.001s
im_detect: 3355/4024 0.221s 0.001s
im_detect: 3356/4024 0.221s 0.001s
im_detect: 3357/4024 0.221s 0.001s
im_detect: 3358/4024 0.221s 0.001s
im_detect: 3359/4024 0.221s 0.001s
im_detect: 3360/4024 0.221s 0.001s
im_detect: 3361/4024 0.221s 0.001s
im_detect: 3362/4024 0.221s 0.001s
im_detect: 3363/4024 0.221s 0.001s
im_detect: 3364/4024 0.221s 0.001s
im_detect: 3365/4024 0.221s 0.001s
im_detect: 3366/4024 0.221s 0.001s
im_detect: 3367/4024 0.221s 0.001s
im_detect: 3368/4024 0.221s 0.001s
im_detect: 3369/4024 0.221s 0.001s
im_detect: 3370/4024 0.221s 0.001s
im_detect: 3371/4024 0.221s 0.001s
im_detect: 3372/4024 0.221s 0.001s
im_detect: 3373/4024 0.221s 0.001s
im_detect: 3374/4024 0.221s 0.001s
im_detect: 3375/4024 0.221s 0.001s
im_detect: 3376/4024 0.221s 0.001s
im_detect: 3377/4024 0.221s 0.001s
im_detect: 3378/4024 0.221s 0.001s
im_detect: 3379/4024 0.221s 0.001s
im_detect: 3380/4024 0.221s 0.001s
im_detect: 3381/4024 0.221s 0.001s
im_detect: 3382/4024 0.221s 0.001s
im_detect: 3383/4024 0.221s 0.001s
im_detect: 3384/4024 0.221s 0.001s
im_detect: 3385/4024 0.221s 0.001s
im_detect: 3386/4024 0.221s 0.001s
im_detect: 3387/4024 0.221s 0.001s
im_detect: 3388/4024 0.221s 0.001s
im_detect: 3389/4024 0.221s 0.001s
im_detect: 3390/4024 0.221s 0.001s
im_detect: 3391/4024 0.221s 0.001s
im_detect: 3392/4024 0.221s 0.001s
im_detect: 3393/4024 0.221s 0.001s
im_detect: 3394/4024 0.221s 0.001s
im_detect: 3395/4024 0.221s 0.001s
im_detect: 3396/4024 0.221s 0.001s
im_detect: 3397/4024 0.221s 0.001s
im_detect: 3398/4024 0.221s 0.001s
im_detect: 3399/4024 0.221s 0.001s
im_detect: 3400/4024 0.221s 0.001s
im_detect: 3401/4024 0.221s 0.001s
im_detect: 3402/4024 0.221s 0.001s
im_detect: 3403/4024 0.221s 0.001s
im_detect: 3404/4024 0.221s 0.001s
im_detect: 3405/4024 0.221s 0.001s
im_detect: 3406/4024 0.221s 0.001s
im_detect: 3407/4024 0.221s 0.001s
im_detect: 3408/4024 0.221s 0.001s
im_detect: 3409/4024 0.221s 0.001s
im_detect: 3410/4024 0.221s 0.001s
im_detect: 3411/4024 0.221s 0.001s
im_detect: 3412/4024 0.221s 0.001s
im_detect: 3413/4024 0.221s 0.001s
im_detect: 3414/4024 0.221s 0.001s
im_detect: 3415/4024 0.221s 0.001s
im_detect: 3416/4024 0.221s 0.001s
im_detect: 3417/4024 0.221s 0.001s
im_detect: 3418/4024 0.221s 0.001s
im_detect: 3419/4024 0.221s 0.001s
im_detect: 3420/4024 0.221s 0.001s
im_detect: 3421/4024 0.221s 0.001s
im_detect: 3422/4024 0.221s 0.001s
im_detect: 3423/4024 0.221s 0.001s
im_detect: 3424/4024 0.221s 0.001s
im_detect: 3425/4024 0.221s 0.001s
im_detect: 3426/4024 0.221s 0.001s
im_detect: 3427/4024 0.221s 0.001s
im_detect: 3428/4024 0.221s 0.001s
im_detect: 3429/4024 0.221s 0.001s
im_detect: 3430/4024 0.221s 0.001s
im_detect: 3431/4024 0.221s 0.001s
im_detect: 3432/4024 0.221s 0.001s
im_detect: 3433/4024 0.221s 0.001s
im_detect: 3434/4024 0.221s 0.001s
im_detect: 3435/4024 0.221s 0.001s
im_detect: 3436/4024 0.221s 0.001s
im_detect: 3437/4024 0.221s 0.001s
im_detect: 3438/4024 0.221s 0.001s
im_detect: 3439/4024 0.221s 0.001s
im_detect: 3440/4024 0.221s 0.001s
im_detect: 3441/4024 0.221s 0.001s
im_detect: 3442/4024 0.221s 0.001s
im_detect: 3443/4024 0.221s 0.001s
im_detect: 3444/4024 0.221s 0.001s
im_detect: 3445/4024 0.221s 0.001s
im_detect: 3446/4024 0.221s 0.001s
im_detect: 3447/4024 0.221s 0.001s
im_detect: 3448/4024 0.221s 0.001s
im_detect: 3449/4024 0.221s 0.001s
im_detect: 3450/4024 0.221s 0.001s
im_detect: 3451/4024 0.221s 0.001s
im_detect: 3452/4024 0.221s 0.001s
im_detect: 3453/4024 0.221s 0.001s
im_detect: 3454/4024 0.221s 0.001s
im_detect: 3455/4024 0.221s 0.001s
im_detect: 3456/4024 0.221s 0.001s
im_detect: 3457/4024 0.221s 0.001s
im_detect: 3458/4024 0.221s 0.001s
im_detect: 3459/4024 0.221s 0.001s
im_detect: 3460/4024 0.221s 0.001s
im_detect: 3461/4024 0.221s 0.001s
im_detect: 3462/4024 0.221s 0.001s
im_detect: 3463/4024 0.221s 0.001s
im_detect: 3464/4024 0.221s 0.001s
im_detect: 3465/4024 0.221s 0.001s
im_detect: 3466/4024 0.221s 0.001s
im_detect: 3467/4024 0.221s 0.001s
im_detect: 3468/4024 0.221s 0.001s
im_detect: 3469/4024 0.221s 0.001s
im_detect: 3470/4024 0.221s 0.001s
im_detect: 3471/4024 0.221s 0.001s
im_detect: 3472/4024 0.221s 0.001s
im_detect: 3473/4024 0.221s 0.001s
im_detect: 3474/4024 0.221s 0.001s
im_detect: 3475/4024 0.221s 0.001s
im_detect: 3476/4024 0.221s 0.001s
im_detect: 3477/4024 0.221s 0.001s
im_detect: 3478/4024 0.221s 0.001s
im_detect: 3479/4024 0.221s 0.001s
im_detect: 3480/4024 0.221s 0.001s
im_detect: 3481/4024 0.221s 0.001s
im_detect: 3482/4024 0.221s 0.001s
im_detect: 3483/4024 0.221s 0.001s
im_detect: 3484/4024 0.221s 0.001s
im_detect: 3485/4024 0.221s 0.001s
im_detect: 3486/4024 0.221s 0.001s
im_detect: 3487/4024 0.221s 0.001s
im_detect: 3488/4024 0.221s 0.001s
im_detect: 3489/4024 0.221s 0.001s
im_detect: 3490/4024 0.221s 0.001s
im_detect: 3491/4024 0.221s 0.001s
im_detect: 3492/4024 0.221s 0.001s
im_detect: 3493/4024 0.221s 0.001s
im_detect: 3494/4024 0.221s 0.001s
im_detect: 3495/4024 0.221s 0.001s
im_detect: 3496/4024 0.221s 0.001s
im_detect: 3497/4024 0.221s 0.001s
im_detect: 3498/4024 0.221s 0.001s
im_detect: 3499/4024 0.221s 0.001s
im_detect: 3500/4024 0.221s 0.001s
im_detect: 3501/4024 0.221s 0.001s
im_detect: 3502/4024 0.221s 0.001s
im_detect: 3503/4024 0.221s 0.001s
im_detect: 3504/4024 0.221s 0.001s
im_detect: 3505/4024 0.221s 0.001s
im_detect: 3506/4024 0.221s 0.001s
im_detect: 3507/4024 0.221s 0.001s
im_detect: 3508/4024 0.221s 0.001s
im_detect: 3509/4024 0.221s 0.001s
im_detect: 3510/4024 0.221s 0.001s
im_detect: 3511/4024 0.221s 0.001s
im_detect: 3512/4024 0.221s 0.001s
im_detect: 3513/4024 0.221s 0.001s
im_detect: 3514/4024 0.221s 0.001s
im_detect: 3515/4024 0.221s 0.001s
im_detect: 3516/4024 0.221s 0.001s
im_detect: 3517/4024 0.221s 0.001s
im_detect: 3518/4024 0.221s 0.001s
im_detect: 3519/4024 0.221s 0.001s
im_detect: 3520/4024 0.221s 0.001s
im_detect: 3521/4024 0.221s 0.001s
im_detect: 3522/4024 0.221s 0.001s
im_detect: 3523/4024 0.221s 0.001s
im_detect: 3524/4024 0.221s 0.001s
im_detect: 3525/4024 0.221s 0.001s
im_detect: 3526/4024 0.221s 0.001s
im_detect: 3527/4024 0.221s 0.001s
im_detect: 3528/4024 0.221s 0.001s
im_detect: 3529/4024 0.221s 0.001s
im_detect: 3530/4024 0.221s 0.001s
im_detect: 3531/4024 0.221s 0.001s
im_detect: 3532/4024 0.221s 0.001s
im_detect: 3533/4024 0.221s 0.001s
im_detect: 3534/4024 0.221s 0.001s
im_detect: 3535/4024 0.221s 0.001s
im_detect: 3536/4024 0.221s 0.001s
im_detect: 3537/4024 0.221s 0.001s
im_detect: 3538/4024 0.221s 0.001s
im_detect: 3539/4024 0.221s 0.001s
im_detect: 3540/4024 0.221s 0.001s
im_detect: 3541/4024 0.221s 0.001s
im_detect: 3542/4024 0.221s 0.001s
im_detect: 3543/4024 0.221s 0.001s
im_detect: 3544/4024 0.221s 0.001s
im_detect: 3545/4024 0.221s 0.001s
im_detect: 3546/4024 0.221s 0.001s
im_detect: 3547/4024 0.221s 0.001s
im_detect: 3548/4024 0.221s 0.001s
im_detect: 3549/4024 0.221s 0.001s
im_detect: 3550/4024 0.221s 0.001s
im_detect: 3551/4024 0.221s 0.001s
im_detect: 3552/4024 0.221s 0.001s
im_detect: 3553/4024 0.221s 0.001s
im_detect: 3554/4024 0.221s 0.001s
im_detect: 3555/4024 0.221s 0.001s
im_detect: 3556/4024 0.221s 0.001s
im_detect: 3557/4024 0.221s 0.001s
im_detect: 3558/4024 0.221s 0.001s
im_detect: 3559/4024 0.221s 0.001s
im_detect: 3560/4024 0.221s 0.001s
im_detect: 3561/4024 0.221s 0.001s
im_detect: 3562/4024 0.221s 0.001s
im_detect: 3563/4024 0.221s 0.001s
im_detect: 3564/4024 0.221s 0.001s
im_detect: 3565/4024 0.221s 0.001s
im_detect: 3566/4024 0.221s 0.001s
im_detect: 3567/4024 0.221s 0.001s
im_detect: 3568/4024 0.221s 0.001s
im_detect: 3569/4024 0.221s 0.001s
im_detect: 3570/4024 0.221s 0.001s
im_detect: 3571/4024 0.221s 0.001s
im_detect: 3572/4024 0.221s 0.001s
im_detect: 3573/4024 0.221s 0.001s
im_detect: 3574/4024 0.221s 0.001s
im_detect: 3575/4024 0.221s 0.001s
im_detect: 3576/4024 0.221s 0.001s
im_detect: 3577/4024 0.221s 0.001s
im_detect: 3578/4024 0.221s 0.001s
im_detect: 3579/4024 0.221s 0.001s
im_detect: 3580/4024 0.221s 0.001s
im_detect: 3581/4024 0.221s 0.001s
im_detect: 3582/4024 0.221s 0.001s
im_detect: 3583/4024 0.221s 0.001s
im_detect: 3584/4024 0.221s 0.001s
im_detect: 3585/4024 0.221s 0.001s
im_detect: 3586/4024 0.221s 0.001s
im_detect: 3587/4024 0.221s 0.001s
im_detect: 3588/4024 0.221s 0.001s
im_detect: 3589/4024 0.221s 0.001s
im_detect: 3590/4024 0.221s 0.001s
im_detect: 3591/4024 0.221s 0.001s
im_detect: 3592/4024 0.221s 0.001s
im_detect: 3593/4024 0.221s 0.001s
im_detect: 3594/4024 0.221s 0.001s
im_detect: 3595/4024 0.221s 0.001s
im_detect: 3596/4024 0.221s 0.001s
im_detect: 3597/4024 0.221s 0.001s
im_detect: 3598/4024 0.221s 0.001s
im_detect: 3599/4024 0.221s 0.001s
im_detect: 3600/4024 0.221s 0.001s
im_detect: 3601/4024 0.221s 0.001s
im_detect: 3602/4024 0.221s 0.001s
im_detect: 3603/4024 0.221s 0.001s
im_detect: 3604/4024 0.221s 0.001s
im_detect: 3605/4024 0.221s 0.001s
im_detect: 3606/4024 0.221s 0.001s
im_detect: 3607/4024 0.221s 0.001s
im_detect: 3608/4024 0.221s 0.001s
im_detect: 3609/4024 0.221s 0.001s
im_detect: 3610/4024 0.221s 0.001s
im_detect: 3611/4024 0.221s 0.001s
im_detect: 3612/4024 0.221s 0.001s
im_detect: 3613/4024 0.221s 0.001s
im_detect: 3614/4024 0.221s 0.001s
im_detect: 3615/4024 0.221s 0.001s
im_detect: 3616/4024 0.221s 0.001s
im_detect: 3617/4024 0.221s 0.001s
im_detect: 3618/4024 0.221s 0.001s
im_detect: 3619/4024 0.221s 0.001s
im_detect: 3620/4024 0.221s 0.001s
im_detect: 3621/4024 0.221s 0.001s
im_detect: 3622/4024 0.221s 0.001s
im_detect: 3623/4024 0.221s 0.001s
im_detect: 3624/4024 0.221s 0.001s
im_detect: 3625/4024 0.221s 0.001s
im_detect: 3626/4024 0.221s 0.001s
im_detect: 3627/4024 0.221s 0.001s
im_detect: 3628/4024 0.221s 0.001s
im_detect: 3629/4024 0.221s 0.001s
im_detect: 3630/4024 0.221s 0.001s
im_detect: 3631/4024 0.221s 0.001s
im_detect: 3632/4024 0.221s 0.001s
im_detect: 3633/4024 0.221s 0.001s
im_detect: 3634/4024 0.221s 0.001s
im_detect: 3635/4024 0.221s 0.001s
im_detect: 3636/4024 0.221s 0.001s
im_detect: 3637/4024 0.221s 0.001s
im_detect: 3638/4024 0.221s 0.001s
im_detect: 3639/4024 0.221s 0.001s
im_detect: 3640/4024 0.221s 0.001s
im_detect: 3641/4024 0.221s 0.001s
im_detect: 3642/4024 0.221s 0.001s
im_detect: 3643/4024 0.221s 0.001s
im_detect: 3644/4024 0.221s 0.001s
im_detect: 3645/4024 0.221s 0.001s
im_detect: 3646/4024 0.221s 0.001s
im_detect: 3647/4024 0.221s 0.001s
im_detect: 3648/4024 0.221s 0.001s
im_detect: 3649/4024 0.221s 0.001s
im_detect: 3650/4024 0.221s 0.001s
im_detect: 3651/4024 0.221s 0.001s
im_detect: 3652/4024 0.221s 0.001s
im_detect: 3653/4024 0.221s 0.001s
im_detect: 3654/4024 0.221s 0.001s
im_detect: 3655/4024 0.221s 0.001s
im_detect: 3656/4024 0.221s 0.001s
im_detect: 3657/4024 0.221s 0.001s
im_detect: 3658/4024 0.221s 0.001s
im_detect: 3659/4024 0.221s 0.001s
im_detect: 3660/4024 0.221s 0.001s
im_detect: 3661/4024 0.221s 0.001s
im_detect: 3662/4024 0.221s 0.001s
im_detect: 3663/4024 0.221s 0.001s
im_detect: 3664/4024 0.221s 0.001s
im_detect: 3665/4024 0.221s 0.001s
im_detect: 3666/4024 0.221s 0.001s
im_detect: 3667/4024 0.221s 0.001s
im_detect: 3668/4024 0.221s 0.001s
im_detect: 3669/4024 0.221s 0.001s
im_detect: 3670/4024 0.221s 0.001s
im_detect: 3671/4024 0.221s 0.001s
im_detect: 3672/4024 0.221s 0.001s
im_detect: 3673/4024 0.221s 0.001s
im_detect: 3674/4024 0.221s 0.001s
im_detect: 3675/4024 0.221s 0.001s
im_detect: 3676/4024 0.221s 0.001s
im_detect: 3677/4024 0.221s 0.001s
im_detect: 3678/4024 0.221s 0.001s
im_detect: 3679/4024 0.221s 0.001s
im_detect: 3680/4024 0.221s 0.001s
im_detect: 3681/4024 0.221s 0.001s
im_detect: 3682/4024 0.221s 0.001s
im_detect: 3683/4024 0.221s 0.001s
im_detect: 3684/4024 0.221s 0.001s
im_detect: 3685/4024 0.221s 0.001s
im_detect: 3686/4024 0.221s 0.001s
im_detect: 3687/4024 0.221s 0.001s
im_detect: 3688/4024 0.221s 0.001s
im_detect: 3689/4024 0.221s 0.001s
im_detect: 3690/4024 0.221s 0.001s
im_detect: 3691/4024 0.221s 0.001s
im_detect: 3692/4024 0.221s 0.001s
im_detect: 3693/4024 0.221s 0.001s
im_detect: 3694/4024 0.221s 0.001s
im_detect: 3695/4024 0.221s 0.001s
im_detect: 3696/4024 0.221s 0.001s
im_detect: 3697/4024 0.221s 0.001s
im_detect: 3698/4024 0.221s 0.001s
im_detect: 3699/4024 0.221s 0.001s
im_detect: 3700/4024 0.221s 0.001s
im_detect: 3701/4024 0.221s 0.001s
im_detect: 3702/4024 0.221s 0.001s
im_detect: 3703/4024 0.221s 0.001s
im_detect: 3704/4024 0.221s 0.001s
im_detect: 3705/4024 0.221s 0.001s
im_detect: 3706/4024 0.221s 0.001s
im_detect: 3707/4024 0.221s 0.001s
im_detect: 3708/4024 0.221s 0.001s
im_detect: 3709/4024 0.221s 0.001s
im_detect: 3710/4024 0.221s 0.001s
im_detect: 3711/4024 0.221s 0.001s
im_detect: 3712/4024 0.221s 0.001s
im_detect: 3713/4024 0.221s 0.001s
im_detect: 3714/4024 0.221s 0.001s
im_detect: 3715/4024 0.221s 0.001s
im_detect: 3716/4024 0.221s 0.001s
im_detect: 3717/4024 0.221s 0.001s
im_detect: 3718/4024 0.221s 0.001s
im_detect: 3719/4024 0.221s 0.001s
im_detect: 3720/4024 0.221s 0.001s
im_detect: 3721/4024 0.221s 0.001s
im_detect: 3722/4024 0.221s 0.001s
im_detect: 3723/4024 0.221s 0.001s
im_detect: 3724/4024 0.221s 0.001s
im_detect: 3725/4024 0.221s 0.001s
im_detect: 3726/4024 0.221s 0.001s
im_detect: 3727/4024 0.221s 0.001s
im_detect: 3728/4024 0.221s 0.001s
im_detect: 3729/4024 0.221s 0.001s
im_detect: 3730/4024 0.221s 0.001s
im_detect: 3731/4024 0.221s 0.001s
im_detect: 3732/4024 0.221s 0.001s
im_detect: 3733/4024 0.221s 0.001s
im_detect: 3734/4024 0.221s 0.001s
im_detect: 3735/4024 0.221s 0.001s
im_detect: 3736/4024 0.221s 0.001s
im_detect: 3737/4024 0.221s 0.001s
im_detect: 3738/4024 0.221s 0.001s
im_detect: 3739/4024 0.221s 0.001s
im_detect: 3740/4024 0.221s 0.001s
im_detect: 3741/4024 0.221s 0.001s
im_detect: 3742/4024 0.221s 0.001s
im_detect: 3743/4024 0.221s 0.001s
im_detect: 3744/4024 0.221s 0.001s
im_detect: 3745/4024 0.221s 0.001s
im_detect: 3746/4024 0.221s 0.001s
im_detect: 3747/4024 0.221s 0.001s
im_detect: 3748/4024 0.221s 0.001s
im_detect: 3749/4024 0.221s 0.001s
im_detect: 3750/4024 0.221s 0.001s
im_detect: 3751/4024 0.221s 0.001s
im_detect: 3752/4024 0.221s 0.001s
im_detect: 3753/4024 0.221s 0.001s
im_detect: 3754/4024 0.221s 0.001s
im_detect: 3755/4024 0.221s 0.001s
im_detect: 3756/4024 0.221s 0.001s
im_detect: 3757/4024 0.221s 0.001s
im_detect: 3758/4024 0.221s 0.001s
im_detect: 3759/4024 0.221s 0.001s
im_detect: 3760/4024 0.221s 0.001s
im_detect: 3761/4024 0.221s 0.001s
im_detect: 3762/4024 0.221s 0.001s
im_detect: 3763/4024 0.221s 0.001s
im_detect: 3764/4024 0.221s 0.001s
im_detect: 3765/4024 0.221s 0.001s
im_detect: 3766/4024 0.221s 0.001s
im_detect: 3767/4024 0.221s 0.001s
im_detect: 3768/4024 0.221s 0.001s
im_detect: 3769/4024 0.221s 0.001s
im_detect: 3770/4024 0.221s 0.001s
im_detect: 3771/4024 0.221s 0.001s
im_detect: 3772/4024 0.221s 0.001s
im_detect: 3773/4024 0.221s 0.001s
im_detect: 3774/4024 0.221s 0.001s
im_detect: 3775/4024 0.222s 0.001s
im_detect: 3776/4024 0.222s 0.001s
im_detect: 3777/4024 0.222s 0.001s
im_detect: 3778/4024 0.222s 0.001s
im_detect: 3779/4024 0.221s 0.001s
im_detect: 3780/4024 0.221s 0.001s
im_detect: 3781/4024 0.221s 0.001s
im_detect: 3782/4024 0.221s 0.001s
im_detect: 3783/4024 0.221s 0.001s
im_detect: 3784/4024 0.221s 0.001s
im_detect: 3785/4024 0.221s 0.001s
im_detect: 3786/4024 0.221s 0.001s
im_detect: 3787/4024 0.221s 0.001s
im_detect: 3788/4024 0.221s 0.001s
im_detect: 3789/4024 0.221s 0.001s
im_detect: 3790/4024 0.221s 0.001s
im_detect: 3791/4024 0.221s 0.001s
im_detect: 3792/4024 0.221s 0.001s
im_detect: 3793/4024 0.221s 0.001s
im_detect: 3794/4024 0.221s 0.001s
im_detect: 3795/4024 0.221s 0.001s
im_detect: 3796/4024 0.221s 0.001s
im_detect: 3797/4024 0.221s 0.001s
im_detect: 3798/4024 0.221s 0.001s
im_detect: 3799/4024 0.221s 0.001s
im_detect: 3800/4024 0.221s 0.001s
im_detect: 3801/4024 0.221s 0.001s
im_detect: 3802/4024 0.221s 0.001s
im_detect: 3803/4024 0.221s 0.001s
im_detect: 3804/4024 0.221s 0.001s
im_detect: 3805/4024 0.221s 0.001s
im_detect: 3806/4024 0.221s 0.001s
im_detect: 3807/4024 0.221s 0.001s
im_detect: 3808/4024 0.221s 0.001s
im_detect: 3809/4024 0.221s 0.001s
im_detect: 3810/4024 0.221s 0.001s
im_detect: 3811/4024 0.221s 0.001s
im_detect: 3812/4024 0.221s 0.001s
im_detect: 3813/4024 0.221s 0.001s
im_detect: 3814/4024 0.221s 0.001s
im_detect: 3815/4024 0.221s 0.001s
im_detect: 3816/4024 0.222s 0.001s
im_detect: 3817/4024 0.222s 0.001s
im_detect: 3818/4024 0.222s 0.001s
im_detect: 3819/4024 0.222s 0.001s
im_detect: 3820/4024 0.222s 0.001s
im_detect: 3821/4024 0.222s 0.001s
im_detect: 3822/4024 0.222s 0.001s
im_detect: 3823/4024 0.222s 0.001s
im_detect: 3824/4024 0.222s 0.001s
im_detect: 3825/4024 0.222s 0.001s
im_detect: 3826/4024 0.222s 0.001s
im_detect: 3827/4024 0.222s 0.001s
im_detect: 3828/4024 0.222s 0.001s
im_detect: 3829/4024 0.222s 0.001s
im_detect: 3830/4024 0.222s 0.001s
im_detect: 3831/4024 0.222s 0.001s
im_detect: 3832/4024 0.222s 0.001s
im_detect: 3833/4024 0.222s 0.001s
im_detect: 3834/4024 0.222s 0.001s
im_detect: 3835/4024 0.222s 0.001s
im_detect: 3836/4024 0.222s 0.001s
im_detect: 3837/4024 0.222s 0.001s
im_detect: 3838/4024 0.222s 0.001s
im_detect: 3839/4024 0.222s 0.001s
im_detect: 3840/4024 0.222s 0.001s
im_detect: 3841/4024 0.222s 0.001s
im_detect: 3842/4024 0.222s 0.001s
im_detect: 3843/4024 0.222s 0.001s
im_detect: 3844/4024 0.222s 0.001s
im_detect: 3845/4024 0.222s 0.001s
im_detect: 3846/4024 0.222s 0.001s
im_detect: 3847/4024 0.222s 0.001s
im_detect: 3848/4024 0.222s 0.001s
im_detect: 3849/4024 0.222s 0.001s
im_detect: 3850/4024 0.222s 0.001s
im_detect: 3851/4024 0.222s 0.001s
im_detect: 3852/4024 0.222s 0.001s
im_detect: 3853/4024 0.222s 0.001s
im_detect: 3854/4024 0.222s 0.001s
im_detect: 3855/4024 0.222s 0.001s
im_detect: 3856/4024 0.222s 0.001s
im_detect: 3857/4024 0.222s 0.001s
im_detect: 3858/4024 0.222s 0.001s
im_detect: 3859/4024 0.222s 0.001s
im_detect: 3860/4024 0.222s 0.001s
im_detect: 3861/4024 0.222s 0.001s
im_detect: 3862/4024 0.222s 0.001s
im_detect: 3863/4024 0.222s 0.001s
im_detect: 3864/4024 0.222s 0.001s
im_detect: 3865/4024 0.222s 0.001s
im_detect: 3866/4024 0.222s 0.001s
im_detect: 3867/4024 0.222s 0.001s
im_detect: 3868/4024 0.222s 0.001s
im_detect: 3869/4024 0.222s 0.001s
im_detect: 3870/4024 0.222s 0.001s
im_detect: 3871/4024 0.222s 0.001s
im_detect: 3872/4024 0.222s 0.001s
im_detect: 3873/4024 0.222s 0.001s
im_detect: 3874/4024 0.222s 0.001s
im_detect: 3875/4024 0.222s 0.001s
im_detect: 3876/4024 0.222s 0.001s
im_detect: 3877/4024 0.222s 0.001s
im_detect: 3878/4024 0.222s 0.001s
im_detect: 3879/4024 0.222s 0.001s
im_detect: 3880/4024 0.222s 0.001s
im_detect: 3881/4024 0.222s 0.001s
im_detect: 3882/4024 0.222s 0.001s
im_detect: 3883/4024 0.222s 0.001s
im_detect: 3884/4024 0.222s 0.001s
im_detect: 3885/4024 0.222s 0.001s
im_detect: 3886/4024 0.222s 0.001s
im_detect: 3887/4024 0.222s 0.001s
im_detect: 3888/4024 0.222s 0.001s
im_detect: 3889/4024 0.222s 0.001s
im_detect: 3890/4024 0.222s 0.001s
im_detect: 3891/4024 0.222s 0.001s
im_detect: 3892/4024 0.222s 0.001s
im_detect: 3893/4024 0.222s 0.001s
im_detect: 3894/4024 0.222s 0.001s
im_detect: 3895/4024 0.222s 0.001s
im_detect: 3896/4024 0.222s 0.001s
im_detect: 3897/4024 0.222s 0.001s
im_detect: 3898/4024 0.222s 0.001s
im_detect: 3899/4024 0.222s 0.001s
im_detect: 3900/4024 0.222s 0.001s
im_detect: 3901/4024 0.222s 0.001s
im_detect: 3902/4024 0.222s 0.001s
im_detect: 3903/4024 0.222s 0.001s
im_detect: 3904/4024 0.222s 0.001s
im_detect: 3905/4024 0.222s 0.001s
im_detect: 3906/4024 0.222s 0.001s
im_detect: 3907/4024 0.222s 0.001s
im_detect: 3908/4024 0.222s 0.001s
im_detect: 3909/4024 0.222s 0.001s
im_detect: 3910/4024 0.222s 0.001s
im_detect: 3911/4024 0.222s 0.001s
im_detect: 3912/4024 0.222s 0.001s
im_detect: 3913/4024 0.222s 0.001s
im_detect: 3914/4024 0.222s 0.001s
im_detect: 3915/4024 0.222s 0.001s
im_detect: 3916/4024 0.222s 0.001s
im_detect: 3917/4024 0.222s 0.001s
im_detect: 3918/4024 0.222s 0.001s
im_detect: 3919/4024 0.222s 0.001s
im_detect: 3920/4024 0.222s 0.001s
im_detect: 3921/4024 0.222s 0.001s
im_detect: 3922/4024 0.222s 0.001s
im_detect: 3923/4024 0.222s 0.001s
im_detect: 3924/4024 0.222s 0.001s
im_detect: 3925/4024 0.222s 0.001s
im_detect: 3926/4024 0.222s 0.001s
im_detect: 3927/4024 0.222s 0.001s
im_detect: 3928/4024 0.222s 0.001s
im_detect: 3929/4024 0.222s 0.001s
im_detect: 3930/4024 0.222s 0.001s
im_detect: 3931/4024 0.222s 0.001s
im_detect: 3932/4024 0.222s 0.001s
im_detect: 3933/4024 0.222s 0.001s
im_detect: 3934/4024 0.222s 0.001s
im_detect: 3935/4024 0.222s 0.001s
im_detect: 3936/4024 0.222s 0.001s
im_detect: 3937/4024 0.222s 0.001s
im_detect: 3938/4024 0.222s 0.001s
im_detect: 3939/4024 0.222s 0.001s
im_detect: 3940/4024 0.222s 0.001s
im_detect: 3941/4024 0.222s 0.001s
im_detect: 3942/4024 0.222s 0.001s
im_detect: 3943/4024 0.222s 0.001s
im_detect: 3944/4024 0.222s 0.001s
im_detect: 3945/4024 0.222s 0.001s
im_detect: 3946/4024 0.222s 0.001s
im_detect: 3947/4024 0.222s 0.001s
im_detect: 3948/4024 0.222s 0.001s
im_detect: 3949/4024 0.222s 0.001s
im_detect: 3950/4024 0.222s 0.001s
im_detect: 3951/4024 0.222s 0.001s
im_detect: 3952/4024 0.222s 0.001s
im_detect: 3953/4024 0.222s 0.001s
im_detect: 3954/4024 0.222s 0.001s
im_detect: 3955/4024 0.222s 0.001s
im_detect: 3956/4024 0.222s 0.001s
im_detect: 3957/4024 0.222s 0.001s
im_detect: 3958/4024 0.222s 0.001s
im_detect: 3959/4024 0.222s 0.001s
im_detect: 3960/4024 0.222s 0.001s
im_detect: 3961/4024 0.222s 0.001s
im_detect: 3962/4024 0.222s 0.001s
im_detect: 3963/4024 0.222s 0.001s
im_detect: 3964/4024 0.222s 0.001s
im_detect: 3965/4024 0.222s 0.001s
im_detect: 3966/4024 0.222s 0.001s
im_detect: 3967/4024 0.222s 0.001s
im_detect: 3968/4024 0.222s 0.001s
im_detect: 3969/4024 0.222s 0.001s
im_detect: 3970/4024 0.222s 0.001s
im_detect: 3971/4024 0.222s 0.001s
im_detect: 3972/4024 0.222s 0.001s
im_detect: 3973/4024 0.222s 0.001s
im_detect: 3974/4024 0.222s 0.001s
im_detect: 3975/4024 0.222s 0.001s
im_detect: 3976/4024 0.222s 0.001s
im_detect: 3977/4024 0.222s 0.001s
im_detect: 3978/4024 0.222s 0.001s
im_detect: 3979/4024 0.222s 0.001s
im_detect: 3980/4024 0.222s 0.001s
im_detect: 3981/4024 0.222s 0.001s
im_detect: 3982/4024 0.222s 0.001s
im_detect: 3983/4024 0.222s 0.001s
im_detect: 3984/4024 0.222s 0.001s
im_detect: 3985/4024 0.222s 0.001s
im_detect: 3986/4024 0.222s 0.001s
im_detect: 3987/4024 0.222s 0.001s
im_detect: 3988/4024 0.222s 0.001s
im_detect: 3989/4024 0.222s 0.001s
im_detect: 3990/4024 0.222s 0.001s
im_detect: 3991/4024 0.222s 0.001s
im_detect: 3992/4024 0.222s 0.001s
im_detect: 3993/4024 0.222s 0.001s
im_detect: 3994/4024 0.222s 0.001s
im_detect: 3995/4024 0.222s 0.001s
im_detect: 3996/4024 0.222s 0.001s
im_detect: 3997/4024 0.222s 0.001s
im_detect: 3998/4024 0.222s 0.001s
im_detect: 3999/4024 0.222s 0.001s
im_detect: 4000/4024 0.222s 0.001s
im_detect: 4001/4024 0.222s 0.001s
im_detect: 4002/4024 0.222s 0.001s
im_detect: 4003/4024 0.222s 0.001s
im_detect: 4004/4024 0.222s 0.001s
im_detect: 4005/4024 0.222s 0.001s
im_detect: 4006/4024 0.222s 0.001s
im_detect: 4007/4024 0.222s 0.001s
im_detect: 4008/4024 0.222s 0.001s
im_detect: 4009/4024 0.222s 0.001s
im_detect: 4010/4024 0.222s 0.001s
im_detect: 4011/4024 0.222s 0.001s
im_detect: 4012/4024 0.222s 0.001s
im_detect: 4013/4024 0.222s 0.001s
im_detect: 4014/4024 0.222s 0.001s
im_detect: 4015/4024 0.222s 0.001s
im_detect: 4016/4024 0.222s 0.001s
im_detect: 4017/4024 0.222s 0.001s
im_detect: 4018/4024 0.222s 0.001s
im_detect: 4019/4024 0.222s 0.001s
im_detect: 4020/4024 0.222s 0.001s
im_detect: 4021/4024 0.222s 0.001s
im_detect: 4022/4024 0.222s 0.001s
im_detect: 4023/4024 0.222s 0.001s
im_detect: 4024/4024 0.222s 0.001s
Evaluating detections
Writing person VOC results file
VOC07 metric? Yes
[      0.       0.       0. ... 1265735. 1265736. 1265737.] [1.000e+00 2.000e+00 3.000e+00 ... 1.901e+03 1.901e+03 1.901e+03] 0.0
/home/neuiva1/sol/10_12/py-R-FCN/tools/../lib/datasets/voc_eval.py:197: RuntimeWarning: divide by zero encountered in divide
  rec = tp / float(npos)
AP for person = 1.0000
Mean AP = 1.0000
~~~~~~~~
Results:
1.000
1.000
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	15m53.949s
user	15m17.672s
sys	1m30.816s
